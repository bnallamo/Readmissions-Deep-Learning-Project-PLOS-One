{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.5.4 |Anaconda, Inc.| (default, Oct 15 2017, 03:43:24) [MSC v.1900 64 bit (AMD64)]\n",
      "Numpy version: 1.14.5\n",
      "Pandas version: 0.21.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "\n",
    "print('Python version: '+sys.version)\n",
    "print('Numpy version: '+np.__version__)\n",
    "print('Pandas version: '+pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os, sys, time\n",
    "from importlib import reload\n",
    "path=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample shape: (18463, 49)\n",
      "test sample shape: (19214, 49)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('sample_train.csv')\n",
    "df_train.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "print('train sample shape: '+str(df_train.shape))\n",
    "df_test = pd.read_csv('sample_test.csv')\n",
    "df_test.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "print('test sample shape: '+str(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wsliu\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Concatenate, Reshape, BatchNormalization, LSTM, CuDNNLSTM, CuDNNGRU, Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_DX = 29\n",
    "n_PR = 15\n",
    "DXs = ['DX'+str(n) for n in range(2,n_DX+2)]\n",
    "PRs = ['PR'+str(n) for n in range(1,n_PR+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "df_train['y'] = 0\n",
    "df_train.loc[df_train['readm30']==True, 'y'] = 1\n",
    "df_test['y'] = 0\n",
    "df_test.loc[df_test['readm30']==True, 'y'] = 1\n",
    "\n",
    "X_cols = ['DX1', 'DX2', 'DX3', 'DX4', 'DX5', 'DX6', 'DX7', 'DX8', 'DX9', 'DX10',\n",
    "          'DX11', 'DX12', 'DX13', 'DX14', 'DX15', 'DX16', 'DX17', 'DX18', 'DX19',\n",
    "          'DX20', 'DX21', 'DX22', 'DX23', 'DX24', 'DX25', 'DX26', 'DX27', 'DX28',\n",
    "          'DX29', 'DX30', 'PR1', 'PR2', 'PR3', 'PR4', 'PR5', 'PR6', 'PR7', 'PR8',\n",
    "          'PR9', 'PR10', 'PR11', 'PR12', 'PR13', 'PR14', 'PR15', 'AGE', 'FEMALE', 'HOSP_NRD']\n",
    "\n",
    "X_train = df_train[X_cols].values.astype(np.int)\n",
    "Y_train = df_train[['y']].values.astype(np.int)\n",
    "X_test = df_test[X_cols].values.astype(np.int)\n",
    "Y_test = df_test[['y']].values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from setsum_layer import SetSum, MaskedSum, MaskedDense, MaskedPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_embed_dim = 300\n",
    "md_width = 5\n",
    "fc_width = 512\n",
    "hosp_embed_dim = 1\n",
    "dropout = 0.3\n",
    "job_index = 0\n",
    "batchsize = 28\n",
    "n_fold = 5\n",
    "n_samples=100\n",
    "n_disease=2135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_mat=np.random.uniform(0,1,size=[2135,code_embed_dim])\n",
    "embed_initializer = Constant(np.random.uniform(0,1,size=[2135,code_embed_dim]))\n",
    "skf = StratifiedKFold(n_splits=n_fold, random_state=24, shuffle=True)\n",
    "trn_idx, val_idx = next(skf.split(X_train,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=df_train\n",
    "DX1_array_train = train_df['DX1'].values\n",
    "            \n",
    "DX1_array_trn = DX1_array_train[trn_idx]\n",
    "DX1_array_val = DX1_array_train[val_idx]\n",
    "\n",
    "DX_mat_train = train_df[DXs].values\n",
    "            \n",
    "DX_mat_trn = DX_mat_train[trn_idx, :]\n",
    "DX_mat_val = DX_mat_train[val_idx, :]\n",
    "\n",
    "PR_mat_train = train_df[PRs].values\n",
    "            \n",
    "PR_mat_trn = PR_mat_train[trn_idx, :]\n",
    "PR_mat_val = PR_mat_train[val_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hosp_array_train = train_df['HOSP_NRD'].values\n",
    "    \n",
    "hosp_array_trn = hosp_array_train[trn_idx]\n",
    "hosp_array_val = hosp_array_train[val_idx]\n",
    "age_mean = train_df['AGE'].mean()\n",
    "age_std = train_df['AGE'].std()\n",
    "demo_mat_train = train_df[['AGE', 'FEMALE']].values\n",
    "demo_mat_train[:, 0] = (demo_mat_train[:, 0]-age_mean)/age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_mat_train = demo_mat_train\n",
    "\n",
    "other_mat_trn = other_mat_train[trn_idx, :]\n",
    "other_mat_val = other_mat_train[val_idx, :]\n",
    "\n",
    "y_train = train_df.readm30.astype(int).values\n",
    "Y_trn = to_categorical(y_train[trn_idx])\n",
    "Y_val = to_categorical(y_train[val_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'setsum_nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numvar=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hosp_cat = set(df_train['HOSP_NRD']).union(set(df_test['HOSP_NRD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "from keras import objectives\n",
    "\n",
    "def zero_loss(y_true, y_pred):\n",
    "    return K.zeros_like(y_pred)\n",
    "\n",
    "\n",
    "class CustomRegularization(Layer):\n",
    "    def __init__(self, num_samples,num_classes, **kwargs):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_classes = num_classes\n",
    "        super(CustomRegularization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        dense_shape, classes_shape = input_shape\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(self.num_classes, dense_shape[1]),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.num_classes,),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True) \n",
    "        super(CustomRegularization, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        inputs_in, labels_in = x\n",
    "        labels = tf.manip.roll(labels_in,shift=1,axis=1)\n",
    "        loss = tf.nn.sampled_softmax_loss(\n",
    "            weights = self.kernel,\n",
    "            biases = self.bias,\n",
    "            labels = labels,\n",
    "            inputs = inputs_in,\n",
    "            num_sampled=self.num_samples,\n",
    "            num_classes=self.num_classes,\n",
    "            num_true=45)\n",
    "        for i in range(2,45):\n",
    "            labels = tf.manip.roll(labels_in,shift=i,axis=1)\n",
    "            loss += tf.nn.sampled_softmax_loss(\n",
    "            weights = self.kernel,\n",
    "            biases = self.bias,\n",
    "            labels = labels,\n",
    "            inputs = inputs_in,\n",
    "            num_sampled=self.num_samples,\n",
    "            num_classes=self.num_classes,\n",
    "            num_true=45)\n",
    "            \n",
    "        cost = tf.reduce_mean(loss)\n",
    "        self.add_loss(cost,x)\n",
    "        #you can output whatever you need, just update output_shape adequately\n",
    "        #But this is probably useful\n",
    "        return cost\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        dense_shape,classes_shape = input_shape\n",
    "        return (dense_shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_DX1 = Input(shape=(1,))\n",
    "DX1_embed0 = Embedding(input_dim=embed_mat.shape[0], output_dim=code_embed_dim, embeddings_initializer=embed_initializer, \n",
    "                      name='DX1_embed')(input_DX1)\n",
    "DX1_embed = Reshape((code_embed_dim,))(DX1_embed0)\n",
    "input_DX = Input(shape = (len(DXs),))\n",
    "DX_embed0 = Embedding(input_dim=embed_mat.shape[0], output_dim=code_embed_dim, mask_zero=False, embeddings_initializer=embed_initializer, \n",
    "                     name='DX_embed')(input_DX)\n",
    "if model_name=='setsum_nn' or 'setsum_lr':\n",
    "    DX_embed = MaskedDense(md_width, activation='relu')(DX_embed0)\n",
    "    DX_embed = MaskedSum()(DX_embed0)\n",
    "elif model_name=='embed_sum':\n",
    "    DX_embed = MaskedSum()(DX_embed0)\n",
    "elif model_name=='embed_pool':\n",
    "    DX_embed = MaskedPooling()(DX_embed0)\n",
    "input_PR = Input(shape = (len(PRs),))\n",
    "PR_embed0 = Embedding(input_dim=embed_mat.shape[0], output_dim=code_embed_dim, mask_zero=False, embeddings_initializer=embed_initializer, \n",
    "                     name='PR_embed')(input_PR)\n",
    "if model_name=='setsum_nn' or 'setsum_lr':\n",
    "    PR_embed = MaskedDense(md_width, activation='relu')(PR_embed0)\n",
    "    PR_embed = MaskedSum()(PR_embed0)\n",
    "elif model_name=='embed_sum':\n",
    "    PR_embed = MaskedSum()(PR_embed0)\n",
    "elif model_name=='embed_pool':\n",
    "    PR_embed = MaskedPooling()(PR_embed0)\n",
    "input_hosp = Input(shape=(1,))\n",
    "hosp_embed = Embedding(input_dim=len(hosp_cat), output_dim=hosp_embed_dim, input_length=1)(input_hosp)\n",
    "hosp_embed = Reshape((hosp_embed_dim, ))(hosp_embed)\n",
    "input_other = Input(shape=(other_mat_train.shape[1], ))\n",
    "merged = Concatenate(axis=1)([DX1_embed, DX_embed, PR_embed, hosp_embed, input_other])\n",
    "merged1 = Concatenate(axis=1)([DX1_embed0, DX_embed0, PR_embed0])\n",
    "merged1 = Reshape((numvar*300,))(merged1)\n",
    "merged2 = Concatenate(axis=1)([input_DX1,input_DX,input_PR])\n",
    "merged2 = Reshape((45,))(merged2)\n",
    "#merged3 = Concatenate(axis=2)([merged1,merged2])\n",
    "cr =  CustomRegularization(n_samples,n_disease)([merged1,merged2])\n",
    "if model_name=='setsum_nn':\n",
    "    merged = Dense(fc_width, activation='relu')(merged)\n",
    "    merged = Dropout(dropout)(merged)\n",
    "prediction = Dense(2, activation='softmax')(merged)\n",
    "model = Model(inputs=[input_DX1, input_DX, input_PR, input_hosp, input_other], outputs=[prediction,cr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    if l.name=='DX_embed' or l.name=='PR_embed':\n",
    "        l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0002)\n",
    "model.compile(optimizer=adam, loss=[K.categorical_crossentropy,zero_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14770 samples, validate on 3693 samples\n",
      "Epoch 1/10\n",
      "  224/14770 [..............................] - ETA: 4:47:04 - loss: 228.1792 - dense_4_loss: 2.0867 - custom_regularization_2_loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4f963c9331c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDX1_array_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDX_mat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPR_mat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhosp_array_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_mat_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit([DX1_array_trn, DX_mat_trn, PR_mat_trn, hosp_array_trn, other_mat_trn], [Y_trn,np.random.randn(Y_trn.shape[0],1)], \n",
    "                     batch_size=batchsize, epochs=10, \n",
    "                     validation_data=[[DX1_array_val, DX_mat_val, PR_mat_val, hosp_array_val, other_mat_val], [Y_val,np.random.randn(Y_val.shape[0],1)]], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
