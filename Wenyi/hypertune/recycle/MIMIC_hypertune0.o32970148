nyx7510
2019-03-08 01:22:02.970500: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:22:03.138961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:22:03.139003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:22:15.507349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:22:15.507407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:22:15.507420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:22:15.507782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 15s - loss: 1.1584
Epoch 2/80
 - 2s - loss: 0.2165
Epoch 3/80
 - 2s - loss: 0.1655
Epoch 4/80
 - 2s - loss: 0.1519
Epoch 5/80
 - 2s - loss: 0.1435
Epoch 6/80
 - 2s - loss: 0.1368
Epoch 7/80
 - 2s - loss: 0.1301
Epoch 8/80
 - 2s - loss: 0.1229
Epoch 9/80
 - 2s - loss: 0.1150
Epoch 10/80
 - 2s - loss: 0.1069
Epoch 11/80
 - 2s - loss: 0.0992
Epoch 12/80
 - 2s - loss: 0.0924
Epoch 13/80
 - 2s - loss: 0.0864
Epoch 14/80
 - 2s - loss: 0.0813
Epoch 15/80
 - 2s - loss: 0.0770
Epoch 16/80
 - 2s - loss: 0.0734
Epoch 17/80
 - 2s - loss: 0.0703
Epoch 18/80
 - 2s - loss: 0.0677
Epoch 19/80
 - 2s - loss: 0.0654
Epoch 20/80
 - 2s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0618
Epoch 22/80
 - 2s - loss: 0.0604
Epoch 23/80
 - 2s - loss: 0.0591
Epoch 24/80
 - 2s - loss: 0.0580
Epoch 25/80
 - 2s - loss: 0.0570
Epoch 26/80
 - 2s - loss: 0.0562
Epoch 27/80
 - 2s - loss: 0.0554
Epoch 28/80
 - 2s - loss: 0.0548
Epoch 29/80
 - 2s - loss: 0.0543
Epoch 30/80
 - 2s - loss: 0.0538
Epoch 31/80
 - 2s - loss: 0.0534
Epoch 32/80
 - 2s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0525
Epoch 35/80
 - 2s - loss: 0.0522
Epoch 36/80
 - 2s - loss: 0.0520
Epoch 37/80
 - 2s - loss: 0.0518
Epoch 38/80
 - 2s - loss: 0.0517
Epoch 39/80
 - 2s - loss: 0.0515
Epoch 40/80
 - 2s - loss: 0.0514
Epoch 41/80
 - 2s - loss: 0.0512
Epoch 42/80
 - 2s - loss: 0.0511
Epoch 43/80
 - 2s - loss: 0.0510
Epoch 44/80
 - 2s - loss: 0.0509
Epoch 45/80
 - 2s - loss: 0.0509
Epoch 46/80
 - 2s - loss: 0.0508
Epoch 47/80
 - 2s - loss: 0.0507
Epoch 48/80
 - 2s - loss: 0.0506
Epoch 49/80
 - 2s - loss: 0.0506
Epoch 50/80
 - 2s - loss: 0.0505
Epoch 51/80
 - 2s - loss: 0.0504
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0503
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0503
Epoch 56/80
 - 2s - loss: 0.0502
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0501
Epoch 59/80
 - 2s - loss: 0.0501
Epoch 60/80
 - 2s - loss: 0.0501
Epoch 61/80
 - 2s - loss: 0.0501
Epoch 62/80
 - 2s - loss: 0.0500
Epoch 63/80
 - 2s - loss: 0.0500
Epoch 64/80
 - 2s - loss: 0.0489
Epoch 65/80
 - 2s - loss: 0.0488
Epoch 66/80
 - 2s - loss: 0.0487
Epoch 67/80
 - 2s - loss: 0.0487
Epoch 68/80
 - 2s - loss: 0.0487
Epoch 69/80
 - 2s - loss: 0.0485
Epoch 70/80
 - 2s - loss: 0.0484
Epoch 71/80
 - 2s - loss: 0.0484
Epoch 72/80
 - 2s - loss: 0.0484
Epoch 73/80
 - 2s - loss: 0.0484
Epoch 74/80
 - 2s - loss: 0.0484
Epoch 75/80
 - 2s - loss: 0.0484
Epoch 76/80
 - 2s - loss: 0.0484
Epoch 77/80
 - 2s - loss: 0.0484
Epoch 78/80
 - 2s - loss: 0.0484
Epoch 79/80
 - 2s - loss: 0.0484
Epoch 80/80
 - 2s - loss: 0.0484
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.8596 - val_loss: 1.3698
AUC: 0.8002

Epoch 2/80
 - 0s - loss: 2.1912 - val_loss: 0.9273
AUC: 0.8337

Epoch 3/80
 - 0s - loss: 1.4918 - val_loss: 0.7384
AUC: 0.8391

Epoch 4/80
 - 0s - loss: 1.2697 - val_loss: 0.7555
AUC: 0.8475

Epoch 5/80
 - 0s - loss: 1.1743 - val_loss: 0.6515
AUC: 0.8505

Epoch 6/80
 - 0s - loss: 1.1368 - val_loss: 0.6977
AUC: 0.8567

Epoch 7/80
 - 0s - loss: 1.1209 - val_loss: 0.6764
AUC: 0.8576

Epoch 8/80
 - 0s - loss: 1.1029 - val_loss: 0.6461
AUC: 0.8625

Epoch 9/80
 - 0s - loss: 1.0884 - val_loss: 0.7121
AUC: 0.8633

Epoch 10/80
 - 0s - loss: 1.0805 - val_loss: 0.6299
AUC: 0.8631

Epoch 11/80
 - 0s - loss: 1.0667 - val_loss: 0.6840
AUC: 0.8655

Epoch 12/80
 - 0s - loss: 1.0629 - val_loss: 0.6724
AUC: 0.8638

Epoch 13/80
 - 0s - loss: 1.0474 - val_loss: 0.6173
AUC: 0.8662

Epoch 14/80
 - 0s - loss: 1.0500 - val_loss: 0.6222
AUC: 0.8680

Epoch 15/80
 - 0s - loss: 1.0386 - val_loss: 0.6506
AUC: 0.8669

Epoch 16/80
 - 0s - loss: 1.0388 - val_loss: 0.6260
AUC: 0.8680

Epoch 17/80
 - 0s - loss: 1.0351 - val_loss: 0.5771
AUC: 0.8667

Epoch 18/80
 - 0s - loss: 1.0280 - val_loss: 0.6474
AUC: 0.8689

Epoch 19/80
 - 0s - loss: 1.0215 - val_loss: 0.6167
AUC: 0.8692

Epoch 20/80
 - 0s - loss: 1.0221 - val_loss: 0.6157
AUC: 0.8687

Epoch 21/80
 - 0s - loss: 1.0186 - val_loss: 0.5953
AUC: 0.8705

Epoch 22/80
 - 0s - loss: 1.0208 - val_loss: 0.6181
AUC: 0.8703

Epoch 23/80
 - 0s - loss: 1.0110 - val_loss: 0.6490
AUC: 0.8718

Epoch 24/80
 - 0s - loss: 1.0093 - val_loss: 0.5757
AUC: 0.8706

Epoch 25/80
 - 0s - loss: 1.0120 - val_loss: 0.5571
AUC: 0.8710

Epoch 26/80
 - 0s - loss: 1.0015 - val_loss: 0.6254
AUC: 0.8725

Epoch 27/80
 - 0s - loss: 1.0045 - val_loss: 0.5927
AUC: 0.8720

Epoch 28/80
 - 0s - loss: 0.9986 - val_loss: 0.5766
AUC: 0.8731

Epoch 29/80
 - 0s - loss: 0.9998 - val_loss: 0.6059
AUC: 0.8733

Epoch 30/80
 - 0s - loss: 0.9943 - val_loss: 0.5804
AUC: 0.8731

Epoch 31/80
 - 0s - loss: 0.9940 - val_loss: 0.6501
AUC: 0.8744

Epoch 32/80
 - 0s - loss: 0.9931 - val_loss: 0.5712
AUC: 0.8718

Epoch 33/80
 - 0s - loss: 0.9875 - val_loss: 0.6303
AUC: 0.8729

Epoch 34/80
 - 0s - loss: 0.9883 - val_loss: 0.6545
AUC: 0.8731

Epoch 35/80
 - 0s - loss: 0.9888 - val_loss: 0.6392
AUC: 0.8732

Epoch 36/80
 - 0s - loss: 0.9765 - val_loss: 0.5818
AUC: 0.8741

Epoch 37/80
 - 0s - loss: 0.9770 - val_loss: 0.5849
AUC: 0.8743

Epoch 38/80
 - 0s - loss: 0.9736 - val_loss: 0.5939
AUC: 0.8742

Epoch 39/80
 - 0s - loss: 0.9778 - val_loss: 0.6051
AUC: 0.8744

Epoch 40/80
 - 0s - loss: 0.9693 - val_loss: 0.6053
AUC: 0.8742

Epoch 41/80
 - 0s - loss: 0.9671 - val_loss: 0.5976
AUC: 0.8736

Epoch 42/80
 - 0s - loss: 0.9689 - val_loss: 0.5836
AUC: 0.8745

Epoch 43/80
 - 0s - loss: 0.9712 - val_loss: 0.5757
AUC: 0.8742

Epoch 44/80
 - 0s - loss: 0.9671 - val_loss: 0.6127
AUC: 0.8747

Epoch 45/80
 - 0s - loss: 0.9681 - val_loss: 0.5768
AUC: 0.8743

Epoch 46/80
 - 0s - loss: 0.9697 - val_loss: 0.6047
AUC: 0.8745

Epoch 47/80
 - 0s - loss: 0.9690 - val_loss: 0.5883
AUC: 0.8744

Epoch 48/80
 - 0s - loss: 0.9682 - val_loss: 0.5969
AUC: 0.8744

Epoch 49/80
 - 0s - loss: 0.9652 - val_loss: 0.5887
AUC: 0.8743

Epoch 50/80
 - 0s - loss: 0.9681 - val_loss: 0.5930
AUC: 0.8743

Epoch 51/80
 - 0s - loss: 0.9683 - val_loss: 0.5988
AUC: 0.8745

Epoch 52/80
 - 0s - loss: 0.9649 - val_loss: 0.5991
AUC: 0.8746

Epoch 53/80
 - 0s - loss: 0.9682 - val_loss: 0.5959
AUC: 0.8746

Epoch 54/80
 - 0s - loss: 0.9655 - val_loss: 0.5999
AUC: 0.8745

Epoch 55/80
 - 0s - loss: 0.9633 - val_loss: 0.5944
AUC: 0.8745

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9675 - val_loss: 0.5776
AUC: 0.8742

Epoch 2/30
 - 0s - loss: 0.9671 - val_loss: 0.6111
AUC: 0.8744

Epoch 3/30
 - 0s - loss: 0.9686 - val_loss: 0.6002
AUC: 0.8747

Epoch 4/30
 - 0s - loss: 0.9612 - val_loss: 0.5722
AUC: 0.8744

Epoch 5/30
 - 0s - loss: 0.9629 - val_loss: 0.5646
AUC: 0.8746

Epoch 6/30
 - 0s - loss: 0.9673 - val_loss: 0.5871
AUC: 0.8748

Epoch 7/30
 - 0s - loss: 0.9592 - val_loss: 0.6268
AUC: 0.8752

Epoch 8/30
 - 0s - loss: 0.9597 - val_loss: 0.5861
AUC: 0.8750

Epoch 9/30
 - 0s - loss: 0.9580 - val_loss: 0.5888
AUC: 0.8749

Epoch 10/30
 - 0s - loss: 0.9661 - val_loss: 0.6067
AUC: 0.8752

Epoch 11/30
 - 0s - loss: 0.9584 - val_loss: 0.5978
AUC: 0.8751

Epoch 12/30
 - 0s - loss: 0.9536 - val_loss: 0.5822
AUC: 0.8750

Epoch 13/30
 - 0s - loss: 0.9516 - val_loss: 0.6047
AUC: 0.8752

Epoch 14/30
 - 0s - loss: 0.9485 - val_loss: 0.5917
AUC: 0.8754

Epoch 15/30
 - 0s - loss: 0.9502 - val_loss: 0.5965
AUC: 0.8755

Epoch 16/30
 - 0s - loss: 0.9523 - val_loss: 0.5922
AUC: 0.8754

Epoch 17/30
 - 0s - loss: 0.9489 - val_loss: 0.5899
AUC: 0.8754

Epoch 18/30
 - 0s - loss: 0.9437 - val_loss: 0.5916
AUC: 0.8754

Epoch 19/30
 - 0s - loss: 0.9498 - val_loss: 0.5945
AUC: 0.8754

Epoch 20/30
 - 0s - loss: 0.9521 - val_loss: 0.5896
AUC: 0.8753

Epoch 21/30
 - 0s - loss: 0.9464 - val_loss: 0.5909
AUC: 0.8753

Epoch 22/30
 - 0s - loss: 0.9448 - val_loss: 0.5915
AUC: 0.8753

Epoch 23/30
 - 0s - loss: 0.9509 - val_loss: 0.5865
AUC: 0.8752

Epoch 24/30
 - 0s - loss: 0.9481 - val_loss: 0.5903
AUC: 0.8753

Epoch 25/30
 - 0s - loss: 0.9417 - val_loss: 0.5914
AUC: 0.8753

Epoch 26/30
 - 0s - loss: 0.9473 - val_loss: 0.5904
AUC: 0.8753

Epoch 27/30
 - 0s - loss: 0.9452 - val_loss: 0.5905
AUC: 0.8753

Epoch 28/30
 - 0s - loss: 0.9466 - val_loss: 0.5900
AUC: 0.8753

Epoch 29/30
 - 0s - loss: 0.9475 - val_loss: 0.5899
AUC: 0.8753

Epoch 30/30
 - 0s - loss: 0.9475 - val_loss: 0.5899
Using TensorFlow backend.
AUC: 0.8753

2019-03-08 01:25:38.142960: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:25:38.320589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:25:38.320632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:25:38.612182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:25:38.612227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:25:38.612236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:25:38.612493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1526
Epoch 2/80
 - 2s - loss: 0.2173
Epoch 3/80
 - 2s - loss: 0.1735
Epoch 4/80
 - 2s - loss: 0.1660
Epoch 5/80
 - 2s - loss: 0.1596
Epoch 6/80
 - 2s - loss: 0.1515
Epoch 7/80
 - 2s - loss: 0.1410
Epoch 8/80
 - 2s - loss: 0.1285
Epoch 9/80
 - 2s - loss: 0.1165
Epoch 10/80
 - 2s - loss: 0.1069
Epoch 11/80
 - 2s - loss: 0.0993
Epoch 12/80
 - 2s - loss: 0.0928
Epoch 13/80
 - 2s - loss: 0.0871
Epoch 14/80
 - 2s - loss: 0.0822
Epoch 15/80
 - 2s - loss: 0.0778
Epoch 16/80
 - 2s - loss: 0.0741
Epoch 17/80
 - 2s - loss: 0.0709
Epoch 18/80
 - 2s - loss: 0.0680
Epoch 19/80
 - 2s - loss: 0.0656
Epoch 20/80
 - 2s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0617
Epoch 22/80
 - 2s - loss: 0.0603
Epoch 23/80
 - 2s - loss: 0.0590
Epoch 24/80
 - 2s - loss: 0.0579
Epoch 25/80
 - 2s - loss: 0.0570
Epoch 26/80
 - 2s - loss: 0.0562
Epoch 27/80
 - 2s - loss: 0.0555
Epoch 28/80
 - 2s - loss: 0.0549
Epoch 29/80
 - 2s - loss: 0.0544
Epoch 30/80
 - 2s - loss: 0.0540
Epoch 31/80
 - 2s - loss: 0.0536
Epoch 32/80
 - 2s - loss: 0.0532
Epoch 33/80
 - 2s - loss: 0.0529
Epoch 34/80
 - 2s - loss: 0.0526
Epoch 35/80
 - 2s - loss: 0.0524
Epoch 36/80
 - 2s - loss: 0.0522
Epoch 37/80
 - 2s - loss: 0.0520
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0517
Epoch 40/80
 - 2s - loss: 0.0516
Epoch 41/80
 - 2s - loss: 0.0514
Epoch 42/80
 - 2s - loss: 0.0513
Epoch 43/80
 - 2s - loss: 0.0512
Epoch 44/80
 - 2s - loss: 0.0511
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0509
Epoch 47/80
 - 2s - loss: 0.0509
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0507
Epoch 50/80
 - 2s - loss: 0.0507
Epoch 51/80
 - 2s - loss: 0.0506
Epoch 52/80
 - 2s - loss: 0.0506
Epoch 53/80
 - 2s - loss: 0.0505
Epoch 54/80
 - 2s - loss: 0.0505
Epoch 55/80
 - 2s - loss: 0.0504
Epoch 56/80
 - 2s - loss: 0.0504
Epoch 57/80
 - 2s - loss: 0.0503
Epoch 58/80
 - 2s - loss: 0.0503
Epoch 59/80
 - 2s - loss: 0.0503
Epoch 60/80
 - 2s - loss: 0.0502
Epoch 61/80
 - 2s - loss: 0.0502
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b0b37d566a0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 01:27:38.256999: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:27:38.419737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:27:38.419779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:27:38.708695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:27:38.708763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:27:38.708773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:27:38.709043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1415
Epoch 2/80
 - 2s - loss: 0.2164
Epoch 3/80
 - 2s - loss: 0.1668
Epoch 4/80
 - 2s - loss: 0.1522
Epoch 5/80
 - 2s - loss: 0.1430
Epoch 6/80
 - 2s - loss: 0.1358
Epoch 7/80
 - 2s - loss: 0.1291
Epoch 8/80
 - 2s - loss: 0.1225
Epoch 9/80
 - 2s - loss: 0.1161
Epoch 10/80
 - 2s - loss: 0.1100
Epoch 11/80
 - 2s - loss: 0.1036
Epoch 12/80
 - 2s - loss: 0.0971
Epoch 13/80
 - 2s - loss: 0.0907
Epoch 14/80
 - 2s - loss: 0.0849
Epoch 15/80
 - 2s - loss: 0.0800
Epoch 16/80
 - 2s - loss: 0.0758
Epoch 17/80
 - 2s - loss: 0.0722
Epoch 18/80
 - 2s - loss: 0.0692
Epoch 19/80
 - 2s - loss: 0.0666
Epoch 20/80
 - 2s - loss: 0.0643
Epoch 21/80
 - 2s - loss: 0.0624
Epoch 22/80
 - 2s - loss: 0.0607
Epoch 23/80
 - 2s - loss: 0.0593
Epoch 24/80
 - 2s - loss: 0.0580
Epoch 25/80
 - 2s - loss: 0.0570
Epoch 26/80
 - 2s - loss: 0.0561
Epoch 27/80
 - 2s - loss: 0.0554
Epoch 28/80
 - 2s - loss: 0.0547
Epoch 29/80
 - 2s - loss: 0.0542
Epoch 30/80
 - 2s - loss: 0.0537
Epoch 31/80
 - 2s - loss: 0.0533
Epoch 32/80
 - 2s - loss: 0.0530
Epoch 33/80
 - 2s - loss: 0.0527
Epoch 34/80
 - 2s - loss: 0.0524
Epoch 35/80
 - 2s - loss: 0.0522
Epoch 36/80
 - 2s - loss: 0.0520
Epoch 37/80
 - 2s - loss: 0.0518
Epoch 38/80
 - 2s - loss: 0.0516
Epoch 39/80
 - 2s - loss: 0.0515
Epoch 40/80
 - 2s - loss: 0.0513
Epoch 41/80
 - 2s - loss: 0.0512
Epoch 42/80
 - 2s - loss: 0.0511
Epoch 43/80
 - 2s - loss: 0.0510
Epoch 44/80
 - 2s - loss: 0.0509
Epoch 45/80
 - 2s - loss: 0.0508
Epoch 46/80
 - 2s - loss: 0.0508
Epoch 47/80
 - 2s - loss: 0.0507
Epoch 48/80
 - 2s - loss: 0.0506
Epoch 49/80
 - 2s - loss: 0.0506
Epoch 50/80
 - 2s - loss: 0.0505
Epoch 51/80
 - 2s - loss: 0.0504
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0503
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0503
Epoch 56/80
 - 2s - loss: 0.0502
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0501
Epoch 59/80
 - 2s - loss: 0.0501
Epoch 60/80
 - 2s - loss: 0.0501
Epoch 61/80
 - 2s - loss: 0.0490
Epoch 62/80
 - 2s - loss: 0.0489
Epoch 63/80
 - 2s - loss: 0.0488
Epoch 64/80
 - 2s - loss: 0.0488
Epoch 65/80
 - 2s - loss: 0.0488
Epoch 66/80
 - 2s - loss: 0.0485
Epoch 67/80
 - 2s - loss: 0.0485
Epoch 68/80
 - 2s - loss: 0.0485
Epoch 69/80
 - 2s - loss: 0.0485
Epoch 70/80
 - 2s - loss: 0.0485
Epoch 71/80
 - 2s - loss: 0.0485
Epoch 72/80
 - 2s - loss: 0.0485
Epoch 73/80
 - 2s - loss: 0.0485
Epoch 74/80
 - 2s - loss: 0.0485
Epoch 75/80
 - 2s - loss: 0.0485
Epoch 76/80
 - 2s - loss: 0.0485
Epoch 77/80
 - 1s - loss: 0.0485
Epoch 78/80
 - 1s - loss: 0.0485
Epoch 79/80
 - 1s - loss: 0.0485
Epoch 80/80
 - 1s - loss: 0.0485
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.0434 - val_loss: 1.6597
AUC: 0.7996

Epoch 2/80
 - 0s - loss: 2.3572 - val_loss: 1.2342
AUC: 0.8248

Epoch 3/80
 - 0s - loss: 1.6095 - val_loss: 0.7034
AUC: 0.8340

Epoch 4/80
 - 0s - loss: 1.3051 - val_loss: 0.7555
AUC: 0.8458

Epoch 5/80
 - 0s - loss: 1.2098 - val_loss: 0.7480
AUC: 0.8505

Epoch 6/80
 - 0s - loss: 1.1466 - val_loss: 0.6607
AUC: 0.8529

Epoch 7/80
 - 0s - loss: 1.1164 - val_loss: 0.6121
AUC: 0.8544

Epoch 8/80
 - 0s - loss: 1.0982 - val_loss: 0.7201
AUC: 0.8574

Epoch 9/80
 - 0s - loss: 1.0889 - val_loss: 0.5892
AUC: 0.8551

Epoch 10/80
 - 0s - loss: 1.0746 - val_loss: 0.6724
AUC: 0.8598

Epoch 11/80
 - 0s - loss: 1.0684 - val_loss: 0.6709
AUC: 0.8579

Epoch 12/80
 - 0s - loss: 1.0524 - val_loss: 0.6422
AUC: 0.8602

Epoch 13/80
 - 0s - loss: 1.0500 - val_loss: 0.5870
AUC: 0.8592

Epoch 14/80
 - 0s - loss: 1.0378 - val_loss: 0.6773
AUC: 0.8629

Epoch 15/80
 - 0s - loss: 1.0426 - val_loss: 0.7241
AUC: 0.8619

Epoch 16/80
 - 0s - loss: 1.0289 - val_loss: 0.6301
AUC: 0.8628

Epoch 17/80
 - 0s - loss: 1.0329 - val_loss: 0.6475
AUC: 0.8639

Epoch 18/80
 - 0s - loss: 1.0239 - val_loss: 0.6360
AUC: 0.8635

Epoch 19/80
 - 0s - loss: 1.0193 - val_loss: 0.6281
AUC: 0.8638

Epoch 20/80
 - 0s - loss: 1.0108 - val_loss: 0.5859
AUC: 0.8637

Epoch 21/80
 - 0s - loss: 1.0073 - val_loss: 0.6019
AUC: 0.8643

Epoch 22/80
 - 0s - loss: 1.0136 - val_loss: 0.5712
AUC: 0.8638

Epoch 23/80
 - 0s - loss: 0.9985 - val_loss: 0.6033
AUC: 0.8637

Epoch 24/80
 - 0s - loss: 1.0000 - val_loss: 0.6146
AUC: 0.8654

Epoch 25/80
 - 0s - loss: 1.0036 - val_loss: 0.6062
AUC: 0.8650

Epoch 26/80
 - 0s - loss: 0.9922 - val_loss: 0.6535
AUC: 0.8641

Epoch 27/80
 - 0s - loss: 0.9935 - val_loss: 0.6300
AUC: 0.8664

Epoch 28/80
 - 0s - loss: 0.9868 - val_loss: 0.5892
AUC: 0.8661

Epoch 29/80
 - 0s - loss: 0.9856 - val_loss: 0.5930
AUC: 0.8667

Epoch 30/80
 - 0s - loss: 0.9886 - val_loss: 0.6103
AUC: 0.8664

Epoch 31/80
 - 0s - loss: 0.9850 - val_loss: 0.6495
AUC: 0.8669

Epoch 32/80
 - 0s - loss: 0.9830 - val_loss: 0.6180
AUC: 0.8658

Epoch 33/80
 - 0s - loss: 0.9708 - val_loss: 0.6086
AUC: 0.8667

Epoch 34/80
 - 0s - loss: 0.9664 - val_loss: 0.6000
AUC: 0.8674

Epoch 35/80
 - 0s - loss: 0.9694 - val_loss: 0.5978
AUC: 0.8671

Epoch 36/80
 - 0s - loss: 0.9638 - val_loss: 0.6006
AUC: 0.8670

Epoch 37/80
 - 0s - loss: 0.9723 - val_loss: 0.6148
AUC: 0.8673

Epoch 38/80
 - 0s - loss: 0.9644 - val_loss: 0.6027
AUC: 0.8671

Epoch 39/80
 - 0s - loss: 0.9643 - val_loss: 0.6298
AUC: 0.8675

Epoch 40/80
 - 0s - loss: 0.9730 - val_loss: 0.6205
AUC: 0.8676

Epoch 41/80
 - 0s - loss: 0.9622 - val_loss: 0.6070
AUC: 0.8672

Epoch 42/80
 - 0s - loss: 0.9638 - val_loss: 0.6010
AUC: 0.8674

Epoch 43/80
 - 0s - loss: 0.9624 - val_loss: 0.6034
AUC: 0.8674

Epoch 44/80
 - 0s - loss: 0.9616 - val_loss: 0.5992
AUC: 0.8674

Epoch 45/80
 - 0s - loss: 0.9649 - val_loss: 0.6012
AUC: 0.8674

Epoch 46/80
 - 0s - loss: 0.9597 - val_loss: 0.6011
AUC: 0.8674

Epoch 47/80
 - 0s - loss: 0.9614 - val_loss: 0.6061
AUC: 0.8676

Epoch 48/80
 - 0s - loss: 0.9606 - val_loss: 0.6006
AUC: 0.8674

Epoch 49/80
 - 0s - loss: 0.9611 - val_loss: 0.6038
AUC: 0.8675

Epoch 50/80
 - 0s - loss: 0.9580 - val_loss: 0.6011
AUC: 0.8674

Epoch 51/80
 - 0s - loss: 0.9598 - val_loss: 0.5911
AUC: 0.8674

Epoch 52/80
 - 0s - loss: 0.9603 - val_loss: 0.6080
AUC: 0.8676

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9640 - val_loss: 0.6104
AUC: 0.8673

Epoch 2/30
 - 0s - loss: 0.9649 - val_loss: 0.6156
AUC: 0.8677

Epoch 3/30
 - 0s - loss: 0.9619 - val_loss: 0.5999
AUC: 0.8675

Epoch 4/30
 - 0s - loss: 0.9600 - val_loss: 0.5828
AUC: 0.8674

Epoch 5/30
 - 0s - loss: 0.9569 - val_loss: 0.6103
AUC: 0.8678

Epoch 6/30
 - 0s - loss: 0.9593 - val_loss: 0.6024
AUC: 0.8679

Epoch 7/30
 - 0s - loss: 0.9575 - val_loss: 0.5932
AUC: 0.8679

Epoch 8/30
 - 0s - loss: 0.9524 - val_loss: 0.6038
AUC: 0.8682

Epoch 9/30
 - 0s - loss: 0.9540 - val_loss: 0.6126
AUC: 0.8685

Epoch 10/30
 - 0s - loss: 0.9521 - val_loss: 0.5929
AUC: 0.8681

Epoch 11/30
 - 0s - loss: 0.9516 - val_loss: 0.6033
AUC: 0.8684

Epoch 12/30
 - 0s - loss: 0.9504 - val_loss: 0.6013
AUC: 0.8687

Epoch 13/30
 - 0s - loss: 0.9490 - val_loss: 0.6137
AUC: 0.8689

Epoch 14/30
 - 0s - loss: 0.9489 - val_loss: 0.5860
AUC: 0.8684

Epoch 15/30
 - 0s - loss: 0.9474 - val_loss: 0.5932
AUC: 0.8685

Epoch 16/30
 - 0s - loss: 0.9479 - val_loss: 0.5949
AUC: 0.8686

Epoch 17/30
 - 0s - loss: 0.9424 - val_loss: 0.5935
AUC: 0.8686

Epoch 18/30
 - 0s - loss: 0.9487 - val_loss: 0.5963
AUC: 0.8687

Epoch 19/30
 - 0s - loss: 0.9462 - val_loss: 0.5964
AUC: 0.8687

Epoch 20/30
 - 0s - loss: 0.9505 - val_loss: 0.5937
AUC: 0.8687

Epoch 21/30
 - 0s - loss: 0.9446 - val_loss: 0.5974
AUC: 0.8688

Epoch 22/30
 - 0s - loss: 0.9463 - val_loss: 0.5996
AUC: 0.8689

Epoch 23/30
 - 0s - loss: 0.9475 - val_loss: 0.5958
AUC: 0.8688

Epoch 24/30
 - 0s - loss: 0.9446 - val_loss: 0.5947
AUC: 0.8688

Epoch 25/30
 - 0s - loss: 0.9449 - val_loss: 0.5954
AUC: 0.8689

Epoch 26/30
 - 0s - loss: 0.9397 - val_loss: 0.5951
AUC: 0.8689

Epoch 27/30
 - 0s - loss: 0.9425 - val_loss: 0.5960
AUC: 0.8689

Epoch 28/30
 - 0s - loss: 0.9439 - val_loss: 0.5952
AUC: 0.8689

Epoch 29/30
 - 0s - loss: 0.9399 - val_loss: 0.5955
AUC: 0.8688

Epoch 30/30
 - 0s - loss: 0.9379 - val_loss: 0.5947
Using TensorFlow backend.
AUC: 0.8688

2019-03-08 01:30:57.972749: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:30:58.138582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:30:58.138625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:30:58.434160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:30:58.434244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:30:58.434255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:30:58.434582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1303
Epoch 2/80
 - 2s - loss: 0.2128
Epoch 3/80
 - 2s - loss: 0.1654
Epoch 4/80
 - 2s - loss: 0.1513
Epoch 5/80
 - 2s - loss: 0.1427
Epoch 6/80
 - 2s - loss: 0.1361
Epoch 7/80
 - 2s - loss: 0.1303
Epoch 8/80
 - 2s - loss: 0.1247
Epoch 9/80
 - 2s - loss: 0.1191
Epoch 10/80
 - 2s - loss: 0.1127
Epoch 11/80
 - 2s - loss: 0.1055
Epoch 12/80
 - 2s - loss: 0.0983
Epoch 13/80
 - 2s - loss: 0.0917
Epoch 14/80
 - 2s - loss: 0.0856
Epoch 15/80
 - 2s - loss: 0.0804
Epoch 16/80
 - 2s - loss: 0.0759
Epoch 17/80
 - 2s - loss: 0.0722
Epoch 18/80
 - 2s - loss: 0.0690
Epoch 19/80
 - 2s - loss: 0.0664
Epoch 20/80
 - 2s - loss: 0.0642
Epoch 21/80
 - 2s - loss: 0.0623
Epoch 22/80
 - 2s - loss: 0.0607
Epoch 23/80
 - 2s - loss: 0.0594
Epoch 24/80
 - 2s - loss: 0.0583
Epoch 25/80
 - 2s - loss: 0.0573
Epoch 26/80
 - 2s - loss: 0.0565
Epoch 27/80
 - 2s - loss: 0.0558
Epoch 28/80
 - 2s - loss: 0.0552
Epoch 29/80
 - 2s - loss: 0.0547
Epoch 30/80
 - 2s - loss: 0.0542
Epoch 31/80
 - 2s - loss: 0.0538
Epoch 32/80
 - 2s - loss: 0.0535
Epoch 33/80
 - 2s - loss: 0.0532
Epoch 34/80
 - 2s - loss: 0.0529
Epoch 35/80
 - 2s - loss: 0.0526
Epoch 36/80
 - 2s - loss: 0.0524
Epoch 37/80
 - 2s - loss: 0.0522
Epoch 38/80
 - 2s - loss: 0.0521
Epoch 39/80
 - 2s - loss: 0.0519
Epoch 40/80
 - 2s - loss: 0.0518
Epoch 41/80
 - 2s - loss: 0.0516
Epoch 42/80
 - 2s - loss: 0.0515
Epoch 43/80
 - 2s - loss: 0.0514
Epoch 44/80
 - 2s - loss: 0.0513
Epoch 45/80
 - 2s - loss: 0.0512
Epoch 46/80
 - 2s - loss: 0.0511
Epoch 47/80
 - 2s - loss: 0.0510
Epoch 48/80
 - 2s - loss: 0.0510
Epoch 49/80
 - 2s - loss: 0.0509
Epoch 50/80
 - 2s - loss: 0.0508
Epoch 51/80
 - 2s - loss: 0.0508
Epoch 52/80
 - 2s - loss: 0.0507
Epoch 53/80
 - 2s - loss: 0.0507
Epoch 54/80
 - 2s - loss: 0.0506
Epoch 55/80
 - 2s - loss: 0.0506
Epoch 56/80
 - 2s - loss: 0.0505
Epoch 57/80
 - 2s - loss: 0.0505
Epoch 58/80
 - 2s - loss: 0.0505
Epoch 59/80
 - 2s - loss: 0.0504
Epoch 60/80
 - 2s - loss: 0.0504
Epoch 61/80
 - 2s - loss: 0.0503
Epoch 62/80
 - 2s - loss: 0.0503
Epoch 63/80
 - 2s - loss: 0.0503
Epoch 64/80
 - 2s - loss: 0.0492
Epoch 65/80
 - 2s - loss: 0.0491
Epoch 66/80
 - 2s - loss: 0.0490
Epoch 67/80
 - 2s - loss: 0.0490
Epoch 68/80
 - 2s - loss: 0.0490
Epoch 69/80
 - 2s - loss: 0.0487
Epoch 70/80
 - 2s - loss: 0.0487
Epoch 71/80
 - 2s - loss: 0.0487
Epoch 72/80
 - 2s - loss: 0.0487
Epoch 73/80
 - 2s - loss: 0.0487
Epoch 74/80
 - 2s - loss: 0.0487
Epoch 75/80
 - 2s - loss: 0.0487
Epoch 76/80
 - 2s - loss: 0.0487
Epoch 77/80
 - 2s - loss: 0.0487
Epoch 78/80
 - 2s - loss: 0.0487
Epoch 79/80
 - 2s - loss: 0.0487
Epoch 80/80
 - 2s - loss: 0.0487
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.1409 - val_loss: 1.0678
AUC: 0.8184

Epoch 2/80
 - 0s - loss: 1.7064 - val_loss: 0.7811
AUC: 0.8360

Epoch 3/80
 - 0s - loss: 1.2778 - val_loss: 0.7111
AUC: 0.8379

Epoch 4/80
 - 0s - loss: 1.1726 - val_loss: 0.7530
AUC: 0.8452

Epoch 5/80
 - 0s - loss: 1.1408 - val_loss: 0.6198
AUC: 0.8467

Epoch 6/80
 - 0s - loss: 1.1048 - val_loss: 0.6987
AUC: 0.8520

Epoch 7/80
 - 0s - loss: 1.0926 - val_loss: 0.6284
AUC: 0.8532

Epoch 8/80
 - 0s - loss: 1.0723 - val_loss: 0.6254
AUC: 0.8512

Epoch 9/80
 - 0s - loss: 1.0725 - val_loss: 0.6411
AUC: 0.8572

Epoch 10/80
 - 0s - loss: 1.0559 - val_loss: 0.6164
AUC: 0.8577

Epoch 11/80
 - 0s - loss: 1.0420 - val_loss: 0.6107
AUC: 0.8586

Epoch 12/80
 - 0s - loss: 1.0481 - val_loss: 0.6234
AUC: 0.8587

Epoch 13/80
 - 0s - loss: 1.0402 - val_loss: 0.6587
AUC: 0.8603

Epoch 14/80
 - 0s - loss: 1.0310 - val_loss: 0.6144
AUC: 0.8607

Epoch 15/80
 - 0s - loss: 1.0293 - val_loss: 0.6275
AUC: 0.8606

Epoch 16/80
 - 0s - loss: 1.0210 - val_loss: 0.6461
AUC: 0.8628

Epoch 17/80
 - 0s - loss: 1.0187 - val_loss: 0.6116
AUC: 0.8613

Epoch 18/80
 - 0s - loss: 1.0116 - val_loss: 0.6408
AUC: 0.8623

Epoch 19/80
 - 0s - loss: 1.0070 - val_loss: 0.6239
AUC: 0.8637

Epoch 20/80
 - 0s - loss: 1.0121 - val_loss: 0.6849
AUC: 0.8645

Epoch 21/80
 - 0s - loss: 1.0019 - val_loss: 0.6233
AUC: 0.8646

Epoch 22/80
 - 0s - loss: 0.9913 - val_loss: 0.5965
AUC: 0.8639

Epoch 23/80
 - 0s - loss: 0.9901 - val_loss: 0.6248
AUC: 0.8647

Epoch 24/80
 - 0s - loss: 0.9888 - val_loss: 0.6179
AUC: 0.8649

Epoch 25/80
 - 0s - loss: 0.9855 - val_loss: 0.6244
AUC: 0.8648

Epoch 26/80
 - 0s - loss: 0.9826 - val_loss: 0.5990
AUC: 0.8644

Epoch 27/80
 - 0s - loss: 0.9912 - val_loss: 0.6061
AUC: 0.8648

Epoch 28/80
 - 0s - loss: 0.9863 - val_loss: 0.6101
AUC: 0.8650

Epoch 29/80
 - 0s - loss: 0.9829 - val_loss: 0.6107
AUC: 0.8651

Epoch 30/80
 - 0s - loss: 0.9890 - val_loss: 0.6153
AUC: 0.8655

Epoch 31/80
 - 0s - loss: 0.9886 - val_loss: 0.6114
AUC: 0.8649

Epoch 32/80
 - 0s - loss: 0.9844 - val_loss: 0.5920
AUC: 0.8656

Epoch 33/80
 - 0s - loss: 0.9850 - val_loss: 0.6059
AUC: 0.8654

Epoch 34/80
 - 0s - loss: 0.9834 - val_loss: 0.6180
AUC: 0.8654

Epoch 35/80
 - 0s - loss: 0.9800 - val_loss: 0.5926
AUC: 0.8650

Epoch 36/80
 - 0s - loss: 0.9777 - val_loss: 0.6126
AUC: 0.8660

Epoch 37/80
 - 0s - loss: 0.9792 - val_loss: 0.6451
AUC: 0.8662

Epoch 38/80
 - 0s - loss: 0.9753 - val_loss: 0.6006
AUC: 0.8656

Epoch 39/80
 - 0s - loss: 0.9815 - val_loss: 0.6221
AUC: 0.8662

Epoch 40/80
 - 0s - loss: 0.9766 - val_loss: 0.6278
AUC: 0.8667

Epoch 41/80
 - 0s - loss: 0.9742 - val_loss: 0.6253
AUC: 0.8659

Epoch 42/80
 - 0s - loss: 0.9744 - val_loss: 0.5771
AUC: 0.8663

Epoch 43/80
 - 0s - loss: 0.9801 - val_loss: 0.6324
AUC: 0.8663

Epoch 44/80
 - 0s - loss: 0.9711 - val_loss: 0.6212
AUC: 0.8665

Epoch 45/80
 - 0s - loss: 0.9777 - val_loss: 0.5850
AUC: 0.8664

Epoch 46/80
 - 0s - loss: 0.9733 - val_loss: 0.6483
AUC: 0.8665

Epoch 47/80
 - 0s - loss: 0.9680 - val_loss: 0.6044
AUC: 0.8665

Epoch 48/80
 - 0s - loss: 0.9761 - val_loss: 0.5992
AUC: 0.8667

Epoch 49/80
 - 0s - loss: 0.9698 - val_loss: 0.6111
AUC: 0.8666

Epoch 50/80
 - 0s - loss: 0.9691 - val_loss: 0.5897
AUC: 0.8666

Epoch 51/80
 - 0s - loss: 0.9727 - val_loss: 0.6092
AUC: 0.8670

Epoch 52/80
 - 0s - loss: 0.9692 - val_loss: 0.5927
AUC: 0.8665

Epoch 53/80
 - 0s - loss: 0.9640 - val_loss: 0.6028
AUC: 0.8666

Epoch 54/80
 - 0s - loss: 0.9584 - val_loss: 0.5993
AUC: 0.8667

Epoch 55/80
 - 0s - loss: 0.9652 - val_loss: 0.6101
AUC: 0.8668

Epoch 56/80
 - 0s - loss: 0.9659 - val_loss: 0.5991
AUC: 0.8666

Epoch 57/80
 - 0s - loss: 0.9643 - val_loss: 0.6045
AUC: 0.8667

Epoch 58/80
 - 0s - loss: 0.9617 - val_loss: 0.6020
AUC: 0.8668

Epoch 59/80
 - 0s - loss: 0.9621 - val_loss: 0.5987
AUC: 0.8666

Epoch 60/80
 - 0s - loss: 0.9681 - val_loss: 0.6067
AUC: 0.8666

Epoch 61/80
 - 0s - loss: 0.9665 - val_loss: 0.6052
AUC: 0.8666

Epoch 62/80
 - 0s - loss: 0.9668 - val_loss: 0.6122
AUC: 0.8667

Epoch 63/80
 - 0s - loss: 0.9653 - val_loss: 0.6087
AUC: 0.8666

Epoch 64/80
 - 0s - loss: 0.9641 - val_loss: 0.6071
AUC: 0.8666

Epoch 65/80
 - 0s - loss: 0.9640 - val_loss: 0.6072
AUC: 0.8666

Epoch 66/80
 - 0s - loss: 0.9663 - val_loss: 0.6061
AUC: 0.8666

Epoch 67/80
 - 0s - loss: 0.9616 - val_loss: 0.6054
AUC: 0.8667

Epoch 68/80
 - 0s - loss: 0.9649 - val_loss: 0.6045
AUC: 0.8667

Epoch 69/80
 - 0s - loss: 0.9656 - val_loss: 0.6036
AUC: 0.8667

Epoch 70/80
 - 0s - loss: 0.9619 - val_loss: 0.6058
AUC: 0.8667

Epoch 71/80
 - 0s - loss: 0.9653 - val_loss: 0.6060
AUC: 0.8667

Epoch 72/80
 - 0s - loss: 0.9672 - val_loss: 0.6065
AUC: 0.8667

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9664 - val_loss: 0.6227
AUC: 0.8670

Epoch 2/30
 - 0s - loss: 0.9655 - val_loss: 0.6143
AUC: 0.8671

Epoch 3/30
 - 0s - loss: 0.9656 - val_loss: 0.6121
AUC: 0.8668

Epoch 4/30
 - 0s - loss: 0.9661 - val_loss: 0.6068
AUC: 0.8671

Epoch 5/30
 - 0s - loss: 0.9639 - val_loss: 0.5989
AUC: 0.8671

Epoch 6/30
 - 0s - loss: 0.9620 - val_loss: 0.6116
AUC: 0.8673

Epoch 7/30
 - 0s - loss: 0.9608 - val_loss: 0.6090
AUC: 0.8670

Epoch 8/30
 - 0s - loss: 0.9655 - val_loss: 0.6239
AUC: 0.8674

Epoch 9/30
 - 0s - loss: 0.9576 - val_loss: 0.6066
AUC: 0.8673

Epoch 10/30
 - 0s - loss: 0.9559 - val_loss: 0.6125
AUC: 0.8674

Epoch 11/30
 - 0s - loss: 0.9566 - val_loss: 0.5995
AUC: 0.8677

Epoch 12/30
 - 0s - loss: 0.9586 - val_loss: 0.6234
AUC: 0.8679

Epoch 13/30
 - 0s - loss: 0.9609 - val_loss: 0.6293
AUC: 0.8681

Epoch 14/30
 - 0s - loss: 0.9525 - val_loss: 0.5923
AUC: 0.8678

Epoch 15/30
 - 0s - loss: 0.9510 - val_loss: 0.5940
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.9487 - val_loss: 0.5989
AUC: 0.8681

Epoch 17/30
 - 0s - loss: 0.9533 - val_loss: 0.5738
AUC: 0.8679

Epoch 18/30
 - 0s - loss: 0.9523 - val_loss: 0.5768
AUC: 0.8677

Epoch 19/30
 - 0s - loss: 0.9507 - val_loss: 0.5706
AUC: 0.8679

Epoch 20/30
 - 0s - loss: 0.9498 - val_loss: 0.5980
AUC: 0.8679

Epoch 21/30
 - 0s - loss: 0.9438 - val_loss: 0.5832
AUC: 0.8682

Epoch 22/30
 - 0s - loss: 0.9484 - val_loss: 0.6272
AUC: 0.8685

Epoch 23/30
 - 0s - loss: 0.9462 - val_loss: 0.5922
AUC: 0.8682

Epoch 24/30
 - 0s - loss: 0.9475 - val_loss: 0.6010
AUC: 0.8684

Epoch 25/30
 - 0s - loss: 0.9445 - val_loss: 0.6147
AUC: 0.8686

Epoch 26/30
 - 0s - loss: 0.9454 - val_loss: 0.5960
AUC: 0.8685

Epoch 27/30
 - 0s - loss: 0.9428 - val_loss: 0.6013
AUC: 0.8686

Epoch 28/30
 - 0s - loss: 0.9369 - val_loss: 0.5947
AUC: 0.8687

Epoch 29/30
 - 0s - loss: 0.9385 - val_loss: 0.6018
AUC: 0.8689

Epoch 30/30
 - 0s - loss: 0.9364 - val_loss: 0.5953
Using TensorFlow backend.
AUC: 0.8688

2019-03-08 01:34:30.375334: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:34:30.539636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:34:30.539681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:34:30.829986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:34:30.830035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:34:30.830044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:34:30.830325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0681
Epoch 2/80
 - 2s - loss: 0.1950
Epoch 3/80
 - 2s - loss: 0.1683
Epoch 4/80
 - 2s - loss: 0.1573
Epoch 5/80
 - 2s - loss: 0.1465
Epoch 6/80
 - 2s - loss: 0.1363
Epoch 7/80
 - 2s - loss: 0.1250
Epoch 8/80
 - 2s - loss: 0.1137
Epoch 9/80
 - 2s - loss: 0.1040
Epoch 10/80
 - 2s - loss: 0.0954
Epoch 11/80
 - 2s - loss: 0.0877
Epoch 12/80
 - 2s - loss: 0.0811
Epoch 13/80
 - 2s - loss: 0.0756
Epoch 14/80
 - 2s - loss: 0.0711
Epoch 15/80
 - 2s - loss: 0.0671
Epoch 16/80
 - 2s - loss: 0.0638
Epoch 17/80
 - 2s - loss: 0.0610
Epoch 18/80
 - 2s - loss: 0.0586
Epoch 19/80
 - 2s - loss: 0.0566
Epoch 20/80
 - 2s - loss: 0.0549
Epoch 21/80
 - 2s - loss: 0.0535
Epoch 22/80
 - 2s - loss: 0.0523
Epoch 23/80
 - 2s - loss: 0.0513
Epoch 24/80
 - 2s - loss: 0.0503
Epoch 25/80
 - 2s - loss: 0.0496
Epoch 26/80
 - 2s - loss: 0.0489
Epoch 27/80
 - 2s - loss: 0.0483
Epoch 28/80
 - 2s - loss: 0.0478
Epoch 29/80
 - 2s - loss: 0.0473
Epoch 30/80
 - 2s - loss: 0.0469
Epoch 31/80
 - 2s - loss: 0.0466
Epoch 32/80
 - 2s - loss: 0.0463
Epoch 33/80
 - 2s - loss: 0.0460
Epoch 34/80
 - 2s - loss: 0.0458
Epoch 35/80
 - 2s - loss: 0.0456
Epoch 36/80
 - 2s - loss: 0.0454
Epoch 37/80
 - 2s - loss: 0.0452
Epoch 38/80
 - 2s - loss: 0.0450
Epoch 39/80
 - 2s - loss: 0.0449
Epoch 40/80
 - 2s - loss: 0.0448
Epoch 41/80
 - 2s - loss: 0.0447
Epoch 42/80
 - 2s - loss: 0.0445
Epoch 43/80
 - 2s - loss: 0.0445
Epoch 44/80
 - 2s - loss: 0.0444
Epoch 45/80
 - 2s - loss: 0.0443
Epoch 46/80
 - 2s - loss: 0.0442
Epoch 47/80
 - 2s - loss: 0.0441
Epoch 48/80
 - 2s - loss: 0.0441
Epoch 49/80
 - 2s - loss: 0.0440
Epoch 50/80
 - 2s - loss: 0.0440
Epoch 51/80
 - 2s - loss: 0.0439
Epoch 52/80
 - 2s - loss: 0.0439
Epoch 53/80
 - 2s - loss: 0.0438
Epoch 54/80
 - 2s - loss: 0.0438
Epoch 55/80
 - 2s - loss: 0.0437
Epoch 56/80
 - 2s - loss: 0.0437
Epoch 57/80
 - 2s - loss: 0.0436
Epoch 58/80
 - 2s - loss: 0.0436
Epoch 59/80
 - 2s - loss: 0.0436
Epoch 60/80
 - 2s - loss: 0.0435
Epoch 61/80
 - 2s - loss: 0.0435
Epoch 62/80
 - 2s - loss: 0.0423
Epoch 63/80
 - 2s - loss: 0.0421
Epoch 64/80
 - 2s - loss: 0.0421
Epoch 65/80
 - 2s - loss: 0.0421
Epoch 66/80
 - 2s - loss: 0.0421
Epoch 67/80
 - 2s - loss: 0.0418
Epoch 68/80
 - 2s - loss: 0.0418
Epoch 69/80
 - 2s - loss: 0.0418
Epoch 70/80
 - 2s - loss: 0.0418
Epoch 71/80
 - 2s - loss: 0.0417
Epoch 72/80
 - 2s - loss: 0.0417
Epoch 73/80
 - 2s - loss: 0.0417
Epoch 74/80
 - 2s - loss: 0.0417
Epoch 75/80
 - 2s - loss: 0.0417
Epoch 76/80
 - 2s - loss: 0.0417
Epoch 77/80
 - 2s - loss: 0.0417
Epoch 78/80
 - 2s - loss: 0.0417
Epoch 79/80
 - 2s - loss: 0.0417
Epoch 80/80
 - 2s - loss: 0.0417
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.6298 - val_loss: 1.3417
AUC: 0.7980

Epoch 2/80
 - 0s - loss: 2.0777 - val_loss: 0.7868
AUC: 0.8317

Epoch 3/80
 - 0s - loss: 1.4468 - val_loss: 0.7299
AUC: 0.8455

Epoch 4/80
 - 0s - loss: 1.2210 - val_loss: 0.6699
AUC: 0.8481

Epoch 5/80
 - 0s - loss: 1.1313 - val_loss: 0.6269
AUC: 0.8509

Epoch 6/80
 - 0s - loss: 1.0993 - val_loss: 0.6501
AUC: 0.8542

Epoch 7/80
 - 0s - loss: 1.0783 - val_loss: 0.6847
AUC: 0.8552

Epoch 8/80
 - 0s - loss: 1.0670 - val_loss: 0.6433
AUC: 0.8560

Epoch 9/80
 - 0s - loss: 1.0607 - val_loss: 0.6721
AUC: 0.8572

Epoch 10/80
 - 0s - loss: 1.0383 - val_loss: 0.6457
AUC: 0.8590

Epoch 11/80
 - 0s - loss: 1.0379 - val_loss: 0.7083
AUC: 0.8606

Epoch 12/80
 - 0s - loss: 1.0289 - val_loss: 0.6778
AUC: 0.8604

Epoch 13/80
 - 0s - loss: 1.0280 - val_loss: 0.5910
AUC: 0.8605

Epoch 14/80
 - 0s - loss: 1.0159 - val_loss: 0.6404
AUC: 0.8615

Epoch 15/80
 - 0s - loss: 1.0102 - val_loss: 0.5939
AUC: 0.8607

Epoch 16/80
 - 0s - loss: 1.0121 - val_loss: 0.6842
AUC: 0.8626

Epoch 17/80
 - 0s - loss: 1.0078 - val_loss: 0.7102
AUC: 0.8643

Epoch 18/80
 - 0s - loss: 1.0014 - val_loss: 0.6260
AUC: 0.8630

Epoch 19/80
 - 0s - loss: 0.9946 - val_loss: 0.5706
AUC: 0.8618

Epoch 20/80
 - 0s - loss: 0.9879 - val_loss: 0.6514
AUC: 0.8628

Epoch 21/80
 - 0s - loss: 0.9953 - val_loss: 0.6799
AUC: 0.8660

Epoch 22/80
 - 0s - loss: 0.9946 - val_loss: 0.6011
AUC: 0.8627

Epoch 23/80
 - 0s - loss: 0.9884 - val_loss: 0.5884
AUC: 0.8631

Epoch 24/80
 - 0s - loss: 0.9824 - val_loss: 0.5439
AUC: 0.8625

Epoch 25/80
 - 0s - loss: 0.9825 - val_loss: 0.5659
AUC: 0.8635

Epoch 26/80
 - 0s - loss: 0.9803 - val_loss: 0.6484
AUC: 0.8646

Epoch 27/80
 - 0s - loss: 0.9725 - val_loss: 0.6785
AUC: 0.8642

Epoch 28/80
 - 0s - loss: 0.9666 - val_loss: 0.5817
AUC: 0.8645

Epoch 29/80
 - 0s - loss: 0.9670 - val_loss: 0.6198
AUC: 0.8642

Epoch 30/80
 - 0s - loss: 0.9618 - val_loss: 0.6278
AUC: 0.8650

Epoch 31/80
 - 0s - loss: 0.9607 - val_loss: 0.6181
AUC: 0.8652

Epoch 32/80
 - 0s - loss: 0.9612 - val_loss: 0.6089
AUC: 0.8660

Epoch 33/80
 - 0s - loss: 0.9597 - val_loss: 0.6255
AUC: 0.8655

Epoch 34/80
 - 0s - loss: 0.9622 - val_loss: 0.7412
AUC: 0.8660

Epoch 35/80
 - 0s - loss: 0.9566 - val_loss: 0.5916
AUC: 0.8655

Epoch 36/80
 - 0s - loss: 0.9451 - val_loss: 0.6005
AUC: 0.8659

Epoch 37/80
 - 0s - loss: 0.9451 - val_loss: 0.6012
AUC: 0.8657

Epoch 38/80
 - 0s - loss: 0.9450 - val_loss: 0.6059
AUC: 0.8658

Epoch 39/80
 - 0s - loss: 0.9448 - val_loss: 0.5875
AUC: 0.8653

Epoch 40/80
 - 0s - loss: 0.9427 - val_loss: 0.5871
AUC: 0.8651

Epoch 41/80
 - 0s - loss: 0.9408 - val_loss: 0.6080
AUC: 0.8656

Epoch 42/80
 - 0s - loss: 0.9378 - val_loss: 0.6026
AUC: 0.8657

Epoch 43/80
 - 0s - loss: 0.9429 - val_loss: 0.6007
AUC: 0.8652

Epoch 44/80
 - 0s - loss: 0.9376 - val_loss: 0.6050
AUC: 0.8654

Epoch 45/80
 - 0s - loss: 0.9347 - val_loss: 0.5864
AUC: 0.8651

Epoch 46/80
 - 0s - loss: 0.9330 - val_loss: 0.5894
AUC: 0.8653

Epoch 47/80
 - 0s - loss: 0.9342 - val_loss: 0.5873
AUC: 0.8654

Epoch 48/80
 - 0s - loss: 0.9389 - val_loss: 0.5884
AUC: 0.8653

Epoch 49/80
 - 0s - loss: 0.9360 - val_loss: 0.6044
AUC: 0.8656

Epoch 50/80
 - 0s - loss: 0.9281 - val_loss: 0.5892
AUC: 0.8652

Epoch 51/80
 - 0s - loss: 0.9359 - val_loss: 0.5895
AUC: 0.8652

Epoch 52/80
 - 0s - loss: 0.9362 - val_loss: 0.5943
AUC: 0.8653

Epoch 53/80
 - 0s - loss: 0.9340 - val_loss: 0.5868
AUC: 0.8653

Epoch 54/80
 - 0s - loss: 0.9409 - val_loss: 0.5929
AUC: 0.8654

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9773 - val_loss: 0.6093
AUC: 0.8651

Epoch 2/30
 - 0s - loss: 0.9832 - val_loss: 0.6369
AUC: 0.8652

Epoch 3/30
 - 0s - loss: 0.9770 - val_loss: 0.6116
AUC: 0.8647

Epoch 4/30
 - 0s - loss: 0.9775 - val_loss: 0.6148
AUC: 0.8647

Epoch 5/30
 - 0s - loss: 0.9713 - val_loss: 0.6071
AUC: 0.8647

Epoch 6/30
 - 0s - loss: 0.9685 - val_loss: 0.6105
AUC: 0.8649

Epoch 7/30
 - 0s - loss: 0.9706 - val_loss: 0.5833
AUC: 0.8643

Epoch 8/30
 - 0s - loss: 0.9661 - val_loss: 0.5916
AUC: 0.8645

Epoch 9/30
 - 0s - loss: 0.9661 - val_loss: 0.5963
AUC: 0.8646

Epoch 10/30
 - 0s - loss: 0.9636 - val_loss: 0.6144
AUC: 0.8652

Epoch 11/30
 - 0s - loss: 0.9622 - val_loss: 0.6050
AUC: 0.8652

Epoch 12/30
 - 0s - loss: 0.9604 - val_loss: 0.6097
AUC: 0.8653

Epoch 13/30
 - 0s - loss: 0.9616 - val_loss: 0.6166
AUC: 0.8655

Epoch 14/30
 - 0s - loss: 0.9601 - val_loss: 0.6089
AUC: 0.8654

Epoch 15/30
 - 0s - loss: 0.9531 - val_loss: 0.6372
AUC: 0.8661

Epoch 16/30
 - 0s - loss: 0.9544 - val_loss: 0.5988
AUC: 0.8655

Epoch 17/30
 - 0s - loss: 0.9507 - val_loss: 0.5999
AUC: 0.8656

Epoch 18/30
 - 0s - loss: 0.9495 - val_loss: 0.6016
AUC: 0.8657

Epoch 19/30
 - 0s - loss: 0.9535 - val_loss: 0.5986
AUC: 0.8657

Epoch 20/30
 - 0s - loss: 0.9541 - val_loss: 0.6032
AUC: 0.8658

Epoch 21/30
 - 0s - loss: 0.9543 - val_loss: 0.5996
AUC: 0.8657

Epoch 22/30
 - 0s - loss: 0.9479 - val_loss: 0.6008
AUC: 0.8658

Epoch 23/30
 - 0s - loss: 0.9460 - val_loss: 0.5969
AUC: 0.8658

Epoch 24/30
 - 0s - loss: 0.9486 - val_loss: 0.5950
AUC: 0.8658

Epoch 25/30
 - 0s - loss: 0.9514 - val_loss: 0.5967
AUC: 0.8658

Epoch 26/30
 - 0s - loss: 0.9471 - val_loss: 0.5992
AUC: 0.8659

Epoch 27/30
 - 0s - loss: 0.9465 - val_loss: 0.5945
AUC: 0.8658

Epoch 28/30
 - 0s - loss: 0.9506 - val_loss: 0.5969
AUC: 0.8659

Epoch 29/30
 - 0s - loss: 0.9422 - val_loss: 0.5983
AUC: 0.8659

Epoch 30/30
 - 0s - loss: 0.9475 - val_loss: 0.5985
Using TensorFlow backend.
AUC: 0.8659

2019-03-08 01:37:51.750288: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:37:51.914312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:37:51.914356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:37:52.206746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:37:52.206794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:37:52.206802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:37:52.207057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0839
Epoch 2/80
 - 2s - loss: 0.1958
Epoch 3/80
 - 2s - loss: 0.1706
Epoch 4/80
 - 2s - loss: 0.1621
Epoch 5/80
 - 2s - loss: 0.1506
Epoch 6/80
 - 2s - loss: 0.1365
Epoch 7/80
 - 2s - loss: 0.1227
Epoch 8/80
 - 2s - loss: 0.1108
Epoch 9/80
 - 2s - loss: 0.1008
Epoch 10/80
 - 2s - loss: 0.0926
Epoch 11/80
 - 2s - loss: 0.0854
Epoch 12/80
 - 2s - loss: 0.0792
Epoch 13/80
 - 2s - loss: 0.0738
Epoch 14/80
 - 2s - loss: 0.0694
Epoch 15/80
 - 2s - loss: 0.0657
Epoch 16/80
 - 2s - loss: 0.0628
Epoch 17/80
 - 2s - loss: 0.0603
Epoch 18/80
 - 2s - loss: 0.0583
Epoch 19/80
 - 2s - loss: 0.0565
Epoch 20/80
 - 2s - loss: 0.0550
Epoch 21/80
 - 2s - loss: 0.0537
Epoch 22/80
 - 2s - loss: 0.0525
Epoch 23/80
 - 2s - loss: 0.0515
Epoch 24/80
 - 2s - loss: 0.0506
Epoch 25/80
 - 2s - loss: 0.0499
Epoch 26/80
 - 2s - loss: 0.0492
Epoch 27/80
 - 2s - loss: 0.0486
Epoch 28/80
 - 2s - loss: 0.0481
Epoch 29/80
 - 2s - loss: 0.0477
Epoch 30/80
 - 2s - loss: 0.0472
Epoch 31/80
 - 2s - loss: 0.0469
Epoch 32/80
 - 2s - loss: 0.0466
Epoch 33/80
 - 2s - loss: 0.0463
Epoch 34/80
 - 2s - loss: 0.0461
Epoch 35/80
 - 2s - loss: 0.0459
Epoch 36/80
 - 2s - loss: 0.0457
Epoch 37/80
 - 2s - loss: 0.0455
Epoch 38/80
 - 2s - loss: 0.0453
Epoch 39/80
 - 2s - loss: 0.0452
Epoch 40/80
 - 2s - loss: 0.0451
Epoch 41/80
 - 2s - loss: 0.0449
Epoch 42/80
 - 2s - loss: 0.0448
Epoch 43/80
 - 2s - loss: 0.0447
Epoch 44/80
 - 2s - loss: 0.0446
Epoch 45/80
 - 2s - loss: 0.0446
Epoch 46/80
 - 2s - loss: 0.0445
Epoch 47/80
 - 2s - loss: 0.0444
Epoch 48/80
 - 2s - loss: 0.0443
Epoch 49/80
 - 2s - loss: 0.0443
Epoch 50/80
 - 2s - loss: 0.0442
Epoch 51/80
 - 2s - loss: 0.0441
Epoch 52/80
 - 2s - loss: 0.0441
Epoch 53/80
 - 2s - loss: 0.0440
Epoch 54/80
 - 2s - loss: 0.0440
Epoch 55/80
 - 2s - loss: 0.0440
Epoch 56/80
 - 2s - loss: 0.0439
Epoch 57/80
 - 2s - loss: 0.0439
Epoch 58/80
 - 2s - loss: 0.0438
Epoch 59/80
 - 2s - loss: 0.0438
Epoch 60/80
 - 2s - loss: 0.0425
Epoch 61/80
 - 2s - loss: 0.0424
Epoch 62/80
 - 2s - loss: 0.0424
Epoch 63/80
 - 2s - loss: 0.0424
Epoch 64/80
 - 2s - loss: 0.0424
Epoch 65/80
 - 2s - loss: 0.0420
Epoch 66/80
 - 2s - loss: 0.0420
Epoch 67/80
 - 2s - loss: 0.0420
Epoch 68/80
 - 2s - loss: 0.0420
Epoch 69/80
 - 2s - loss: 0.0420
Epoch 70/80
 - 2s - loss: 0.0420
Epoch 71/80
 - 2s - loss: 0.0420
Epoch 72/80
 - 2s - loss: 0.0419
Epoch 73/80
 - 2s - loss: 0.0419
Epoch 74/80
 - 2s - loss: 0.0419
Epoch 75/80
 - 2s - loss: 0.0419
Epoch 76/80
 - 2s - loss: 0.0419
Epoch 77/80
 - 2s - loss: 0.0419
Epoch 78/80
 - 2s - loss: 0.0419
Epoch 79/80
 - 2s - loss: 0.0419
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:40:17.307467: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:40:17.471222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:40:17.471267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:40:17.763505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:40:17.763588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:40:17.763599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:40:17.763897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0875
Epoch 2/80
 - 2s - loss: 0.1949
Epoch 3/80
 - 2s - loss: 0.1617
Epoch 4/80
 - 2s - loss: 0.1456
Epoch 5/80
 - 2s - loss: 0.1324
Epoch 6/80
 - 2s - loss: 0.1219
Epoch 7/80
 - 2s - loss: 0.1126
Epoch 8/80
 - 2s - loss: 0.1035
Epoch 9/80
 - 2s - loss: 0.0947
Epoch 10/80
 - 2s - loss: 0.0869
Epoch 11/80
 - 2s - loss: 0.0804
Epoch 12/80
 - 2s - loss: 0.0750
Epoch 13/80
 - 2s - loss: 0.0705
Epoch 14/80
 - 2s - loss: 0.0667
Epoch 15/80
 - 2s - loss: 0.0635
Epoch 16/80
 - 2s - loss: 0.0610
Epoch 17/80
 - 2s - loss: 0.0589
Epoch 18/80
 - 2s - loss: 0.0570
Epoch 19/80
 - 2s - loss: 0.0555
Epoch 20/80
 - 2s - loss: 0.0542
Epoch 21/80
 - 2s - loss: 0.0529
Epoch 22/80
 - 2s - loss: 0.0519
Epoch 23/80
 - 2s - loss: 0.0510
Epoch 24/80
 - 2s - loss: 0.0502
Epoch 25/80
 - 2s - loss: 0.0494
Epoch 26/80
 - 2s - loss: 0.0488
Epoch 27/80
 - 2s - loss: 0.0482
Epoch 28/80
 - 2s - loss: 0.0477
Epoch 29/80
 - 2s - loss: 0.0473
Epoch 30/80
 - 2s - loss: 0.0469
Epoch 31/80
 - 2s - loss: 0.0466
Epoch 32/80
 - 2s - loss: 0.0463
Epoch 33/80
 - 2s - loss: 0.0460
Epoch 34/80
 - 2s - loss: 0.0458
Epoch 35/80
 - 2s - loss: 0.0456
Epoch 36/80
 - 2s - loss: 0.0454
Epoch 37/80
 - 2s - loss: 0.0452
Epoch 38/80
 - 2s - loss: 0.0451
Epoch 39/80
 - 2s - loss: 0.0449
Epoch 40/80
 - 2s - loss: 0.0448
Epoch 41/80
 - 2s - loss: 0.0447
Epoch 42/80
 - 2s - loss: 0.0446
Epoch 43/80
 - 2s - loss: 0.0445
Epoch 44/80
 - 2s - loss: 0.0444
Epoch 45/80
 - 2s - loss: 0.0443
Epoch 46/80
 - 2s - loss: 0.0443
Epoch 47/80
 - 2s - loss: 0.0442
Epoch 48/80
 - 2s - loss: 0.0441
Epoch 49/80
 - 2s - loss: 0.0441
Epoch 50/80
 - 2s - loss: 0.0440
Epoch 51/80
 - 2s - loss: 0.0440
Epoch 52/80
 - 2s - loss: 0.0439
Epoch 53/80
 - 2s - loss: 0.0439
Epoch 54/80
 - 2s - loss: 0.0438
Epoch 55/80
 - 2s - loss: 0.0438
Epoch 56/80
 - 2s - loss: 0.0437
Epoch 57/80
 - 2s - loss: 0.0437
Epoch 58/80
 - 2s - loss: 0.0437
Epoch 59/80
 - 2s - loss: 0.0436
Epoch 60/80
 - 2s - loss: 0.0436
Epoch 61/80
 - 2s - loss: 0.0436
Epoch 62/80
 - 2s - loss: 0.0435
Epoch 63/80
 - 2s - loss: 0.0423
Epoch 64/80
 - 2s - loss: 0.0421
Epoch 65/80
 - 2s - loss: 0.0421
Epoch 66/80
 - 2s - loss: 0.0421
Epoch 67/80
 - 2s - loss: 0.0421
Epoch 68/80
 - 2s - loss: 0.0418
Epoch 69/80
 - 2s - loss: 0.0418
Epoch 70/80
 - 2s - loss: 0.0418
Epoch 71/80
 - 2s - loss: 0.0418
Epoch 72/80
 - 2s - loss: 0.0417
Epoch 73/80
 - 2s - loss: 0.0417
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:42:33.549454: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:42:33.716288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:42:33.716333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:42:34.012505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:42:34.012545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:42:34.012554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:42:34.012818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0054
Epoch 2/80
 - 2s - loss: 0.1822
Epoch 3/80
 - 2s - loss: 0.1573
Epoch 4/80
 - 2s - loss: 0.1357
Epoch 5/80
 - 2s - loss: 0.1180
Epoch 6/80
 - 2s - loss: 0.1045
Epoch 7/80
 - 2s - loss: 0.0933
Epoch 8/80
 - 2s - loss: 0.0841
Epoch 9/80
 - 2s - loss: 0.0768
Epoch 10/80
 - 2s - loss: 0.0708
Epoch 11/80
 - 2s - loss: 0.0658
Epoch 12/80
 - 2s - loss: 0.0616
Epoch 13/80
 - 2s - loss: 0.0581
Epoch 14/80
 - 2s - loss: 0.0551
Epoch 15/80
 - 2s - loss: 0.0527
Epoch 16/80
 - 2s - loss: 0.0506
Epoch 17/80
 - 2s - loss: 0.0488
Epoch 18/80
 - 2s - loss: 0.0472
Epoch 19/80
 - 2s - loss: 0.0459
Epoch 20/80
 - 2s - loss: 0.0447
Epoch 21/80
 - 2s - loss: 0.0437
Epoch 22/80
 - 2s - loss: 0.0428
Epoch 23/80
 - 2s - loss: 0.0421
Epoch 24/80
 - 2s - loss: 0.0414
Epoch 25/80
 - 2s - loss: 0.0408
Epoch 26/80
 - 2s - loss: 0.0403
Epoch 27/80
 - 2s - loss: 0.0399
Epoch 28/80
 - 2s - loss: 0.0395
Epoch 29/80
 - 2s - loss: 0.0392
Epoch 30/80
 - 2s - loss: 0.0389
Epoch 31/80
 - 2s - loss: 0.0386
Epoch 32/80
 - 2s - loss: 0.0384
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:43:47.535349: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:43:47.698459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:43:47.698512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:43:47.988759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:43:47.988803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:43:47.988812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:43:47.989065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0003
Epoch 2/80
 - 2s - loss: 0.1822
Epoch 3/80
 - 2s - loss: 0.1553
Epoch 4/80
 - 2s - loss: 0.1297
Epoch 5/80
 - 2s - loss: 0.1120
Epoch 6/80
 - 2s - loss: 0.1000
Epoch 7/80
 - 2s - loss: 0.0903
Epoch 8/80
 - 2s - loss: 0.0822
Epoch 9/80
 - 2s - loss: 0.0756
Epoch 10/80
 - 2s - loss: 0.0700
Epoch 11/80
 - 2s - loss: 0.0654
Epoch 12/80
 - 2s - loss: 0.0615
Epoch 13/80
 - 2s - loss: 0.0582
Epoch 14/80
 - 2s - loss: 0.0555
Epoch 15/80
 - 2s - loss: 0.0531
Epoch 16/80
 - 2s - loss: 0.0511
Epoch 17/80
 - 2s - loss: 0.0493
Epoch 18/80
 - 2s - loss: 0.0477
Epoch 19/80
 - 2s - loss: 0.0464
Epoch 20/80
 - 2s - loss: 0.0452
Epoch 21/80
 - 2s - loss: 0.0441
Epoch 22/80
 - 2s - loss: 0.0433
Epoch 23/80
 - 2s - loss: 0.0424
Epoch 24/80
 - 2s - loss: 0.0418
Epoch 25/80
 - 2s - loss: 0.0411
Epoch 26/80
 - 2s - loss: 0.0406
Epoch 27/80
 - 2s - loss: 0.0401
Epoch 28/80
 - 2s - loss: 0.0397
Epoch 29/80
 - 2s - loss: 0.0394
Epoch 30/80
 - 2s - loss: 0.0390
Epoch 31/80
 - 2s - loss: 0.0388
Epoch 32/80
 - 2s - loss: 0.0385
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0381
Epoch 35/80
 - 2s - loss: 0.0379
Epoch 36/80
 - 2s - loss: 0.0378
Epoch 37/80
 - 2s - loss: 0.0376
Epoch 38/80
 - 2s - loss: 0.0375
Epoch 39/80
 - 2s - loss: 0.0374
Epoch 40/80
 - 2s - loss: 0.0373
Epoch 41/80
 - 2s - loss: 0.0372
Epoch 42/80
 - 2s - loss: 0.0371
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:45:16.283098: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:45:16.445432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:45:16.445475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:45:16.739860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:45:16.739909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:45:16.739918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:45:16.740210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9737
Epoch 2/80
 - 2s - loss: 0.1820
Epoch 3/80
 - 2s - loss: 0.1648
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:45:38.905383: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:45:39.069523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:45:39.069574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:45:39.364409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:45:39.364459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:45:39.364478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:45:39.364734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.8897
Epoch 2/80
 - 2s - loss: 0.1679
Epoch 3/80
 - 2s - loss: 0.1330
Epoch 4/80
 - 2s - loss: 0.1083
Epoch 5/80
 - 2s - loss: 0.0918
Epoch 6/80
 - 2s - loss: 0.0796
Epoch 7/80
 - 2s - loss: 0.0704
Epoch 8/80
 - 2s - loss: 0.0637
Epoch 9/80
 - 2s - loss: 0.0584
Epoch 10/80
 - 2s - loss: 0.0542
Epoch 11/80
 - 2s - loss: 0.0506
Epoch 12/80
 - 2s - loss: 0.0476
Epoch 13/80
 - 2s - loss: 0.0450
Epoch 14/80
 - 2s - loss: 0.0428
Epoch 15/80
 - 2s - loss: 0.0409
Epoch 16/80
 - 2s - loss: 0.0391
Epoch 17/80
 - 2s - loss: 0.0377
Epoch 18/80
 - 2s - loss: 0.0363
Epoch 19/80
 - 2s - loss: 0.0351
Epoch 20/80
 - 2s - loss: 0.0341
Epoch 21/80
 - 2s - loss: 0.0332
Epoch 22/80
 - 2s - loss: 0.0324
Epoch 23/80
 - 2s - loss: 0.0316
Epoch 24/80
 - 2s - loss: 0.0310
Epoch 25/80
 - 2s - loss: 0.0305
Epoch 26/80
 - 2s - loss: 0.0300
Epoch 27/80
 - 2s - loss: 0.0295
Epoch 28/80
 - 2s - loss: 0.0292
Epoch 29/80
 - 2s - loss: 0.0288
Epoch 30/80
 - 2s - loss: 0.0286
Epoch 31/80
 - 2s - loss: 0.0283
Epoch 32/80
 - 2s - loss: 0.0281
Epoch 33/80
 - 2s - loss: 0.0279
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:46:55.301360: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:46:55.464833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:46:55.464888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:46:55.752829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:46:55.752880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:46:55.752889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:46:55.753170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.8906
Epoch 2/80
 - 2s - loss: 0.1686
Epoch 3/80
 - 2s - loss: 0.1321
Epoch 4/80
 - 2s - loss: 0.1062
Epoch 5/80
 - 2s - loss: 0.0910
Epoch 6/80
 - 2s - loss: 0.0797
Epoch 7/80
 - 2s - loss: 0.0707
Epoch 8/80
 - 2s - loss: 0.0640
Epoch 9/80
 - 2s - loss: 0.0586
Epoch 10/80
 - 2s - loss: 0.0543
Epoch 11/80
 - 2s - loss: 0.0507
Epoch 12/80
 - 2s - loss: 0.0477
Epoch 13/80
 - 2s - loss: 0.0450
Epoch 14/80
 - 2s - loss: 0.0428
Epoch 15/80
 - 2s - loss: 0.0409
Epoch 16/80
 - 2s - loss: 0.0391
Epoch 17/80
 - 2s - loss: 0.0376
Epoch 18/80
 - 2s - loss: 0.0363
Epoch 19/80
 - 2s - loss: 0.0351
Epoch 20/80
 - 2s - loss: 0.0340
Epoch 21/80
 - 2s - loss: 0.0331
Epoch 22/80
 - 2s - loss: 0.0323
Epoch 23/80
 - 2s - loss: 0.0316
Epoch 24/80
 - 2s - loss: 0.0310
Epoch 25/80
 - 2s - loss: 0.0304
Epoch 26/80
 - 2s - loss: 0.0299
Epoch 27/80
 - 2s - loss: 0.0295
Epoch 28/80
 - 2s - loss: 0.0291
Epoch 29/80
 - 2s - loss: 0.0288
Epoch 30/80
 - 2s - loss: 0.0285
Epoch 31/80
 - 2s - loss: 0.0283
Epoch 32/80
 - 2s - loss: 0.0280
Epoch 33/80
 - 2s - loss: 0.0279
Epoch 34/80
 - 2s - loss: 0.0277
Epoch 35/80
 - 2s - loss: 0.0275
Epoch 36/80
 - 2s - loss: 0.0274
Epoch 37/80
 - 2s - loss: 0.0272
Epoch 38/80
 - 2s - loss: 0.0271
Epoch 39/80
 - 2s - loss: 0.0270
Epoch 40/80
 - 2s - loss: 0.0269
Epoch 41/80
 - 2s - loss: 0.0268
Epoch 42/80
 - 2s - loss: 0.0267
Epoch 43/80
 - 2s - loss: 0.0266
Epoch 44/80
 - 2s - loss: 0.0265
Epoch 45/80
 - 2s - loss: 0.0265
Epoch 46/80
 - 2s - loss: 0.0264
Epoch 47/80
 - 2s - loss: 0.0263
Epoch 48/80
 - 2s - loss: 0.0263
Epoch 49/80
 - 2s - loss: 0.0262
Epoch 50/80
 - 2s - loss: 0.0262
Epoch 51/80
 - 2s - loss: 0.0261
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:48:41.365733: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:48:41.530138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:48:41.530202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:48:41.820882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:48:41.820922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:48:41.820932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:48:41.821241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9009
Epoch 2/80
 - 2s - loss: 0.1680
Epoch 3/80
 - 2s - loss: 0.1328
Epoch 4/80
 - 2s - loss: 0.1076
Epoch 5/80
 - 2s - loss: 0.0912
Epoch 6/80
 - 2s - loss: 0.0795
Epoch 7/80
 - 2s - loss: 0.0706
Epoch 8/80
 - 2s - loss: 0.0638
Epoch 9/80
 - 2s - loss: 0.0585
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:49:14.278000: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:49:14.441322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:49:14.441367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:49:14.732110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:49:14.732161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:49:14.732185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:49:14.732453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.8855
Epoch 2/80
 - 2s - loss: 0.1672
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:49:35.617925: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:49:35.780969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:49:35.781021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:49:36.074687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:49:36.074737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:49:36.074746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:49:36.074999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.8050
Epoch 2/80
 - 2s - loss: 0.1514
Epoch 3/80
 - 2s - loss: 0.1079
Epoch 4/80
 - 2s - loss: 0.0844
Epoch 5/80
 - 2s - loss: 0.0709
Epoch 6/80
 - 2s - loss: 0.0622
Epoch 7/80
 - 2s - loss: 0.0557
Epoch 8/80
 - 2s - loss: 0.0503
Epoch 9/80
 - 2s - loss: 0.0459
Epoch 10/80
 - 2s - loss: 0.0422
Epoch 11/80
 - 2s - loss: 0.0390
Epoch 12/80
 - 2s - loss: 0.0363
Epoch 13/80
 - 2s - loss: 0.0338
Epoch 14/80
 - 2s - loss: 0.0317
Epoch 15/80
 - 2s - loss: 0.0298
Epoch 16/80
 - 2s - loss: 0.0280
Epoch 17/80
 - 2s - loss: 0.0265
Epoch 18/80
 - 2s - loss: 0.0251
Epoch 19/80
 - 2s - loss: 0.0239
Epoch 20/80
 - 2s - loss: 0.0227
Epoch 21/80
 - 2s - loss: 0.0218
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:50:35.986121: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:50:36.151117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:50:36.151160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:50:36.443666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:50:36.443719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:50:36.443734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:50:36.444050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.7901
Epoch 2/80
 - 2s - loss: 0.1537
Epoch 3/80
 - 2s - loss: 0.1113
Epoch 4/80
 - 2s - loss: 0.0868
Epoch 5/80
 - 2s - loss: 0.0727
Epoch 6/80
 - 2s - loss: 0.0632
Epoch 7/80
 - 2s - loss: 0.0563
Epoch 8/80
 - 2s - loss: 0.0508
Epoch 9/80
 - 2s - loss: 0.0463
Epoch 10/80
 - 2s - loss: 0.0425
Epoch 11/80
 - 2s - loss: 0.0393
Epoch 12/80
 - 2s - loss: 0.0366
Epoch 13/80
 - 2s - loss: 0.0341
Epoch 14/80
 - 2s - loss: 0.0320
Epoch 15/80
 - 2s - loss: 0.0300
Epoch 16/80
 - 2s - loss: 0.0283
Epoch 17/80
 - 2s - loss: 0.0268
Epoch 18/80
 - 2s - loss: 0.0254
Epoch 19/80
 - 2s - loss: 0.0241
Epoch 20/80
 - 2s - loss: 0.0230
Epoch 21/80
 - 2s - loss: 0.0220
Epoch 22/80
 - 2s - loss: 0.0211
Epoch 23/80
 - 2s - loss: 0.0203
Epoch 24/80
 - 2s - loss: 0.0196
Epoch 25/80
 - 2s - loss: 0.0190
Epoch 26/80
 - 2s - loss: 0.0184
Epoch 27/80
 - 2s - loss: 0.0179
Epoch 28/80
 - 2s - loss: 0.0175
Epoch 29/80
 - 2s - loss: 0.0171
Epoch 30/80
 - 2s - loss: 0.0167
Epoch 31/80
 - 2s - loss: 0.0164
Epoch 32/80
 - 2s - loss: 0.0162
Epoch 33/80
 - 2s - loss: 0.0159
Epoch 34/80
 - 2s - loss: 0.0157
Epoch 35/80
 - 2s - loss: 0.0155
Epoch 36/80
 - 2s - loss: 0.0153
Epoch 37/80
 - 2s - loss: 0.0152
Epoch 38/80
 - 2s - loss: 0.0150
Epoch 39/80
 - 2s - loss: 0.0149
Epoch 40/80
 - 2s - loss: 0.0148
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0145
Epoch 43/80
 - 2s - loss: 0.0144
Epoch 44/80
 - 2s - loss: 0.0143
Epoch 45/80
 - 2s - loss: 0.0142
Epoch 46/80
 - 2s - loss: 0.0142
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:52:22.120384: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:52:22.284189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:52:22.284235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:52:22.576881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:52:22.576932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:52:22.576942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:52:22.577203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.8073
Epoch 2/80
 - 2s - loss: 0.1519
Epoch 3/80
 - 2s - loss: 0.1084
Epoch 4/80
 - 2s - loss: 0.0850
Epoch 5/80
 - 2s - loss: 0.0717
Epoch 6/80
 - 2s - loss: 0.0629
Epoch 7/80
 - 2s - loss: 0.0561
Epoch 8/80
 - 2s - loss: 0.0507
Epoch 9/80
 - 2s - loss: 0.0462
Epoch 10/80
 - 2s - loss: 0.0424
Epoch 11/80
 - 2s - loss: 0.0392
Epoch 12/80
 - 2s - loss: 0.0364
Epoch 13/80
 - 2s - loss: 0.0339
Epoch 14/80
 - 2s - loss: 0.0317
Epoch 15/80
 - 2s - loss: 0.0298
Epoch 16/80
 - 2s - loss: 0.0281
Epoch 17/80
 - 2s - loss: 0.0265
Epoch 18/80
 - 2s - loss: 0.0251
Epoch 19/80
 - 2s - loss: 0.0239
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:53:15.316844: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:53:15.477938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:53:15.477982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:53:15.765221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:53:15.765270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:53:15.765279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:53:15.765533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3868
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:53:38.346255: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:53:38.506949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:53:38.506992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:53:38.796626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:53:38.796685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:53:38.796694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:53:38.796945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3463
Epoch 2/80
 - 2s - loss: 0.3498
Epoch 3/80
 - 2s - loss: 0.3103
Epoch 4/80
 - 2s - loss: 0.3006
Epoch 5/80
 - 2s - loss: 0.2886
Epoch 6/80
 - 2s - loss: 0.2705
Epoch 7/80
 - 2s - loss: 0.2478
Epoch 8/80
 - 2s - loss: 0.2270
Epoch 9/80
 - 2s - loss: 0.2106
Epoch 10/80
 - 2s - loss: 0.1973
Epoch 11/80
 - 2s - loss: 0.1855
Epoch 12/80
 - 2s - loss: 0.1751
Epoch 13/80
 - 2s - loss: 0.1661
Epoch 14/80
 - 2s - loss: 0.1583
Epoch 15/80
 - 2s - loss: 0.1519
Epoch 16/80
 - 2s - loss: 0.1465
Epoch 17/80
 - 2s - loss: 0.1420
Epoch 18/80
 - 2s - loss: 0.1384
Epoch 19/80
 - 2s - loss: 0.1353
Epoch 20/80
 - 2s - loss: 0.1327
Epoch 21/80
 - 2s - loss: 0.1305
Epoch 22/80
 - 2s - loss: 0.1285
Epoch 23/80
 - 2s - loss: 0.1268
Epoch 24/80
 - 2s - loss: 0.1253
Epoch 25/80
 - 2s - loss: 0.1239
Epoch 26/80
 - 2s - loss: 0.1228
Epoch 27/80
 - 2s - loss: 0.1218
Epoch 28/80
 - 2s - loss: 0.1209
Epoch 29/80
 - 2s - loss: 0.1202
Epoch 30/80
 - 2s - loss: 0.1195
Epoch 31/80
 - 2s - loss: 0.1190
Epoch 32/80
 - 2s - loss: 0.1185
Epoch 33/80
 - 2s - loss: 0.1181
Epoch 34/80
 - 2s - loss: 0.1177
Epoch 35/80
 - 2s - loss: 0.1174
Epoch 36/80
 - 2s - loss: 0.1171
Epoch 37/80
 - 2s - loss: 0.1169
Epoch 38/80
 - 2s - loss: 0.1167
Epoch 39/80
 - 2s - loss: 0.1165
Epoch 40/80
 - 2s - loss: 0.1163
Epoch 41/80
 - 2s - loss: 0.1161
Epoch 42/80
 - 2s - loss: 0.1160
Epoch 43/80
 - 2s - loss: 0.1158
Epoch 44/80
 - 2s - loss: 0.1157
Epoch 45/80
 - 2s - loss: 0.1156
Epoch 46/80
 - 2s - loss: 0.1155
Epoch 47/80
 - 2s - loss: 0.1153
Epoch 48/80
 - 2s - loss: 0.1153
Epoch 49/80
 - 2s - loss: 0.1152
Epoch 50/80
 - 2s - loss: 0.1151
Epoch 51/80
 - 2s - loss: 0.1150
Epoch 52/80
 - 2s - loss: 0.1150
Epoch 53/80
 - 2s - loss: 0.1149
Epoch 54/80
 - 2s - loss: 0.1149
Epoch 55/80
 - 2s - loss: 0.1148
Epoch 56/80
 - 2s - loss: 0.1147
Epoch 57/80
 - 2s - loss: 0.1147
Epoch 58/80
 - 2s - loss: 0.1146
Epoch 59/80
 - 2s - loss: 0.1146
Epoch 60/80
 - 2s - loss: 0.1145
Epoch 61/80
 - 2s - loss: 0.1145
Epoch 62/80
 - 2s - loss: 0.1145
Epoch 63/80
 - 2s - loss: 0.1144
Epoch 64/80
 - 2s - loss: 0.1144
Epoch 65/80
 - 2s - loss: 0.1143
Epoch 66/80
 - 2s - loss: 0.1143
Epoch 67/80
 - 2s - loss: 0.1143
Epoch 68/80
 - 2s - loss: 0.1142
Epoch 69/80
 - 2s - loss: 0.1142
Epoch 70/80
 - 2s - loss: 0.1120
Epoch 71/80
 - 2s - loss: 0.1118
Epoch 72/80
 - 2s - loss: 0.1117
Epoch 73/80
 - 2s - loss: 0.1117
Epoch 74/80
 - 2s - loss: 0.1117
Epoch 75/80
 - 2s - loss: 0.1111
Epoch 76/80
 - 2s - loss: 0.1111
Epoch 77/80
 - 2s - loss: 0.1111
Epoch 78/80
 - 2s - loss: 0.1111
Epoch 79/80
 - 2s - loss: 0.1110
Epoch 80/80
 - 2s - loss: 0.1110
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 6.0572 - val_loss: 2.4170
AUC: 0.7660

Epoch 2/80
 - 0s - loss: 3.5628 - val_loss: 1.2944
AUC: 0.8024

Epoch 3/80
 - 0s - loss: 2.1312 - val_loss: 0.9205
AUC: 0.8047

Epoch 4/80
 - 0s - loss: 1.5195 - val_loss: 0.7118
AUC: 0.8166

Epoch 5/80
 - 0s - loss: 1.2990 - val_loss: 0.6919
AUC: 0.8320

Epoch 6/80
 - 0s - loss: 1.2554 - val_loss: 0.6716
AUC: 0.8354

Epoch 7/80
 - 0s - loss: 1.2181 - val_loss: 0.6986
AUC: 0.8418

Epoch 8/80
 - 0s - loss: 1.1717 - val_loss: 0.7199
AUC: 0.8453

Epoch 9/80
 - 0s - loss: 1.1583 - val_loss: 0.7169
AUC: 0.8479

Epoch 10/80
 - 0s - loss: 1.1411 - val_loss: 0.6559
AUC: 0.8493

Epoch 11/80
 - 0s - loss: 1.1281 - val_loss: 0.7125
AUC: 0.8520

Epoch 12/80
 - 0s - loss: 1.1160 - val_loss: 0.6824
AUC: 0.8535

Epoch 13/80
 - 0s - loss: 1.1101 - val_loss: 0.6634
AUC: 0.8553

Epoch 14/80
 - 0s - loss: 1.0994 - val_loss: 0.6873
AUC: 0.8565

Epoch 15/80
 - 0s - loss: 1.0860 - val_loss: 0.6802
AUC: 0.8567

Epoch 16/80
 - 0s - loss: 1.0916 - val_loss: 0.6323
AUC: 0.8583

Epoch 17/80
 - 0s - loss: 1.0750 - val_loss: 0.6240
AUC: 0.8591

Epoch 18/80
 - 0s - loss: 1.0720 - val_loss: 0.6290
AUC: 0.8591

Epoch 19/80
 - 0s - loss: 1.0745 - val_loss: 0.6596
AUC: 0.8608

Epoch 20/80
 - 0s - loss: 1.0670 - val_loss: 0.6235
AUC: 0.8621

Epoch 21/80
 - 0s - loss: 1.0602 - val_loss: 0.6079
AUC: 0.8617

Epoch 22/80
 - 0s - loss: 1.0592 - val_loss: 0.5913
AUC: 0.8622

Epoch 23/80
 - 0s - loss: 1.0541 - val_loss: 0.6569
AUC: 0.8645

Epoch 24/80
 - 0s - loss: 1.0530 - val_loss: 0.5995
AUC: 0.8641

Epoch 25/80
 - 0s - loss: 1.0462 - val_loss: 0.6487
AUC: 0.8653

Epoch 26/80
 - 0s - loss: 1.0424 - val_loss: 0.6237
AUC: 0.8657

Epoch 27/80
 - 0s - loss: 1.0386 - val_loss: 0.6169
AUC: 0.8655

Epoch 28/80
 - 0s - loss: 1.0383 - val_loss: 0.6197
AUC: 0.8660

Epoch 29/80
 - 0s - loss: 1.0404 - val_loss: 0.6178
AUC: 0.8657

Epoch 30/80
 - 0s - loss: 1.0364 - val_loss: 0.5810
AUC: 0.8654

Epoch 31/80
 - 0s - loss: 1.0310 - val_loss: 0.5975
AUC: 0.8666

Epoch 32/80
 - 0s - loss: 1.0310 - val_loss: 0.5825
AUC: 0.8664

Epoch 33/80
 - 0s - loss: 1.0221 - val_loss: 0.6278
AUC: 0.8674

Epoch 34/80
 - 0s - loss: 1.0239 - val_loss: 0.6400
AUC: 0.8675

Epoch 35/80
 - 0s - loss: 1.0276 - val_loss: 0.6211
AUC: 0.8671

Epoch 36/80
 - 0s - loss: 1.0250 - val_loss: 0.6169
AUC: 0.8680

Epoch 37/80
 - 0s - loss: 1.0198 - val_loss: 0.5701
AUC: 0.8672

Epoch 38/80
 - 0s - loss: 1.0152 - val_loss: 0.5699
AUC: 0.8675

Epoch 39/80
 - 0s - loss: 1.0149 - val_loss: 0.6038
AUC: 0.8675

Epoch 40/80
 - 0s - loss: 1.0176 - val_loss: 0.7310
AUC: 0.8689

Epoch 41/80
 - 0s - loss: 1.0165 - val_loss: 0.6190
AUC: 0.8677

Epoch 42/80
 - 0s - loss: 1.0059 - val_loss: 0.5975
AUC: 0.8685

Epoch 43/80
 - 0s - loss: 1.0034 - val_loss: 0.5897
AUC: 0.8689

Epoch 44/80
 - 0s - loss: 1.0078 - val_loss: 0.5532
AUC: 0.8686

Epoch 45/80
 - 0s - loss: 1.0094 - val_loss: 0.6039
AUC: 0.8686

Epoch 46/80
 - 0s - loss: 1.0080 - val_loss: 0.5856
AUC: 0.8680

Epoch 47/80
 - 0s - loss: 1.0063 - val_loss: 0.6280
AUC: 0.8690

Epoch 48/80
 - 0s - loss: 1.0007 - val_loss: 0.6125
AUC: 0.8692

Epoch 49/80
 - 0s - loss: 1.0012 - val_loss: 0.5943
AUC: 0.8685

Epoch 50/80
 - 0s - loss: 1.0037 - val_loss: 0.5697
AUC: 0.8691

Epoch 51/80
 - 0s - loss: 1.0042 - val_loss: 0.6297
AUC: 0.8699

Epoch 52/80
 - 0s - loss: 0.9934 - val_loss: 0.5543
AUC: 0.8684

Epoch 53/80
 - 0s - loss: 0.9941 - val_loss: 0.5868
AUC: 0.8697

Epoch 54/80
 - 0s - loss: 0.9949 - val_loss: 0.5975
AUC: 0.8694

Epoch 55/80
 - 0s - loss: 0.9881 - val_loss: 0.5801
AUC: 0.8697

Epoch 56/80
 - 0s - loss: 0.9861 - val_loss: 0.5712
AUC: 0.8696

Epoch 57/80
 - 0s - loss: 0.9846 - val_loss: 0.5872
AUC: 0.8697

Epoch 58/80
 - 0s - loss: 0.9898 - val_loss: 0.5993
AUC: 0.8700

Epoch 59/80
 - 0s - loss: 0.9869 - val_loss: 0.5712
AUC: 0.8695

Epoch 60/80
 - 0s - loss: 0.9827 - val_loss: 0.5914
AUC: 0.8700

Epoch 61/80
 - 0s - loss: 0.9883 - val_loss: 0.6019
AUC: 0.8699

Epoch 62/80
 - 0s - loss: 0.9864 - val_loss: 0.6084
AUC: 0.8700

Epoch 63/80
 - 0s - loss: 0.9872 - val_loss: 0.6257
AUC: 0.8701

Epoch 64/80
 - 0s - loss: 0.9859 - val_loss: 0.5597
AUC: 0.8694

Epoch 65/80
 - 0s - loss: 0.9882 - val_loss: 0.5941
AUC: 0.8698

Epoch 66/80
 - 0s - loss: 0.9900 - val_loss: 0.5923
AUC: 0.8698

Epoch 67/80
 - 0s - loss: 0.9895 - val_loss: 0.5948
AUC: 0.8699

Epoch 68/80
 - 0s - loss: 0.9842 - val_loss: 0.5930
AUC: 0.8699

Epoch 69/80
 - 0s - loss: 0.9871 - val_loss: 0.5970
AUC: 0.8699

Epoch 70/80
 - 0s - loss: 0.9831 - val_loss: 0.5975
AUC: 0.8699

Epoch 71/80
 - 0s - loss: 0.9846 - val_loss: 0.5923
AUC: 0.8698

Epoch 72/80
 - 0s - loss: 0.9833 - val_loss: 0.5900
AUC: 0.8698

Epoch 73/80
 - 0s - loss: 0.9847 - val_loss: 0.5947
AUC: 0.8699

Epoch 74/80
 - 0s - loss: 0.9822 - val_loss: 0.5877
AUC: 0.8699

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9913 - val_loss: 0.6032
AUC: 0.8701

Epoch 2/30
 - 0s - loss: 0.9826 - val_loss: 0.5859
AUC: 0.8700

Epoch 3/30
 - 0s - loss: 0.9839 - val_loss: 0.6034
AUC: 0.8703

Epoch 4/30
 - 0s - loss: 0.9850 - val_loss: 0.5833
AUC: 0.8702

Epoch 5/30
 - 0s - loss: 0.9821 - val_loss: 0.5842
AUC: 0.8703

Epoch 6/30
 - 0s - loss: 0.9850 - val_loss: 0.5747
AUC: 0.8703

Epoch 7/30
 - 0s - loss: 0.9807 - val_loss: 0.5855
AUC: 0.8705

Epoch 8/30
 - 0s - loss: 0.9809 - val_loss: 0.5821
AUC: 0.8706

Epoch 9/30
 - 0s - loss: 0.9775 - val_loss: 0.5904
AUC: 0.8707

Epoch 10/30
 - 0s - loss: 0.9728 - val_loss: 0.5827
AUC: 0.8707

Epoch 11/30
 - 0s - loss: 0.9794 - val_loss: 0.5712
AUC: 0.8707

Epoch 12/30
 - 0s - loss: 0.9710 - val_loss: 0.5779
AUC: 0.8708

Epoch 13/30
 - 0s - loss: 0.9753 - val_loss: 0.5797
AUC: 0.8710

Epoch 14/30
 - 0s - loss: 0.9757 - val_loss: 0.5753
AUC: 0.8709

Epoch 15/30
 - 0s - loss: 0.9738 - val_loss: 0.5746
AUC: 0.8710

Epoch 16/30
 - 0s - loss: 0.9691 - val_loss: 0.5860
AUC: 0.8712

Epoch 17/30
 - 0s - loss: 0.9685 - val_loss: 0.5776
AUC: 0.8713

Epoch 18/30
 - 0s - loss: 0.9708 - val_loss: 0.5876
AUC: 0.8715

Epoch 19/30
 - 0s - loss: 0.9665 - val_loss: 0.5908
AUC: 0.8715

Epoch 20/30
 - 0s - loss: 0.9691 - val_loss: 0.5818
AUC: 0.8714

Epoch 21/30
 - 0s - loss: 0.9630 - val_loss: 0.5758
AUC: 0.8715

Epoch 22/30
 - 0s - loss: 0.9654 - val_loss: 0.5811
AUC: 0.8715

Epoch 23/30
 - 0s - loss: 0.9638 - val_loss: 0.5835
AUC: 0.8716

Epoch 24/30
 - 0s - loss: 0.9602 - val_loss: 0.5813
AUC: 0.8716

Epoch 25/30
 - 0s - loss: 0.9663 - val_loss: 0.5831
AUC: 0.8716

Epoch 26/30
 - 0s - loss: 0.9633 - val_loss: 0.5848
AUC: 0.8716

Epoch 27/30
 - 0s - loss: 0.9614 - val_loss: 0.5833
AUC: 0.8716

Epoch 28/30
 - 0s - loss: 0.9636 - val_loss: 0.5846
AUC: 0.8717

Epoch 29/30
 - 0s - loss: 0.9655 - val_loss: 0.5836
AUC: 0.8717

Epoch 30/30
 - 0s - loss: 0.9637 - val_loss: 0.5819
Using TensorFlow backend.
AUC: 0.8717

2019-03-08 01:57:08.381600: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:57:08.544881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:57:08.544925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:57:08.834523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:57:08.834573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:57:08.834582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:57:08.834835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3698
Epoch 2/80
 - 2s - loss: 0.3506
Epoch 3/80
 - 2s - loss: 0.3088
Epoch 4/80
 - 2s - loss: 0.2964
Epoch 5/80
 - 2s - loss: 0.2815
Epoch 6/80
 - 2s - loss: 0.2630
Epoch 7/80
 - 2s - loss: 0.2425
Epoch 8/80
 - 2s - loss: 0.2233
Epoch 9/80
 - 2s - loss: 0.2079
Epoch 10/80
 - 2s - loss: 0.1952
Epoch 11/80
 - 2s - loss: 0.1841
Epoch 12/80
 - 2s - loss: 0.1742
Epoch 13/80
 - 2s - loss: 0.1656
Epoch 14/80
 - 2s - loss: 0.1580
Epoch 15/80
 - 2s - loss: 0.1515
Epoch 16/80
 - 2s - loss: 0.1461
Epoch 17/80
 - 2s - loss: 0.1416
Epoch 18/80
 - 2s - loss: 0.1378
Epoch 19/80
 - 2s - loss: 0.1346
Epoch 20/80
 - 2s - loss: 0.1319
Epoch 21/80
 - 2s - loss: 0.1296
Epoch 22/80
 - 2s - loss: 0.1276
Epoch 23/80
 - 2s - loss: 0.1259
Epoch 24/80
 - 2s - loss: 0.1244
Epoch 25/80
 - 2s - loss: 0.1231
Epoch 26/80
 - 2s - loss: 0.1220
Epoch 27/80
 - 2s - loss: 0.1211
Epoch 28/80
 - 2s - loss: 0.1203
Epoch 29/80
 - 2s - loss: 0.1196
Epoch 30/80
 - 2s - loss: 0.1190
Epoch 31/80
 - 2s - loss: 0.1185
Epoch 32/80
 - 2s - loss: 0.1181
Epoch 33/80
 - 2s - loss: 0.1177
Epoch 34/80
 - 2s - loss: 0.1174
Epoch 35/80
 - 2s - loss: 0.1171
Epoch 36/80
 - 2s - loss: 0.1167
Epoch 37/80
 - 2s - loss: 0.1165
Epoch 38/80
 - 2s - loss: 0.1163
Epoch 39/80
 - 2s - loss: 0.1161
Epoch 40/80
 - 2s - loss: 0.1159
Epoch 41/80
 - 2s - loss: 0.1157
Epoch 42/80
 - 2s - loss: 0.1156
Epoch 43/80
 - 2s - loss: 0.1155
Epoch 44/80
 - 2s - loss: 0.1153
Epoch 45/80
 - 2s - loss: 0.1152
Epoch 46/80
 - 2s - loss: 0.1151
Epoch 47/80
 - 2s - loss: 0.1150
Epoch 48/80
 - 2s - loss: 0.1149
Epoch 49/80
 - 2s - loss: 0.1148
Epoch 50/80
 - 2s - loss: 0.1147
Epoch 51/80
 - 2s - loss: 0.1146
Epoch 52/80
 - 2s - loss: 0.1146
Epoch 53/80
 - 2s - loss: 0.1145
Epoch 54/80
 - 2s - loss: 0.1144
Epoch 55/80
 - 2s - loss: 0.1144
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 01:58:58.071261: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 01:58:58.235333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 01:58:58.235376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 01:58:58.524824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 01:58:58.524876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 01:58:58.524885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 01:58:58.525147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3718
Epoch 2/80
 - 2s - loss: 0.3529
Epoch 3/80
 - 2s - loss: 0.2968
Epoch 4/80
 - 2s - loss: 0.2712
Epoch 5/80
 - 2s - loss: 0.2545
Epoch 6/80
 - 2s - loss: 0.2416
Epoch 7/80
 - 2s - loss: 0.2302
Epoch 8/80
 - 2s - loss: 0.2189
Epoch 9/80
 - 2s - loss: 0.2071
Epoch 10/80
 - 2s - loss: 0.1949
Epoch 11/80
 - 2s - loss: 0.1829
Epoch 12/80
 - 2s - loss: 0.1719
Epoch 13/80
 - 2s - loss: 0.1626
Epoch 14/80
 - 2s - loss: 0.1549
Epoch 15/80
 - 2s - loss: 0.1486
Epoch 16/80
 - 2s - loss: 0.1433
Epoch 17/80
 - 2s - loss: 0.1389
Epoch 18/80
 - 2s - loss: 0.1352
Epoch 19/80
 - 2s - loss: 0.1322
Epoch 20/80
 - 2s - loss: 0.1298
Epoch 21/80
 - 2s - loss: 0.1279
Epoch 22/80
 - 2s - loss: 0.1262
Epoch 23/80
 - 2s - loss: 0.1248
Epoch 24/80
 - 2s - loss: 0.1236
Epoch 25/80
 - 2s - loss: 0.1226
Epoch 26/80
 - 2s - loss: 0.1217
Epoch 27/80
 - 2s - loss: 0.1210
Epoch 28/80
 - 2s - loss: 0.1203
Epoch 29/80
 - 2s - loss: 0.1197
Epoch 30/80
 - 2s - loss: 0.1192
Epoch 31/80
 - 2s - loss: 0.1188
Epoch 32/80
 - 2s - loss: 0.1184
Epoch 33/80
 - 2s - loss: 0.1181
Epoch 34/80
 - 2s - loss: 0.1177
Epoch 35/80
 - 2s - loss: 0.1175
Epoch 36/80
 - 2s - loss: 0.1172
Epoch 37/80
 - 2s - loss: 0.1170
Epoch 38/80
 - 2s - loss: 0.1168
Epoch 39/80
 - 2s - loss: 0.1166
Epoch 40/80
 - 2s - loss: 0.1164
Epoch 41/80
 - 2s - loss: 0.1163
Epoch 42/80
 - 2s - loss: 0.1162
Epoch 43/80
 - 2s - loss: 0.1160
Epoch 44/80
 - 2s - loss: 0.1159
Epoch 45/80
 - 2s - loss: 0.1158
Epoch 46/80
 - 2s - loss: 0.1157
Epoch 47/80
 - 2s - loss: 0.1156
Epoch 48/80
 - 2s - loss: 0.1155
Epoch 49/80
 - 2s - loss: 0.1154
Epoch 50/80
 - 2s - loss: 0.1154
Epoch 51/80
 - 2s - loss: 0.1153
Epoch 52/80
 - 2s - loss: 0.1152
Epoch 53/80
 - 2s - loss: 0.1151
Epoch 54/80
 - 2s - loss: 0.1151
Epoch 55/80
 - 2s - loss: 0.1150
Epoch 56/80
 - 2s - loss: 0.1150
Epoch 57/80
 - 2s - loss: 0.1149
Epoch 58/80
 - 2s - loss: 0.1149
Epoch 59/80
 - 2s - loss: 0.1148
Epoch 60/80
 - 2s - loss: 0.1148
Epoch 61/80
 - 2s - loss: 0.1148
Epoch 62/80
 - 2s - loss: 0.1147
Epoch 63/80
 - 2s - loss: 0.1147
Epoch 64/80
 - 2s - loss: 0.1146
Epoch 65/80
 - 2s - loss: 0.1146
Epoch 66/80
 - 2s - loss: 0.1124
Epoch 67/80
 - 2s - loss: 0.1121
Epoch 68/80
 - 2s - loss: 0.1121
Epoch 69/80
 - 2s - loss: 0.1121
Epoch 70/80
 - 2s - loss: 0.1121
Epoch 71/80
 - 2s - loss: 0.1115
Epoch 72/80
 - 2s - loss: 0.1115
Epoch 73/80
 - 2s - loss: 0.1115
Epoch 74/80
 - 2s - loss: 0.1115
Epoch 75/80
 - 2s - loss: 0.1114
Epoch 76/80
 - 2s - loss: 0.1114
Epoch 77/80
 - 2s - loss: 0.1114
Epoch 78/80
 - 2s - loss: 0.1114
Epoch 79/80
 - 2s - loss: 0.1113
Epoch 80/80
 - 2s - loss: 0.1113
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.5593 - val_loss: 1.6135
AUC: 0.7542

Epoch 2/80
 - 0s - loss: 2.5810 - val_loss: 1.2880
AUC: 0.7967

Epoch 3/80
 - 0s - loss: 1.6854 - val_loss: 0.8112
AUC: 0.8166

Epoch 4/80
 - 0s - loss: 1.3218 - val_loss: 0.7504
AUC: 0.8262

Epoch 5/80
 - 0s - loss: 1.2293 - val_loss: 0.6997
AUC: 0.8347

Epoch 6/80
 - 0s - loss: 1.1864 - val_loss: 0.7127
AUC: 0.8403

Epoch 7/80
 - 0s - loss: 1.1552 - val_loss: 0.6942
AUC: 0.8447

Epoch 8/80
 - 0s - loss: 1.1287 - val_loss: 0.6620
AUC: 0.8460

Epoch 9/80
 - 0s - loss: 1.1219 - val_loss: 0.6560
AUC: 0.8476

Epoch 10/80
 - 0s - loss: 1.1065 - val_loss: 0.6601
AUC: 0.8499

Epoch 11/80
 - 0s - loss: 1.0990 - val_loss: 0.6563
AUC: 0.8515

Epoch 12/80
 - 0s - loss: 1.0903 - val_loss: 0.6224
AUC: 0.8513

Epoch 13/80
 - 0s - loss: 1.0894 - val_loss: 0.6629
AUC: 0.8536

Epoch 14/80
 - 0s - loss: 1.0746 - val_loss: 0.6592
AUC: 0.8538

Epoch 15/80
 - 0s - loss: 1.0714 - val_loss: 0.6163
AUC: 0.8554

Epoch 16/80
 - 0s - loss: 1.0631 - val_loss: 0.6479
AUC: 0.8557

Epoch 17/80
 - 0s - loss: 1.0657 - val_loss: 0.6426
AUC: 0.8563

Epoch 18/80
 - 0s - loss: 1.0530 - val_loss: 0.6459
AUC: 0.8579

Epoch 19/80
 - 0s - loss: 1.0593 - val_loss: 0.6524
AUC: 0.8590

Epoch 20/80
 - 0s - loss: 1.0509 - val_loss: 0.6012
AUC: 0.8584

Epoch 21/80
 - 0s - loss: 1.0409 - val_loss: 0.6612
AUC: 0.8597

Epoch 22/80
 - 0s - loss: 1.0397 - val_loss: 0.6008
AUC: 0.8593

Epoch 23/80
 - 0s - loss: 1.0340 - val_loss: 0.6207
AUC: 0.8594

Epoch 24/80
 - 0s - loss: 1.0403 - val_loss: 0.6485
AUC: 0.8602

Epoch 25/80
 - 0s - loss: 1.0342 - val_loss: 0.6611
AUC: 0.8606

Epoch 26/80
 - 0s - loss: 1.0367 - val_loss: 0.6019
AUC: 0.8601

Epoch 27/80
 - 0s - loss: 1.0271 - val_loss: 0.6634
AUC: 0.8605

Epoch 28/80
 - 0s - loss: 1.0285 - val_loss: 0.6243
AUC: 0.8614

Epoch 29/80
 - 0s - loss: 1.0257 - val_loss: 0.6086
AUC: 0.8621

Epoch 30/80
 - 0s - loss: 1.0235 - val_loss: 0.6351
AUC: 0.8627

Epoch 31/80
 - 0s - loss: 1.0280 - val_loss: 0.6225
AUC: 0.8629

Epoch 32/80
 - 0s - loss: 1.0163 - val_loss: 0.5523
AUC: 0.8622

Epoch 33/80
 - 0s - loss: 1.0214 - val_loss: 0.6506
AUC: 0.8634

Epoch 34/80
 - 0s - loss: 1.0182 - val_loss: 0.6505
AUC: 0.8635

Epoch 35/80
 - 0s - loss: 1.0213 - val_loss: 0.6394
AUC: 0.8635

Epoch 36/80
 - 0s - loss: 1.0180 - val_loss: 0.7143
AUC: 0.8627

Epoch 37/80
 - 0s - loss: 1.0186 - val_loss: 0.6255
AUC: 0.8643

Epoch 38/80
 - 0s - loss: 1.0131 - val_loss: 0.6176
AUC: 0.8640

Epoch 39/80
 - 0s - loss: 1.0088 - val_loss: 0.6065
AUC: 0.8642

Epoch 40/80
 - 0s - loss: 1.0052 - val_loss: 0.5717
AUC: 0.8645

Epoch 41/80
 - 0s - loss: 1.0127 - val_loss: 0.6320
AUC: 0.8651

Epoch 42/80
 - 0s - loss: 1.0015 - val_loss: 0.6051
AUC: 0.8644

Epoch 43/80
 - 0s - loss: 0.9974 - val_loss: 0.5936
AUC: 0.8644

Epoch 44/80
 - 0s - loss: 0.9947 - val_loss: 0.6189
AUC: 0.8650

Epoch 45/80
 - 0s - loss: 0.9939 - val_loss: 0.6345
AUC: 0.8650

Epoch 46/80
 - 0s - loss: 0.9973 - val_loss: 0.6115
AUC: 0.8647

Epoch 47/80
 - 0s - loss: 0.9993 - val_loss: 0.6140
AUC: 0.8653

Epoch 48/80
 - 0s - loss: 0.9982 - val_loss: 0.6097
AUC: 0.8652

Epoch 49/80
 - 0s - loss: 1.0004 - val_loss: 0.6107
AUC: 0.8652

Epoch 50/80
 - 0s - loss: 0.9977 - val_loss: 0.5922
AUC: 0.8652

Epoch 51/80
 - 0s - loss: 0.9942 - val_loss: 0.6020
AUC: 0.8652

Epoch 52/80
 - 0s - loss: 1.0016 - val_loss: 0.6086
AUC: 0.8654

Epoch 53/80
 - 0s - loss: 0.9943 - val_loss: 0.6125
AUC: 0.8654

Epoch 54/80
 - 0s - loss: 0.9947 - val_loss: 0.6151
AUC: 0.8655

Epoch 55/80
 - 0s - loss: 0.9989 - val_loss: 0.6117
AUC: 0.8654

Epoch 56/80
 - 0s - loss: 0.9973 - val_loss: 0.6161
AUC: 0.8654

Epoch 57/80
 - 0s - loss: 0.9914 - val_loss: 0.6117
AUC: 0.8653

Epoch 58/80
 - 0s - loss: 0.9981 - val_loss: 0.6134
AUC: 0.8653

Epoch 59/80
 - 0s - loss: 0.9929 - val_loss: 0.6145
AUC: 0.8653

Epoch 60/80
 - 0s - loss: 0.9908 - val_loss: 0.6138
AUC: 0.8652

Epoch 61/80
 - 0s - loss: 0.9915 - val_loss: 0.6136
AUC: 0.8653

Epoch 62/80
 - 0s - loss: 0.9986 - val_loss: 0.6135
AUC: 0.8652

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9957 - val_loss: 0.6163
AUC: 0.8654

Epoch 2/30
 - 0s - loss: 0.9952 - val_loss: 0.6154
AUC: 0.8655

Epoch 3/30
 - 0s - loss: 0.9981 - val_loss: 0.6103
AUC: 0.8657

Epoch 4/30
 - 0s - loss: 0.9951 - val_loss: 0.6130
AUC: 0.8658

Epoch 5/30
 - 0s - loss: 0.9830 - val_loss: 0.6194
AUC: 0.8659

Epoch 6/30
 - 0s - loss: 0.9925 - val_loss: 0.6113
AUC: 0.8660

Epoch 7/30
 - 0s - loss: 0.9861 - val_loss: 0.6139
AUC: 0.8661

Epoch 8/30
 - 0s - loss: 0.9832 - val_loss: 0.6037
AUC: 0.8663

Epoch 9/30
 - 0s - loss: 0.9859 - val_loss: 0.6189
AUC: 0.8664

Epoch 10/30
 - 0s - loss: 0.9875 - val_loss: 0.6103
AUC: 0.8665

Epoch 11/30
 - 0s - loss: 0.9862 - val_loss: 0.6061
AUC: 0.8667

Epoch 12/30
 - 0s - loss: 0.9860 - val_loss: 0.6189
AUC: 0.8666

Epoch 13/30
 - 0s - loss: 0.9786 - val_loss: 0.6075
AUC: 0.8667

Epoch 14/30
 - 0s - loss: 0.9758 - val_loss: 0.5984
AUC: 0.8669

Epoch 15/30
 - 0s - loss: 0.9789 - val_loss: 0.6068
AUC: 0.8669

Epoch 16/30
 - 0s - loss: 0.9751 - val_loss: 0.6151
AUC: 0.8669

Epoch 17/30
 - 0s - loss: 0.9780 - val_loss: 0.6060
AUC: 0.8673

Epoch 18/30
 - 0s - loss: 0.9726 - val_loss: 0.6149
AUC: 0.8676

Epoch 19/30
 - 0s - loss: 0.9746 - val_loss: 0.6056
AUC: 0.8674

Epoch 20/30
 - 0s - loss: 0.9757 - val_loss: 0.6115
AUC: 0.8676

Epoch 21/30
 - 0s - loss: 0.9749 - val_loss: 0.5957
AUC: 0.8677

Epoch 22/30
 - 0s - loss: 0.9701 - val_loss: 0.6022
AUC: 0.8678

Epoch 23/30
 - 0s - loss: 0.9745 - val_loss: 0.5948
AUC: 0.8678

Epoch 24/30
 - 0s - loss: 0.9705 - val_loss: 0.5989
AUC: 0.8679

Epoch 25/30
 - 0s - loss: 0.9699 - val_loss: 0.5950
AUC: 0.8679

Epoch 26/30
 - 0s - loss: 0.9694 - val_loss: 0.6020
AUC: 0.8680

Epoch 27/30
 - 0s - loss: 0.9680 - val_loss: 0.6079
AUC: 0.8681

Epoch 28/30
 - 0s - loss: 0.9704 - val_loss: 0.6105
AUC: 0.8682

Epoch 29/30
 - 0s - loss: 0.9688 - val_loss: 0.6084
AUC: 0.8683

Epoch 30/30
 - 0s - loss: 0.9621 - val_loss: 0.5875
Using TensorFlow backend.
AUC: 0.8683

2019-03-08 02:02:22.866870: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:02:23.033454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:02:23.033527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:02:23.327445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:02:23.327495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:02:23.327503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:02:23.327757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1535
Epoch 2/80
 - 2s - loss: 0.2169
Epoch 3/80
 - 2s - loss: 0.1722
Epoch 4/80
 - 2s - loss: 0.1639
Epoch 5/80
 - 2s - loss: 0.1557
Epoch 6/80
 - 2s - loss: 0.1454
Epoch 7/80
 - 2s - loss: 0.1343
Epoch 8/80
 - 2s - loss: 0.1235
Epoch 9/80
 - 2s - loss: 0.1136
Epoch 10/80
 - 2s - loss: 0.1051
Epoch 11/80
 - 2s - loss: 0.0981
Epoch 12/80
 - 2s - loss: 0.0923
Epoch 13/80
 - 2s - loss: 0.0872
Epoch 14/80
 - 2s - loss: 0.0825
Epoch 15/80
 - 2s - loss: 0.0783
Epoch 16/80
 - 2s - loss: 0.0745
Epoch 17/80
 - 2s - loss: 0.0712
Epoch 18/80
 - 2s - loss: 0.0685
Epoch 19/80
 - 2s - loss: 0.0661
Epoch 20/80
 - 2s - loss: 0.0641
Epoch 21/80
 - 2s - loss: 0.0623
Epoch 22/80
 - 2s - loss: 0.0609
Epoch 23/80
 - 2s - loss: 0.0596
Epoch 24/80
 - 2s - loss: 0.0585
Epoch 25/80
 - 2s - loss: 0.0576
Epoch 26/80
 - 2s - loss: 0.0567
Epoch 27/80
 - 2s - loss: 0.0560
Epoch 28/80
 - 2s - loss: 0.0554
Epoch 29/80
 - 2s - loss: 0.0549
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:03:31.316338: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:03:31.479835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:03:31.479877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:03:31.772911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:03:31.772960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:03:31.772969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:03:31.773246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1377
Epoch 2/80
 - 2s - loss: 0.2118
Epoch 3/80
 - 2s - loss: 0.1738
Epoch 4/80
 - 2s - loss: 0.1689
Epoch 5/80
 - 2s - loss: 0.1649
Epoch 6/80
 - 2s - loss: 0.1596
Epoch 7/80
 - 2s - loss: 0.1520
Epoch 8/80
 - 2s - loss: 0.1419
Epoch 9/80
 - 2s - loss: 0.1302
Epoch 10/80
 - 2s - loss: 0.1186
Epoch 11/80
 - 2s - loss: 0.1082
Epoch 12/80
 - 2s - loss: 0.0989
Epoch 13/80
 - 2s - loss: 0.0912
Epoch 14/80
 - 2s - loss: 0.0850
Epoch 15/80
 - 2s - loss: 0.0800
Epoch 16/80
 - 2s - loss: 0.0759
Epoch 17/80
 - 2s - loss: 0.0724
Epoch 18/80
 - 2s - loss: 0.0695
Epoch 19/80
 - 2s - loss: 0.0670
Epoch 20/80
 - 2s - loss: 0.0649
Epoch 21/80
 - 2s - loss: 0.0632
Epoch 22/80
 - 2s - loss: 0.0616
Epoch 23/80
 - 2s - loss: 0.0603
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:04:25.258498: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:04:25.422265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:04:25.422311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:04:25.711797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:04:25.711847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:04:25.711855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:04:25.712107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1556
Epoch 2/80
 - 2s - loss: 0.2145
Epoch 3/80
 - 2s - loss: 0.1716
Epoch 4/80
 - 2s - loss: 0.1629
Epoch 5/80
 - 2s - loss: 0.1530
Epoch 6/80
 - 2s - loss: 0.1407
Epoch 7/80
 - 2s - loss: 0.1298
Epoch 8/80
 - 2s - loss: 0.1214
Epoch 9/80
 - 2s - loss: 0.1140
Epoch 10/80
 - 2s - loss: 0.1067
Epoch 11/80
 - 2s - loss: 0.0992
Epoch 12/80
 - 2s - loss: 0.0921
Epoch 13/80
 - 2s - loss: 0.0860
Epoch 14/80
 - 2s - loss: 0.0810
Epoch 15/80
 - 2s - loss: 0.0770
Epoch 16/80
 - 2s - loss: 0.0736
Epoch 17/80
 - 2s - loss: 0.0707
Epoch 18/80
 - 2s - loss: 0.0681
Epoch 19/80
 - 2s - loss: 0.0659
Epoch 20/80
 - 2s - loss: 0.0639
Epoch 21/80
 - 2s - loss: 0.0621
Epoch 22/80
 - 2s - loss: 0.0606
Epoch 23/80
 - 2s - loss: 0.0593
Epoch 24/80
 - 2s - loss: 0.0581
Epoch 25/80
 - 2s - loss: 0.0571
Epoch 26/80
 - 2s - loss: 0.0562
Epoch 27/80
 - 2s - loss: 0.0554
Epoch 28/80
 - 2s - loss: 0.0548
Epoch 29/80
 - 2s - loss: 0.0543
Epoch 30/80
 - 2s - loss: 0.0538
Epoch 31/80
 - 2s - loss: 0.0534
Epoch 32/80
 - 2s - loss: 0.0530
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0525
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0520
Epoch 37/80
 - 2s - loss: 0.0518
Epoch 38/80
 - 2s - loss: 0.0517
Epoch 39/80
 - 2s - loss: 0.0515
Epoch 40/80
 - 2s - loss: 0.0514
Epoch 41/80
 - 2s - loss: 0.0513
Epoch 42/80
 - 2s - loss: 0.0512
Epoch 43/80
 - 2s - loss: 0.0511
Epoch 44/80
 - 2s - loss: 0.0510
Epoch 45/80
 - 2s - loss: 0.0509
Epoch 46/80
 - 2s - loss: 0.0508
Epoch 47/80
 - 2s - loss: 0.0507
Epoch 48/80
 - 2s - loss: 0.0506
Epoch 49/80
 - 2s - loss: 0.0506
Epoch 50/80
 - 2s - loss: 0.0505
Epoch 51/80
 - 2s - loss: 0.0505
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0504
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0503
Epoch 56/80
 - 2s - loss: 0.0502
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0502
Epoch 59/80
 - 2s - loss: 0.0501
Epoch 60/80
 - 2s - loss: 0.0501
Epoch 61/80
 - 2s - loss: 0.0501
Epoch 62/80
 - 2s - loss: 0.0500
Epoch 63/80
 - 2s - loss: 0.0500
Epoch 64/80
 - 2s - loss: 0.0489
Epoch 65/80
 - 2s - loss: 0.0488
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0487
Epoch 68/80
 - 2s - loss: 0.0487
Epoch 69/80
 - 2s - loss: 0.0485
Epoch 70/80
 - 2s - loss: 0.0485
Epoch 71/80
 - 2s - loss: 0.0485
Epoch 72/80
 - 2s - loss: 0.0485
Epoch 73/80
 - 2s - loss: 0.0484
Epoch 74/80
 - 2s - loss: 0.0484
Epoch 75/80
 - 2s - loss: 0.0484
Epoch 76/80
 - 2s - loss: 0.0484
Epoch 77/80
 - 2s - loss: 0.0484
Epoch 78/80
 - 2s - loss: 0.0484
Epoch 79/80
 - 2s - loss: 0.0484
Epoch 80/80
 - 2s - loss: 0.0484
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.9933 - val_loss: 1.7685
AUC: 0.7557

Epoch 2/80
 - 0s - loss: 2.7910 - val_loss: 1.0417
AUC: 0.7868

Epoch 3/80
 - 0s - loss: 1.7374 - val_loss: 0.7987
AUC: 0.8037

Epoch 4/80
 - 0s - loss: 1.3916 - val_loss: 0.7632
AUC: 0.8191

Epoch 5/80
 - 0s - loss: 1.2751 - val_loss: 0.7295
AUC: 0.8276

Epoch 6/80
 - 0s - loss: 1.2152 - val_loss: 0.6819
AUC: 0.8358

Epoch 7/80
 - 0s - loss: 1.1806 - val_loss: 0.6998
AUC: 0.8430

Epoch 8/80
 - 0s - loss: 1.1556 - val_loss: 0.6989
AUC: 0.8475

Epoch 9/80
 - 0s - loss: 1.1503 - val_loss: 0.6713
AUC: 0.8508

Epoch 10/80
 - 0s - loss: 1.1159 - val_loss: 0.6280
AUC: 0.8530

Epoch 11/80
 - 0s - loss: 1.1092 - val_loss: 0.6798
AUC: 0.8562

Epoch 12/80
 - 0s - loss: 1.0963 - val_loss: 0.7107
AUC: 0.8592

Epoch 13/80
 - 0s - loss: 1.0850 - val_loss: 0.6214
AUC: 0.8578

Epoch 14/80
 - 0s - loss: 1.0808 - val_loss: 0.6549
AUC: 0.8597

Epoch 15/80
 - 0s - loss: 1.0707 - val_loss: 0.6274
AUC: 0.8612

Epoch 16/80
 - 0s - loss: 1.0620 - val_loss: 0.6475
AUC: 0.8621

Epoch 17/80
 - 0s - loss: 1.0615 - val_loss: 0.6407
AUC: 0.8636

Epoch 18/80
 - 0s - loss: 1.0552 - val_loss: 0.6105
AUC: 0.8640

Epoch 19/80
 - 0s - loss: 1.0513 - val_loss: 0.5671
AUC: 0.8636

Epoch 20/80
 - 0s - loss: 1.0511 - val_loss: 0.6581
AUC: 0.8663

Epoch 21/80
 - 0s - loss: 1.0407 - val_loss: 0.5901
AUC: 0.8665

Epoch 22/80
 - 0s - loss: 1.0374 - val_loss: 0.6460
AUC: 0.8675

Epoch 23/80
 - 0s - loss: 1.0297 - val_loss: 0.5992
AUC: 0.8668

Epoch 24/80
 - 0s - loss: 1.0258 - val_loss: 0.6033
AUC: 0.8674

Epoch 25/80
 - 0s - loss: 1.0299 - val_loss: 0.6011
AUC: 0.8671

Epoch 26/80
 - 0s - loss: 1.0283 - val_loss: 0.6380
AUC: 0.8685

Epoch 27/80
 - 0s - loss: 1.0196 - val_loss: 0.6063
AUC: 0.8675

Epoch 28/80
 - 0s - loss: 1.0176 - val_loss: 0.6071
AUC: 0.8694

Epoch 29/80
 - 0s - loss: 1.0148 - val_loss: 0.6146
AUC: 0.8698

Epoch 30/80
 - 0s - loss: 1.0203 - val_loss: 0.6471
AUC: 0.8706

Epoch 31/80
 - 0s - loss: 1.0059 - val_loss: 0.6444
AUC: 0.8706

Epoch 32/80
 - 0s - loss: 1.0129 - val_loss: 0.6253
AUC: 0.8704

Epoch 33/80
 - 0s - loss: 1.0104 - val_loss: 0.6180
AUC: 0.8706

Epoch 34/80
 - 0s - loss: 1.0076 - val_loss: 0.6125
AUC: 0.8705

Epoch 35/80
 - 0s - loss: 1.0067 - val_loss: 0.6131
AUC: 0.8705

Epoch 36/80
 - 0s - loss: 1.0076 - val_loss: 0.6057
AUC: 0.8704

Epoch 37/80
 - 0s - loss: 1.0085 - val_loss: 0.6151
AUC: 0.8707

Epoch 38/80
 - 0s - loss: 1.0043 - val_loss: 0.6096
AUC: 0.8706

Epoch 39/80
 - 0s - loss: 1.0097 - val_loss: 0.6044
AUC: 0.8702

Epoch 40/80
 - 0s - loss: 1.0079 - val_loss: 0.6107
AUC: 0.8704

Epoch 41/80
 - 0s - loss: 1.0061 - val_loss: 0.6126
AUC: 0.8705

Epoch 42/80
 - 0s - loss: 1.0092 - val_loss: 0.6139
AUC: 0.8707

Epoch 43/80
 - 0s - loss: 1.0091 - val_loss: 0.6103
AUC: 0.8707

Epoch 44/80
 - 0s - loss: 1.0057 - val_loss: 0.6133
AUC: 0.8707

Epoch 45/80
 - 0s - loss: 1.0075 - val_loss: 0.6132
AUC: 0.8707

Epoch 46/80
 - 0s - loss: 1.0002 - val_loss: 0.6166
AUC: 0.8708

Epoch 47/80
 - 0s - loss: 1.0064 - val_loss: 0.6102
AUC: 0.8708

Epoch 48/80
 - 0s - loss: 1.0046 - val_loss: 0.6079
AUC: 0.8708

Epoch 49/80
 - 0s - loss: 1.0059 - val_loss: 0.6131
AUC: 0.8708

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0063 - val_loss: 0.6265
AUC: 0.8712

Epoch 2/30
 - 0s - loss: 1.0108 - val_loss: 0.6051
AUC: 0.8709

Epoch 3/30
 - 0s - loss: 1.0019 - val_loss: 0.6081
AUC: 0.8711

Epoch 4/30
 - 0s - loss: 0.9981 - val_loss: 0.6049
AUC: 0.8711

Epoch 5/30
 - 0s - loss: 0.9972 - val_loss: 0.5906
AUC: 0.8711

Epoch 6/30
 - 0s - loss: 1.0052 - val_loss: 0.5983
AUC: 0.8715

Epoch 7/30
 - 0s - loss: 1.0023 - val_loss: 0.6078
AUC: 0.8718

Epoch 8/30
 - 0s - loss: 0.9898 - val_loss: 0.6211
AUC: 0.8723

Epoch 9/30
 - 0s - loss: 0.9936 - val_loss: 0.5899
AUC: 0.8718

Epoch 10/30
 - 0s - loss: 0.9963 - val_loss: 0.6135
AUC: 0.8723

Epoch 11/30
 - 0s - loss: 0.9917 - val_loss: 0.5993
AUC: 0.8723

Epoch 12/30
 - 0s - loss: 0.9940 - val_loss: 0.6098
AUC: 0.8726

Epoch 13/30
 - 0s - loss: 0.9935 - val_loss: 0.6113
AUC: 0.8727

Epoch 14/30
 - 0s - loss: 0.9877 - val_loss: 0.6092
AUC: 0.8727

Epoch 15/30
 - 0s - loss: 0.9909 - val_loss: 0.5995
AUC: 0.8728

Epoch 16/30
 - 0s - loss: 0.9927 - val_loss: 0.6070
AUC: 0.8727

Epoch 17/30
 - 0s - loss: 0.9884 - val_loss: 0.6082
AUC: 0.8729

Epoch 18/30
 - 0s - loss: 0.9883 - val_loss: 0.6211
AUC: 0.8731

Epoch 19/30
 - 0s - loss: 0.9832 - val_loss: 0.6027
AUC: 0.8731

Epoch 20/30
 - 0s - loss: 0.9815 - val_loss: 0.6032
AUC: 0.8731

Epoch 21/30
 - 0s - loss: 0.9829 - val_loss: 0.5970
AUC: 0.8730

Epoch 22/30
 - 0s - loss: 0.9933 - val_loss: 0.6031
AUC: 0.8731

Epoch 23/30
 - 0s - loss: 0.9801 - val_loss: 0.5999
AUC: 0.8731

Epoch 24/30
 - 0s - loss: 0.9855 - val_loss: 0.6008
AUC: 0.8732

Epoch 25/30
 - 0s - loss: 0.9869 - val_loss: 0.6040
AUC: 0.8733

Epoch 26/30
 - 0s - loss: 0.9786 - val_loss: 0.5989
AUC: 0.8732

Epoch 27/30
 - 0s - loss: 0.9865 - val_loss: 0.6003
AUC: 0.8732

Epoch 28/30
 - 0s - loss: 0.9813 - val_loss: 0.6017
AUC: 0.8733

Epoch 29/30
 - 0s - loss: 0.9810 - val_loss: 0.5977
AUC: 0.8733

Epoch 30/30
 - 0s - loss: 0.9833 - val_loss: 0.5984
Using TensorFlow backend.
AUC: 0.8733

2019-03-08 02:07:42.777255: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:07:42.948282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:07:42.948326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:07:43.246984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:07:43.247032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:07:43.247040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:07:43.247321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6849
Epoch 2/80
 - 2s - loss: 0.1317
Epoch 3/80
 - 2s - loss: 0.0722
Epoch 4/80
 - 2s - loss: 0.0643
Epoch 5/80
 - 2s - loss: 0.0593
Epoch 6/80
 - 2s - loss: 0.0546
Epoch 7/80
 - 2s - loss: 0.0508
Epoch 8/80
 - 2s - loss: 0.0479
Epoch 9/80
 - 2s - loss: 0.0454
Epoch 10/80
 - 2s - loss: 0.0433
Epoch 11/80
 - 2s - loss: 0.0413
Epoch 12/80
 - 2s - loss: 0.0393
Epoch 13/80
 - 2s - loss: 0.0373
Epoch 14/80
 - 2s - loss: 0.0352
Epoch 15/80
 - 2s - loss: 0.0332
Epoch 16/80
 - 2s - loss: 0.0313
Epoch 17/80
 - 2s - loss: 0.0296
Epoch 18/80
 - 2s - loss: 0.0282
Epoch 19/80
 - 2s - loss: 0.0268
Epoch 20/80
 - 2s - loss: 0.0256
Epoch 21/80
 - 2s - loss: 0.0245
Epoch 22/80
 - 2s - loss: 0.0235
Epoch 23/80
 - 2s - loss: 0.0226
Epoch 24/80
 - 2s - loss: 0.0218
Epoch 25/80
 - 2s - loss: 0.0211
Epoch 26/80
 - 2s - loss: 0.0205
Epoch 27/80
 - 2s - loss: 0.0200
Epoch 28/80
 - 2s - loss: 0.0195
Epoch 29/80
 - 2s - loss: 0.0192
Epoch 30/80
 - 2s - loss: 0.0189
Epoch 31/80
 - 2s - loss: 0.0186
Epoch 32/80
 - 2s - loss: 0.0183
Epoch 33/80
 - 2s - loss: 0.0181
Epoch 34/80
 - 2s - loss: 0.0179
Epoch 35/80
 - 2s - loss: 0.0178
Epoch 36/80
 - 2s - loss: 0.0176
Epoch 37/80
 - 2s - loss: 0.0175
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0167
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:09:17.087426: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:09:17.253279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:09:17.253322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:09:17.546110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:09:17.546161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:09:17.546175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:09:17.546429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6832
Epoch 2/80
 - 2s - loss: 0.1294
Epoch 3/80
 - 2s - loss: 0.0725
Epoch 4/80
 - 2s - loss: 0.0665
Epoch 5/80
 - 2s - loss: 0.0641
Epoch 6/80
 - 2s - loss: 0.0621
Epoch 7/80
 - 2s - loss: 0.0595
Epoch 8/80
 - 2s - loss: 0.0562
Epoch 9/80
 - 2s - loss: 0.0523
Epoch 10/80
 - 2s - loss: 0.0482
Epoch 11/80
 - 2s - loss: 0.0444
Epoch 12/80
 - 2s - loss: 0.0410
Epoch 13/80
 - 2s - loss: 0.0381
Epoch 14/80
 - 2s - loss: 0.0355
Epoch 15/80
 - 2s - loss: 0.0333
Epoch 16/80
 - 2s - loss: 0.0312
Epoch 17/80
 - 2s - loss: 0.0294
Epoch 18/80
 - 2s - loss: 0.0277
Epoch 19/80
 - 2s - loss: 0.0262
Epoch 20/80
 - 2s - loss: 0.0249
Epoch 21/80
 - 2s - loss: 0.0238
Epoch 22/80
 - 2s - loss: 0.0228
Epoch 23/80
 - 2s - loss: 0.0220
Epoch 24/80
 - 2s - loss: 0.0213
Epoch 25/80
 - 2s - loss: 0.0207
Epoch 26/80
 - 2s - loss: 0.0202
Epoch 27/80
 - 2s - loss: 0.0198
Epoch 28/80
 - 2s - loss: 0.0194
Epoch 29/80
 - 2s - loss: 0.0191
Epoch 30/80
 - 2s - loss: 0.0188
Epoch 31/80
 - 2s - loss: 0.0186
Epoch 32/80
 - 2s - loss: 0.0183
Epoch 33/80
 - 2s - loss: 0.0181
Epoch 34/80
 - 2s - loss: 0.0179
Epoch 35/80
 - 2s - loss: 0.0178
Epoch 36/80
 - 2s - loss: 0.0176
Epoch 37/80
 - 2s - loss: 0.0175
Epoch 38/80
 - 2s - loss: 0.0174
Epoch 39/80
 - 2s - loss: 0.0173
Epoch 40/80
 - 2s - loss: 0.0172
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0170
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0169
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0161
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0160
Epoch 60/80
 - 2s - loss: 0.0160
Epoch 61/80
 - 2s - loss: 0.0160
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.2901 - val_loss: 1.3781
AUC: 0.7576

Epoch 2/80
 - 0s - loss: 2.4717 - val_loss: 0.8821
AUC: 0.7853

Epoch 3/80
 - 0s - loss: 1.6143 - val_loss: 0.9026
AUC: 0.8095

Epoch 4/80
 - 0s - loss: 1.3301 - val_loss: 0.7605
AUC: 0.8201

Epoch 5/80
 - 0s - loss: 1.2475 - val_loss: 0.7337
AUC: 0.8329

Epoch 6/80
 - 0s - loss: 1.1851 - val_loss: 0.6823
AUC: 0.8377

Epoch 7/80
 - 0s - loss: 1.1632 - val_loss: 0.7053
AUC: 0.8438

Epoch 8/80
 - 0s - loss: 1.1342 - val_loss: 0.7497
AUC: 0.8490

Epoch 9/80
 - 0s - loss: 1.1192 - val_loss: 0.6561
AUC: 0.8486

Epoch 10/80
 - 0s - loss: 1.1135 - val_loss: 0.6771
AUC: 0.8524

Epoch 11/80
 - 0s - loss: 1.1026 - val_loss: 0.6374
AUC: 0.8539

Epoch 12/80
 - 0s - loss: 1.0849 - val_loss: 0.6673
AUC: 0.8556

Epoch 13/80
 - 0s - loss: 1.0811 - val_loss: 0.5986
AUC: 0.8558

Epoch 14/80
 - 0s - loss: 1.0812 - val_loss: 0.6727
AUC: 0.8579

Epoch 15/80
 - 0s - loss: 1.0714 - val_loss: 0.6303
AUC: 0.8585

Epoch 16/80
 - 0s - loss: 1.0662 - val_loss: 0.5975
AUC: 0.8581

Epoch 17/80
 - 0s - loss: 1.0612 - val_loss: 0.6325
AUC: 0.8594

Epoch 18/80
 - 0s - loss: 1.0611 - val_loss: 0.7050
AUC: 0.8612

Epoch 19/80
 - 0s - loss: 1.0546 - val_loss: 0.6720
AUC: 0.8617

Epoch 20/80
 - 0s - loss: 1.0472 - val_loss: 0.6305
AUC: 0.8620

Epoch 21/80
 - 0s - loss: 1.0507 - val_loss: 0.6245
AUC: 0.8620

Epoch 22/80
 - 0s - loss: 1.0487 - val_loss: 0.6368
AUC: 0.8621

Epoch 23/80
 - 0s - loss: 1.0473 - val_loss: 0.6853
AUC: 0.8646

Epoch 24/80
 - 0s - loss: 1.0409 - val_loss: 0.6233
AUC: 0.8635

Epoch 25/80
 - 0s - loss: 1.0322 - val_loss: 0.6186
AUC: 0.8644

Epoch 26/80
 - 0s - loss: 1.0308 - val_loss: 0.6446
AUC: 0.8654

Epoch 27/80
 - 0s - loss: 1.0260 - val_loss: 0.6309
AUC: 0.8654

Epoch 28/80
 - 0s - loss: 1.0231 - val_loss: 0.6423
AUC: 0.8654

Epoch 29/80
 - 0s - loss: 1.0291 - val_loss: 0.6299
AUC: 0.8652

Epoch 30/80
 - 0s - loss: 1.0244 - val_loss: 0.6228
AUC: 0.8650

Epoch 31/80
 - 0s - loss: 1.0239 - val_loss: 0.6303
AUC: 0.8652

Epoch 32/80
 - 0s - loss: 1.0196 - val_loss: 0.6557
AUC: 0.8655

Epoch 33/80
 - 0s - loss: 1.0232 - val_loss: 0.6256
AUC: 0.8651

Epoch 34/80
 - 0s - loss: 1.0214 - val_loss: 0.6307
AUC: 0.8656

Epoch 35/80
 - 0s - loss: 1.0203 - val_loss: 0.6403
AUC: 0.8656

Epoch 36/80
 - 0s - loss: 1.0177 - val_loss: 0.6355
AUC: 0.8656

Epoch 37/80
 - 0s - loss: 1.0167 - val_loss: 0.6208
AUC: 0.8655

Epoch 38/80
 - 0s - loss: 1.0204 - val_loss: 0.6203
AUC: 0.8654

Epoch 39/80
 - 0s - loss: 1.0149 - val_loss: 0.6257
AUC: 0.8656

Epoch 40/80
 - 0s - loss: 1.0179 - val_loss: 0.6183
AUC: 0.8654

Epoch 41/80
 - 0s - loss: 1.0208 - val_loss: 0.6207
AUC: 0.8655

Epoch 42/80
 - 0s - loss: 1.0221 - val_loss: 0.6262
AUC: 0.8656

Epoch 43/80
 - 0s - loss: 1.0119 - val_loss: 0.6226
AUC: 0.8656

Epoch 44/80
 - 0s - loss: 1.0194 - val_loss: 0.6264
AUC: 0.8657

Epoch 45/80
 - 0s - loss: 1.0146 - val_loss: 0.6176
AUC: 0.8656

Epoch 46/80
 - 0s - loss: 1.0173 - val_loss: 0.6232
AUC: 0.8658

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0196 - val_loss: 0.6254
AUC: 0.8660

Epoch 2/30
 - 0s - loss: 1.0224 - val_loss: 0.6190
AUC: 0.8659

Epoch 3/30
 - 0s - loss: 1.0151 - val_loss: 0.6229
AUC: 0.8661

Epoch 4/30
 - 0s - loss: 1.0213 - val_loss: 0.6196
AUC: 0.8661

Epoch 5/30
 - 0s - loss: 1.0123 - val_loss: 0.6175
AUC: 0.8663

Epoch 6/30
 - 0s - loss: 1.0132 - val_loss: 0.6250
AUC: 0.8666

Epoch 7/30
 - 0s - loss: 1.0118 - val_loss: 0.6253
AUC: 0.8668

Epoch 8/30
 - 0s - loss: 1.0115 - val_loss: 0.6307
AUC: 0.8670

Epoch 9/30
 - 0s - loss: 1.0120 - val_loss: 0.6233
AUC: 0.8668

Epoch 10/30
 - 0s - loss: 1.0134 - val_loss: 0.6254
AUC: 0.8670

Epoch 11/30
 - 0s - loss: 1.0007 - val_loss: 0.6142
AUC: 0.8670

Epoch 12/30
 - 0s - loss: 1.0013 - val_loss: 0.6195
AUC: 0.8672

Epoch 13/30
 - 0s - loss: 1.0068 - val_loss: 0.6106
AUC: 0.8673

Epoch 14/30
 - 0s - loss: 1.0010 - val_loss: 0.6195
AUC: 0.8674

Epoch 15/30
 - 0s - loss: 0.9982 - val_loss: 0.6151
AUC: 0.8675

Epoch 16/30
 - 0s - loss: 1.0050 - val_loss: 0.6104
AUC: 0.8675

Epoch 17/30
 - 0s - loss: 1.0035 - val_loss: 0.6232
AUC: 0.8678

Epoch 18/30
 - 0s - loss: 0.9987 - val_loss: 0.6322
AUC: 0.8680

Epoch 19/30
 - 0s - loss: 0.9935 - val_loss: 0.6102
AUC: 0.8679

Epoch 20/30
 - 0s - loss: 0.9909 - val_loss: 0.6271
AUC: 0.8682

Epoch 21/30
 - 0s - loss: 0.9948 - val_loss: 0.6064
AUC: 0.8681

Epoch 22/30
 - 0s - loss: 0.9884 - val_loss: 0.6160
AUC: 0.8682

Epoch 23/30
 - 0s - loss: 0.9882 - val_loss: 0.6109
AUC: 0.8684

Epoch 24/30
 - 0s - loss: 0.9983 - val_loss: 0.5968
AUC: 0.8683

Epoch 25/30
 - 0s - loss: 0.9916 - val_loss: 0.6183
AUC: 0.8686

Epoch 26/30
 - 0s - loss: 0.9849 - val_loss: 0.6077
AUC: 0.8685

Epoch 27/30
 - 0s - loss: 0.9880 - val_loss: 0.6005
AUC: 0.8684

Epoch 28/30
 - 0s - loss: 0.9834 - val_loss: 0.5903
AUC: 0.8683

Epoch 29/30
 - 0s - loss: 0.9857 - val_loss: 0.6012
AUC: 0.8686

Epoch 30/30
 - 0s - loss: 0.9880 - val_loss: 0.5918
Using TensorFlow backend.
AUC: 0.8687

2019-03-08 02:12:33.177170: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:12:33.356336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:12:33.356389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:12:33.653482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:12:33.653521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:12:33.653529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:12:33.653796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6918
Epoch 2/80
 - 2s - loss: 0.1302
Epoch 3/80
 - 2s - loss: 0.0725
Epoch 4/80
 - 2s - loss: 0.0656
Epoch 5/80
 - 2s - loss: 0.0626
Epoch 6/80
 - 2s - loss: 0.0600
Epoch 7/80
 - 2s - loss: 0.0570
Epoch 8/80
 - 2s - loss: 0.0538
Epoch 9/80
 - 2s - loss: 0.0506
Epoch 10/80
 - 2s - loss: 0.0476
Epoch 11/80
 - 2s - loss: 0.0449
Epoch 12/80
 - 2s - loss: 0.0422
Epoch 13/80
 - 2s - loss: 0.0394
Epoch 14/80
 - 2s - loss: 0.0367
Epoch 15/80
 - 2s - loss: 0.0341
Epoch 16/80
 - 2s - loss: 0.0316
Epoch 17/80
 - 2s - loss: 0.0295
Epoch 18/80
 - 2s - loss: 0.0276
Epoch 19/80
 - 2s - loss: 0.0260
Epoch 20/80
 - 2s - loss: 0.0246
Epoch 21/80
 - 2s - loss: 0.0235
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0217
Epoch 24/80
 - 2s - loss: 0.0210
Epoch 25/80
 - 2s - loss: 0.0204
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0195
Epoch 28/80
 - 2s - loss: 0.0191
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0168
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Epoch 53/80
 - 2s - loss: 0.0162
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0160
Epoch 60/80
 - 2s - loss: 0.0160
Epoch 61/80
 - 2s - loss: 0.0160
Epoch 62/80
 - 2s - loss: 0.0160
Epoch 63/80
 - 2s - loss: 0.0160
Epoch 64/80
 - 2s - loss: 0.0160
Epoch 65/80
 - 2s - loss: 0.0160
Epoch 66/80
 - 2s - loss: 0.0160
Epoch 67/80
 - 2s - loss: 0.0160
Epoch 68/80
 - 2s - loss: 0.0160
Epoch 69/80
 - 2s - loss: 0.0160
Epoch 70/80
 - 2s - loss: 0.0160
Epoch 71/80
 - 2s - loss: 0.0160
Epoch 72/80
 - 2s - loss: 0.0160
Epoch 73/80
 - 2s - loss: 0.0160
Epoch 74/80
 - 2s - loss: 0.0160
Epoch 75/80
 - 2s - loss: 0.0160
Epoch 76/80
 - 2s - loss: 0.0160
Epoch 77/80
 - 2s - loss: 0.0160
Epoch 78/80
 - 2s - loss: 0.0160
Epoch 79/80
 - 2s - loss: 0.0160
Epoch 80/80
 - 2s - loss: 0.0160
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.9307 - val_loss: 1.3067
AUC: 0.7748

Epoch 2/80
 - 0s - loss: 2.2072 - val_loss: 0.7924
AUC: 0.8039

Epoch 3/80
 - 0s - loss: 1.5038 - val_loss: 0.7233
AUC: 0.8267

Epoch 4/80
 - 0s - loss: 1.3003 - val_loss: 0.7117
AUC: 0.8358

Epoch 5/80
 - 0s - loss: 1.2053 - val_loss: 0.7273
AUC: 0.8434

Epoch 6/80
 - 0s - loss: 1.1671 - val_loss: 0.7163
AUC: 0.8467

Epoch 7/80
 - 0s - loss: 1.1402 - val_loss: 0.6299
AUC: 0.8448

Epoch 8/80
 - 0s - loss: 1.1204 - val_loss: 0.7230
AUC: 0.8506

Epoch 9/80
 - 0s - loss: 1.1089 - val_loss: 0.7137
AUC: 0.8523

Epoch 10/80
 - 0s - loss: 1.0984 - val_loss: 0.7049
AUC: 0.8534

Epoch 11/80
 - 0s - loss: 1.0844 - val_loss: 0.6680
AUC: 0.8523

Epoch 12/80
 - 0s - loss: 1.0836 - val_loss: 0.6220
AUC: 0.8535

Epoch 13/80
 - 0s - loss: 1.0796 - val_loss: 0.6397
AUC: 0.8531

Epoch 14/80
 - 0s - loss: 1.0677 - val_loss: 0.6128
AUC: 0.8542

Epoch 15/80
 - 0s - loss: 1.0619 - val_loss: 0.6596
AUC: 0.8566

Epoch 16/80
 - 0s - loss: 1.0570 - val_loss: 0.6304
AUC: 0.8565

Epoch 17/80
 - 0s - loss: 1.0551 - val_loss: 0.5756
AUC: 0.8558

Epoch 18/80
 - 0s - loss: 1.0553 - val_loss: 0.6271
AUC: 0.8582

Epoch 19/80
 - 0s - loss: 1.0446 - val_loss: 0.6142
AUC: 0.8571

Epoch 20/80
 - 0s - loss: 1.0426 - val_loss: 0.6532
AUC: 0.8586

Epoch 21/80
 - 0s - loss: 1.0365 - val_loss: 0.6838
AUC: 0.8600

Epoch 22/80
 - 0s - loss: 1.0302 - val_loss: 0.6205
AUC: 0.8587

Epoch 23/80
 - 0s - loss: 1.0294 - val_loss: 0.6160
AUC: 0.8591

Epoch 24/80
 - 0s - loss: 1.0383 - val_loss: 0.6449
AUC: 0.8601

Epoch 25/80
 - 0s - loss: 1.0312 - val_loss: 0.6988
AUC: 0.8604

Epoch 26/80
 - 0s - loss: 1.0263 - val_loss: 0.6017
AUC: 0.8602

Epoch 27/80
 - 0s - loss: 1.0253 - val_loss: 0.6536
AUC: 0.8608

Epoch 28/80
 - 0s - loss: 1.0184 - val_loss: 0.6152
AUC: 0.8606

Epoch 29/80
 - 0s - loss: 1.0143 - val_loss: 0.6361
AUC: 0.8608

Epoch 30/80
 - 0s - loss: 1.0123 - val_loss: 0.6145
AUC: 0.8609

Epoch 31/80
 - 0s - loss: 1.0146 - val_loss: 0.6224
AUC: 0.8608

Epoch 32/80
 - 0s - loss: 1.0100 - val_loss: 0.6280
AUC: 0.8609

Epoch 33/80
 - 0s - loss: 1.0144 - val_loss: 0.6165
AUC: 0.8609

Epoch 34/80
 - 0s - loss: 1.0170 - val_loss: 0.6124
AUC: 0.8609

Epoch 35/80
 - 0s - loss: 1.0102 - val_loss: 0.6042
AUC: 0.8609

Epoch 36/80
 - 0s - loss: 1.0134 - val_loss: 0.6349
AUC: 0.8615

Epoch 37/80
 - 0s - loss: 1.0055 - val_loss: 0.6031
AUC: 0.8612

Epoch 38/80
 - 0s - loss: 1.0062 - val_loss: 0.6301
AUC: 0.8615

Epoch 39/80
 - 0s - loss: 1.0070 - val_loss: 0.6218
AUC: 0.8614

Epoch 40/80
 - 0s - loss: 1.0062 - val_loss: 0.6175
AUC: 0.8614

Epoch 41/80
 - 0s - loss: 1.0141 - val_loss: 0.6212
AUC: 0.8614

Epoch 42/80
 - 0s - loss: 1.0068 - val_loss: 0.6219
AUC: 0.8614

Epoch 43/80
 - 0s - loss: 1.0036 - val_loss: 0.6260
AUC: 0.8614

Epoch 44/80
 - 0s - loss: 1.0118 - val_loss: 0.6209
AUC: 0.8614

Epoch 45/80
 - 0s - loss: 1.0116 - val_loss: 0.6243
AUC: 0.8615

Epoch 46/80
 - 0s - loss: 1.0061 - val_loss: 0.6184
AUC: 0.8614

Epoch 47/80
 - 0s - loss: 1.0090 - val_loss: 0.6238
AUC: 0.8615

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0104 - val_loss: 0.6263
AUC: 0.8616

Epoch 2/30
 - 0s - loss: 1.0117 - val_loss: 0.6034
AUC: 0.8613

Epoch 3/30
 - 0s - loss: 1.0118 - val_loss: 0.6219
AUC: 0.8617

Epoch 4/30
 - 0s - loss: 1.0020 - val_loss: 0.6260
AUC: 0.8619

Epoch 5/30
 - 0s - loss: 1.0030 - val_loss: 0.6243
AUC: 0.8622

Epoch 6/30
 - 0s - loss: 1.0041 - val_loss: 0.6262
AUC: 0.8624

Epoch 7/30
 - 0s - loss: 1.0025 - val_loss: 0.6186
AUC: 0.8626

Epoch 8/30
 - 0s - loss: 1.0013 - val_loss: 0.6222
AUC: 0.8626

Epoch 9/30
 - 0s - loss: 0.9983 - val_loss: 0.6137
AUC: 0.8626

Epoch 10/30
 - 0s - loss: 0.9973 - val_loss: 0.6096
AUC: 0.8627

Epoch 11/30
 - 0s - loss: 0.9978 - val_loss: 0.6256
AUC: 0.8629

Epoch 12/30
 - 0s - loss: 0.9975 - val_loss: 0.6182
AUC: 0.8629

Epoch 13/30
 - 0s - loss: 0.9966 - val_loss: 0.6162
AUC: 0.8629

Epoch 14/30
 - 0s - loss: 0.9901 - val_loss: 0.6186
AUC: 0.8630

Epoch 15/30
 - 0s - loss: 0.9906 - val_loss: 0.6178
AUC: 0.8630

Epoch 16/30
 - 0s - loss: 0.9926 - val_loss: 0.6179
AUC: 0.8630

Epoch 17/30
 - 0s - loss: 0.9985 - val_loss: 0.6206
AUC: 0.8631

Epoch 18/30
 - 0s - loss: 0.9918 - val_loss: 0.6200
AUC: 0.8631

Epoch 19/30
 - 0s - loss: 0.9946 - val_loss: 0.6167
AUC: 0.8631

Epoch 20/30
 - 0s - loss: 0.9935 - val_loss: 0.6183
AUC: 0.8632

Epoch 21/30
 - 0s - loss: 0.9907 - val_loss: 0.6172
AUC: 0.8632

Epoch 22/30
 - 0s - loss: 0.9955 - val_loss: 0.6134
AUC: 0.8632

Epoch 23/30
 - 0s - loss: 0.9892 - val_loss: 0.6141
AUC: 0.8632

Epoch 24/30
 - 0s - loss: 0.9925 - val_loss: 0.6149
AUC: 0.8632

Epoch 25/30
 - 0s - loss: 0.9890 - val_loss: 0.6151
AUC: 0.8632

Epoch 26/30
 - 0s - loss: 0.9944 - val_loss: 0.6165
AUC: 0.8632

Epoch 27/30
 - 0s - loss: 0.9920 - val_loss: 0.6160
AUC: 0.8632

Epoch 28/30
 - 0s - loss: 0.9897 - val_loss: 0.6160
AUC: 0.8632

Epoch 29/30
 - 0s - loss: 0.9954 - val_loss: 0.6162
AUC: 0.8632

Epoch 30/30
 - 0s - loss: 0.9898 - val_loss: 0.6166
Using TensorFlow backend.
AUC: 0.8633

2019-03-08 02:15:51.463722: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:15:51.627439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:15:51.627483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:15:51.919193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:15:51.919245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:15:51.919254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:15:51.919536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3673
Epoch 2/80
 - 2s - loss: 0.3501
Epoch 3/80
 - 2s - loss: 0.3017
Epoch 4/80
 - 2s - loss: 0.2832
Epoch 5/80
 - 2s - loss: 0.2664
Epoch 6/80
 - 2s - loss: 0.2518
Epoch 7/80
 - 2s - loss: 0.2378
Epoch 8/80
 - 2s - loss: 0.2230
Epoch 9/80
 - 2s - loss: 0.2077
Epoch 10/80
 - 2s - loss: 0.1938
Epoch 11/80
 - 2s - loss: 0.1818
Epoch 12/80
 - 2s - loss: 0.1714
Epoch 13/80
 - 2s - loss: 0.1626
Epoch 14/80
 - 2s - loss: 0.1553
Epoch 15/80
 - 2s - loss: 0.1491
Epoch 16/80
 - 2s - loss: 0.1438
Epoch 17/80
 - 2s - loss: 0.1394
Epoch 18/80
 - 2s - loss: 0.1356
Epoch 19/80
 - 2s - loss: 0.1325
Epoch 20/80
 - 2s - loss: 0.1299
Epoch 21/80
 - 2s - loss: 0.1277
Epoch 22/80
 - 2s - loss: 0.1259
Epoch 23/80
 - 2s - loss: 0.1243
Epoch 24/80
 - 2s - loss: 0.1230
Epoch 25/80
 - 2s - loss: 0.1219
Epoch 26/80
 - 2s - loss: 0.1208
Epoch 27/80
 - 2s - loss: 0.1200
Epoch 28/80
 - 2s - loss: 0.1193
Epoch 29/80
 - 2s - loss: 0.1186
Epoch 30/80
 - 2s - loss: 0.1181
Epoch 31/80
 - 2s - loss: 0.1176
Epoch 32/80
 - 2s - loss: 0.1172
Epoch 33/80
 - 2s - loss: 0.1169
Epoch 34/80
 - 2s - loss: 0.1166
Epoch 35/80
 - 2s - loss: 0.1162
Epoch 36/80
 - 2s - loss: 0.1160
Epoch 37/80
 - 2s - loss: 0.1158
Epoch 38/80
 - 2s - loss: 0.1156
Epoch 39/80
 - 2s - loss: 0.1154
Epoch 40/80
 - 2s - loss: 0.1153
Epoch 41/80
 - 2s - loss: 0.1151
Epoch 42/80
 - 2s - loss: 0.1150
Epoch 43/80
 - 2s - loss: 0.1148
Epoch 44/80
 - 2s - loss: 0.1147
Epoch 45/80
 - 2s - loss: 0.1146
Epoch 46/80
 - 2s - loss: 0.1145
Epoch 47/80
 - 2s - loss: 0.1144
Epoch 48/80
 - 2s - loss: 0.1144
Epoch 49/80
 - 2s - loss: 0.1143
Epoch 50/80
 - 2s - loss: 0.1142
Epoch 51/80
 - 2s - loss: 0.1141
Epoch 52/80
 - 2s - loss: 0.1141
Epoch 53/80
 - 2s - loss: 0.1140
Epoch 54/80
 - 2s - loss: 0.1140
Epoch 55/80
 - 2s - loss: 0.1139
Epoch 56/80
 - 2s - loss: 0.1139
Epoch 57/80
 - 2s - loss: 0.1138
Epoch 58/80
 - 2s - loss: 0.1138
Epoch 59/80
 - 2s - loss: 0.1137
Epoch 60/80
 - 2s - loss: 0.1137
Epoch 61/80
 - 2s - loss: 0.1137
Epoch 62/80
 - 2s - loss: 0.1136
Epoch 63/80
 - 2s - loss: 0.1114
Epoch 64/80
 - 2s - loss: 0.1112
Epoch 65/80
 - 2s - loss: 0.1111
Epoch 66/80
 - 2s - loss: 0.1111
Epoch 67/80
 - 2s - loss: 0.1111
Epoch 68/80
 - 2s - loss: 0.1105
Epoch 69/80
 - 2s - loss: 0.1105
Epoch 70/80
 - 2s - loss: 0.1105
Epoch 71/80
 - 2s - loss: 0.1105
Epoch 72/80
 - 2s - loss: 0.1104
Epoch 73/80
 - 2s - loss: 0.1104
Epoch 74/80
 - 2s - loss: 0.1104
Epoch 75/80
 - 2s - loss: 0.1104
Epoch 76/80
 - 2s - loss: 0.1104
Epoch 77/80
 - 2s - loss: 0.1104
Epoch 78/80
 - 2s - loss: 0.1104
Epoch 79/80
 - 2s - loss: 0.1104
Epoch 80/80
 - 2s - loss: 0.1104
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0670 - val_loss: 0.9569
AUC: 0.7783

Epoch 2/80
 - 0s - loss: 1.6419 - val_loss: 0.8184
AUC: 0.8074

Epoch 3/80
 - 0s - loss: 1.3240 - val_loss: 0.7388
AUC: 0.8242

Epoch 4/80
 - 0s - loss: 1.2418 - val_loss: 0.7904
AUC: 0.8356

Epoch 5/80
 - 0s - loss: 1.2017 - val_loss: 0.7093
AUC: 0.8442

Epoch 6/80
 - 0s - loss: 1.1650 - val_loss: 0.6661
AUC: 0.8486

Epoch 7/80
 - 0s - loss: 1.1485 - val_loss: 0.6769
AUC: 0.8526

Epoch 8/80
 - 0s - loss: 1.1316 - val_loss: 0.7001
AUC: 0.8563

Epoch 9/80
 - 0s - loss: 1.1180 - val_loss: 0.6401
AUC: 0.8577

Epoch 10/80
 - 0s - loss: 1.1115 - val_loss: 0.6072
AUC: 0.8589

Epoch 11/80
 - 0s - loss: 1.0982 - val_loss: 0.6607
AUC: 0.8610

Epoch 12/80
 - 0s - loss: 1.0878 - val_loss: 0.6842
AUC: 0.8627

Epoch 13/80
 - 0s - loss: 1.0861 - val_loss: 0.6857
AUC: 0.8630

Epoch 14/80
 - 0s - loss: 1.0798 - val_loss: 0.6303
AUC: 0.8629

Epoch 15/80
 - 0s - loss: 1.0660 - val_loss: 0.6213
AUC: 0.8648

Epoch 16/80
 - 0s - loss: 1.0655 - val_loss: 0.6020
AUC: 0.8652

Epoch 17/80
 - 0s - loss: 1.0630 - val_loss: 0.6640
AUC: 0.8659

Epoch 18/80
 - 0s - loss: 1.0643 - val_loss: 0.6907
AUC: 0.8666

Epoch 19/80
 - 0s - loss: 1.0582 - val_loss: 0.6476
AUC: 0.8667

Epoch 20/80
 - 0s - loss: 1.0531 - val_loss: 0.6733
AUC: 0.8683

Epoch 21/80
 - 0s - loss: 1.0480 - val_loss: 0.6128
AUC: 0.8676

Epoch 22/80
 - 0s - loss: 1.0437 - val_loss: 0.6594
AUC: 0.8693

Epoch 23/80
 - 0s - loss: 1.0433 - val_loss: 0.5806
AUC: 0.8680

Epoch 24/80
 - 0s - loss: 1.0387 - val_loss: 0.6545
AUC: 0.8680

Epoch 25/80
 - 0s - loss: 1.0305 - val_loss: 0.6531
AUC: 0.8695

Epoch 26/80
 - 0s - loss: 1.0319 - val_loss: 0.5961
AUC: 0.8699

Epoch 27/80
 - 0s - loss: 1.0267 - val_loss: 0.6508
AUC: 0.8712

Epoch 28/80
 - 0s - loss: 1.0266 - val_loss: 0.6157
AUC: 0.8709

Epoch 29/80
 - 0s - loss: 1.0232 - val_loss: 0.6888
AUC: 0.8705

Epoch 30/80
 - 0s - loss: 1.0304 - val_loss: 0.6736
AUC: 0.8716

Epoch 31/80
 - 0s - loss: 1.0240 - val_loss: 0.6508
AUC: 0.8714

Epoch 32/80
 - 0s - loss: 1.0140 - val_loss: 0.6689
AUC: 0.8724

Epoch 33/80
 - 0s - loss: 1.0155 - val_loss: 0.6177
AUC: 0.8721

Epoch 34/80
 - 0s - loss: 1.0077 - val_loss: 0.6256
AUC: 0.8723

Epoch 35/80
 - 0s - loss: 1.0045 - val_loss: 0.6294
AUC: 0.8722

Epoch 36/80
 - 0s - loss: 1.0134 - val_loss: 0.6090
AUC: 0.8722

Epoch 37/80
 - 0s - loss: 1.0022 - val_loss: 0.6375
AUC: 0.8719

Epoch 38/80
 - 0s - loss: 1.0070 - val_loss: 0.6046
AUC: 0.8722

Epoch 39/80
 - 0s - loss: 1.0095 - val_loss: 0.6233
AUC: 0.8724

Epoch 40/80
 - 0s - loss: 1.0117 - val_loss: 0.6177
AUC: 0.8724

Epoch 41/80
 - 0s - loss: 1.0057 - val_loss: 0.6121
AUC: 0.8724

Epoch 42/80
 - 0s - loss: 1.0045 - val_loss: 0.6304
AUC: 0.8723

Epoch 43/80
 - 0s - loss: 1.0039 - val_loss: 0.6119
AUC: 0.8722

Epoch 44/80
 - 0s - loss: 1.0012 - val_loss: 0.6093
AUC: 0.8722

Epoch 45/80
 - 0s - loss: 1.0034 - val_loss: 0.6088
AUC: 0.8723

Epoch 46/80
 - 0s - loss: 1.0023 - val_loss: 0.6136
AUC: 0.8724

Epoch 47/80
 - 0s - loss: 1.0025 - val_loss: 0.6082
AUC: 0.8724

Epoch 48/80
 - 0s - loss: 1.0018 - val_loss: 0.6128
AUC: 0.8724

Epoch 49/80
 - 0s - loss: 1.0028 - val_loss: 0.6079
AUC: 0.8724

Epoch 50/80
 - 0s - loss: 1.0018 - val_loss: 0.6133
AUC: 0.8724

Epoch 51/80
 - 0s - loss: 0.9993 - val_loss: 0.6131
AUC: 0.8725

Epoch 52/80
 - 0s - loss: 0.9977 - val_loss: 0.6114
AUC: 0.8725

Epoch 53/80
 - 0s - loss: 0.9998 - val_loss: 0.6088
AUC: 0.8724

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0001 - val_loss: 0.6131
AUC: 0.8726

Epoch 2/30
 - 0s - loss: 1.0023 - val_loss: 0.6159
AUC: 0.8727

Epoch 3/30
 - 0s - loss: 1.0048 - val_loss: 0.6109
AUC: 0.8728

Epoch 4/30
 - 0s - loss: 1.0025 - val_loss: 0.6138
AUC: 0.8730

Epoch 5/30
 - 0s - loss: 0.9997 - val_loss: 0.6132
AUC: 0.8731

Epoch 6/30
 - 0s - loss: 0.9976 - val_loss: 0.6061
AUC: 0.8730

Epoch 7/30
 - 0s - loss: 0.9986 - val_loss: 0.5940
AUC: 0.8730

Epoch 8/30
 - 0s - loss: 0.9918 - val_loss: 0.6144
AUC: 0.8732

Epoch 9/30
 - 0s - loss: 0.9951 - val_loss: 0.6247
AUC: 0.8732

Epoch 10/30
 - 0s - loss: 0.9875 - val_loss: 0.6133
AUC: 0.8732

Epoch 11/30
 - 0s - loss: 0.9902 - val_loss: 0.6129
AUC: 0.8734

Epoch 12/30
 - 0s - loss: 0.9899 - val_loss: 0.6058
AUC: 0.8733

Epoch 13/30
 - 0s - loss: 0.9883 - val_loss: 0.6360
AUC: 0.8735

Epoch 14/30
 - 0s - loss: 0.9932 - val_loss: 0.6013
AUC: 0.8734

Epoch 15/30
 - 0s - loss: 0.9874 - val_loss: 0.6182
AUC: 0.8735

Epoch 16/30
 - 0s - loss: 0.9913 - val_loss: 0.5988
AUC: 0.8735

Epoch 17/30
 - 0s - loss: 0.9858 - val_loss: 0.6135
AUC: 0.8738

Epoch 18/30
 - 0s - loss: 0.9829 - val_loss: 0.6067
AUC: 0.8737

Epoch 19/30
 - 0s - loss: 0.9892 - val_loss: 0.6076
AUC: 0.8737

Epoch 20/30
 - 0s - loss: 0.9817 - val_loss: 0.6057
AUC: 0.8737

Epoch 21/30
 - 0s - loss: 0.9814 - val_loss: 0.6064
AUC: 0.8737

Epoch 22/30
 - 0s - loss: 0.9881 - val_loss: 0.6031
AUC: 0.8737

Epoch 23/30
 - 0s - loss: 0.9858 - val_loss: 0.6043
AUC: 0.8737

Epoch 24/30
 - 0s - loss: 0.9814 - val_loss: 0.6080
AUC: 0.8737

Epoch 25/30
 - 0s - loss: 0.9866 - val_loss: 0.6041
AUC: 0.8737

Epoch 26/30
 - 0s - loss: 0.9806 - val_loss: 0.6038
AUC: 0.8737

Epoch 27/30
 - 0s - loss: 0.9793 - val_loss: 0.6046
AUC: 0.8737

Epoch 28/30
 - 0s - loss: 0.9826 - val_loss: 0.6050
AUC: 0.8737

Epoch 29/30
 - 0s - loss: 0.9788 - val_loss: 0.6047
AUC: 0.8737

Epoch 30/30
 - 0s - loss: 0.9834 - val_loss: 0.6048
Using TensorFlow backend.
AUC: 0.8737

2019-03-08 02:19:13.181701: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:19:13.349501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:19:13.349562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:19:13.641669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:19:13.641719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:19:13.641727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:19:13.641981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3852
Epoch 2/80
 - 2s - loss: 0.3522
Epoch 3/80
 - 2s - loss: 0.2995
Epoch 4/80
 - 2s - loss: 0.2786
Epoch 5/80
 - 2s - loss: 0.2604
Epoch 6/80
 - 2s - loss: 0.2460
Epoch 7/80
 - 2s - loss: 0.2330
Epoch 8/80
 - 2s - loss: 0.2189
Epoch 9/80
 - 2s - loss: 0.2038
Epoch 10/80
 - 2s - loss: 0.1900
Epoch 11/80
 - 2s - loss: 0.1786
Epoch 12/80
 - 2s - loss: 0.1694
Epoch 13/80
 - 2s - loss: 0.1619
Epoch 14/80
 - 2s - loss: 0.1557
Epoch 15/80
 - 2s - loss: 0.1505
Epoch 16/80
 - 2s - loss: 0.1460
Epoch 17/80
 - 2s - loss: 0.1418
Epoch 18/80
 - 2s - loss: 0.1382
Epoch 19/80
 - 2s - loss: 0.1348
Epoch 20/80
 - 2s - loss: 0.1319
Epoch 21/80
 - 2s - loss: 0.1294
Epoch 22/80
 - 2s - loss: 0.1272
Epoch 23/80
 - 2s - loss: 0.1254
Epoch 24/80
 - 2s - loss: 0.1239
Epoch 25/80
 - 2s - loss: 0.1226
Epoch 26/80
 - 2s - loss: 0.1216
Epoch 27/80
 - 2s - loss: 0.1206
Epoch 28/80
 - 2s - loss: 0.1200
Epoch 29/80
 - 2s - loss: 0.1193
Epoch 30/80
 - 2s - loss: 0.1187
Epoch 31/80
 - 2s - loss: 0.1183
Epoch 32/80
 - 2s - loss: 0.1179
Epoch 33/80
 - 2s - loss: 0.1175
Epoch 34/80
 - 2s - loss: 0.1173
Epoch 35/80
 - 2s - loss: 0.1170
Epoch 36/80
 - 2s - loss: 0.1167
Epoch 37/80
 - 2s - loss: 0.1165
Epoch 38/80
 - 2s - loss: 0.1163
Epoch 39/80
 - 2s - loss: 0.1161
Epoch 40/80
 - 2s - loss: 0.1159
Epoch 41/80
 - 2s - loss: 0.1158
Epoch 42/80
 - 2s - loss: 0.1157
Epoch 43/80
 - 2s - loss: 0.1155
Epoch 44/80
 - 2s - loss: 0.1154
Epoch 45/80
 - 2s - loss: 0.1153
Epoch 46/80
 - 2s - loss: 0.1152
Epoch 47/80
 - 2s - loss: 0.1151
Epoch 48/80
 - 2s - loss: 0.1150
Epoch 49/80
 - 2s - loss: 0.1150
Epoch 50/80
 - 2s - loss: 0.1149
Epoch 51/80
 - 2s - loss: 0.1148
Epoch 52/80
 - 2s - loss: 0.1147
Epoch 53/80
 - 2s - loss: 0.1147
Epoch 54/80
 - 2s - loss: 0.1146
Epoch 55/80
 - 2s - loss: 0.1146
Epoch 56/80
 - 2s - loss: 0.1145
Epoch 57/80
 - 2s - loss: 0.1145
Epoch 58/80
 - 2s - loss: 0.1144
Epoch 59/80
 - 2s - loss: 0.1144
Epoch 60/80
 - 2s - loss: 0.1144
Epoch 61/80
 - 2s - loss: 0.1121
Epoch 62/80
 - 2s - loss: 0.1119
Epoch 63/80
 - 2s - loss: 0.1118
Epoch 64/80
 - 2s - loss: 0.1118
Epoch 65/80
 - 2s - loss: 0.1118
Epoch 66/80
 - 2s - loss: 0.1112
Epoch 67/80
 - 2s - loss: 0.1112
Epoch 68/80
 - 2s - loss: 0.1112
Epoch 69/80
 - 2s - loss: 0.1112
Epoch 70/80
 - 2s - loss: 0.1111
Epoch 71/80
 - 2s - loss: 0.1111
Epoch 72/80
 - 2s - loss: 0.1111
Epoch 73/80
 - 2s - loss: 0.1111
Epoch 74/80
 - 2s - loss: 0.1111
Epoch 75/80
 - 2s - loss: 0.1111
Epoch 76/80
 - 2s - loss: 0.1111
Epoch 77/80
 - 2s - loss: 0.1111
Epoch 78/80
 - 2s - loss: 0.1111
Epoch 79/80
 - 2s - loss: 0.1111
Epoch 80/80
 - 2s - loss: 0.1111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.6536 - val_loss: 1.6638
AUC: 0.7902

Epoch 2/80
 - 0s - loss: 2.6776 - val_loss: 1.1157
AUC: 0.8175

Epoch 3/80
 - 0s - loss: 1.9193 - val_loss: 0.8791
AUC: 0.8337

Epoch 4/80
 - 0s - loss: 1.4640 - val_loss: 0.7238
AUC: 0.8420

Epoch 5/80
 - 0s - loss: 1.2824 - val_loss: 0.7082
AUC: 0.8495

Epoch 6/80
 - 0s - loss: 1.2016 - val_loss: 0.7184
AUC: 0.8529

Epoch 7/80
 - 0s - loss: 1.1579 - val_loss: 0.6905
AUC: 0.8542

Epoch 8/80
 - 0s - loss: 1.1325 - val_loss: 0.6846
AUC: 0.8537

Epoch 9/80
 - 0s - loss: 1.1191 - val_loss: 0.6234
AUC: 0.8546

Epoch 10/80
 - 0s - loss: 1.1106 - val_loss: 0.6477
AUC: 0.8564

Epoch 11/80
 - 0s - loss: 1.0918 - val_loss: 0.6608
AUC: 0.8561

Epoch 12/80
 - 0s - loss: 1.0794 - val_loss: 0.6627
AUC: 0.8580

Epoch 13/80
 - 0s - loss: 1.0793 - val_loss: 0.6240
AUC: 0.8591

Epoch 14/80
 - 0s - loss: 1.0663 - val_loss: 0.5872
AUC: 0.8587

Epoch 15/80
 - 0s - loss: 1.0651 - val_loss: 0.6527
AUC: 0.8613

Epoch 16/80
 - 0s - loss: 1.0618 - val_loss: 0.6394
AUC: 0.8613

Epoch 17/80
 - 0s - loss: 1.0515 - val_loss: 0.6226
AUC: 0.8623

Epoch 18/80
 - 0s - loss: 1.0498 - val_loss: 0.6456
AUC: 0.8633

Epoch 19/80
 - 0s - loss: 1.0436 - val_loss: 0.5807
AUC: 0.8625

Epoch 20/80
 - 0s - loss: 1.0433 - val_loss: 0.5922
AUC: 0.8631

Epoch 21/80
 - 0s - loss: 1.0409 - val_loss: 0.6112
AUC: 0.8628

Epoch 22/80
 - 0s - loss: 1.0372 - val_loss: 0.6032
AUC: 0.8654

Epoch 23/80
 - 0s - loss: 1.0354 - val_loss: 0.6252
AUC: 0.8645

Epoch 24/80
 - 0s - loss: 1.0367 - val_loss: 0.6132
AUC: 0.8654

Epoch 25/80
 - 0s - loss: 1.0288 - val_loss: 0.5826
AUC: 0.8652

Epoch 26/80
 - 0s - loss: 1.0271 - val_loss: 0.6159
AUC: 0.8656

Epoch 27/80
 - 0s - loss: 1.0169 - val_loss: 0.6319
AUC: 0.8666

Epoch 28/80
 - 0s - loss: 1.0207 - val_loss: 0.5842
AUC: 0.8662

Epoch 29/80
 - 0s - loss: 1.0182 - val_loss: 0.6962
AUC: 0.8675

Epoch 30/80
 - 0s - loss: 1.0096 - val_loss: 0.6024
AUC: 0.8670

Epoch 31/80
 - 0s - loss: 1.0056 - val_loss: 0.5942
AUC: 0.8671

Epoch 32/80
 - 0s - loss: 1.0051 - val_loss: 0.6016
AUC: 0.8669

Epoch 33/80
 - 0s - loss: 1.0051 - val_loss: 0.6052
AUC: 0.8671

Epoch 34/80
 - 0s - loss: 0.9965 - val_loss: 0.6147
AUC: 0.8671

Epoch 35/80
 - 0s - loss: 1.0113 - val_loss: 0.5787
AUC: 0.8668

Epoch 36/80
 - 0s - loss: 0.9992 - val_loss: 0.6141
AUC: 0.8677

Epoch 37/80
 - 0s - loss: 1.0065 - val_loss: 0.6253
AUC: 0.8679

Epoch 38/80
 - 0s - loss: 1.0031 - val_loss: 0.6106
AUC: 0.8677

Epoch 39/80
 - 0s - loss: 1.0028 - val_loss: 0.5984
AUC: 0.8679

Epoch 40/80
 - 0s - loss: 1.0068 - val_loss: 0.6146
AUC: 0.8679

Epoch 41/80
 - 0s - loss: 1.0062 - val_loss: 0.6135
AUC: 0.8679

Epoch 42/80
 - 0s - loss: 1.0022 - val_loss: 0.6165
AUC: 0.8679

Epoch 43/80
 - 0s - loss: 1.0057 - val_loss: 0.5955
AUC: 0.8678

Epoch 44/80
 - 0s - loss: 1.0015 - val_loss: 0.6101
AUC: 0.8680

Epoch 45/80
 - 0s - loss: 1.0047 - val_loss: 0.6168
AUC: 0.8682

Epoch 46/80
 - 0s - loss: 1.0002 - val_loss: 0.6083
AUC: 0.8681

Epoch 47/80
 - 0s - loss: 0.9989 - val_loss: 0.6036
AUC: 0.8680

Epoch 48/80
 - 0s - loss: 0.9960 - val_loss: 0.6053
AUC: 0.8680

Epoch 49/80
 - 0s - loss: 0.9966 - val_loss: 0.6004
AUC: 0.8680

Epoch 50/80
 - 0s - loss: 1.0008 - val_loss: 0.6059
AUC: 0.8681

Epoch 51/80
 - 0s - loss: 0.9961 - val_loss: 0.6034
AUC: 0.8680

Epoch 52/80
 - 0s - loss: 0.9971 - val_loss: 0.6020
AUC: 0.8680

Epoch 53/80
 - 0s - loss: 0.9947 - val_loss: 0.6079
AUC: 0.8681

Epoch 54/80
 - 0s - loss: 1.0068 - val_loss: 0.6038
AUC: 0.8681

Epoch 55/80
 - 0s - loss: 0.9991 - val_loss: 0.6083
AUC: 0.8681

Epoch 56/80
 - 0s - loss: 1.0051 - val_loss: 0.6076
AUC: 0.8681

Epoch 57/80
 - 0s - loss: 0.9977 - val_loss: 0.6046
AUC: 0.8680

Epoch 58/80
 - 0s - loss: 0.9992 - val_loss: 0.6048
AUC: 0.8680

Epoch 59/80
 - 0s - loss: 1.0010 - val_loss: 0.6036
AUC: 0.8680

Epoch 60/80
 - 0s - loss: 0.9940 - val_loss: 0.6039
AUC: 0.8681

Epoch 61/80
 - 0s - loss: 0.9974 - val_loss: 0.6027
AUC: 0.8680

Epoch 62/80
 - 0s - loss: 1.0040 - val_loss: 0.6046
AUC: 0.8681

Epoch 63/80
 - 0s - loss: 0.9975 - val_loss: 0.6049
AUC: 0.8681

Epoch 64/80
 - 0s - loss: 1.0000 - val_loss: 0.6035
AUC: 0.8681

Epoch 65/80
 - 0s - loss: 1.0031 - val_loss: 0.6051
AUC: 0.8681

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9993 - val_loss: 0.6041
AUC: 0.8680

Epoch 2/30
 - 0s - loss: 1.0050 - val_loss: 0.6095
AUC: 0.8684

Epoch 3/30
 - 0s - loss: 0.9928 - val_loss: 0.5985
AUC: 0.8685

Epoch 4/30
 - 0s - loss: 1.0023 - val_loss: 0.6076
AUC: 0.8686

Epoch 5/30
 - 0s - loss: 1.0014 - val_loss: 0.6089
AUC: 0.8689

Epoch 6/30
 - 0s - loss: 0.9960 - val_loss: 0.6041
AUC: 0.8688

Epoch 7/30
 - 0s - loss: 1.0005 - val_loss: 0.6031
AUC: 0.8689

Epoch 8/30
 - 0s - loss: 0.9908 - val_loss: 0.5948
AUC: 0.8688

Epoch 9/30
 - 0s - loss: 0.9898 - val_loss: 0.6130
AUC: 0.8692

Epoch 10/30
 - 0s - loss: 0.9892 - val_loss: 0.5973
AUC: 0.8693

Epoch 11/30
 - 0s - loss: 0.9879 - val_loss: 0.6086
AUC: 0.8696

Epoch 12/30
 - 0s - loss: 0.9890 - val_loss: 0.6017
AUC: 0.8695

Epoch 13/30
 - 0s - loss: 0.9914 - val_loss: 0.5950
AUC: 0.8693

Epoch 14/30
 - 0s - loss: 0.9834 - val_loss: 0.6120
AUC: 0.8696

Epoch 15/30
 - 0s - loss: 0.9854 - val_loss: 0.5796
AUC: 0.8695

Epoch 16/30
 - 0s - loss: 0.9877 - val_loss: 0.5919
AUC: 0.8697

Epoch 17/30
 - 0s - loss: 0.9841 - val_loss: 0.5953
AUC: 0.8697

Epoch 18/30
 - 0s - loss: 0.9819 - val_loss: 0.6064
AUC: 0.8702

Epoch 19/30
 - 0s - loss: 0.9796 - val_loss: 0.5971
AUC: 0.8700

Epoch 20/30
 - 0s - loss: 0.9810 - val_loss: 0.5884
AUC: 0.8699

Epoch 21/30
 - 0s - loss: 0.9818 - val_loss: 0.5832
AUC: 0.8700

Epoch 22/30
 - 0s - loss: 0.9748 - val_loss: 0.5977
AUC: 0.8702

Epoch 23/30
 - 0s - loss: 0.9694 - val_loss: 0.5916
AUC: 0.8703

Epoch 24/30
 - 0s - loss: 0.9762 - val_loss: 0.5960
AUC: 0.8704

Epoch 25/30
 - 0s - loss: 0.9683 - val_loss: 0.5933
AUC: 0.8703

Epoch 26/30
 - 0s - loss: 0.9731 - val_loss: 0.5892
AUC: 0.8703

Epoch 27/30
 - 0s - loss: 0.9757 - val_loss: 0.5924
AUC: 0.8704

Epoch 28/30
 - 0s - loss: 0.9789 - val_loss: 0.5972
AUC: 0.8705

Epoch 29/30
 - 0s - loss: 0.9702 - val_loss: 0.5931
AUC: 0.8705

Epoch 30/30
 - 0s - loss: 0.9763 - val_loss: 0.5909
Using TensorFlow backend.
AUC: 0.8704

2019-03-08 02:22:40.167145: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:22:40.332749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:22:40.332793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:22:40.624357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:22:40.624411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:22:40.624420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:22:40.624691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3471
Epoch 2/80
 - 2s - loss: 0.3501
Epoch 3/80
 - 2s - loss: 0.3098
Epoch 4/80
 - 2s - loss: 0.2984
Epoch 5/80
 - 2s - loss: 0.2847
Epoch 6/80
 - 2s - loss: 0.2674
Epoch 7/80
 - 2s - loss: 0.2467
Epoch 8/80
 - 2s - loss: 0.2268
Epoch 9/80
 - 2s - loss: 0.2106
Epoch 10/80
 - 2s - loss: 0.1970
Epoch 11/80
 - 2s - loss: 0.1848
Epoch 12/80
 - 2s - loss: 0.1742
Epoch 13/80
 - 2s - loss: 0.1655
Epoch 14/80
 - 2s - loss: 0.1582
Epoch 15/80
 - 2s - loss: 0.1518
Epoch 16/80
 - 2s - loss: 0.1464
Epoch 17/80
 - 2s - loss: 0.1417
Epoch 18/80
 - 2s - loss: 0.1377
Epoch 19/80
 - 2s - loss: 0.1343
Epoch 20/80
 - 2s - loss: 0.1315
Epoch 21/80
 - 2s - loss: 0.1292
Epoch 22/80
 - 2s - loss: 0.1272
Epoch 23/80
 - 2s - loss: 0.1256
Epoch 24/80
 - 2s - loss: 0.1242
Epoch 25/80
 - 2s - loss: 0.1230
Epoch 26/80
 - 2s - loss: 0.1220
Epoch 27/80
 - 2s - loss: 0.1211
Epoch 28/80
 - 2s - loss: 0.1204
Epoch 29/80
 - 2s - loss: 0.1197
Epoch 30/80
 - 2s - loss: 0.1192
Epoch 31/80
 - 2s - loss: 0.1187
Epoch 32/80
 - 2s - loss: 0.1183
Epoch 33/80
 - 2s - loss: 0.1179
Epoch 34/80
 - 2s - loss: 0.1176
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:23:55.996667: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:23:56.158647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:23:56.158691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:23:56.451242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:23:56.451294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:23:56.451303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:23:56.451582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3635
Epoch 2/80
 - 2s - loss: 0.3525
Epoch 3/80
 - 2s - loss: 0.3090
Epoch 4/80
 - 2s - loss: 0.2927
Epoch 5/80
 - 2s - loss: 0.2706
Epoch 6/80
 - 2s - loss: 0.2500
Epoch 7/80
 - 2s - loss: 0.2341
Epoch 8/80
 - 2s - loss: 0.2193
Epoch 9/80
 - 2s - loss: 0.2044
Epoch 10/80
 - 2s - loss: 0.1905
Epoch 11/80
 - 2s - loss: 0.1790
Epoch 12/80
 - 2s - loss: 0.1698
Epoch 13/80
 - 2s - loss: 0.1624
Epoch 14/80
 - 2s - loss: 0.1560
Epoch 15/80
 - 2s - loss: 0.1506
Epoch 16/80
 - 2s - loss: 0.1457
Epoch 17/80
 - 2s - loss: 0.1416
Epoch 18/80
 - 2s - loss: 0.1379
Epoch 19/80
 - 2s - loss: 0.1348
Epoch 20/80
 - 2s - loss: 0.1321
Epoch 21/80
 - 2s - loss: 0.1298
Epoch 22/80
 - 2s - loss: 0.1279
Epoch 23/80
 - 2s - loss: 0.1262
Epoch 24/80
 - 2s - loss: 0.1248
Epoch 25/80
 - 2s - loss: 0.1236
Epoch 26/80
 - 2s - loss: 0.1226
Epoch 27/80
 - 2s - loss: 0.1217
Epoch 28/80
 - 2s - loss: 0.1209
Epoch 29/80
 - 2s - loss: 0.1203
Epoch 30/80
 - 2s - loss: 0.1197
Epoch 31/80
 - 2s - loss: 0.1192
Epoch 32/80
 - 2s - loss: 0.1187
Epoch 33/80
 - 2s - loss: 0.1183
Epoch 34/80
 - 2s - loss: 0.1180
Epoch 35/80
 - 2s - loss: 0.1177
Epoch 36/80
 - 2s - loss: 0.1174
Epoch 37/80
 - 2s - loss: 0.1172
Epoch 38/80
 - 2s - loss: 0.1169
Epoch 39/80
 - 2s - loss: 0.1167
Epoch 40/80
 - 2s - loss: 0.1165
Epoch 41/80
 - 2s - loss: 0.1163
Epoch 42/80
 - 2s - loss: 0.1162
Epoch 43/80
 - 2s - loss: 0.1160
Epoch 44/80
 - 2s - loss: 0.1159
Epoch 45/80
 - 2s - loss: 0.1157
Epoch 46/80
 - 2s - loss: 0.1156
Epoch 47/80
 - 2s - loss: 0.1155
Epoch 48/80
 - 2s - loss: 0.1154
Epoch 49/80
 - 2s - loss: 0.1153
Epoch 50/80
 - 2s - loss: 0.1152
Epoch 51/80
 - 2s - loss: 0.1152
Epoch 52/80
 - 2s - loss: 0.1151
Epoch 53/80
 - 2s - loss: 0.1150
Epoch 54/80
 - 2s - loss: 0.1149
Epoch 55/80
 - 2s - loss: 0.1149
Epoch 56/80
 - 2s - loss: 0.1148
Epoch 57/80
 - 2s - loss: 0.1148
Epoch 58/80
 - 2s - loss: 0.1147
Epoch 59/80
 - 2s - loss: 0.1147
Epoch 60/80
 - 2s - loss: 0.1146
Epoch 61/80
 - 2s - loss: 0.1146
Epoch 62/80
 - 2s - loss: 0.1145
Epoch 63/80
 - 2s - loss: 0.1145
Epoch 64/80
 - 2s - loss: 0.1123
Epoch 65/80
 - 2s - loss: 0.1120
Epoch 66/80
 - 2s - loss: 0.1120
Epoch 67/80
 - 2s - loss: 0.1120
Epoch 68/80
 - 2s - loss: 0.1120
Epoch 69/80
 - 2s - loss: 0.1114
Epoch 70/80
 - 2s - loss: 0.1114
Epoch 71/80
 - 2s - loss: 0.1114
Epoch 72/80
 - 2s - loss: 0.1114
Epoch 73/80
 - 2s - loss: 0.1112
Epoch 74/80
 - 2s - loss: 0.1112
Epoch 75/80
 - 2s - loss: 0.1112
Epoch 76/80
 - 2s - loss: 0.1112
Epoch 77/80
 - 2s - loss: 0.1112
Epoch 78/80
 - 2s - loss: 0.1112
Epoch 79/80
 - 2s - loss: 0.1112
Epoch 80/80
 - 2s - loss: 0.1112
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.3954 - val_loss: 1.2861
AUC: 0.7119

Epoch 2/80
 - 0s - loss: 2.1918 - val_loss: 0.8824
AUC: 0.7816

Epoch 3/80
 - 0s - loss: 1.5455 - val_loss: 0.8438
AUC: 0.8044

Epoch 4/80
 - 0s - loss: 1.3274 - val_loss: 0.7465
AUC: 0.8188

Epoch 5/80
 - 0s - loss: 1.2488 - val_loss: 0.7069
AUC: 0.8281

Epoch 6/80
 - 0s - loss: 1.2003 - val_loss: 0.7323
AUC: 0.8365

Epoch 7/80
 - 0s - loss: 1.1813 - val_loss: 0.7682
AUC: 0.8403

Epoch 8/80
 - 0s - loss: 1.1459 - val_loss: 0.7489
AUC: 0.8428

Epoch 9/80
 - 0s - loss: 1.1380 - val_loss: 0.6957
AUC: 0.8446

Epoch 10/80
 - 0s - loss: 1.1258 - val_loss: 0.7299
AUC: 0.8478

Epoch 11/80
 - 0s - loss: 1.1155 - val_loss: 0.6913
AUC: 0.8495

Epoch 12/80
 - 0s - loss: 1.1039 - val_loss: 0.6362
AUC: 0.8511

Epoch 13/80
 - 0s - loss: 1.1011 - val_loss: 0.6801
AUC: 0.8510

Epoch 14/80
 - 0s - loss: 1.0793 - val_loss: 0.5747
AUC: 0.8498

Epoch 15/80
 - 0s - loss: 1.0790 - val_loss: 0.6767
AUC: 0.8552

Epoch 16/80
 - 0s - loss: 1.0764 - val_loss: 0.6461
AUC: 0.8547

Epoch 17/80
 - 0s - loss: 1.0725 - val_loss: 0.6711
AUC: 0.8559

Epoch 18/80
 - 0s - loss: 1.0734 - val_loss: 0.6761
AUC: 0.8554

Epoch 19/80
 - 0s - loss: 1.0640 - val_loss: 0.6502
AUC: 0.8567

Epoch 20/80
 - 0s - loss: 1.0580 - val_loss: 0.6059
AUC: 0.8559

Epoch 21/80
 - 0s - loss: 1.0515 - val_loss: 0.6143
AUC: 0.8575

Epoch 22/80
 - 0s - loss: 1.0473 - val_loss: 0.6184
AUC: 0.8562

Epoch 23/80
 - 0s - loss: 1.0440 - val_loss: 0.5631
AUC: 0.8571

Epoch 24/80
 - 0s - loss: 1.0482 - val_loss: 0.6012
AUC: 0.8592

Epoch 25/80
 - 0s - loss: 1.0380 - val_loss: 0.6179
AUC: 0.8592

Epoch 26/80
 - 0s - loss: 1.0466 - val_loss: 0.5913
AUC: 0.8590

Epoch 27/80
 - 0s - loss: 1.0387 - val_loss: 0.6106
AUC: 0.8595

Epoch 28/80
 - 0s - loss: 1.0394 - val_loss: 0.6561
AUC: 0.8608

Epoch 29/80
 - 0s - loss: 1.0326 - val_loss: 0.6310
AUC: 0.8605

Epoch 30/80
 - 0s - loss: 1.0297 - val_loss: 0.5924
AUC: 0.8609

Epoch 31/80
 - 0s - loss: 1.0265 - val_loss: 0.6482
AUC: 0.8615

Epoch 32/80
 - 0s - loss: 1.0248 - val_loss: 0.5892
AUC: 0.8618

Epoch 33/80
 - 0s - loss: 1.0245 - val_loss: 0.6334
AUC: 0.8607

Epoch 34/80
 - 0s - loss: 1.0183 - val_loss: 0.6140
AUC: 0.8617

Epoch 35/80
 - 0s - loss: 1.0173 - val_loss: 0.6297
AUC: 0.8621

Epoch 36/80
 - 0s - loss: 1.0112 - val_loss: 0.6287
AUC: 0.8619

Epoch 37/80
 - 0s - loss: 1.0136 - val_loss: 0.6049
AUC: 0.8620

Epoch 38/80
 - 0s - loss: 1.0154 - val_loss: 0.6126
AUC: 0.8623

Epoch 39/80
 - 0s - loss: 1.0100 - val_loss: 0.6033
AUC: 0.8622

Epoch 40/80
 - 0s - loss: 1.0154 - val_loss: 0.6178
AUC: 0.8624

Epoch 41/80
 - 0s - loss: 1.0117 - val_loss: 0.6277
AUC: 0.8627

Epoch 42/80
 - 0s - loss: 1.0105 - val_loss: 0.6283
AUC: 0.8624

Epoch 43/80
 - 0s - loss: 1.0100 - val_loss: 0.6274
AUC: 0.8625

Epoch 44/80
 - 0s - loss: 1.0128 - val_loss: 0.6207
AUC: 0.8626

Epoch 45/80
 - 0s - loss: 1.0068 - val_loss: 0.6179
AUC: 0.8625

Epoch 46/80
 - 0s - loss: 1.0088 - val_loss: 0.6190
AUC: 0.8625

Epoch 47/80
 - 0s - loss: 1.0065 - val_loss: 0.6238
AUC: 0.8625

Epoch 48/80
 - 0s - loss: 1.0046 - val_loss: 0.6206
AUC: 0.8625

Epoch 49/80
 - 0s - loss: 1.0093 - val_loss: 0.6252
AUC: 0.8625

Epoch 50/80
 - 0s - loss: 1.0043 - val_loss: 0.6188
AUC: 0.8625

Epoch 51/80
 - 0s - loss: 1.0118 - val_loss: 0.6167
AUC: 0.8626

Epoch 52/80
 - 0s - loss: 1.0127 - val_loss: 0.6189
AUC: 0.8626

Epoch 53/80
 - 0s - loss: 1.0081 - val_loss: 0.6220
AUC: 0.8625

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0112 - val_loss: 0.6262
AUC: 0.8626

Epoch 2/30
 - 0s - loss: 1.0070 - val_loss: 0.5943
AUC: 0.8626

Epoch 3/30
 - 0s - loss: 1.0046 - val_loss: 0.6095
AUC: 0.8629

Epoch 4/30
 - 0s - loss: 1.0104 - val_loss: 0.6279
AUC: 0.8631

Epoch 5/30
 - 0s - loss: 1.0088 - val_loss: 0.5968
AUC: 0.8633

Epoch 6/30
 - 0s - loss: 1.0045 - val_loss: 0.6177
AUC: 0.8633

Epoch 7/30
 - 0s - loss: 1.0002 - val_loss: 0.6060
AUC: 0.8633

Epoch 8/30
 - 0s - loss: 1.0029 - val_loss: 0.6183
AUC: 0.8636

Epoch 9/30
 - 0s - loss: 0.9958 - val_loss: 0.6227
AUC: 0.8636

Epoch 10/30
 - 0s - loss: 0.9973 - val_loss: 0.6223
AUC: 0.8637

Epoch 11/30
 - 0s - loss: 0.9919 - val_loss: 0.6175
AUC: 0.8640

Epoch 12/30
 - 0s - loss: 0.9962 - val_loss: 0.6069
AUC: 0.8640

Epoch 13/30
 - 0s - loss: 0.9968 - val_loss: 0.6110
AUC: 0.8641

Epoch 14/30
 - 0s - loss: 0.9976 - val_loss: 0.6122
AUC: 0.8642

Epoch 15/30
 - 0s - loss: 0.9947 - val_loss: 0.6108
AUC: 0.8642

Epoch 16/30
 - 0s - loss: 0.9987 - val_loss: 0.6117
AUC: 0.8642

Epoch 17/30
 - 0s - loss: 0.9929 - val_loss: 0.6148
AUC: 0.8643

Epoch 18/30
 - 0s - loss: 0.9932 - val_loss: 0.6142
AUC: 0.8643

Epoch 19/30
 - 0s - loss: 0.9882 - val_loss: 0.6114
AUC: 0.8643

Epoch 20/30
 - 0s - loss: 0.9899 - val_loss: 0.6110
AUC: 0.8643

Epoch 21/30
 - 0s - loss: 0.9945 - val_loss: 0.6132
AUC: 0.8643

Epoch 22/30
 - 0s - loss: 0.9857 - val_loss: 0.6099
AUC: 0.8643

Epoch 23/30
 - 0s - loss: 0.9895 - val_loss: 0.6100
AUC: 0.8643

Epoch 24/30
 - 0s - loss: 0.9915 - val_loss: 0.6105
AUC: 0.8643

Epoch 25/30
 - 0s - loss: 0.9902 - val_loss: 0.6110
AUC: 0.8643

Epoch 26/30
 - 0s - loss: 0.9877 - val_loss: 0.6107
AUC: 0.8643

Epoch 27/30
 - 0s - loss: 0.9923 - val_loss: 0.6119
AUC: 0.8643

Epoch 28/30
 - 0s - loss: 0.9936 - val_loss: 0.6117
AUC: 0.8643

Epoch 29/30
 - 0s - loss: 0.9934 - val_loss: 0.6101
AUC: 0.8643

Epoch 30/30
 - 0s - loss: 0.9874 - val_loss: 0.6106
Using TensorFlow backend.
AUC: 0.8643

2019-03-08 02:27:16.781812: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:27:16.949639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:27:16.949682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:27:17.244417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:27:17.244498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:27:17.244507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:27:17.244760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1532
Epoch 2/80
 - 2s - loss: 0.2186
Epoch 3/80
 - 2s - loss: 0.1701
Epoch 4/80
 - 2s - loss: 0.1564
Epoch 5/80
 - 2s - loss: 0.1443
Epoch 6/80
 - 2s - loss: 0.1341
Epoch 7/80
 - 2s - loss: 0.1254
Epoch 8/80
 - 2s - loss: 0.1179
Epoch 9/80
 - 2s - loss: 0.1112
Epoch 10/80
 - 2s - loss: 0.1050
Epoch 11/80
 - 2s - loss: 0.0989
Epoch 12/80
 - 2s - loss: 0.0931
Epoch 13/80
 - 2s - loss: 0.0879
Epoch 14/80
 - 2s - loss: 0.0832
Epoch 15/80
 - 2s - loss: 0.0791
Epoch 16/80
 - 2s - loss: 0.0753
Epoch 17/80
 - 2s - loss: 0.0720
Epoch 18/80
 - 2s - loss: 0.0690
Epoch 19/80
 - 2s - loss: 0.0664
Epoch 20/80
 - 2s - loss: 0.0641
Epoch 21/80
 - 2s - loss: 0.0622
Epoch 22/80
 - 2s - loss: 0.0606
Epoch 23/80
 - 2s - loss: 0.0592
Epoch 24/80
 - 2s - loss: 0.0580
Epoch 25/80
 - 2s - loss: 0.0570
Epoch 26/80
 - 2s - loss: 0.0561
Epoch 27/80
 - 2s - loss: 0.0554
Epoch 28/80
 - 2s - loss: 0.0548
Epoch 29/80
 - 2s - loss: 0.0542
Epoch 30/80
 - 2s - loss: 0.0538
Epoch 31/80
 - 2s - loss: 0.0534
Epoch 32/80
 - 2s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0525
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0519
Epoch 38/80
 - 2s - loss: 0.0517
Epoch 39/80
 - 2s - loss: 0.0516
Epoch 40/80
 - 2s - loss: 0.0514
Epoch 41/80
 - 2s - loss: 0.0513
Epoch 42/80
 - 2s - loss: 0.0512
Epoch 43/80
 - 2s - loss: 0.0511
Epoch 44/80
 - 2s - loss: 0.0510
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0509
Epoch 47/80
 - 2s - loss: 0.0508
Epoch 48/80
 - 2s - loss: 0.0507
Epoch 49/80
 - 2s - loss: 0.0507
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2afb18d2d0f0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 02:28:56.600761: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:28:56.763792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:28:56.763837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:28:57.054490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:28:57.054542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:28:57.054551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:28:57.054804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1513
Epoch 2/80
 - 2s - loss: 0.2161
Epoch 3/80
 - 2s - loss: 0.1734
Epoch 4/80
 - 2s - loss: 0.1662
Epoch 5/80
 - 2s - loss: 0.1597
Epoch 6/80
 - 2s - loss: 0.1510
Epoch 7/80
 - 2s - loss: 0.1401
Epoch 8/80
 - 2s - loss: 0.1287
Epoch 9/80
 - 2s - loss: 0.1185
Epoch 10/80
 - 2s - loss: 0.1096
Epoch 11/80
 - 2s - loss: 0.1017
Epoch 12/80
 - 2s - loss: 0.0946
Epoch 13/80
 - 2s - loss: 0.0884
Epoch 14/80
 - 2s - loss: 0.0831
Epoch 15/80
 - 2s - loss: 0.0786
Epoch 16/80
 - 2s - loss: 0.0747
Epoch 17/80
 - 2s - loss: 0.0713
Epoch 18/80
 - 2s - loss: 0.0684
Epoch 19/80
 - 2s - loss: 0.0660
Epoch 20/80
 - 2s - loss: 0.0640
Epoch 21/80
 - 2s - loss: 0.0622
Epoch 22/80
 - 2s - loss: 0.0608
Epoch 23/80
 - 2s - loss: 0.0595
Epoch 24/80
 - 2s - loss: 0.0584
Epoch 25/80
 - 2s - loss: 0.0575
Epoch 26/80
 - 2s - loss: 0.0567
Epoch 27/80
 - 2s - loss: 0.0560
Epoch 28/80
 - 2s - loss: 0.0554
Epoch 29/80
 - 2s - loss: 0.0548
Epoch 30/80
 - 2s - loss: 0.0544
Epoch 31/80
 - 2s - loss: 0.0539
Epoch 32/80
 - 2s - loss: 0.0536
Epoch 33/80
 - 2s - loss: 0.0533
Epoch 34/80
 - 2s - loss: 0.0530
Epoch 35/80
 - 2s - loss: 0.0527
Epoch 36/80
 - 2s - loss: 0.0525
Epoch 37/80
 - 2s - loss: 0.0523
Epoch 38/80
 - 2s - loss: 0.0521
Epoch 39/80
 - 2s - loss: 0.0519
Epoch 40/80
 - 2s - loss: 0.0518
Epoch 41/80
 - 2s - loss: 0.0516
Epoch 42/80
 - 2s - loss: 0.0515
Epoch 43/80
 - 2s - loss: 0.0514
Epoch 44/80
 - 2s - loss: 0.0513
Epoch 45/80
 - 2s - loss: 0.0512
Epoch 46/80
 - 2s - loss: 0.0511
Epoch 47/80
 - 2s - loss: 0.0511
Epoch 48/80
 - 2s - loss: 0.0510
Epoch 49/80
 - 2s - loss: 0.0509
Epoch 50/80
 - 2s - loss: 0.0509
Epoch 51/80
 - 2s - loss: 0.0508
Epoch 52/80
 - 2s - loss: 0.0507
Epoch 53/80
 - 2s - loss: 0.0507
Epoch 54/80
 - 2s - loss: 0.0506
Epoch 55/80
 - 2s - loss: 0.0506
Epoch 56/80
 - 2s - loss: 0.0506
Epoch 57/80
 - 2s - loss: 0.0505
Epoch 58/80
 - 2s - loss: 0.0505
Epoch 59/80
 - 2s - loss: 0.0505
Epoch 60/80
 - 2s - loss: 0.0504
Epoch 61/80
 - 2s - loss: 0.0504
Epoch 62/80
 - 2s - loss: 0.0503
Epoch 63/80
 - 2s - loss: 0.0503
Epoch 64/80
 - 2s - loss: 0.0492
Epoch 65/80
 - 2s - loss: 0.0491
Epoch 66/80
 - 2s - loss: 0.0491
Epoch 67/80
 - 2s - loss: 0.0491
Epoch 68/80
 - 2s - loss: 0.0491
Epoch 69/80
 - 2s - loss: 0.0488
Epoch 70/80
 - 2s - loss: 0.0488
Epoch 71/80
 - 2s - loss: 0.0488
Epoch 72/80
 - 2s - loss: 0.0488
Epoch 73/80
 - 2s - loss: 0.0487
Epoch 74/80
 - 2s - loss: 0.0487
Epoch 75/80
 - 2s - loss: 0.0487
Epoch 76/80
 - 2s - loss: 0.0487
Epoch 77/80
 - 2s - loss: 0.0487
Epoch 78/80
 - 2s - loss: 0.0487
Epoch 79/80
 - 2s - loss: 0.0487
Epoch 80/80
 - 2s - loss: 0.0487
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.0709 - val_loss: 1.4336
AUC: 0.7824

Epoch 2/80
 - 0s - loss: 2.8485 - val_loss: 1.1020
AUC: 0.8072

Epoch 3/80
 - 0s - loss: 1.9397 - val_loss: 0.8212
AUC: 0.8217

Epoch 4/80
 - 0s - loss: 1.4674 - val_loss: 0.7856
AUC: 0.8277

Epoch 5/80
 - 0s - loss: 1.2999 - val_loss: 0.7333
AUC: 0.8385

Epoch 6/80
 - 0s - loss: 1.2307 - val_loss: 0.6947
AUC: 0.8428

Epoch 7/80
 - 0s - loss: 1.1927 - val_loss: 0.6885
AUC: 0.8470

Epoch 8/80
 - 0s - loss: 1.1687 - val_loss: 0.6488
AUC: 0.8520

Epoch 9/80
 - 0s - loss: 1.1486 - val_loss: 0.6097
AUC: 0.8549

Epoch 10/80
 - 0s - loss: 1.1392 - val_loss: 0.6612
AUC: 0.8569

Epoch 11/80
 - 0s - loss: 1.1148 - val_loss: 0.6777
AUC: 0.8598

Epoch 12/80
 - 0s - loss: 1.1115 - val_loss: 0.6602
AUC: 0.8606

Epoch 13/80
 - 0s - loss: 1.1036 - val_loss: 0.6623
AUC: 0.8621

Epoch 14/80
 - 0s - loss: 1.1021 - val_loss: 0.6208
AUC: 0.8622

Epoch 15/80
 - 0s - loss: 1.0973 - val_loss: 0.6414
AUC: 0.8636

Epoch 16/80
 - 0s - loss: 1.0899 - val_loss: 0.6463
AUC: 0.8641

Epoch 17/80
 - 0s - loss: 1.0823 - val_loss: 0.6412
AUC: 0.8648

Epoch 18/80
 - 0s - loss: 1.0777 - val_loss: 0.6844
AUC: 0.8665

Epoch 19/80
 - 0s - loss: 1.0704 - val_loss: 0.6477
AUC: 0.8660

Epoch 20/80
 - 0s - loss: 1.0764 - val_loss: 0.6364
AUC: 0.8660

Epoch 21/80
 - 0s - loss: 1.0660 - val_loss: 0.6356
AUC: 0.8662

Epoch 22/80
 - 0s - loss: 1.0703 - val_loss: 0.6509
AUC: 0.8667

Epoch 23/80
 - 0s - loss: 1.0648 - val_loss: 0.6352
AUC: 0.8663

Epoch 24/80
 - 0s - loss: 1.0604 - val_loss: 0.6420
AUC: 0.8668

Epoch 25/80
 - 0s - loss: 1.0583 - val_loss: 0.6167
AUC: 0.8661

Epoch 26/80
 - 0s - loss: 1.0588 - val_loss: 0.6373
AUC: 0.8669

Epoch 27/80
 - 0s - loss: 1.0530 - val_loss: 0.6483
AUC: 0.8673

Epoch 28/80
 - 0s - loss: 1.0507 - val_loss: 0.6334
AUC: 0.8670

Epoch 29/80
 - 0s - loss: 1.0603 - val_loss: 0.6424
AUC: 0.8672

Epoch 30/80
 - 0s - loss: 1.0541 - val_loss: 0.6357
AUC: 0.8671

Epoch 31/80
 - 0s - loss: 1.0513 - val_loss: 0.6334
AUC: 0.8671

Epoch 32/80
 - 0s - loss: 1.0524 - val_loss: 0.6292
AUC: 0.8670

Epoch 33/80
 - 0s - loss: 1.0577 - val_loss: 0.6328
AUC: 0.8671

Epoch 34/80
 - 0s - loss: 1.0592 - val_loss: 0.6362
AUC: 0.8672

Epoch 35/80
 - 0s - loss: 1.0511 - val_loss: 0.6380
AUC: 0.8673

Epoch 36/80
 - 0s - loss: 1.0507 - val_loss: 0.6264
AUC: 0.8670

Epoch 37/80
 - 0s - loss: 1.0529 - val_loss: 0.6315
AUC: 0.8672

Epoch 38/80
 - 0s - loss: 1.0514 - val_loss: 0.6323
AUC: 0.8672

Epoch 39/80
 - 0s - loss: 1.0523 - val_loss: 0.6282
AUC: 0.8672

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0562 - val_loss: 0.6449
AUC: 0.8673

Epoch 2/30
 - 0s - loss: 1.0552 - val_loss: 0.6371
AUC: 0.8673

Epoch 3/30
 - 0s - loss: 1.0510 - val_loss: 0.6345
AUC: 0.8676

Epoch 4/30
 - 0s - loss: 1.0480 - val_loss: 0.6202
AUC: 0.8673

Epoch 5/30
 - 0s - loss: 1.0470 - val_loss: 0.6203
AUC: 0.8676

Epoch 6/30
 - 0s - loss: 1.0550 - val_loss: 0.6254
AUC: 0.8680

Epoch 7/30
 - 0s - loss: 1.0504 - val_loss: 0.6351
AUC: 0.8684

Epoch 8/30
 - 0s - loss: 1.0462 - val_loss: 0.6325
AUC: 0.8684

Epoch 9/30
 - 0s - loss: 1.0427 - val_loss: 0.6218
AUC: 0.8686

Epoch 10/30
 - 0s - loss: 1.0399 - val_loss: 0.6310
AUC: 0.8689

Epoch 11/30
 - 0s - loss: 1.0372 - val_loss: 0.6271
AUC: 0.8691

Epoch 12/30
 - 0s - loss: 1.0356 - val_loss: 0.6181
AUC: 0.8691

Epoch 13/30
 - 0s - loss: 1.0345 - val_loss: 0.6140
AUC: 0.8690

Epoch 14/30
 - 0s - loss: 1.0412 - val_loss: 0.6228
AUC: 0.8695

Epoch 15/30
 - 0s - loss: 1.0325 - val_loss: 0.6243
AUC: 0.8696

Epoch 16/30
 - 0s - loss: 1.0305 - val_loss: 0.6207
AUC: 0.8696

Epoch 17/30
 - 0s - loss: 1.0336 - val_loss: 0.6240
AUC: 0.8700

Epoch 18/30
 - 0s - loss: 1.0306 - val_loss: 0.6330
AUC: 0.8702

Epoch 19/30
 - 0s - loss: 1.0319 - val_loss: 0.6125
AUC: 0.8699

Epoch 20/30
 - 0s - loss: 1.0234 - val_loss: 0.6272
AUC: 0.8705

Epoch 21/30
 - 0s - loss: 1.0259 - val_loss: 0.6071
AUC: 0.8701

Epoch 22/30
 - 0s - loss: 1.0288 - val_loss: 0.6207
AUC: 0.8705

Epoch 23/30
 - 0s - loss: 1.0271 - val_loss: 0.6134
AUC: 0.8704

Epoch 24/30
 - 0s - loss: 1.0267 - val_loss: 0.6280
AUC: 0.8710

Epoch 25/30
 - 0s - loss: 1.0172 - val_loss: 0.6223
AUC: 0.8710

Epoch 26/30
 - 0s - loss: 1.0209 - val_loss: 0.6048
AUC: 0.8707

Epoch 27/30
 - 0s - loss: 1.0190 - val_loss: 0.6216
AUC: 0.8711

Epoch 28/30
 - 0s - loss: 1.0165 - val_loss: 0.6097
AUC: 0.8710

Epoch 29/30
 - 0s - loss: 1.0120 - val_loss: 0.6097
AUC: 0.8714

Epoch 30/30
 - 0s - loss: 1.0171 - val_loss: 0.6019
Using TensorFlow backend.
AUC: 0.8711

2019-03-08 02:32:09.264054: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:32:09.430521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:32:09.430565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:32:09.723024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:32:09.723076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:32:09.723095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:32:09.723357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1802
Epoch 2/80
 - 2s - loss: 0.2235
Epoch 3/80
 - 2s - loss: 0.1699
Epoch 4/80
 - 2s - loss: 0.1570
Epoch 5/80
 - 2s - loss: 0.1444
Epoch 6/80
 - 2s - loss: 0.1319
Epoch 7/80
 - 2s - loss: 0.1215
Epoch 8/80
 - 2s - loss: 0.1133
Epoch 9/80
 - 2s - loss: 0.1064
Epoch 10/80
 - 2s - loss: 0.1004
Epoch 11/80
 - 2s - loss: 0.0950
Epoch 12/80
 - 2s - loss: 0.0899
Epoch 13/80
 - 2s - loss: 0.0851
Epoch 14/80
 - 2s - loss: 0.0807
Epoch 15/80
 - 2s - loss: 0.0768
Epoch 16/80
 - 2s - loss: 0.0734
Epoch 17/80
 - 2s - loss: 0.0704
Epoch 18/80
 - 2s - loss: 0.0678
Epoch 19/80
 - 2s - loss: 0.0655
Epoch 20/80
 - 2s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0618
Epoch 22/80
 - 2s - loss: 0.0603
Epoch 23/80
 - 2s - loss: 0.0590
Epoch 24/80
 - 2s - loss: 0.0578
Epoch 25/80
 - 2s - loss: 0.0568
Epoch 26/80
 - 2s - loss: 0.0560
Epoch 27/80
 - 2s - loss: 0.0553
Epoch 28/80
 - 2s - loss: 0.0547
Epoch 29/80
 - 2s - loss: 0.0542
Epoch 30/80
 - 2s - loss: 0.0537
Epoch 31/80
 - 2s - loss: 0.0533
Epoch 32/80
 - 2s - loss: 0.0530
Epoch 33/80
 - 2s - loss: 0.0527
Epoch 34/80
 - 2s - loss: 0.0524
Epoch 35/80
 - 2s - loss: 0.0522
Epoch 36/80
 - 2s - loss: 0.0520
Epoch 37/80
 - 2s - loss: 0.0518
Epoch 38/80
 - 2s - loss: 0.0516
Epoch 39/80
 - 2s - loss: 0.0515
Epoch 40/80
 - 2s - loss: 0.0513
Epoch 41/80
 - 2s - loss: 0.0512
Epoch 42/80
 - 2s - loss: 0.0511
Epoch 43/80
 - 2s - loss: 0.0510
Epoch 44/80
 - 2s - loss: 0.0509
Epoch 45/80
 - 2s - loss: 0.0508
Epoch 46/80
 - 2s - loss: 0.0507
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:33:44.558706: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:33:44.727036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:33:44.727078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:33:45.028252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:33:45.028294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:33:45.028303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:33:45.028559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6901
Epoch 2/80
 - 2s - loss: 0.1304
Epoch 3/80
 - 2s - loss: 0.0724
Epoch 4/80
 - 2s - loss: 0.0662
Epoch 5/80
 - 2s - loss: 0.0637
Epoch 6/80
 - 2s - loss: 0.0615
Epoch 7/80
 - 2s - loss: 0.0587
Epoch 8/80
 - 2s - loss: 0.0548
Epoch 9/80
 - 2s - loss: 0.0501
Epoch 10/80
 - 2s - loss: 0.0457
Epoch 11/80
 - 2s - loss: 0.0420
Epoch 12/80
 - 2s - loss: 0.0388
Epoch 13/80
 - 2s - loss: 0.0362
Epoch 14/80
 - 2s - loss: 0.0339
Epoch 15/80
 - 2s - loss: 0.0318
Epoch 16/80
 - 2s - loss: 0.0300
Epoch 17/80
 - 2s - loss: 0.0284
Epoch 18/80
 - 2s - loss: 0.0269
Epoch 19/80
 - 2s - loss: 0.0256
Epoch 20/80
 - 2s - loss: 0.0245
Epoch 21/80
 - 2s - loss: 0.0234
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0218
Epoch 24/80
 - 2s - loss: 0.0211
Epoch 25/80
 - 2s - loss: 0.0205
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:34:46.817457: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:34:46.984635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:34:46.984677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:34:47.285383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:34:47.285435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:34:47.285445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:34:47.285712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6866
Epoch 2/80
 - 2s - loss: 0.1309
Epoch 3/80
 - 2s - loss: 0.0723
Epoch 4/80
 - 2s - loss: 0.0665
Epoch 5/80
 - 2s - loss: 0.0642
Epoch 6/80
 - 2s - loss: 0.0621
Epoch 7/80
 - 2s - loss: 0.0592
Epoch 8/80
 - 2s - loss: 0.0554
Epoch 9/80
 - 2s - loss: 0.0512
Epoch 10/80
 - 2s - loss: 0.0470
Epoch 11/80
 - 2s - loss: 0.0433
Epoch 12/80
 - 2s - loss: 0.0400
Epoch 13/80
 - 2s - loss: 0.0372
Epoch 14/80
 - 2s - loss: 0.0347
Epoch 15/80
 - 2s - loss: 0.0325
Epoch 16/80
 - 2s - loss: 0.0306
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:35:31.159685: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:35:31.328076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:35:31.328129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:35:31.627501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:35:31.627554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:35:31.627563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:35:31.627838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.7021
Epoch 2/80
 - 2s - loss: 0.1363
Epoch 3/80
 - 2s - loss: 0.0737
Epoch 4/80
 - 2s - loss: 0.0664
Epoch 5/80
 - 2s - loss: 0.0635
Epoch 6/80
 - 2s - loss: 0.0611
Epoch 7/80
 - 2s - loss: 0.0582
Epoch 8/80
 - 2s - loss: 0.0544
Epoch 9/80
 - 2s - loss: 0.0502
Epoch 10/80
 - 2s - loss: 0.0464
Epoch 11/80
 - 2s - loss: 0.0430
Epoch 12/80
 - 2s - loss: 0.0399
Epoch 13/80
 - 2s - loss: 0.0369
Epoch 14/80
 - 2s - loss: 0.0341
Epoch 15/80
 - 2s - loss: 0.0317
Epoch 16/80
 - 2s - loss: 0.0295
Epoch 17/80
 - 2s - loss: 0.0278
Epoch 18/80
 - 2s - loss: 0.0262
Epoch 19/80
 - 2s - loss: 0.0249
Epoch 20/80
 - 2s - loss: 0.0238
Epoch 21/80
 - 2s - loss: 0.0228
Epoch 22/80
 - 2s - loss: 0.0220
Epoch 23/80
 - 2s - loss: 0.0213
Epoch 24/80
 - 2s - loss: 0.0207
Epoch 25/80
 - 2s - loss: 0.0202
Epoch 26/80
 - 2s - loss: 0.0198
Epoch 27/80
 - 2s - loss: 0.0194
Epoch 28/80
 - 2s - loss: 0.0191
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0186
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0180
Epoch 34/80
 - 2s - loss: 0.0178
Epoch 35/80
 - 2s - loss: 0.0177
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0169
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0168
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0167
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Epoch 53/80
 - 2s - loss: 0.0166
Epoch 54/80
 - 2s - loss: 0.0165
Epoch 55/80
 - 2s - loss: 0.0165
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0161
Epoch 58/80
 - 2s - loss: 0.0161
Epoch 59/80
 - 2s - loss: 0.0161
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 8.0356 - val_loss: 1.4145
AUC: 0.7035

Epoch 2/80
 - 0s - loss: 3.4005 - val_loss: 1.3045
AUC: 0.7857

Epoch 3/80
 - 0s - loss: 2.3249 - val_loss: 0.8647
AUC: 0.7965

Epoch 4/80
 - 0s - loss: 1.6103 - val_loss: 0.7273
AUC: 0.8213

Epoch 5/80
 - 0s - loss: 1.3361 - val_loss: 0.7204
AUC: 0.8263

Epoch 6/80
 - 0s - loss: 1.2661 - val_loss: 0.7398
AUC: 0.8335

Epoch 7/80
 - 0s - loss: 1.2273 - val_loss: 0.7431
AUC: 0.8362

Epoch 8/80
 - 0s - loss: 1.1945 - val_loss: 0.7247
AUC: 0.8371

Epoch 9/80
 - 0s - loss: 1.1770 - val_loss: 0.7391
AUC: 0.8423

Epoch 10/80
 - 0s - loss: 1.1665 - val_loss: 0.7072
AUC: 0.8444

Epoch 11/80
 - 0s - loss: 1.1375 - val_loss: 0.7194
AUC: 0.8450

Epoch 12/80
 - 0s - loss: 1.1294 - val_loss: 0.6775
AUC: 0.8466

Epoch 13/80
 - 0s - loss: 1.1298 - val_loss: 0.7335
AUC: 0.8498

Epoch 14/80
 - 0s - loss: 1.1069 - val_loss: 0.7072
AUC: 0.8503

Epoch 15/80
 - 0s - loss: 1.1034 - val_loss: 0.6550
AUC: 0.8513

Epoch 16/80
 - 0s - loss: 1.0988 - val_loss: 0.6583
AUC: 0.8529

Epoch 17/80
 - 0s - loss: 1.0924 - val_loss: 0.6580
AUC: 0.8540

Epoch 18/80
 - 0s - loss: 1.0789 - val_loss: 0.6518
AUC: 0.8547

Epoch 19/80
 - 0s - loss: 1.0785 - val_loss: 0.6977
AUC: 0.8569

Epoch 20/80
 - 0s - loss: 1.0701 - val_loss: 0.6273
AUC: 0.8556

Epoch 21/80
 - 0s - loss: 1.0687 - val_loss: 0.6715
AUC: 0.8577

Epoch 22/80
 - 0s - loss: 1.0653 - val_loss: 0.6362
AUC: 0.8578

Epoch 23/80
 - 0s - loss: 1.0613 - val_loss: 0.6671
AUC: 0.8573

Epoch 24/80
 - 0s - loss: 1.0569 - val_loss: 0.6800
AUC: 0.8596

Epoch 25/80
 - 0s - loss: 1.0526 - val_loss: 0.6401
AUC: 0.8591

Epoch 26/80
 - 0s - loss: 1.0497 - val_loss: 0.6059
AUC: 0.8599

Epoch 27/80
 - 0s - loss: 1.0407 - val_loss: 0.6037
AUC: 0.8604

Epoch 28/80
 - 0s - loss: 1.0446 - val_loss: 0.6042
AUC: 0.8602

Epoch 29/80
 - 0s - loss: 1.0428 - val_loss: 0.6264
AUC: 0.8618

Epoch 30/80
 - 0s - loss: 1.0391 - val_loss: 0.6212
AUC: 0.8621

Epoch 31/80
 - 0s - loss: 1.0345 - val_loss: 0.6658
AUC: 0.8619

Epoch 32/80
 - 0s - loss: 1.0330 - val_loss: 0.6381
AUC: 0.8631

Epoch 33/80
 - 0s - loss: 1.0280 - val_loss: 0.5643
AUC: 0.8627

Epoch 34/80
 - 0s - loss: 1.0288 - val_loss: 0.6948
AUC: 0.8641

Epoch 35/80
 - 0s - loss: 1.0197 - val_loss: 0.6327
AUC: 0.8646

Epoch 36/80
 - 0s - loss: 1.0189 - val_loss: 0.6728
AUC: 0.8646

Epoch 37/80
 - 0s - loss: 1.0196 - val_loss: 0.6299
AUC: 0.8646

Epoch 38/80
 - 0s - loss: 1.0264 - val_loss: 0.6111
AUC: 0.8647

Epoch 39/80
 - 0s - loss: 1.0214 - val_loss: 0.6198
AUC: 0.8649

Epoch 40/80
 - 0s - loss: 1.0100 - val_loss: 0.6301
AUC: 0.8647

Epoch 41/80
 - 0s - loss: 1.0214 - val_loss: 0.6081
AUC: 0.8645

Epoch 42/80
 - 0s - loss: 1.0112 - val_loss: 0.6134
AUC: 0.8654

Epoch 43/80
 - 0s - loss: 1.0174 - val_loss: 0.6208
AUC: 0.8654

Epoch 44/80
 - 0s - loss: 1.0072 - val_loss: 0.6063
AUC: 0.8656

Epoch 45/80
 - 0s - loss: 1.0048 - val_loss: 0.6149
AUC: 0.8658

Epoch 46/80
 - 0s - loss: 0.9947 - val_loss: 0.5926
AUC: 0.8657

Epoch 47/80
 - 0s - loss: 0.9985 - val_loss: 0.5964
AUC: 0.8658

Epoch 48/80
 - 0s - loss: 0.9961 - val_loss: 0.6210
AUC: 0.8660

Epoch 49/80
 - 0s - loss: 1.0013 - val_loss: 0.5995
AUC: 0.8659

Epoch 50/80
 - 0s - loss: 0.9997 - val_loss: 0.6134
AUC: 0.8660

Epoch 51/80
 - 0s - loss: 1.0003 - val_loss: 0.5973
AUC: 0.8660

Epoch 52/80
 - 0s - loss: 1.0001 - val_loss: 0.6026
AUC: 0.8658

Epoch 53/80
 - 0s - loss: 1.0032 - val_loss: 0.6133
AUC: 0.8659

Epoch 54/80
 - 0s - loss: 0.9965 - val_loss: 0.6183
AUC: 0.8660

Epoch 55/80
 - 0s - loss: 1.0026 - val_loss: 0.6150
AUC: 0.8661

Epoch 56/80
 - 0s - loss: 0.9991 - val_loss: 0.6143
AUC: 0.8661

Epoch 57/80
 - 0s - loss: 0.9976 - val_loss: 0.6139
AUC: 0.8661

Epoch 58/80
 - 0s - loss: 0.9974 - val_loss: 0.6173
AUC: 0.8661

Epoch 59/80
 - 0s - loss: 0.9936 - val_loss: 0.6139
AUC: 0.8661

Epoch 60/80
 - 0s - loss: 1.0022 - val_loss: 0.6154
AUC: 0.8661

Epoch 61/80
 - 0s - loss: 0.9922 - val_loss: 0.6113
AUC: 0.8660

Epoch 62/80
 - 0s - loss: 0.9954 - val_loss: 0.6082
AUC: 0.8660

Epoch 63/80
 - 0s - loss: 0.9893 - val_loss: 0.6074
AUC: 0.8660

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9969 - val_loss: 0.6120
AUC: 0.8660

Epoch 2/30
 - 0s - loss: 0.9964 - val_loss: 0.6042
AUC: 0.8661

Epoch 3/30
 - 0s - loss: 0.9986 - val_loss: 0.6053
AUC: 0.8662

Epoch 4/30
 - 0s - loss: 0.9935 - val_loss: 0.6329
AUC: 0.8665

Epoch 5/30
 - 0s - loss: 0.9956 - val_loss: 0.6244
AUC: 0.8667

Epoch 6/30
 - 0s - loss: 0.9880 - val_loss: 0.6086
AUC: 0.8670

Epoch 7/30
 - 0s - loss: 0.9855 - val_loss: 0.6229
AUC: 0.8670

Epoch 8/30
 - 0s - loss: 0.9932 - val_loss: 0.6124
AUC: 0.8670

Epoch 9/30
 - 0s - loss: 0.9888 - val_loss: 0.6132
AUC: 0.8670

Epoch 10/30
 - 0s - loss: 0.9853 - val_loss: 0.5964
AUC: 0.8670

Epoch 11/30
 - 0s - loss: 0.9889 - val_loss: 0.6048
AUC: 0.8673

Epoch 12/30
 - 0s - loss: 0.9906 - val_loss: 0.5959
AUC: 0.8672

Epoch 13/30
 - 0s - loss: 0.9903 - val_loss: 0.6043
AUC: 0.8674

Epoch 14/30
 - 0s - loss: 0.9823 - val_loss: 0.6082
AUC: 0.8674

Epoch 15/30
 - 0s - loss: 0.9880 - val_loss: 0.6198
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.9831 - val_loss: 0.5968
AUC: 0.8675

Epoch 17/30
 - 0s - loss: 0.9799 - val_loss: 0.6085
AUC: 0.8677

Epoch 18/30
 - 0s - loss: 0.9788 - val_loss: 0.6146
AUC: 0.8679

Epoch 19/30
 - 0s - loss: 0.9767 - val_loss: 0.6009
AUC: 0.8679

Epoch 20/30
 - 0s - loss: 0.9815 - val_loss: 0.5991
AUC: 0.8679

Epoch 21/30
 - 0s - loss: 0.9765 - val_loss: 0.5891
AUC: 0.8678

Epoch 22/30
 - 0s - loss: 0.9767 - val_loss: 0.6047
AUC: 0.8681

Epoch 23/30
 - 0s - loss: 0.9742 - val_loss: 0.6034
AUC: 0.8683

Epoch 24/30
 - 0s - loss: 0.9677 - val_loss: 0.5847
AUC: 0.8680

Epoch 25/30
 - 0s - loss: 0.9684 - val_loss: 0.6049
AUC: 0.8683

Epoch 26/30
 - 0s - loss: 0.9745 - val_loss: 0.5858
AUC: 0.8684

Epoch 27/30
 - 0s - loss: 0.9734 - val_loss: 0.6003
AUC: 0.8685

Epoch 28/30
 - 0s - loss: 0.9673 - val_loss: 0.5902
AUC: 0.8685

Epoch 29/30
 - 0s - loss: 0.9653 - val_loss: 0.5951
AUC: 0.8684

Epoch 30/30
 - 0s - loss: 0.9688 - val_loss: 0.6017
Using TensorFlow backend.
AUC: 0.8686

2019-03-08 02:38:57.670530: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:38:57.837628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:38:57.837671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:38:58.140000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:38:58.140040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:38:58.140050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:38:58.140351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3660
Epoch 2/80
 - 2s - loss: 0.3506
Epoch 3/80
 - 2s - loss: 0.3078
Epoch 4/80
 - 2s - loss: 0.2954
Epoch 5/80
 - 2s - loss: 0.2795
Epoch 6/80
 - 2s - loss: 0.2590
Epoch 7/80
 - 2s - loss: 0.2397
Epoch 8/80
 - 2s - loss: 0.2240
Epoch 9/80
 - 2s - loss: 0.2103
Epoch 10/80
 - 2s - loss: 0.1975
Epoch 11/80
 - 2s - loss: 0.1857
Epoch 12/80
 - 2s - loss: 0.1749
Epoch 13/80
 - 2s - loss: 0.1652
Epoch 14/80
 - 2s - loss: 0.1568
Epoch 15/80
 - 2s - loss: 0.1496
Epoch 16/80
 - 2s - loss: 0.1436
Epoch 17/80
 - 2s - loss: 0.1387
Epoch 18/80
 - 2s - loss: 0.1347
Epoch 19/80
 - 2s - loss: 0.1314
Epoch 20/80
 - 2s - loss: 0.1288
Epoch 21/80
 - 2s - loss: 0.1266
Epoch 22/80
 - 2s - loss: 0.1248
Epoch 23/80
 - 2s - loss: 0.1233
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:39:52.558414: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:39:52.723284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:39:52.723329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:39:53.016557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:39:53.016611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:39:53.016622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:39:53.016996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3570
Epoch 2/80
 - 2s - loss: 0.3515
Epoch 3/80
 - 2s - loss: 0.3030
Epoch 4/80
 - 2s - loss: 0.2821
Epoch 5/80
 - 2s - loss: 0.2593
Epoch 6/80
 - 2s - loss: 0.2413
Epoch 7/80
 - 2s - loss: 0.2277
Epoch 8/80
 - 2s - loss: 0.2163
Epoch 9/80
 - 2s - loss: 0.2056
Epoch 10/80
 - 2s - loss: 0.1951
Epoch 11/80
 - 2s - loss: 0.1846
Epoch 12/80
 - 2s - loss: 0.1743
Epoch 13/80
 - 2s - loss: 0.1650
Epoch 14/80
 - 2s - loss: 0.1571
Epoch 15/80
 - 2s - loss: 0.1505
Epoch 16/80
 - 2s - loss: 0.1451
Epoch 17/80
 - 2s - loss: 0.1404
Epoch 18/80
 - 2s - loss: 0.1365
Epoch 19/80
 - 2s - loss: 0.1332
Epoch 20/80
 - 2s - loss: 0.1305
Epoch 21/80
 - 2s - loss: 0.1283
Epoch 22/80
 - 2s - loss: 0.1265
Epoch 23/80
 - 2s - loss: 0.1249
Epoch 24/80
 - 2s - loss: 0.1236
Epoch 25/80
 - 2s - loss: 0.1225
Epoch 26/80
 - 2s - loss: 0.1216
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:40:56.444553: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:40:56.606932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:40:56.606977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:40:56.901908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:40:56.901959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:40:56.901968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:40:56.902245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3809
Epoch 2/80
 - 2s - loss: 0.3516
Epoch 3/80
 - 2s - loss: 0.3082
Epoch 4/80
 - 2s - loss: 0.2949
Epoch 5/80
 - 2s - loss: 0.2802
Epoch 6/80
 - 2s - loss: 0.2645
Epoch 7/80
 - 2s - loss: 0.2472
Epoch 8/80
 - 2s - loss: 0.2280
Epoch 9/80
 - 2s - loss: 0.2095
Epoch 10/80
 - 2s - loss: 0.1939
Epoch 11/80
 - 2s - loss: 0.1811
Epoch 12/80
 - 2s - loss: 0.1706
Epoch 13/80
 - 2s - loss: 0.1617
Epoch 14/80
 - 2s - loss: 0.1544
Epoch 15/80
 - 2s - loss: 0.1482
Epoch 16/80
 - 2s - loss: 0.1429
Epoch 17/80
 - 2s - loss: 0.1385
Epoch 18/80
 - 2s - loss: 0.1348
Epoch 19/80
 - 2s - loss: 0.1319
Epoch 20/80
 - 2s - loss: 0.1294
Epoch 21/80
 - 2s - loss: 0.1274
Epoch 22/80
 - 2s - loss: 0.1257
Epoch 23/80
 - 2s - loss: 0.1242
Epoch 24/80
 - 2s - loss: 0.1230
Epoch 25/80
 - 2s - loss: 0.1219
Epoch 26/80
 - 2s - loss: 0.1210
Epoch 27/80
 - 2s - loss: 0.1203
Epoch 28/80
 - 2s - loss: 0.1196
Epoch 29/80
 - 2s - loss: 0.1190
Epoch 30/80
 - 2s - loss: 0.1185
Epoch 31/80
 - 2s - loss: 0.1181
Epoch 32/80
 - 2s - loss: 0.1177
Epoch 33/80
 - 2s - loss: 0.1174
Epoch 34/80
 - 2s - loss: 0.1171
Epoch 35/80
 - 2s - loss: 0.1168
Epoch 36/80
 - 2s - loss: 0.1166
Epoch 37/80
 - 2s - loss: 0.1164
Epoch 38/80
 - 2s - loss: 0.1162
Epoch 39/80
 - 2s - loss: 0.1160
Epoch 40/80
 - 2s - loss: 0.1159
Epoch 41/80
 - 2s - loss: 0.1157
Epoch 42/80
 - 2s - loss: 0.1156
Epoch 43/80
 - 2s - loss: 0.1154
Epoch 44/80
 - 2s - loss: 0.1153
Epoch 45/80
 - 2s - loss: 0.1152
Epoch 46/80
 - 2s - loss: 0.1151
Epoch 47/80
 - 2s - loss: 0.1150
Epoch 48/80
 - 2s - loss: 0.1150
Epoch 49/80
 - 2s - loss: 0.1149
Epoch 50/80
 - 2s - loss: 0.1148
Epoch 51/80
 - 2s - loss: 0.1147
Epoch 52/80
 - 2s - loss: 0.1147
Epoch 53/80
 - 2s - loss: 0.1146
Epoch 54/80
 - 2s - loss: 0.1145
Epoch 55/80
 - 2s - loss: 0.1145
Epoch 56/80
 - 2s - loss: 0.1144
Epoch 57/80
 - 2s - loss: 0.1144
Epoch 58/80
 - 2s - loss: 0.1143
Epoch 59/80
 - 2s - loss: 0.1143
Epoch 60/80
 - 2s - loss: 0.1142
Epoch 61/80
 - 2s - loss: 0.1142
Epoch 62/80
 - 2s - loss: 0.1142
Epoch 63/80
 - 2s - loss: 0.1141
Epoch 64/80
 - 2s - loss: 0.1141
Epoch 65/80
 - 2s - loss: 0.1140
Epoch 66/80
 - 2s - loss: 0.1140
Epoch 67/80
 - 2s - loss: 0.1140
Epoch 68/80
 - 2s - loss: 0.1139
Epoch 69/80
 - 2s - loss: 0.1117
Epoch 70/80
 - 2s - loss: 0.1115
Epoch 71/80
 - 2s - loss: 0.1114
Epoch 72/80
 - 2s - loss: 0.1114
Epoch 73/80
 - 2s - loss: 0.1114
Epoch 74/80
 - 2s - loss: 0.1108
Epoch 75/80
 - 2s - loss: 0.1108
Epoch 76/80
 - 2s - loss: 0.1108
Epoch 77/80
 - 2s - loss: 0.1108
Epoch 78/80
 - 2s - loss: 0.1107
Epoch 79/80
 - 2s - loss: 0.1107
Epoch 80/80
 - 2s - loss: 0.1107
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.8507 - val_loss: 0.7990
AUC: 0.8197

Epoch 2/80
 - 0s - loss: 1.3436 - val_loss: 0.7975
AUC: 0.8361

Epoch 3/80
 - 0s - loss: 1.2025 - val_loss: 0.6777
AUC: 0.8415

Epoch 4/80
 - 0s - loss: 1.1450 - val_loss: 0.7419
AUC: 0.8486

Epoch 5/80
 - 0s - loss: 1.1184 - val_loss: 0.6302
AUC: 0.8499

Epoch 6/80
 - 0s - loss: 1.0973 - val_loss: 0.7063
AUC: 0.8540

Epoch 7/80
 - 0s - loss: 1.0968 - val_loss: 0.6961
AUC: 0.8555

Epoch 8/80
 - 0s - loss: 1.0887 - val_loss: 0.7111
AUC: 0.8577

Epoch 9/80
 - 0s - loss: 1.0676 - val_loss: 0.5987
AUC: 0.8571

Epoch 10/80
 - 0s - loss: 1.0705 - val_loss: 0.6747
AUC: 0.8599

Epoch 11/80
 - 0s - loss: 1.0611 - val_loss: 0.6082
AUC: 0.8595

Epoch 12/80
 - 0s - loss: 1.0524 - val_loss: 0.6539
AUC: 0.8604

Epoch 13/80
 - 0s - loss: 1.0465 - val_loss: 0.5762
AUC: 0.8600

Epoch 14/80
 - 0s - loss: 1.0421 - val_loss: 0.6195
AUC: 0.8608

Epoch 15/80
 - 0s - loss: 1.0405 - val_loss: 0.6431
AUC: 0.8639

Epoch 16/80
 - 0s - loss: 1.0254 - val_loss: 0.6419
AUC: 0.8631

Epoch 17/80
 - 0s - loss: 1.0287 - val_loss: 0.5853
AUC: 0.8616

Epoch 18/80
 - 0s - loss: 1.0231 - val_loss: 0.6454
AUC: 0.8643

Epoch 19/80
 - 0s - loss: 1.0196 - val_loss: 0.6212
AUC: 0.8638

Epoch 20/80
 - 0s - loss: 1.0200 - val_loss: 0.6569
AUC: 0.8644

Epoch 21/80
 - 0s - loss: 1.0139 - val_loss: 0.6228
AUC: 0.8650

Epoch 22/80
 - 0s - loss: 1.0092 - val_loss: 0.6470
AUC: 0.8664

Epoch 23/80
 - 0s - loss: 1.0061 - val_loss: 0.6871
AUC: 0.8664

Epoch 24/80
 - 0s - loss: 0.9985 - val_loss: 0.6214
AUC: 0.8658

Epoch 25/80
 - 0s - loss: 0.9996 - val_loss: 0.6124
AUC: 0.8658

Epoch 26/80
 - 0s - loss: 1.0007 - val_loss: 0.6245
AUC: 0.8660

Epoch 27/80
 - 0s - loss: 0.9931 - val_loss: 0.6212
AUC: 0.8661

Epoch 28/80
 - 0s - loss: 0.9942 - val_loss: 0.6042
AUC: 0.8659

Epoch 29/80
 - 0s - loss: 0.9963 - val_loss: 0.6014
AUC: 0.8657

Epoch 30/80
 - 0s - loss: 0.9920 - val_loss: 0.6271
AUC: 0.8658

Epoch 31/80
 - 0s - loss: 0.9939 - val_loss: 0.6091
AUC: 0.8659

Epoch 32/80
 - 0s - loss: 0.9945 - val_loss: 0.6158
AUC: 0.8665

Epoch 33/80
 - 0s - loss: 0.9917 - val_loss: 0.6016
AUC: 0.8663

Epoch 34/80
 - 0s - loss: 0.9929 - val_loss: 0.6076
AUC: 0.8666

Epoch 35/80
 - 0s - loss: 0.9885 - val_loss: 0.6068
AUC: 0.8664

Epoch 36/80
 - 0s - loss: 0.9860 - val_loss: 0.6046
AUC: 0.8664

Epoch 37/80
 - 0s - loss: 0.9868 - val_loss: 0.6128
AUC: 0.8665

Epoch 38/80
 - 0s - loss: 0.9930 - val_loss: 0.6043
AUC: 0.8664

Epoch 39/80
 - 0s - loss: 0.9921 - val_loss: 0.6009
AUC: 0.8663

Epoch 40/80
 - 0s - loss: 0.9874 - val_loss: 0.6104
AUC: 0.8664

Epoch 41/80
 - 0s - loss: 0.9875 - val_loss: 0.6101
AUC: 0.8664

Epoch 42/80
 - 0s - loss: 0.9867 - val_loss: 0.6092
AUC: 0.8664

Epoch 43/80
 - 0s - loss: 0.9848 - val_loss: 0.6066
AUC: 0.8664

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9867 - val_loss: 0.5841
AUC: 0.8659

Epoch 2/30
 - 0s - loss: 0.9843 - val_loss: 0.5901
AUC: 0.8662

Epoch 3/30
 - 0s - loss: 0.9839 - val_loss: 0.6161
AUC: 0.8667

Epoch 4/30
 - 0s - loss: 0.9891 - val_loss: 0.5816
AUC: 0.8664

Epoch 5/30
 - 0s - loss: 0.9904 - val_loss: 0.6261
AUC: 0.8671

Epoch 6/30
 - 0s - loss: 0.9843 - val_loss: 0.6148
AUC: 0.8670

Epoch 7/30
 - 0s - loss: 0.9844 - val_loss: 0.5978
AUC: 0.8672

Epoch 8/30
 - 0s - loss: 0.9831 - val_loss: 0.6208
AUC: 0.8675

Epoch 9/30
 - 0s - loss: 0.9804 - val_loss: 0.5854
AUC: 0.8672

Epoch 10/30
 - 0s - loss: 0.9786 - val_loss: 0.6121
AUC: 0.8676

Epoch 11/30
 - 0s - loss: 0.9781 - val_loss: 0.6144
AUC: 0.8677

Epoch 12/30
 - 0s - loss: 0.9760 - val_loss: 0.6080
AUC: 0.8675

Epoch 13/30
 - 0s - loss: 0.9726 - val_loss: 0.6151
AUC: 0.8677

Epoch 14/30
 - 0s - loss: 0.9715 - val_loss: 0.6031
AUC: 0.8676

Epoch 15/30
 - 0s - loss: 0.9746 - val_loss: 0.6034
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.9765 - val_loss: 0.6021
AUC: 0.8677

Epoch 17/30
 - 0s - loss: 0.9687 - val_loss: 0.6055
AUC: 0.8678

Epoch 18/30
 - 0s - loss: 0.9730 - val_loss: 0.6014
AUC: 0.8677

Epoch 19/30
 - 0s - loss: 0.9707 - val_loss: 0.6042
AUC: 0.8678

Epoch 20/30
 - 0s - loss: 0.9704 - val_loss: 0.6004
AUC: 0.8678

Epoch 21/30
 - 0s - loss: 0.9700 - val_loss: 0.5997
AUC: 0.8678

Epoch 22/30
 - 0s - loss: 0.9732 - val_loss: 0.6079
AUC: 0.8680

Epoch 23/30
 - 0s - loss: 0.9708 - val_loss: 0.6067
AUC: 0.8679

Epoch 24/30
 - 0s - loss: 0.9691 - val_loss: 0.6007
AUC: 0.8679

Epoch 25/30
 - 0s - loss: 0.9704 - val_loss: 0.6020
AUC: 0.8679

Epoch 26/30
 - 0s - loss: 0.9618 - val_loss: 0.6010
AUC: 0.8679

Epoch 27/30
 - 0s - loss: 0.9707 - val_loss: 0.6021
AUC: 0.8679

Epoch 28/30
 - 0s - loss: 0.9689 - val_loss: 0.6027
AUC: 0.8679

Epoch 29/30
 - 0s - loss: 0.9751 - val_loss: 0.6030
AUC: 0.8679

Epoch 30/30
 - 0s - loss: 0.9715 - val_loss: 0.6021
Using TensorFlow backend.
AUC: 0.8679

2019-03-08 02:44:15.961421: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:44:16.130998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:44:16.131042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:44:16.428535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:44:16.428585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:44:16.428595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:44:16.428847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3796
Epoch 2/80
 - 2s - loss: 0.3527
Epoch 3/80
 - 2s - loss: 0.2989
Epoch 4/80
 - 2s - loss: 0.2701
Epoch 5/80
 - 2s - loss: 0.2463
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:44:42.780957: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:44:42.944790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:44:42.944832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:44:43.260964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:44:43.261010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:44:43.261018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:44:43.261304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1456
Epoch 2/80
 - 2s - loss: 0.2150
Epoch 3/80
 - 2s - loss: 0.1742
Epoch 4/80
 - 2s - loss: 0.1676
Epoch 5/80
 - 2s - loss: 0.1620
Epoch 6/80
 - 2s - loss: 0.1538
Epoch 7/80
 - 2s - loss: 0.1431
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:45:16.422592: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:45:16.587137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:45:16.587201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:45:16.878725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:45:16.878776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:45:16.878785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:45:16.879042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1346
Epoch 2/80
 - 2s - loss: 0.2133
Epoch 3/80
 - 2s - loss: 0.1734
Epoch 4/80
 - 2s - loss: 0.1668
Epoch 5/80
 - 2s - loss: 0.1612
Epoch 6/80
 - 2s - loss: 0.1544
Epoch 7/80
 - 2s - loss: 0.1460
Epoch 8/80
 - 2s - loss: 0.1361
Epoch 9/80
 - 2s - loss: 0.1253
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:45:48.967737: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:45:49.131848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:45:49.131892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:45:49.424970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:45:49.425020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:45:49.425028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:45:49.425290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1651
Epoch 2/80
 - 2s - loss: 0.2197
Epoch 3/80
 - 2s - loss: 0.1693
Epoch 4/80
 - 2s - loss: 0.1570
Epoch 5/80
 - 2s - loss: 0.1454
Epoch 6/80
 - 2s - loss: 0.1336
Epoch 7/80
 - 2s - loss: 0.1237
Epoch 8/80
 - 2s - loss: 0.1163
Epoch 9/80
 - 2s - loss: 0.1102
Epoch 10/80
 - 2s - loss: 0.1044
Epoch 11/80
 - 2s - loss: 0.0985
Epoch 12/80
 - 2s - loss: 0.0926
Epoch 13/80
 - 2s - loss: 0.0869
Epoch 14/80
 - 2s - loss: 0.0819
Epoch 15/80
 - 2s - loss: 0.0774
Epoch 16/80
 - 2s - loss: 0.0734
Epoch 17/80
 - 2s - loss: 0.0699
Epoch 18/80
 - 2s - loss: 0.0669
Epoch 19/80
 - 2s - loss: 0.0644
Epoch 20/80
 - 2s - loss: 0.0623
Epoch 21/80
 - 2s - loss: 0.0606
Epoch 22/80
 - 2s - loss: 0.0592
Epoch 23/80
 - 2s - loss: 0.0580
Epoch 24/80
 - 2s - loss: 0.0570
Epoch 25/80
 - 2s - loss: 0.0561
Epoch 26/80
 - 2s - loss: 0.0553
Epoch 27/80
 - 2s - loss: 0.0547
Epoch 28/80
 - 2s - loss: 0.0541
Epoch 29/80
 - 2s - loss: 0.0536
Epoch 30/80
 - 2s - loss: 0.0532
Epoch 31/80
 - 2s - loss: 0.0529
Epoch 32/80
 - 2s - loss: 0.0525
Epoch 33/80
 - 2s - loss: 0.0523
Epoch 34/80
 - 2s - loss: 0.0520
Epoch 35/80
 - 2s - loss: 0.0518
Epoch 36/80
 - 2s - loss: 0.0516
Epoch 37/80
 - 2s - loss: 0.0515
Epoch 38/80
 - 2s - loss: 0.0513
Epoch 39/80
 - 2s - loss: 0.0512
Epoch 40/80
 - 2s - loss: 0.0511
Epoch 41/80
 - 2s - loss: 0.0510
Epoch 42/80
 - 2s - loss: 0.0509
Epoch 43/80
 - 2s - loss: 0.0508
Epoch 44/80
 - 2s - loss: 0.0507
Epoch 45/80
 - 2s - loss: 0.0506
Epoch 46/80
 - 2s - loss: 0.0505
Epoch 47/80
 - 2s - loss: 0.0505
Epoch 48/80
 - 2s - loss: 0.0504
Epoch 49/80
 - 2s - loss: 0.0504
Epoch 50/80
 - 2s - loss: 0.0503
Epoch 51/80
 - 2s - loss: 0.0503
Epoch 52/80
 - 2s - loss: 0.0502
Epoch 53/80
 - 2s - loss: 0.0502
Epoch 54/80
 - 2s - loss: 0.0502
Epoch 55/80
 - 2s - loss: 0.0501
Epoch 56/80
 - 2s - loss: 0.0501
Epoch 57/80
 - 2s - loss: 0.0500
Epoch 58/80
 - 2s - loss: 0.0500
Epoch 59/80
 - 2s - loss: 0.0500
Epoch 60/80
 - 2s - loss: 0.0500
Epoch 61/80
 - 2s - loss: 0.0489
Epoch 62/80
 - 2s - loss: 0.0488
Epoch 63/80
 - 2s - loss: 0.0487
Epoch 64/80
 - 2s - loss: 0.0487
Epoch 65/80
 - 2s - loss: 0.0487
Epoch 66/80
 - 2s - loss: 0.0484
Epoch 67/80
 - 2s - loss: 0.0484
Epoch 68/80
 - 2s - loss: 0.0484
Epoch 69/80
 - 2s - loss: 0.0484
Epoch 70/80
 - 2s - loss: 0.0484
Epoch 71/80
 - 2s - loss: 0.0484
Epoch 72/80
 - 2s - loss: 0.0484
Epoch 73/80
 - 2s - loss: 0.0484
Epoch 74/80
 - 2s - loss: 0.0484
Epoch 75/80
 - 2s - loss: 0.0484
Epoch 76/80
 - 2s - loss: 0.0483
Epoch 77/80
 - 2s - loss: 0.0483
Epoch 78/80
 - 2s - loss: 0.0483
Epoch 79/80
 - 2s - loss: 0.0483
Epoch 80/80
 - 2s - loss: 0.0483
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.6764 - val_loss: 1.1436
AUC: 0.7920

Epoch 2/80
 - 0s - loss: 2.0919 - val_loss: 0.8112
AUC: 0.8323

Epoch 3/80
 - 0s - loss: 1.3773 - val_loss: 0.7149
AUC: 0.8466

Epoch 4/80
 - 0s - loss: 1.2150 - val_loss: 0.7627
AUC: 0.8541

Epoch 5/80
 - 0s - loss: 1.1581 - val_loss: 0.6436
AUC: 0.8550

Epoch 6/80
 - 0s - loss: 1.1346 - val_loss: 0.7132
AUC: 0.8594

Epoch 7/80
 - 0s - loss: 1.0976 - val_loss: 0.6253
AUC: 0.8595

Epoch 8/80
 - 0s - loss: 1.0904 - val_loss: 0.6254
AUC: 0.8596

Epoch 9/80
 - 0s - loss: 1.0704 - val_loss: 0.6570
AUC: 0.8619

Epoch 10/80
 - 0s - loss: 1.0708 - val_loss: 0.6179
AUC: 0.8646

Epoch 11/80
 - 0s - loss: 1.0532 - val_loss: 0.6330
AUC: 0.8654

Epoch 12/80
 - 0s - loss: 1.0478 - val_loss: 0.6192
AUC: 0.8660

Epoch 13/80
 - 0s - loss: 1.0406 - val_loss: 0.6374
AUC: 0.8653

Epoch 14/80
 - 0s - loss: 1.0376 - val_loss: 0.5688
AUC: 0.8655

Epoch 15/80
 - 0s - loss: 1.0349 - val_loss: 0.6638
AUC: 0.8676

Epoch 16/80
 - 0s - loss: 1.0238 - val_loss: 0.5639
AUC: 0.8647

Epoch 17/80
 - 0s - loss: 1.0247 - val_loss: 0.5963
AUC: 0.8680

Epoch 18/80
 - 0s - loss: 1.0223 - val_loss: 0.6113
AUC: 0.8693

Epoch 19/80
 - 0s - loss: 1.0180 - val_loss: 0.6287
AUC: 0.8696

Epoch 20/80
 - 0s - loss: 1.0127 - val_loss: 0.5921
AUC: 0.8697

Epoch 21/80
 - 0s - loss: 1.0082 - val_loss: 0.5931
AUC: 0.8701

Epoch 22/80
 - 0s - loss: 1.0079 - val_loss: 0.6456
AUC: 0.8716

Epoch 23/80
 - 0s - loss: 1.0030 - val_loss: 0.5648
AUC: 0.8703

Epoch 24/80
 - 0s - loss: 1.0019 - val_loss: 0.5553
AUC: 0.8696

Epoch 25/80
 - 0s - loss: 0.9950 - val_loss: 0.6058
AUC: 0.8728

Epoch 26/80
 - 0s - loss: 0.9967 - val_loss: 0.6323
AUC: 0.8733

Epoch 27/80
 - 0s - loss: 0.9939 - val_loss: 0.6175
AUC: 0.8738

Epoch 28/80
 - 0s - loss: 0.9896 - val_loss: 0.6036
AUC: 0.8722

Epoch 29/80
 - 0s - loss: 0.9868 - val_loss: 0.6043
AUC: 0.8736

Epoch 30/80
 - 0s - loss: 0.9810 - val_loss: 0.6305
AUC: 0.8742

Epoch 31/80
 - 0s - loss: 0.9840 - val_loss: 0.5701
AUC: 0.8733

Epoch 32/80
 - 0s - loss: 0.9807 - val_loss: 0.5813
AUC: 0.8734

Epoch 33/80
 - 0s - loss: 0.9786 - val_loss: 0.5856
AUC: 0.8750

Epoch 34/80
 - 0s - loss: 0.9817 - val_loss: 0.6258
AUC: 0.8739

Epoch 35/80
 - 0s - loss: 0.9681 - val_loss: 0.5914
AUC: 0.8750

Epoch 36/80
 - 0s - loss: 0.9671 - val_loss: 0.5709
AUC: 0.8743

Epoch 37/80
 - 0s - loss: 0.9615 - val_loss: 0.6004
AUC: 0.8752

Epoch 38/80
 - 0s - loss: 0.9612 - val_loss: 0.5694
AUC: 0.8743

Epoch 39/80
 - 0s - loss: 0.9668 - val_loss: 0.5827
AUC: 0.8748

Epoch 40/80
 - 0s - loss: 0.9651 - val_loss: 0.5989
AUC: 0.8751

Epoch 41/80
 - 0s - loss: 0.9607 - val_loss: 0.5730
AUC: 0.8748

Epoch 42/80
 - 0s - loss: 0.9630 - val_loss: 0.5789
AUC: 0.8752

Epoch 43/80
 - 0s - loss: 0.9634 - val_loss: 0.5963
AUC: 0.8748

Epoch 44/80
 - 0s - loss: 0.9629 - val_loss: 0.5729
AUC: 0.8747

Epoch 45/80
 - 0s - loss: 0.9606 - val_loss: 0.5877
AUC: 0.8750

Epoch 46/80
 - 0s - loss: 0.9594 - val_loss: 0.5809
AUC: 0.8750

Epoch 47/80
 - 0s - loss: 0.9599 - val_loss: 0.5782
AUC: 0.8750

Epoch 48/80
 - 0s - loss: 0.9612 - val_loss: 0.5884
AUC: 0.8752

Epoch 49/80
 - 0s - loss: 0.9568 - val_loss: 0.5868
AUC: 0.8752

Epoch 50/80
 - 0s - loss: 0.9603 - val_loss: 0.5876
AUC: 0.8752

Epoch 51/80
 - 0s - loss: 0.9567 - val_loss: 0.5881
AUC: 0.8752

Epoch 52/80
 - 0s - loss: 0.9585 - val_loss: 0.5836
AUC: 0.8752

Epoch 53/80
 - 0s - loss: 0.9593 - val_loss: 0.5913
AUC: 0.8753

Epoch 54/80
 - 0s - loss: 0.9555 - val_loss: 0.5829
AUC: 0.8751

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9594 - val_loss: 0.5918
AUC: 0.8753

Epoch 2/30
 - 0s - loss: 0.9562 - val_loss: 0.5981
AUC: 0.8755

Epoch 3/30
 - 0s - loss: 0.9532 - val_loss: 0.5786
AUC: 0.8753

Epoch 4/30
 - 0s - loss: 0.9554 - val_loss: 0.5849
AUC: 0.8757

Epoch 5/30
 - 0s - loss: 0.9520 - val_loss: 0.5909
AUC: 0.8756

Epoch 6/30
 - 0s - loss: 0.9507 - val_loss: 0.5860
AUC: 0.8758

Epoch 7/30
 - 0s - loss: 0.9510 - val_loss: 0.5940
AUC: 0.8758

Epoch 8/30
 - 0s - loss: 0.9484 - val_loss: 0.5864
AUC: 0.8759

Epoch 9/30
 - 0s - loss: 0.9548 - val_loss: 0.5906
AUC: 0.8761

Epoch 10/30
 - 0s - loss: 0.9443 - val_loss: 0.5594
AUC: 0.8756

Epoch 11/30
 - 0s - loss: 0.9435 - val_loss: 0.5852
AUC: 0.8761

Epoch 12/30
 - 0s - loss: 0.9495 - val_loss: 0.5835
AUC: 0.8761

Epoch 13/30
 - 0s - loss: 0.9424 - val_loss: 0.5943
AUC: 0.8763

Epoch 14/30
 - 0s - loss: 0.9442 - val_loss: 0.5817
AUC: 0.8762

Epoch 15/30
 - 0s - loss: 0.9418 - val_loss: 0.5594
AUC: 0.8760

Epoch 16/30
 - 0s - loss: 0.9445 - val_loss: 0.5712
AUC: 0.8762

Epoch 17/30
 - 0s - loss: 0.9421 - val_loss: 0.5751
AUC: 0.8763

Epoch 18/30
 - 0s - loss: 0.9367 - val_loss: 0.5905
AUC: 0.8764

Epoch 19/30
 - 0s - loss: 0.9306 - val_loss: 0.6050
AUC: 0.8766

Epoch 20/30
 - 0s - loss: 0.9337 - val_loss: 0.5796
AUC: 0.8766

Epoch 21/30
 - 0s - loss: 0.9328 - val_loss: 0.5726
AUC: 0.8765

Epoch 22/30
 - 0s - loss: 0.9387 - val_loss: 0.5777
AUC: 0.8765

Epoch 23/30
 - 0s - loss: 0.9345 - val_loss: 0.5806
AUC: 0.8766

Epoch 24/30
 - 0s - loss: 0.9352 - val_loss: 0.5699
AUC: 0.8764

Epoch 25/30
 - 0s - loss: 0.9401 - val_loss: 0.5777
AUC: 0.8766

Epoch 26/30
 - 0s - loss: 0.9403 - val_loss: 0.5752
AUC: 0.8765

Epoch 27/30
 - 0s - loss: 0.9358 - val_loss: 0.5758
AUC: 0.8765

Epoch 28/30
 - 0s - loss: 0.9324 - val_loss: 0.5740
AUC: 0.8765

Epoch 29/30
 - 0s - loss: 0.9359 - val_loss: 0.5712
AUC: 0.8765

Epoch 30/30
 - 0s - loss: 0.9305 - val_loss: 0.5706
Using TensorFlow backend.
AUC: 0.8765

2019-03-08 02:49:14.672531: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:49:14.850502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:49:14.850545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:49:15.145796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:49:15.145845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:49:15.145854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:49:15.146119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6854
Epoch 2/80
 - 2s - loss: 0.1300
Epoch 3/80
 - 2s - loss: 0.0725
Epoch 4/80
 - 2s - loss: 0.0662
Epoch 5/80
 - 2s - loss: 0.0636
Epoch 6/80
 - 2s - loss: 0.0614
Epoch 7/80
 - 2s - loss: 0.0586
Epoch 8/80
 - 2s - loss: 0.0551
Epoch 9/80
 - 2s - loss: 0.0513
Epoch 10/80
 - 2s - loss: 0.0477
Epoch 11/80
 - 2s - loss: 0.0446
Epoch 12/80
 - 2s - loss: 0.0417
Epoch 13/80
 - 2s - loss: 0.0389
Epoch 14/80
 - 2s - loss: 0.0363
Epoch 15/80
 - 2s - loss: 0.0338
Epoch 16/80
 - 2s - loss: 0.0316
Epoch 17/80
 - 2s - loss: 0.0296
Epoch 18/80
 - 2s - loss: 0.0279
Epoch 19/80
 - 2s - loss: 0.0264
Epoch 20/80
 - 2s - loss: 0.0251
Epoch 21/80
 - 2s - loss: 0.0239
Epoch 22/80
 - 2s - loss: 0.0229
Epoch 23/80
 - 2s - loss: 0.0221
Epoch 24/80
 - 2s - loss: 0.0213
Epoch 25/80
 - 2s - loss: 0.0207
Epoch 26/80
 - 2s - loss: 0.0201
Epoch 27/80
 - 2s - loss: 0.0196
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0189
Epoch 30/80
 - 2s - loss: 0.0186
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0175
Epoch 36/80
 - 2s - loss: 0.0174
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0172
Epoch 39/80
 - 2s - loss: 0.0171
Epoch 40/80
 - 2s - loss: 0.0170
Epoch 41/80
 - 2s - loss: 0.0169
Epoch 42/80
 - 2s - loss: 0.0169
Epoch 43/80
 - 2s - loss: 0.0168
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0167
Epoch 46/80
 - 2s - loss: 0.0167
Epoch 47/80
 - 2s - loss: 0.0166
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0165
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0161
Epoch 53/80
 - 2s - loss: 0.0160
Epoch 54/80
 - 2s - loss: 0.0160
Epoch 55/80
 - 2s - loss: 0.0160
Epoch 56/80
 - 2s - loss: 0.0159
Epoch 57/80
 - 2s - loss: 0.0159
Epoch 58/80
 - 2s - loss: 0.0159
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:51:20.560900: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:51:20.730631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:51:20.730673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:51:21.020098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:51:21.020149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:51:21.020158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:51:21.020452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6871
Epoch 2/80
 - 2s - loss: 0.1319
Epoch 3/80
 - 2s - loss: 0.0732
Epoch 4/80
 - 2s - loss: 0.0665
Epoch 5/80
 - 2s - loss: 0.0640
Epoch 6/80
 - 2s - loss: 0.0621
Epoch 7/80
 - 2s - loss: 0.0601
Epoch 8/80
 - 2s - loss: 0.0576
Epoch 9/80
 - 2s - loss: 0.0546
Epoch 10/80
 - 2s - loss: 0.0509
Epoch 11/80
 - 2s - loss: 0.0467
Epoch 12/80
 - 2s - loss: 0.0426
Epoch 13/80
 - 2s - loss: 0.0390
Epoch 14/80
 - 2s - loss: 0.0358
Epoch 15/80
 - 2s - loss: 0.0331
Epoch 16/80
 - 2s - loss: 0.0308
Epoch 17/80
 - 2s - loss: 0.0288
Epoch 18/80
 - 2s - loss: 0.0271
Epoch 19/80
 - 2s - loss: 0.0257
Epoch 20/80
 - 2s - loss: 0.0245
Epoch 21/80
 - 2s - loss: 0.0234
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0217
Epoch 24/80
 - 2s - loss: 0.0210
Epoch 25/80
 - 2s - loss: 0.0204
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0195
Epoch 28/80
 - 2s - loss: 0.0191
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 02:52:27.658750: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:52:27.822299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:52:27.822351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:52:28.119339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:52:28.119373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:52:28.119382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:52:28.119649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6964
Epoch 2/80
 - 2s - loss: 0.1338
Epoch 3/80
 - 2s - loss: 0.0715
Epoch 4/80
 - 2s - loss: 0.0635
Epoch 5/80
 - 2s - loss: 0.0592
Epoch 6/80
 - 2s - loss: 0.0555
Epoch 7/80
 - 2s - loss: 0.0523
Epoch 8/80
 - 2s - loss: 0.0495
Epoch 9/80
 - 2s - loss: 0.0469
Epoch 10/80
 - 2s - loss: 0.0443
Epoch 11/80
 - 2s - loss: 0.0418
Epoch 12/80
 - 2s - loss: 0.0394
Epoch 13/80
 - 2s - loss: 0.0371
Epoch 14/80
 - 2s - loss: 0.0350
Epoch 15/80
 - 2s - loss: 0.0330
Epoch 16/80
 - 2s - loss: 0.0311
Epoch 17/80
 - 2s - loss: 0.0293
Epoch 18/80
 - 2s - loss: 0.0276
Epoch 19/80
 - 2s - loss: 0.0261
Epoch 20/80
 - 2s - loss: 0.0248
Epoch 21/80
 - 2s - loss: 0.0236
Epoch 22/80
 - 2s - loss: 0.0227
Epoch 23/80
 - 2s - loss: 0.0218
Epoch 24/80
 - 2s - loss: 0.0211
Epoch 25/80
 - 2s - loss: 0.0205
Epoch 26/80
 - 2s - loss: 0.0200
Epoch 27/80
 - 2s - loss: 0.0196
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0189
Epoch 30/80
 - 2s - loss: 0.0186
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0178
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b1e2cd486d8>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 02:54:12.871573: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:54:13.041274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:54:13.041319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:54:13.336410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:54:13.336462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:54:13.336476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:54:13.336751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.4052
Epoch 2/80
 - 2s - loss: 0.3553
Epoch 3/80
 - 2s - loss: 0.3063
Epoch 4/80
 - 2s - loss: 0.2903
Epoch 5/80
 - 2s - loss: 0.2712
Epoch 6/80
 - 2s - loss: 0.2497
Epoch 7/80
 - 2s - loss: 0.2291
Epoch 8/80
 - 2s - loss: 0.2125
Epoch 9/80
 - 2s - loss: 0.2003
Epoch 10/80
 - 2s - loss: 0.1900
Epoch 11/80
 - 2s - loss: 0.1803
Epoch 12/80
 - 2s - loss: 0.1710
Epoch 13/80
 - 2s - loss: 0.1627
Epoch 14/80
 - 2s - loss: 0.1554
Epoch 15/80
 - 2s - loss: 0.1491
Epoch 16/80
 - 2s - loss: 0.1437
Epoch 17/80
 - 2s - loss: 0.1391
Epoch 18/80
 - 2s - loss: 0.1353
Epoch 19/80
 - 2s - loss: 0.1321
Epoch 20/80
 - 2s - loss: 0.1296
Epoch 21/80
 - 2s - loss: 0.1275
Epoch 22/80
 - 2s - loss: 0.1258
Epoch 23/80
 - 2s - loss: 0.1243
Epoch 24/80
 - 2s - loss: 0.1231
Epoch 25/80
 - 2s - loss: 0.1221
Epoch 26/80
 - 2s - loss: 0.1212
Epoch 27/80
 - 2s - loss: 0.1205
Epoch 28/80
 - 2s - loss: 0.1198
Epoch 29/80
 - 2s - loss: 0.1192
Epoch 30/80
 - 2s - loss: 0.1187
Epoch 31/80
 - 2s - loss: 0.1182
Epoch 32/80
 - 2s - loss: 0.1178
Epoch 33/80
 - 2s - loss: 0.1175
Epoch 34/80
 - 2s - loss: 0.1172
Epoch 35/80
 - 2s - loss: 0.1169
Epoch 36/80
 - 2s - loss: 0.1166
Epoch 37/80
 - 2s - loss: 0.1164
Epoch 38/80
 - 2s - loss: 0.1162
Epoch 39/80
 - 2s - loss: 0.1160
Epoch 40/80
 - 2s - loss: 0.1158
Epoch 41/80
 - 2s - loss: 0.1157
Epoch 42/80
 - 2s - loss: 0.1155
Epoch 43/80
 - 2s - loss: 0.1154
Epoch 44/80
 - 2s - loss: 0.1153
Epoch 45/80
 - 2s - loss: 0.1151
Epoch 46/80
 - 2s - loss: 0.1150
Epoch 47/80
 - 2s - loss: 0.1149
Epoch 48/80
 - 2s - loss: 0.1148
Epoch 49/80
 - 2s - loss: 0.1147
Epoch 50/80
 - 2s - loss: 0.1147
Epoch 51/80
 - 2s - loss: 0.1146
Epoch 52/80
 - 2s - loss: 0.1145
Epoch 53/80
 - 2s - loss: 0.1144
Epoch 54/80
 - 2s - loss: 0.1144
Epoch 55/80
 - 2s - loss: 0.1143
Epoch 56/80
 - 2s - loss: 0.1143
Epoch 57/80
 - 2s - loss: 0.1142
Epoch 58/80
 - 2s - loss: 0.1142
Epoch 59/80
 - 2s - loss: 0.1141
Epoch 60/80
 - 2s - loss: 0.1141
Epoch 61/80
 - 2s - loss: 0.1140
Epoch 62/80
 - 2s - loss: 0.1140
Epoch 63/80
 - 2s - loss: 0.1140
Epoch 64/80
 - 2s - loss: 0.1139
Epoch 65/80
 - 2s - loss: 0.1117
Epoch 66/80
 - 2s - loss: 0.1115
Epoch 67/80
 - 2s - loss: 0.1114
Epoch 68/80
 - 2s - loss: 0.1114
Epoch 69/80
 - 2s - loss: 0.1114
Epoch 70/80
 - 2s - loss: 0.1108
Epoch 71/80
 - 2s - loss: 0.1108
Epoch 72/80
 - 2s - loss: 0.1108
Epoch 73/80
 - 2s - loss: 0.1108
Epoch 74/80
 - 2s - loss: 0.1107
Epoch 75/80
 - 2s - loss: 0.1107
Epoch 76/80
 - 2s - loss: 0.1107
Epoch 77/80
 - 2s - loss: 0.1107
Epoch 78/80
 - 2s - loss: 0.1107
Epoch 79/80
 - 2s - loss: 0.1107
Epoch 80/80
 - 2s - loss: 0.1107
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.9271 - val_loss: 1.5318
AUC: 0.8193

Epoch 2/80
 - 0s - loss: 2.4259 - val_loss: 0.8298
AUC: 0.8315

Epoch 3/80
 - 0s - loss: 1.6305 - val_loss: 0.7555
AUC: 0.8446

Epoch 4/80
 - 0s - loss: 1.2929 - val_loss: 0.7050
AUC: 0.8446

Epoch 5/80
 - 0s - loss: 1.2190 - val_loss: 0.7104
AUC: 0.8482

Epoch 6/80
 - 0s - loss: 1.1711 - val_loss: 0.7483
AUC: 0.8506

Epoch 7/80
 - 0s - loss: 1.1415 - val_loss: 0.6919
AUC: 0.8510

Epoch 8/80
 - 0s - loss: 1.1269 - val_loss: 0.6901
AUC: 0.8536

Epoch 9/80
 - 0s - loss: 1.1045 - val_loss: 0.6885
AUC: 0.8560

Epoch 10/80
 - 0s - loss: 1.0911 - val_loss: 0.7060
AUC: 0.8564

Epoch 11/80
 - 0s - loss: 1.0831 - val_loss: 0.6337
AUC: 0.8576

Epoch 12/80
 - 0s - loss: 1.0830 - val_loss: 0.6527
AUC: 0.8603

Epoch 13/80
 - 0s - loss: 1.0765 - val_loss: 0.5980
AUC: 0.8611

Epoch 14/80
 - 0s - loss: 1.0718 - val_loss: 0.6312
AUC: 0.8624

Epoch 15/80
 - 0s - loss: 1.0624 - val_loss: 0.6737
AUC: 0.8637

Epoch 16/80
 - 0s - loss: 1.0603 - val_loss: 0.6262
AUC: 0.8635

Epoch 17/80
 - 0s - loss: 1.0543 - val_loss: 0.6372
AUC: 0.8645

Epoch 18/80
 - 0s - loss: 1.0510 - val_loss: 0.6314
AUC: 0.8648

Epoch 19/80
 - 0s - loss: 1.0524 - val_loss: 0.7034
AUC: 0.8658

Epoch 20/80
 - 0s - loss: 1.0437 - val_loss: 0.6446
AUC: 0.8659

Epoch 21/80
 - 0s - loss: 1.0370 - val_loss: 0.6259
AUC: 0.8666

Epoch 22/80
 - 0s - loss: 1.0280 - val_loss: 0.6265
AUC: 0.8665

Epoch 23/80
 - 0s - loss: 1.0303 - val_loss: 0.6170
AUC: 0.8669

Epoch 24/80
 - 0s - loss: 1.0219 - val_loss: 0.6126
AUC: 0.8672

Epoch 25/80
 - 0s - loss: 1.0176 - val_loss: 0.6313
AUC: 0.8677

Epoch 26/80
 - 0s - loss: 1.0200 - val_loss: 0.6371
AUC: 0.8676

Epoch 27/80
 - 0s - loss: 1.0191 - val_loss: 0.6703
AUC: 0.8681

Epoch 28/80
 - 0s - loss: 1.0264 - val_loss: 0.6051
AUC: 0.8674

Epoch 29/80
 - 0s - loss: 1.0168 - val_loss: 0.6586
AUC: 0.8679

Epoch 30/80
 - 0s - loss: 1.0187 - val_loss: 0.6274
AUC: 0.8679

Epoch 31/80
 - 0s - loss: 1.0167 - val_loss: 0.6184
AUC: 0.8679

Epoch 32/80
 - 0s - loss: 1.0124 - val_loss: 0.6246
AUC: 0.8680

Epoch 33/80
 - 0s - loss: 1.0162 - val_loss: 0.6286
AUC: 0.8683

Epoch 34/80
 - 0s - loss: 1.0138 - val_loss: 0.6229
AUC: 0.8683

Epoch 35/80
 - 0s - loss: 1.0110 - val_loss: 0.6223
AUC: 0.8684

Epoch 36/80
 - 0s - loss: 1.0133 - val_loss: 0.6278
AUC: 0.8683

Epoch 37/80
 - 0s - loss: 1.0094 - val_loss: 0.6233
AUC: 0.8683

Epoch 38/80
 - 0s - loss: 1.0093 - val_loss: 0.6173
AUC: 0.8683

Epoch 39/80
 - 0s - loss: 1.0174 - val_loss: 0.6219
AUC: 0.8684

Epoch 40/80
 - 0s - loss: 1.0097 - val_loss: 0.6295
AUC: 0.8685

Epoch 41/80
 - 0s - loss: 1.0158 - val_loss: 0.6324
AUC: 0.8685

Epoch 42/80
 - 0s - loss: 1.0170 - val_loss: 0.6238
AUC: 0.8685

Epoch 43/80
 - 0s - loss: 1.0126 - val_loss: 0.6231
AUC: 0.8685

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0094 - val_loss: 0.6095
AUC: 0.8683

Epoch 2/30
 - 0s - loss: 1.0065 - val_loss: 0.6168
AUC: 0.8685

Epoch 3/30
 - 0s - loss: 1.0082 - val_loss: 0.6180
AUC: 0.8686

Epoch 4/30
 - 0s - loss: 1.0105 - val_loss: 0.6118
AUC: 0.8688

Epoch 5/30
 - 0s - loss: 1.0088 - val_loss: 0.6043
AUC: 0.8690

Epoch 6/30
 - 0s - loss: 1.0077 - val_loss: 0.6130
AUC: 0.8693

Epoch 7/30
 - 0s - loss: 1.0016 - val_loss: 0.6287
AUC: 0.8695

Epoch 8/30
 - 0s - loss: 1.0051 - val_loss: 0.6238
AUC: 0.8697

Epoch 9/30
 - 0s - loss: 1.0017 - val_loss: 0.6256
AUC: 0.8700

Epoch 10/30
 - 0s - loss: 1.0037 - val_loss: 0.6210
AUC: 0.8701

Epoch 11/30
 - 0s - loss: 1.0040 - val_loss: 0.6324
AUC: 0.8704

Epoch 12/30
 - 0s - loss: 1.0027 - val_loss: 0.6225
AUC: 0.8703

Epoch 13/30
 - 0s - loss: 0.9963 - val_loss: 0.6185
AUC: 0.8705

Epoch 14/30
 - 0s - loss: 0.9976 - val_loss: 0.6143
AUC: 0.8707

Epoch 15/30
 - 0s - loss: 0.9984 - val_loss: 0.6128
AUC: 0.8706

Epoch 16/30
 - 0s - loss: 0.9942 - val_loss: 0.6157
AUC: 0.8707

Epoch 17/30
 - 0s - loss: 0.9964 - val_loss: 0.6131
AUC: 0.8707

Epoch 18/30
 - 0s - loss: 0.9944 - val_loss: 0.6117
AUC: 0.8707

Epoch 19/30
 - 0s - loss: 0.9927 - val_loss: 0.6173
AUC: 0.8708

Epoch 20/30
 - 0s - loss: 0.9961 - val_loss: 0.6182
AUC: 0.8708

Epoch 21/30
 - 0s - loss: 0.9957 - val_loss: 0.6121
AUC: 0.8708

Epoch 22/30
 - 0s - loss: 0.9930 - val_loss: 0.6092
AUC: 0.8708

Epoch 23/30
 - 0s - loss: 0.9936 - val_loss: 0.6168
AUC: 0.8709

Epoch 24/30
 - 0s - loss: 0.9939 - val_loss: 0.6158
AUC: 0.8710

Epoch 25/30
 - 0s - loss: 0.9978 - val_loss: 0.6151
AUC: 0.8710

Epoch 26/30
 - 0s - loss: 0.9956 - val_loss: 0.6156
AUC: 0.8710

Epoch 27/30
 - 0s - loss: 0.9904 - val_loss: 0.6142
AUC: 0.8710

Epoch 28/30
 - 0s - loss: 0.9920 - val_loss: 0.6134
AUC: 0.8710

Epoch 29/30
 - 0s - loss: 0.9953 - val_loss: 0.6138
AUC: 0.8710

Epoch 30/30
 - 0s - loss: 0.9841 - val_loss: 0.6113
Using TensorFlow backend.
AUC: 0.8710

2019-03-08 02:57:27.166913: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 02:57:27.333081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 02:57:27.333141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 02:57:27.628249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 02:57:27.628299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 02:57:27.628308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 02:57:27.628563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3831
Epoch 2/80
 - 2s - loss: 0.3540
Epoch 3/80
 - 2s - loss: 0.2959
Epoch 4/80
 - 2s - loss: 0.2716
Epoch 5/80
 - 2s - loss: 0.2554
Epoch 6/80
 - 2s - loss: 0.2420
Epoch 7/80
 - 2s - loss: 0.2291
Epoch 8/80
 - 2s - loss: 0.2162
Epoch 9/80
 - 2s - loss: 0.2036
Epoch 10/80
 - 2s - loss: 0.1917
Epoch 11/80
 - 2s - loss: 0.1809
Epoch 12/80
 - 2s - loss: 0.1712
Epoch 13/80
 - 2s - loss: 0.1629
Epoch 14/80
 - 2s - loss: 0.1559
Epoch 15/80
 - 2s - loss: 0.1497
Epoch 16/80
 - 2s - loss: 0.1444
Epoch 17/80
 - 2s - loss: 0.1399
Epoch 18/80
 - 2s - loss: 0.1360
Epoch 19/80
 - 2s - loss: 0.1328
Epoch 20/80
 - 2s - loss: 0.1301
Epoch 21/80
 - 2s - loss: 0.1279
Epoch 22/80
 - 2s - loss: 0.1260
Epoch 23/80
 - 2s - loss: 0.1245
Epoch 24/80
 - 2s - loss: 0.1232
Epoch 25/80
 - 2s - loss: 0.1220
Epoch 26/80
 - 2s - loss: 0.1211
Epoch 27/80
 - 2s - loss: 0.1204
Epoch 28/80
 - 2s - loss: 0.1197
Epoch 29/80
 - 2s - loss: 0.1191
Epoch 30/80
 - 2s - loss: 0.1187
Epoch 31/80
 - 2s - loss: 0.1183
Epoch 32/80
 - 2s - loss: 0.1179
Epoch 33/80
 - 2s - loss: 0.1176
Epoch 34/80
 - 2s - loss: 0.1173
Epoch 35/80
 - 2s - loss: 0.1170
Epoch 36/80
 - 2s - loss: 0.1168
Epoch 37/80
 - 2s - loss: 0.1166
Epoch 38/80
 - 2s - loss: 0.1164
Epoch 39/80
 - 2s - loss: 0.1162
Epoch 40/80
 - 2s - loss: 0.1161
Epoch 41/80
 - 2s - loss: 0.1159
Epoch 42/80
 - 2s - loss: 0.1158
Epoch 43/80
 - 2s - loss: 0.1157
Epoch 44/80
 - 2s - loss: 0.1156
Epoch 45/80
 - 2s - loss: 0.1155
Epoch 46/80
 - 2s - loss: 0.1154
Epoch 47/80
 - 2s - loss: 0.1153
Epoch 48/80
 - 2s - loss: 0.1152
Epoch 49/80
 - 2s - loss: 0.1151
Epoch 50/80
 - 2s - loss: 0.1150
Epoch 51/80
 - 2s - loss: 0.1149
Epoch 52/80
 - 2s - loss: 0.1149
Epoch 53/80
 - 2s - loss: 0.1149
Epoch 54/80
 - 2s - loss: 0.1148
Epoch 55/80
 - 2s - loss: 0.1147
Epoch 56/80
 - 2s - loss: 0.1147
Epoch 57/80
 - 2s - loss: 0.1147
Epoch 58/80
 - 2s - loss: 0.1146
Epoch 59/80
 - 2s - loss: 0.1146
Epoch 60/80
 - 2s - loss: 0.1145
Epoch 61/80
 - 2s - loss: 0.1145
Epoch 62/80
 - 2s - loss: 0.1144
Epoch 63/80
 - 2s - loss: 0.1144
Epoch 64/80
 - 2s - loss: 0.1144
Epoch 65/80
 - 2s - loss: 0.1143
Epoch 66/80
 - 2s - loss: 0.1143
Epoch 67/80
 - 2s - loss: 0.1143
Epoch 68/80
 - 2s - loss: 0.1142
Epoch 69/80
 - 2s - loss: 0.1142
Epoch 70/80
 - 2s - loss: 0.1142
Epoch 71/80
 - 2s - loss: 0.1141
Epoch 72/80
 - 2s - loss: 0.1119
Epoch 73/80
 - 2s - loss: 0.1117
Epoch 74/80
 - 2s - loss: 0.1117
Epoch 75/80
 - 2s - loss: 0.1116
Epoch 76/80
 - 2s - loss: 0.1116
Epoch 77/80
 - 2s - loss: 0.1111
Epoch 78/80
 - 2s - loss: 0.1111
Epoch 79/80
 - 2s - loss: 0.1111
Epoch 80/80
 - 2s - loss: 0.1111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.2956 - val_loss: 1.4484
AUC: 0.7998

Epoch 2/80
 - 0s - loss: 2.6624 - val_loss: 1.0033
AUC: 0.8202

Epoch 3/80
 - 0s - loss: 1.7734 - val_loss: 0.8593
AUC: 0.8369

Epoch 4/80
 - 0s - loss: 1.3503 - val_loss: 0.7739
AUC: 0.8423

Epoch 5/80
 - 0s - loss: 1.2381 - val_loss: 0.6741
AUC: 0.8441

Epoch 6/80
 - 0s - loss: 1.1779 - val_loss: 0.6581
AUC: 0.8483

Epoch 7/80
 - 0s - loss: 1.1359 - val_loss: 0.7625
AUC: 0.8517

Epoch 8/80
 - 0s - loss: 1.1046 - val_loss: 0.6935
AUC: 0.8531

Epoch 9/80
 - 0s - loss: 1.0973 - val_loss: 0.7012
AUC: 0.8562

Epoch 10/80
 - 0s - loss: 1.0808 - val_loss: 0.5738
AUC: 0.8549

Epoch 11/80
 - 0s - loss: 1.0802 - val_loss: 0.6089
AUC: 0.8565

Epoch 12/80
 - 0s - loss: 1.0652 - val_loss: 0.6386
AUC: 0.8569

Epoch 13/80
 - 0s - loss: 1.0563 - val_loss: 0.6437
AUC: 0.8586

Epoch 14/80
 - 0s - loss: 1.0587 - val_loss: 0.6346
AUC: 0.8589

Epoch 15/80
 - 0s - loss: 1.0564 - val_loss: 0.5769
AUC: 0.8590

Epoch 16/80
 - 0s - loss: 1.0395 - val_loss: 0.5939
AUC: 0.8599

Epoch 17/80
 - 0s - loss: 1.0384 - val_loss: 0.6216
AUC: 0.8607

Epoch 18/80
 - 0s - loss: 1.0388 - val_loss: 0.5802
AUC: 0.8615

Epoch 19/80
 - 0s - loss: 1.0258 - val_loss: 0.6092
AUC: 0.8625

Epoch 20/80
 - 0s - loss: 1.0257 - val_loss: 0.6299
AUC: 0.8629

Epoch 21/80
 - 0s - loss: 1.0246 - val_loss: 0.6165
AUC: 0.8632

Epoch 22/80
 - 0s - loss: 1.0178 - val_loss: 0.6165
AUC: 0.8631

Epoch 23/80
 - 0s - loss: 1.0144 - val_loss: 0.6199
AUC: 0.8635

Epoch 24/80
 - 0s - loss: 1.0161 - val_loss: 0.6215
AUC: 0.8635

Epoch 25/80
 - 0s - loss: 1.0129 - val_loss: 0.5986
AUC: 0.8631

Epoch 26/80
 - 0s - loss: 1.0111 - val_loss: 0.5821
AUC: 0.8630

Epoch 27/80
 - 0s - loss: 1.0146 - val_loss: 0.5936
AUC: 0.8633

Epoch 28/80
 - 0s - loss: 1.0101 - val_loss: 0.6217
AUC: 0.8638

Epoch 29/80
 - 0s - loss: 1.0180 - val_loss: 0.6207
AUC: 0.8638

Epoch 30/80
 - 0s - loss: 1.0089 - val_loss: 0.5812
AUC: 0.8634

Epoch 31/80
 - 0s - loss: 1.0098 - val_loss: 0.6097
AUC: 0.8638

Epoch 32/80
 - 0s - loss: 1.0118 - val_loss: 0.6154
AUC: 0.8638

Epoch 33/80
 - 0s - loss: 1.0100 - val_loss: 0.6125
AUC: 0.8638

Epoch 34/80
 - 0s - loss: 1.0100 - val_loss: 0.6161
AUC: 0.8639

Epoch 35/80
 - 0s - loss: 1.0097 - val_loss: 0.6156
AUC: 0.8639

Epoch 36/80
 - 0s - loss: 1.0075 - val_loss: 0.6109
AUC: 0.8639

Epoch 37/80
 - 0s - loss: 1.0113 - val_loss: 0.6129
AUC: 0.8639

Epoch 38/80
 - 0s - loss: 1.0079 - val_loss: 0.6117
AUC: 0.8639

Epoch 39/80
 - 0s - loss: 1.0116 - val_loss: 0.6098
AUC: 0.8639

Epoch 40/80
 - 0s - loss: 1.0079 - val_loss: 0.6191
AUC: 0.8639

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0119 - val_loss: 0.6161
AUC: 0.8641

Epoch 2/30
 - 0s - loss: 1.0031 - val_loss: 0.6191
AUC: 0.8644

Epoch 3/30
 - 0s - loss: 1.0057 - val_loss: 0.5919
AUC: 0.8644

Epoch 4/30
 - 0s - loss: 1.0049 - val_loss: 0.6158
AUC: 0.8648

Epoch 5/30
 - 0s - loss: 1.0055 - val_loss: 0.6186
AUC: 0.8648

Epoch 6/30
 - 0s - loss: 1.0042 - val_loss: 0.6181
AUC: 0.8649

Epoch 7/30
 - 0s - loss: 1.0003 - val_loss: 0.6105
AUC: 0.8649

Epoch 8/30
 - 0s - loss: 1.0025 - val_loss: 0.6172
AUC: 0.8651

Epoch 9/30
 - 0s - loss: 0.9966 - val_loss: 0.5909
AUC: 0.8653

Epoch 10/30
 - 0s - loss: 0.9908 - val_loss: 0.5857
AUC: 0.8653

Epoch 11/30
 - 0s - loss: 0.9955 - val_loss: 0.6065
AUC: 0.8656

Epoch 12/30
 - 0s - loss: 0.9952 - val_loss: 0.6227
AUC: 0.8659

Epoch 13/30
 - 0s - loss: 0.9966 - val_loss: 0.6072
AUC: 0.8659

Epoch 14/30
 - 0s - loss: 0.9899 - val_loss: 0.6059
AUC: 0.8660

Epoch 15/30
 - 0s - loss: 0.9851 - val_loss: 0.5840
AUC: 0.8659

Epoch 16/30
 - 0s - loss: 0.9864 - val_loss: 0.5938
AUC: 0.8660

Epoch 17/30
 - 0s - loss: 0.9862 - val_loss: 0.5920
AUC: 0.8662

Epoch 18/30
 - 0s - loss: 0.9854 - val_loss: 0.6144
AUC: 0.8667

Epoch 19/30
 - 0s - loss: 0.9889 - val_loss: 0.6131
AUC: 0.8667

Epoch 20/30
 - 0s - loss: 0.9823 - val_loss: 0.6070
AUC: 0.8668

Epoch 21/30
 - 0s - loss: 0.9833 - val_loss: 0.6049
AUC: 0.8668

Epoch 22/30
 - 0s - loss: 0.9819 - val_loss: 0.5899
AUC: 0.8667

Epoch 23/30
 - 0s - loss: 0.9786 - val_loss: 0.5925
AUC: 0.8669

Epoch 24/30
 - 0s - loss: 0.9754 - val_loss: 0.6167
AUC: 0.8672

Epoch 25/30
 - 0s - loss: 0.9746 - val_loss: 0.6053
AUC: 0.8674

Epoch 26/30
 - 0s - loss: 0.9771 - val_loss: 0.5984
AUC: 0.8673

Epoch 27/30
 - 0s - loss: 0.9793 - val_loss: 0.5974
AUC: 0.8673

Epoch 28/30
 - 0s - loss: 0.9768 - val_loss: 0.5996
AUC: 0.8674

Epoch 29/30
 - 0s - loss: 0.9706 - val_loss: 0.5969
AUC: 0.8674

Epoch 30/30
 - 0s - loss: 0.9730 - val_loss: 0.5985
Using TensorFlow backend.
AUC: 0.8674

2019-03-08 03:00:39.698563: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:00:39.861628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:00:39.861670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:00:40.152320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:00:40.152363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:00:40.152373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:00:40.152674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.4020
Epoch 2/80
 - 2s - loss: 0.3550
Epoch 3/80
 - 2s - loss: 0.2853
Epoch 4/80
 - 2s - loss: 0.2560
Epoch 5/80
 - 2s - loss: 0.2350
Epoch 6/80
 - 2s - loss: 0.2200
Epoch 7/80
 - 2s - loss: 0.2089
Epoch 8/80
 - 2s - loss: 0.2001
Epoch 9/80
 - 2s - loss: 0.1923
Epoch 10/80
 - 2s - loss: 0.1848
Epoch 11/80
 - 2s - loss: 0.1772
Epoch 12/80
 - 2s - loss: 0.1698
Epoch 13/80
 - 2s - loss: 0.1626
Epoch 14/80
 - 2s - loss: 0.1559
Epoch 15/80
 - 2s - loss: 0.1495
Epoch 16/80
 - 2s - loss: 0.1439
Epoch 17/80
 - 2s - loss: 0.1391
Epoch 18/80
 - 2s - loss: 0.1351
Epoch 19/80
 - 2s - loss: 0.1318
Epoch 20/80
 - 2s - loss: 0.1290
Epoch 21/80
 - 2s - loss: 0.1267
Epoch 22/80
 - 2s - loss: 0.1249
Epoch 23/80
 - 2s - loss: 0.1233
Epoch 24/80
 - 2s - loss: 0.1220
Epoch 25/80
 - 2s - loss: 0.1210
Epoch 26/80
 - 2s - loss: 0.1201
Epoch 27/80
 - 2s - loss: 0.1193
Epoch 28/80
 - 2s - loss: 0.1187
Epoch 29/80
 - 2s - loss: 0.1182
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:01:49.140720: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:01:49.307404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:01:49.307449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:01:49.599540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:01:49.599592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:01:49.599601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:01:49.599871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3824
Epoch 2/80
 - 2s - loss: 0.3520
Epoch 3/80
 - 2s - loss: 0.3111
Epoch 4/80
 - 2s - loss: 0.3006
Epoch 5/80
 - 2s - loss: 0.2870
Epoch 6/80
 - 2s - loss: 0.2667
Epoch 7/80
 - 2s - loss: 0.2432
Epoch 8/80
 - 2s - loss: 0.2235
Epoch 9/80
 - 2s - loss: 0.2083
Epoch 10/80
 - 2s - loss: 0.1947
Epoch 11/80
 - 2s - loss: 0.1822
Epoch 12/80
 - 2s - loss: 0.1715
Epoch 13/80
 - 2s - loss: 0.1628
Epoch 14/80
 - 2s - loss: 0.1555
Epoch 15/80
 - 2s - loss: 0.1495
Epoch 16/80
 - 2s - loss: 0.1444
Epoch 17/80
 - 2s - loss: 0.1400
Epoch 18/80
 - 2s - loss: 0.1364
Epoch 19/80
 - 2s - loss: 0.1334
Epoch 20/80
 - 2s - loss: 0.1308
Epoch 21/80
 - 2s - loss: 0.1286
Epoch 22/80
 - 2s - loss: 0.1268
Epoch 23/80
 - 2s - loss: 0.1253
Epoch 24/80
 - 2s - loss: 0.1240
Epoch 25/80
 - 2s - loss: 0.1230
Epoch 26/80
 - 2s - loss: 0.1220
Epoch 27/80
 - 2s - loss: 0.1212
Epoch 28/80
 - 2s - loss: 0.1205
Epoch 29/80
 - 2s - loss: 0.1200
Epoch 30/80
 - 2s - loss: 0.1194
Epoch 31/80
 - 2s - loss: 0.1189
Epoch 32/80
 - 2s - loss: 0.1186
Epoch 33/80
 - 2s - loss: 0.1182
Epoch 34/80
 - 2s - loss: 0.1179
Epoch 35/80
 - 2s - loss: 0.1176
Epoch 36/80
 - 2s - loss: 0.1174
Epoch 37/80
 - 2s - loss: 0.1172
Epoch 38/80
 - 2s - loss: 0.1170
Epoch 39/80
 - 2s - loss: 0.1168
Epoch 40/80
 - 2s - loss: 0.1166
Epoch 41/80
 - 2s - loss: 0.1164
Epoch 42/80
 - 2s - loss: 0.1163
Epoch 43/80
 - 2s - loss: 0.1162
Epoch 44/80
 - 2s - loss: 0.1161
Epoch 45/80
 - 2s - loss: 0.1159
Epoch 46/80
 - 2s - loss: 0.1158
Epoch 47/80
 - 2s - loss: 0.1158
Epoch 48/80
 - 2s - loss: 0.1156
Epoch 49/80
 - 2s - loss: 0.1156
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:03:28.247357: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:03:28.410878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:03:28.410921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:03:28.698942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:03:28.698993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:03:28.699001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:03:28.699262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1256
Epoch 2/80
 - 2s - loss: 0.2123
Epoch 3/80
 - 2s - loss: 0.1724
Epoch 4/80
 - 2s - loss: 0.1653
Epoch 5/80
 - 2s - loss: 0.1587
Epoch 6/80
 - 2s - loss: 0.1504
Epoch 7/80
 - 2s - loss: 0.1411
Epoch 8/80
 - 2s - loss: 0.1321
Epoch 9/80
 - 2s - loss: 0.1234
Epoch 10/80
 - 2s - loss: 0.1151
Epoch 11/80
 - 2s - loss: 0.1076
Epoch 12/80
 - 2s - loss: 0.1006
Epoch 13/80
 - 2s - loss: 0.0938
Epoch 14/80
 - 2s - loss: 0.0873
Epoch 15/80
 - 2s - loss: 0.0814
Epoch 16/80
 - 2s - loss: 0.0763
Epoch 17/80
 - 2s - loss: 0.0720
Epoch 18/80
 - 2s - loss: 0.0685
Epoch 19/80
 - 2s - loss: 0.0657
Epoch 20/80
 - 2s - loss: 0.0633
Epoch 21/80
 - 2s - loss: 0.0613
Epoch 22/80
 - 2s - loss: 0.0597
Epoch 23/80
 - 2s - loss: 0.0584
Epoch 24/80
 - 2s - loss: 0.0573
Epoch 25/80
 - 2s - loss: 0.0564
Epoch 26/80
 - 2s - loss: 0.0557
Epoch 27/80
 - 2s - loss: 0.0550
Epoch 28/80
 - 2s - loss: 0.0545
Epoch 29/80
 - 2s - loss: 0.0540
Epoch 30/80
 - 2s - loss: 0.0536
Epoch 31/80
 - 2s - loss: 0.0533
Epoch 32/80
 - 2s - loss: 0.0530
Epoch 33/80
 - 2s - loss: 0.0527
Epoch 34/80
 - 2s - loss: 0.0525
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0519
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0516
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0514
Epoch 42/80
 - 2s - loss: 0.0513
Epoch 43/80
 - 2s - loss: 0.0512
Epoch 44/80
 - 2s - loss: 0.0511
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0510
Epoch 47/80
 - 2s - loss: 0.0509
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0508
Epoch 50/80
 - 2s - loss: 0.0507
Epoch 51/80
 - 2s - loss: 0.0507
Epoch 52/80
 - 2s - loss: 0.0506
Epoch 53/80
 - 2s - loss: 0.0506
Epoch 54/80
 - 2s - loss: 0.0505
Epoch 55/80
 - 2s - loss: 0.0505
Epoch 56/80
 - 2s - loss: 0.0505
Epoch 57/80
 - 2s - loss: 0.0504
Epoch 58/80
 - 2s - loss: 0.0504
Epoch 59/80
 - 2s - loss: 0.0503
Epoch 60/80
 - 2s - loss: 0.0503
Epoch 61/80
 - 2s - loss: 0.0492
Epoch 62/80
 - 2s - loss: 0.0491
Epoch 63/80
 - 2s - loss: 0.0491
Epoch 64/80
 - 2s - loss: 0.0491
Epoch 65/80
 - 2s - loss: 0.0490
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0488
Epoch 68/80
 - 2s - loss: 0.0488
Epoch 69/80
 - 2s - loss: 0.0488
Epoch 70/80
 - 2s - loss: 0.0487
Epoch 71/80
 - 2s - loss: 0.0487
Epoch 72/80
 - 2s - loss: 0.0487
Epoch 73/80
 - 2s - loss: 0.0487
Epoch 74/80
 - 2s - loss: 0.0487
Epoch 75/80
 - 2s - loss: 0.0487
Epoch 76/80
 - 2s - loss: 0.0487
Epoch 77/80
 - 2s - loss: 0.0487
Epoch 78/80
 - 2s - loss: 0.0487
Epoch 79/80
 - 2s - loss: 0.0487
Epoch 80/80
 - 2s - loss: 0.0487
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.9356 - val_loss: 1.4147
AUC: 0.7799

Epoch 2/80
 - 0s - loss: 2.6399 - val_loss: 1.0375
AUC: 0.8099

Epoch 3/80
 - 0s - loss: 1.8432 - val_loss: 0.8847
AUC: 0.8324

Epoch 4/80
 - 0s - loss: 1.4135 - val_loss: 0.7249
AUC: 0.8374

Epoch 5/80
 - 0s - loss: 1.2470 - val_loss: 0.6783
AUC: 0.8412

Epoch 6/80
 - 0s - loss: 1.1641 - val_loss: 0.6981
AUC: 0.8462

Epoch 7/80
 - 0s - loss: 1.1277 - val_loss: 0.7322
AUC: 0.8488

Epoch 8/80
 - 0s - loss: 1.1056 - val_loss: 0.6855
AUC: 0.8500

Epoch 9/80
 - 0s - loss: 1.0966 - val_loss: 0.6703
AUC: 0.8504

Epoch 10/80
 - 0s - loss: 1.0706 - val_loss: 0.6744
AUC: 0.8532

Epoch 11/80
 - 0s - loss: 1.0599 - val_loss: 0.6569
AUC: 0.8527

Epoch 12/80
 - 0s - loss: 1.0506 - val_loss: 0.6572
AUC: 0.8551

Epoch 13/80
 - 0s - loss: 1.0380 - val_loss: 0.6063
AUC: 0.8556

Epoch 14/80
 - 0s - loss: 1.0399 - val_loss: 0.6250
AUC: 0.8562

Epoch 15/80
 - 0s - loss: 1.0346 - val_loss: 0.6207
AUC: 0.8562

Epoch 16/80
 - 0s - loss: 1.0313 - val_loss: 0.6771
AUC: 0.8579

Epoch 17/80
 - 0s - loss: 1.0288 - val_loss: 0.5366
AUC: 0.8563

Epoch 18/80
 - 0s - loss: 1.0221 - val_loss: 0.6162
AUC: 0.8594

Epoch 19/80
 - 0s - loss: 1.0171 - val_loss: 0.6503
AUC: 0.8596

Epoch 20/80
 - 0s - loss: 1.0156 - val_loss: 0.6230
AUC: 0.8606

Epoch 21/80
 - 0s - loss: 1.0072 - val_loss: 0.6358
AUC: 0.8599

Epoch 22/80
 - 0s - loss: 1.0062 - val_loss: 0.6489
AUC: 0.8612

Epoch 23/80
 - 0s - loss: 1.0089 - val_loss: 0.6211
AUC: 0.8621

Epoch 24/80
 - 0s - loss: 0.9969 - val_loss: 0.6088
AUC: 0.8618

Epoch 25/80
 - 0s - loss: 0.9984 - val_loss: 0.6411
AUC: 0.8624

Epoch 26/80
 - 0s - loss: 0.9985 - val_loss: 0.6810
AUC: 0.8623

Epoch 27/80
 - 0s - loss: 0.9905 - val_loss: 0.6415
AUC: 0.8624

Epoch 28/80
 - 0s - loss: 0.9885 - val_loss: 0.6049
AUC: 0.8626

Epoch 29/80
 - 0s - loss: 0.9845 - val_loss: 0.6303
AUC: 0.8633

Epoch 30/80
 - 0s - loss: 0.9856 - val_loss: 0.6032
AUC: 0.8629

Epoch 31/80
 - 0s - loss: 0.9845 - val_loss: 0.6171
AUC: 0.8635

Epoch 32/80
 - 0s - loss: 0.9905 - val_loss: 0.6137
AUC: 0.8636

Epoch 33/80
 - 0s - loss: 0.9892 - val_loss: 0.6123
AUC: 0.8633

Epoch 34/80
 - 0s - loss: 0.9854 - val_loss: 0.6346
AUC: 0.8637

Epoch 35/80
 - 0s - loss: 0.9820 - val_loss: 0.5921
AUC: 0.8634

Epoch 36/80
 - 0s - loss: 0.9831 - val_loss: 0.6093
AUC: 0.8635

Epoch 37/80
 - 0s - loss: 0.9795 - val_loss: 0.6201
AUC: 0.8637

Epoch 38/80
 - 0s - loss: 0.9775 - val_loss: 0.6115
AUC: 0.8636

Epoch 39/80
 - 0s - loss: 0.9788 - val_loss: 0.6174
AUC: 0.8636

Epoch 40/80
 - 0s - loss: 0.9790 - val_loss: 0.6118
AUC: 0.8636

Epoch 41/80
 - 0s - loss: 0.9871 - val_loss: 0.6221
AUC: 0.8638

Epoch 42/80
 - 0s - loss: 0.9806 - val_loss: 0.6164
AUC: 0.8637

Epoch 43/80
 - 0s - loss: 0.9803 - val_loss: 0.6107
AUC: 0.8636

Epoch 44/80
 - 0s - loss: 0.9782 - val_loss: 0.6099
AUC: 0.8637

Epoch 45/80
 - 0s - loss: 0.9802 - val_loss: 0.6155
AUC: 0.8638

Epoch 46/80
 - 0s - loss: 0.9792 - val_loss: 0.6151
AUC: 0.8639

Epoch 47/80
 - 0s - loss: 0.9810 - val_loss: 0.6115
AUC: 0.8639

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9860 - val_loss: 0.6304
AUC: 0.8642

Epoch 2/30
 - 0s - loss: 0.9804 - val_loss: 0.5990
AUC: 0.8638

Epoch 3/30
 - 0s - loss: 0.9784 - val_loss: 0.5807
AUC: 0.8635

Epoch 4/30
 - 0s - loss: 0.9739 - val_loss: 0.6074
AUC: 0.8642

Epoch 5/30
 - 0s - loss: 0.9729 - val_loss: 0.6109
AUC: 0.8644

Epoch 6/30
 - 0s - loss: 0.9699 - val_loss: 0.5846
AUC: 0.8642

Epoch 7/30
 - 0s - loss: 0.9768 - val_loss: 0.6254
AUC: 0.8649

Epoch 8/30
 - 0s - loss: 0.9751 - val_loss: 0.6194
AUC: 0.8649

Epoch 9/30
 - 0s - loss: 0.9710 - val_loss: 0.6096
AUC: 0.8650

Epoch 10/30
 - 0s - loss: 0.9624 - val_loss: 0.5958
AUC: 0.8649

Epoch 11/30
 - 0s - loss: 0.9649 - val_loss: 0.6154
AUC: 0.8653

Epoch 12/30
 - 0s - loss: 0.9697 - val_loss: 0.6047
AUC: 0.8652

Epoch 13/30
 - 0s - loss: 0.9670 - val_loss: 0.6257
AUC: 0.8655

Epoch 14/30
 - 0s - loss: 0.9644 - val_loss: 0.6086
AUC: 0.8653

Epoch 15/30
 - 0s - loss: 0.9615 - val_loss: 0.6040
AUC: 0.8653

Epoch 16/30
 - 0s - loss: 0.9686 - val_loss: 0.6038
AUC: 0.8653

Epoch 17/30
 - 0s - loss: 0.9660 - val_loss: 0.6069
AUC: 0.8653

Epoch 18/30
 - 0s - loss: 0.9648 - val_loss: 0.6069
AUC: 0.8653

Epoch 19/30
 - 0s - loss: 0.9625 - val_loss: 0.6041
AUC: 0.8654

Epoch 20/30
 - 0s - loss: 0.9640 - val_loss: 0.6065
AUC: 0.8654

Epoch 21/30
 - 0s - loss: 0.9626 - val_loss: 0.6085
AUC: 0.8654

Epoch 22/30
 - 0s - loss: 0.9690 - val_loss: 0.6101
AUC: 0.8655

Epoch 23/30
 - 0s - loss: 0.9629 - val_loss: 0.6021
AUC: 0.8654

Epoch 24/30
 - 0s - loss: 0.9606 - val_loss: 0.6024
AUC: 0.8654

Epoch 25/30
 - 0s - loss: 0.9632 - val_loss: 0.6037
AUC: 0.8654

Epoch 26/30
 - 0s - loss: 0.9627 - val_loss: 0.6035
AUC: 0.8654

Epoch 27/30
 - 0s - loss: 0.9620 - val_loss: 0.6055
AUC: 0.8655

Epoch 28/30
 - 0s - loss: 0.9615 - val_loss: 0.6051
AUC: 0.8655

Epoch 29/30
 - 0s - loss: 0.9630 - val_loss: 0.6057
AUC: 0.8655

Epoch 30/30
 - 0s - loss: 0.9588 - val_loss: 0.6049
Using TensorFlow backend.
AUC: 0.8655

2019-03-08 03:06:43.943415: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:06:44.108151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:06:44.108214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:06:44.407505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:06:44.407553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:06:44.407563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:06:44.407810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1369
Epoch 2/80
 - 2s - loss: 0.2139
Epoch 3/80
 - 2s - loss: 0.1706
Epoch 4/80
 - 2s - loss: 0.1609
Epoch 5/80
 - 2s - loss: 0.1523
Epoch 6/80
 - 2s - loss: 0.1440
Epoch 7/80
 - 2s - loss: 0.1361
Epoch 8/80
 - 2s - loss: 0.1285
Epoch 9/80
 - 2s - loss: 0.1204
Epoch 10/80
 - 2s - loss: 0.1123
Epoch 11/80
 - 2s - loss: 0.1048
Epoch 12/80
 - 2s - loss: 0.0980
Epoch 13/80
 - 2s - loss: 0.0917
Epoch 14/80
 - 2s - loss: 0.0859
Epoch 15/80
 - 2s - loss: 0.0806
Epoch 16/80
 - 2s - loss: 0.0759
Epoch 17/80
 - 2s - loss: 0.0719
Epoch 18/80
 - 2s - loss: 0.0686
Epoch 19/80
 - 2s - loss: 0.0659
Epoch 20/80
 - 2s - loss: 0.0636
Epoch 21/80
 - 2s - loss: 0.0617
Epoch 22/80
 - 2s - loss: 0.0602
Epoch 23/80
 - 2s - loss: 0.0589
Epoch 24/80
 - 2s - loss: 0.0578
Epoch 25/80
 - 2s - loss: 0.0569
Epoch 26/80
 - 2s - loss: 0.0561
Epoch 27/80
 - 2s - loss: 0.0554
Epoch 28/80
 - 2s - loss: 0.0548
Epoch 29/80
 - 2s - loss: 0.0543
Epoch 30/80
 - 2s - loss: 0.0538
Epoch 31/80
 - 2s - loss: 0.0535
Epoch 32/80
 - 2s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0526
Epoch 35/80
 - 2s - loss: 0.0524
Epoch 36/80
 - 2s - loss: 0.0522
Epoch 37/80
 - 2s - loss: 0.0520
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0517
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0514
Epoch 42/80
 - 2s - loss: 0.0513
Epoch 43/80
 - 2s - loss: 0.0512
Epoch 44/80
 - 2s - loss: 0.0511
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0510
Epoch 47/80
 - 2s - loss: 0.0509
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0507
Epoch 50/80
 - 2s - loss: 0.0507
Epoch 51/80
 - 2s - loss: 0.0506
Epoch 52/80
 - 2s - loss: 0.0506
Epoch 53/80
 - 2s - loss: 0.0505
Epoch 54/80
 - 2s - loss: 0.0505
Epoch 55/80
 - 2s - loss: 0.0505
Epoch 56/80
 - 2s - loss: 0.0504
Epoch 57/80
 - 2s - loss: 0.0504
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b2e4cac31d0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 03:08:37.025867: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:08:37.190777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:08:37.190820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:08:37.483498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:08:37.483550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:08:37.483560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:08:37.483843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1454
Epoch 2/80
 - 2s - loss: 0.2179
Epoch 3/80
 - 2s - loss: 0.1657
Epoch 4/80
 - 2s - loss: 0.1500
Epoch 5/80
 - 2s - loss: 0.1399
Epoch 6/80
 - 2s - loss: 0.1323
Epoch 7/80
 - 2s - loss: 0.1255
Epoch 8/80
 - 2s - loss: 0.1189
Epoch 9/80
 - 2s - loss: 0.1122
Epoch 10/80
 - 2s - loss: 0.1057
Epoch 11/80
 - 2s - loss: 0.0995
Epoch 12/80
 - 2s - loss: 0.0938
Epoch 13/80
 - 2s - loss: 0.0886
Epoch 14/80
 - 2s - loss: 0.0837
Epoch 15/80
 - 2s - loss: 0.0794
Epoch 16/80
 - 2s - loss: 0.0755
Epoch 17/80
 - 2s - loss: 0.0720
Epoch 18/80
 - 2s - loss: 0.0690
Epoch 19/80
 - 2s - loss: 0.0664
Epoch 20/80
 - 2s - loss: 0.0641
Epoch 21/80
 - 2s - loss: 0.0622
Epoch 22/80
 - 2s - loss: 0.0606
Epoch 23/80
 - 2s - loss: 0.0593
Epoch 24/80
 - 2s - loss: 0.0581
Epoch 25/80
 - 2s - loss: 0.0571
Epoch 26/80
 - 2s - loss: 0.0563
Epoch 27/80
 - 2s - loss: 0.0556
Epoch 28/80
 - 2s - loss: 0.0549
Epoch 29/80
 - 2s - loss: 0.0544
Epoch 30/80
 - 2s - loss: 0.0539
Epoch 31/80
 - 2s - loss: 0.0535
Epoch 32/80
 - 2s - loss: 0.0532
Epoch 33/80
 - 2s - loss: 0.0529
Epoch 34/80
 - 2s - loss: 0.0526
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0519
Epoch 38/80
 - 2s - loss: 0.0517
Epoch 39/80
 - 2s - loss: 0.0516
Epoch 40/80
 - 2s - loss: 0.0514
Epoch 41/80
 - 2s - loss: 0.0513
Epoch 42/80
 - 2s - loss: 0.0511
Epoch 43/80
 - 2s - loss: 0.0511
Epoch 44/80
 - 2s - loss: 0.0509
Epoch 45/80
 - 2s - loss: 0.0509
Epoch 46/80
 - 2s - loss: 0.0508
Epoch 47/80
 - 2s - loss: 0.0507
Epoch 48/80
 - 2s - loss: 0.0506
Epoch 49/80
 - 2s - loss: 0.0505
Epoch 50/80
 - 2s - loss: 0.0505
Epoch 51/80
 - 2s - loss: 0.0504
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0503
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0502
Epoch 56/80
 - 2s - loss: 0.0502
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0501
Epoch 59/80
 - 2s - loss: 0.0501
Epoch 60/80
 - 2s - loss: 0.0500
Epoch 61/80
 - 2s - loss: 0.0500
Epoch 62/80
 - 2s - loss: 0.0489
Epoch 63/80
 - 2s - loss: 0.0488
Epoch 64/80
 - 2s - loss: 0.0488
Epoch 65/80
 - 2s - loss: 0.0488
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0485
Epoch 68/80
 - 2s - loss: 0.0485
Epoch 69/80
 - 2s - loss: 0.0485
Epoch 70/80
 - 2s - loss: 0.0485
Epoch 71/80
 - 2s - loss: 0.0484
Epoch 72/80
 - 2s - loss: 0.0484
Epoch 73/80
 - 2s - loss: 0.0484
Epoch 74/80
 - 2s - loss: 0.0484
Epoch 75/80
 - 2s - loss: 0.0484
Epoch 76/80
 - 2s - loss: 0.0484
Epoch 77/80
 - 2s - loss: 0.0484
Epoch 78/80
 - 2s - loss: 0.0484
Epoch 79/80
 - 2s - loss: 0.0484
Epoch 80/80
 - 2s - loss: 0.0484
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 6.8453 - val_loss: 2.5368
AUC: 0.7638

Epoch 2/80
 - 0s - loss: 4.5538 - val_loss: 1.6739
AUC: 0.8079

Epoch 3/80
 - 0s - loss: 3.5361 - val_loss: 1.2987
AUC: 0.8267

Epoch 4/80
 - 0s - loss: 2.5962 - val_loss: 1.0746
AUC: 0.8415

Epoch 5/80
 - 0s - loss: 2.0083 - val_loss: 0.8605
AUC: 0.8463

Epoch 6/80
 - 0s - loss: 1.5566 - val_loss: 0.8670
AUC: 0.8435

Epoch 7/80
 - 0s - loss: 1.3166 - val_loss: 0.6599
AUC: 0.8478

Epoch 8/80
 - 0s - loss: 1.2060 - val_loss: 0.6847
AUC: 0.8512

Epoch 9/80
 - 0s - loss: 1.1723 - val_loss: 0.6902
AUC: 0.8545

Epoch 10/80
 - 0s - loss: 1.1481 - val_loss: 0.7181
AUC: 0.8561

Epoch 11/80
 - 0s - loss: 1.1142 - val_loss: 0.6327
AUC: 0.8584

Epoch 12/80
 - 0s - loss: 1.0938 - val_loss: 0.6621
AUC: 0.8626

Epoch 13/80
 - 0s - loss: 1.0765 - val_loss: 0.6887
AUC: 0.8631

Epoch 14/80
 - 0s - loss: 1.0706 - val_loss: 0.5936
AUC: 0.8623

Epoch 15/80
 - 0s - loss: 1.0631 - val_loss: 0.6111
AUC: 0.8641

Epoch 16/80
 - 0s - loss: 1.0565 - val_loss: 0.6259
AUC: 0.8645

Epoch 17/80
 - 0s - loss: 1.0481 - val_loss: 0.6454
AUC: 0.8665

Epoch 18/80
 - 0s - loss: 1.0347 - val_loss: 0.6471
AUC: 0.8663

Epoch 19/80
 - 0s - loss: 1.0382 - val_loss: 0.6273
AUC: 0.8660

Epoch 20/80
 - 0s - loss: 1.0295 - val_loss: 0.6172
AUC: 0.8680

Epoch 21/80
 - 0s - loss: 1.0207 - val_loss: 0.6710
AUC: 0.8670

Epoch 22/80
 - 0s - loss: 1.0210 - val_loss: 0.6430
AUC: 0.8683

Epoch 23/80
 - 0s - loss: 1.0170 - val_loss: 0.6657
AUC: 0.8688

Epoch 24/80
 - 0s - loss: 1.0151 - val_loss: 0.5476
AUC: 0.8685

Epoch 25/80
 - 0s - loss: 1.0120 - val_loss: 0.6352
AUC: 0.8703

Epoch 26/80
 - 0s - loss: 1.0075 - val_loss: 0.6181
AUC: 0.8698

Epoch 27/80
 - 0s - loss: 1.0095 - val_loss: 0.6489
AUC: 0.8710

Epoch 28/80
 - 0s - loss: 1.0053 - val_loss: 0.6363
AUC: 0.8726

Epoch 29/80
 - 0s - loss: 1.0051 - val_loss: 0.5949
AUC: 0.8712

Epoch 30/80
 - 0s - loss: 0.9942 - val_loss: 0.5957
AUC: 0.8705

Epoch 31/80
 - 0s - loss: 0.9928 - val_loss: 0.6081
AUC: 0.8728

Epoch 32/80
 - 0s - loss: 0.9954 - val_loss: 0.6203
AUC: 0.8722

Epoch 33/80
 - 0s - loss: 0.9895 - val_loss: 0.5324
AUC: 0.8709

Epoch 34/80
 - 0s - loss: 0.9903 - val_loss: 0.5823
AUC: 0.8726

Epoch 35/80
 - 0s - loss: 0.9860 - val_loss: 0.6424
AUC: 0.8723

Epoch 36/80
 - 0s - loss: 0.9827 - val_loss: 0.6211
AUC: 0.8737

Epoch 37/80
 - 0s - loss: 0.9831 - val_loss: 0.6985
AUC: 0.8744

Epoch 38/80
 - 0s - loss: 0.9793 - val_loss: 0.6329
AUC: 0.8734

Epoch 39/80
 - 0s - loss: 0.9787 - val_loss: 0.5992
AUC: 0.8737

Epoch 40/80
 - 0s - loss: 0.9715 - val_loss: 0.5902
AUC: 0.8741

Epoch 41/80
 - 0s - loss: 0.9679 - val_loss: 0.5788
AUC: 0.8739

Epoch 42/80
 - 0s - loss: 0.9732 - val_loss: 0.5521
AUC: 0.8740

Epoch 43/80
 - 0s - loss: 0.9710 - val_loss: 0.6653
AUC: 0.8746

Epoch 44/80
 - 0s - loss: 0.9680 - val_loss: 0.5824
AUC: 0.8744

Epoch 45/80
 - 0s - loss: 0.9646 - val_loss: 0.5802
AUC: 0.8744

Epoch 46/80
 - 0s - loss: 0.9571 - val_loss: 0.5527
AUC: 0.8739

Epoch 47/80
 - 0s - loss: 0.9614 - val_loss: 0.5857
AUC: 0.8746

Epoch 48/80
 - 0s - loss: 0.9559 - val_loss: 0.5985
AUC: 0.8748

Epoch 49/80
 - 0s - loss: 0.9602 - val_loss: 0.5573
AUC: 0.8737

Epoch 50/80
 - 0s - loss: 0.9618 - val_loss: 0.5963
AUC: 0.8747

Epoch 51/80
 - 0s - loss: 0.9608 - val_loss: 0.6306
AUC: 0.8748

Epoch 52/80
 - 0s - loss: 0.9543 - val_loss: 0.6008
AUC: 0.8747

Epoch 53/80
 - 0s - loss: 0.9605 - val_loss: 0.5968
AUC: 0.8752

Epoch 54/80
 - 0s - loss: 0.9546 - val_loss: 0.5843
AUC: 0.8751

Epoch 55/80
 - 0s - loss: 0.9554 - val_loss: 0.5832
AUC: 0.8750

Epoch 56/80
 - 0s - loss: 0.9530 - val_loss: 0.5897
AUC: 0.8750

Epoch 57/80
 - 0s - loss: 0.9543 - val_loss: 0.5884
AUC: 0.8750

Epoch 58/80
 - 0s - loss: 0.9563 - val_loss: 0.5896
AUC: 0.8750

Epoch 59/80
 - 0s - loss: 0.9556 - val_loss: 0.5796
AUC: 0.8749

Epoch 60/80
 - 0s - loss: 0.9583 - val_loss: 0.5871
AUC: 0.8749

Epoch 61/80
 - 0s - loss: 0.9592 - val_loss: 0.5911
AUC: 0.8749

Epoch 62/80
 - 0s - loss: 0.9573 - val_loss: 0.5916
AUC: 0.8749

Epoch 63/80
 - 0s - loss: 0.9519 - val_loss: 0.5889
AUC: 0.8749

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9623 - val_loss: 0.5997
AUC: 0.8751

Epoch 2/30
 - 0s - loss: 0.9577 - val_loss: 0.5827
AUC: 0.8750

Epoch 3/30
 - 0s - loss: 0.9516 - val_loss: 0.5859
AUC: 0.8752

Epoch 4/30
 - 0s - loss: 0.9527 - val_loss: 0.5945
AUC: 0.8754

Epoch 5/30
 - 0s - loss: 0.9526 - val_loss: 0.5982
AUC: 0.8755

Epoch 6/30
 - 0s - loss: 0.9528 - val_loss: 0.5889
AUC: 0.8754

Epoch 7/30
 - 0s - loss: 0.9518 - val_loss: 0.5653
AUC: 0.8753

Epoch 8/30
 - 0s - loss: 0.9424 - val_loss: 0.5899
AUC: 0.8755

Epoch 9/30
 - 0s - loss: 0.9506 - val_loss: 0.5894
AUC: 0.8756

Epoch 10/30
 - 0s - loss: 0.9458 - val_loss: 0.5754
AUC: 0.8755

Epoch 11/30
 - 0s - loss: 0.9434 - val_loss: 0.5711
AUC: 0.8756

Epoch 12/30
 - 0s - loss: 0.9416 - val_loss: 0.5570
AUC: 0.8756

Epoch 13/30
 - 0s - loss: 0.9437 - val_loss: 0.5779
AUC: 0.8757

Epoch 14/30
 - 0s - loss: 0.9454 - val_loss: 0.5649
AUC: 0.8758

Epoch 15/30
 - 0s - loss: 0.9381 - val_loss: 0.5723
AUC: 0.8760

Epoch 16/30
 - 0s - loss: 0.9420 - val_loss: 0.5694
AUC: 0.8760

Epoch 17/30
 - 0s - loss: 0.9364 - val_loss: 0.5924
AUC: 0.8761

Epoch 18/30
 - 0s - loss: 0.9394 - val_loss: 0.5920
AUC: 0.8764

Epoch 19/30
 - 0s - loss: 0.9367 - val_loss: 0.5652
AUC: 0.8761

Epoch 20/30
 - 0s - loss: 0.9344 - val_loss: 0.5741
AUC: 0.8763

Epoch 21/30
 - 0s - loss: 0.9296 - val_loss: 0.5760
AUC: 0.8762

Epoch 22/30
 - 0s - loss: 0.9324 - val_loss: 0.5788
AUC: 0.8766

Epoch 23/30
 - 0s - loss: 0.9353 - val_loss: 0.5766
AUC: 0.8765

Epoch 24/30
 - 0s - loss: 0.9334 - val_loss: 0.5772
AUC: 0.8765

Epoch 25/30
 - 0s - loss: 0.9322 - val_loss: 0.5748
AUC: 0.8765

Epoch 26/30
 - 0s - loss: 0.9314 - val_loss: 0.5766
AUC: 0.8766

Epoch 27/30
 - 0s - loss: 0.9294 - val_loss: 0.5727
AUC: 0.8765

Epoch 28/30
 - 0s - loss: 0.9334 - val_loss: 0.5751
AUC: 0.8766

Epoch 29/30
 - 0s - loss: 0.9282 - val_loss: 0.5759
AUC: 0.8765

Epoch 30/30
 - 0s - loss: 0.9282 - val_loss: 0.5726
Using TensorFlow backend.
AUC: 0.8765

2019-03-08 03:12:01.032822: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:12:01.201260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:12:01.201304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:12:01.501298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:12:01.501346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:12:01.501356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:12:01.501677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6779
Epoch 2/80
 - 2s - loss: 0.1268
Epoch 3/80
 - 2s - loss: 0.0724
Epoch 4/80
 - 2s - loss: 0.0664
Epoch 5/80
 - 2s - loss: 0.0639
Epoch 6/80
 - 2s - loss: 0.0615
Epoch 7/80
 - 2s - loss: 0.0581
Epoch 8/80
 - 2s - loss: 0.0544
Epoch 9/80
 - 2s - loss: 0.0510
Epoch 10/80
 - 2s - loss: 0.0480
Epoch 11/80
 - 2s - loss: 0.0453
Epoch 12/80
 - 2s - loss: 0.0426
Epoch 13/80
 - 2s - loss: 0.0399
Epoch 14/80
 - 2s - loss: 0.0371
Epoch 15/80
 - 2s - loss: 0.0345
Epoch 16/80
 - 2s - loss: 0.0321
Epoch 17/80
 - 2s - loss: 0.0299
Epoch 18/80
 - 2s - loss: 0.0279
Epoch 19/80
 - 2s - loss: 0.0263
Epoch 20/80
 - 2s - loss: 0.0249
Epoch 21/80
 - 2s - loss: 0.0237
Epoch 22/80
 - 2s - loss: 0.0228
Epoch 23/80
 - 2s - loss: 0.0219
Epoch 24/80
 - 2s - loss: 0.0212
Epoch 25/80
 - 2s - loss: 0.0206
Epoch 26/80
 - 2s - loss: 0.0201
Epoch 27/80
 - 2s - loss: 0.0196
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0189
Epoch 30/80
 - 2s - loss: 0.0186
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0178
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0169
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0167
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0165
Epoch 55/80
 - 2s - loss: 0.0164
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0160
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0158
Epoch 65/80
 - 2s - loss: 0.0158
Epoch 66/80
 - 2s - loss: 0.0158
Epoch 67/80
 - 2s - loss: 0.0158
Epoch 68/80
 - 2s - loss: 0.0158
Epoch 69/80
 - 2s - loss: 0.0158
Epoch 70/80
 - 2s - loss: 0.0158
Epoch 71/80
 - 2s - loss: 0.0158
Epoch 72/80
 - 2s - loss: 0.0158
Epoch 73/80
 - 2s - loss: 0.0158
Epoch 74/80
 - 2s - loss: 0.0158
Epoch 75/80
 - 2s - loss: 0.0158
Epoch 76/80
 - 2s - loss: 0.0158
Epoch 77/80
 - 2s - loss: 0.0158
Epoch 78/80
 - 2s - loss: 0.0158
Epoch 79/80
 - 2s - loss: 0.0158
Epoch 80/80
 - 2s - loss: 0.0158
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.7499 - val_loss: 1.5085
AUC: 0.7720

Epoch 2/80
 - 0s - loss: 3.0732 - val_loss: 1.1415
AUC: 0.8037

Epoch 3/80
 - 0s - loss: 2.0168 - val_loss: 0.7831
AUC: 0.8138

Epoch 4/80
 - 0s - loss: 1.5407 - val_loss: 0.7147
AUC: 0.8216

Epoch 5/80
 - 0s - loss: 1.3091 - val_loss: 0.7145
AUC: 0.8276

Epoch 6/80
 - 0s - loss: 1.2060 - val_loss: 0.6644
AUC: 0.8349

Epoch 7/80
 - 0s - loss: 1.1670 - val_loss: 0.6421
AUC: 0.8396

Epoch 8/80
 - 0s - loss: 1.1408 - val_loss: 0.6718
AUC: 0.8438

Epoch 9/80
 - 0s - loss: 1.1205 - val_loss: 0.7195
AUC: 0.8467

Epoch 10/80
 - 0s - loss: 1.1003 - val_loss: 0.6071
AUC: 0.8469

Epoch 11/80
 - 0s - loss: 1.0876 - val_loss: 0.6807
AUC: 0.8498

Epoch 12/80
 - 0s - loss: 1.0868 - val_loss: 0.7295
AUC: 0.8513

Epoch 13/80
 - 0s - loss: 1.0705 - val_loss: 0.6381
AUC: 0.8502

Epoch 14/80
 - 0s - loss: 1.0590 - val_loss: 0.6661
AUC: 0.8531

Epoch 15/80
 - 0s - loss: 1.0529 - val_loss: 0.6099
AUC: 0.8520

Epoch 16/80
 - 0s - loss: 1.0445 - val_loss: 0.6507
AUC: 0.8522

Epoch 17/80
 - 0s - loss: 1.0450 - val_loss: 0.6384
AUC: 0.8545

Epoch 18/80
 - 0s - loss: 1.0332 - val_loss: 0.6485
AUC: 0.8546

Epoch 19/80
 - 0s - loss: 1.0307 - val_loss: 0.6171
AUC: 0.8561

Epoch 20/80
 - 0s - loss: 1.0336 - val_loss: 0.6281
AUC: 0.8565

Epoch 21/80
 - 0s - loss: 1.0208 - val_loss: 0.6349
AUC: 0.8568

Epoch 22/80
 - 0s - loss: 1.0227 - val_loss: 0.6175
AUC: 0.8567

Epoch 23/80
 - 0s - loss: 1.0197 - val_loss: 0.6401
AUC: 0.8567

Epoch 24/80
 - 0s - loss: 1.0231 - val_loss: 0.6116
AUC: 0.8566

Epoch 25/80
 - 0s - loss: 1.0231 - val_loss: 0.6221
AUC: 0.8568

Epoch 26/80
 - 0s - loss: 1.0208 - val_loss: 0.6233
AUC: 0.8571

Epoch 27/80
 - 0s - loss: 1.0099 - val_loss: 0.6373
AUC: 0.8571

Epoch 28/80
 - 0s - loss: 1.0142 - val_loss: 0.6297
AUC: 0.8575

Epoch 29/80
 - 0s - loss: 1.0115 - val_loss: 0.6361
AUC: 0.8574

Epoch 30/80
 - 0s - loss: 1.0177 - val_loss: 0.6226
AUC: 0.8573

Epoch 31/80
 - 0s - loss: 1.0088 - val_loss: 0.6284
AUC: 0.8574

Epoch 32/80
 - 0s - loss: 1.0124 - val_loss: 0.6282
AUC: 0.8573

Epoch 33/80
 - 0s - loss: 1.0115 - val_loss: 0.6266
AUC: 0.8574

Epoch 34/80
 - 0s - loss: 1.0109 - val_loss: 0.6289
AUC: 0.8575

Epoch 35/80
 - 0s - loss: 1.0068 - val_loss: 0.6229
AUC: 0.8574

Epoch 36/80
 - 0s - loss: 1.0134 - val_loss: 0.6275
AUC: 0.8575

Epoch 37/80
 - 0s - loss: 1.0103 - val_loss: 0.6204
AUC: 0.8574

Epoch 38/80
 - 0s - loss: 1.0122 - val_loss: 0.6274
AUC: 0.8574

Epoch 39/80
 - 0s - loss: 1.0139 - val_loss: 0.6299
AUC: 0.8575

Epoch 40/80
 - 0s - loss: 1.0088 - val_loss: 0.6198
AUC: 0.8575

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0047 - val_loss: 0.6336
AUC: 0.8577

Epoch 2/30
 - 0s - loss: 1.0122 - val_loss: 0.6269
AUC: 0.8578

Epoch 3/30
 - 0s - loss: 1.0094 - val_loss: 0.6231
AUC: 0.8583

Epoch 4/30
 - 0s - loss: 1.0051 - val_loss: 0.6103
AUC: 0.8583

Epoch 5/30
 - 0s - loss: 1.0047 - val_loss: 0.6169
AUC: 0.8584

Epoch 6/30
 - 0s - loss: 1.0017 - val_loss: 0.6432
AUC: 0.8588

Epoch 7/30
 - 0s - loss: 1.0037 - val_loss: 0.6219
AUC: 0.8587

Epoch 8/30
 - 0s - loss: 1.0011 - val_loss: 0.6314
AUC: 0.8588

Epoch 9/30
 - 0s - loss: 0.9997 - val_loss: 0.6110
AUC: 0.8589

Epoch 10/30
 - 0s - loss: 1.0008 - val_loss: 0.6151
AUC: 0.8590

Epoch 11/30
 - 0s - loss: 0.9954 - val_loss: 0.6419
AUC: 0.8593

Epoch 12/30
 - 0s - loss: 0.9936 - val_loss: 0.5998
AUC: 0.8590

Epoch 13/30
 - 0s - loss: 0.9920 - val_loss: 0.6147
AUC: 0.8594

Epoch 14/30
 - 0s - loss: 0.9924 - val_loss: 0.6238
AUC: 0.8596

Epoch 15/30
 - 0s - loss: 0.9874 - val_loss: 0.5981
AUC: 0.8595

Epoch 16/30
 - 0s - loss: 0.9831 - val_loss: 0.6076
AUC: 0.8598

Epoch 17/30
 - 0s - loss: 0.9908 - val_loss: 0.6300
AUC: 0.8603

Epoch 18/30
 - 0s - loss: 0.9901 - val_loss: 0.6011
AUC: 0.8603

Epoch 19/30
 - 0s - loss: 0.9894 - val_loss: 0.6162
AUC: 0.8602

Epoch 20/30
 - 0s - loss: 0.9796 - val_loss: 0.6146
AUC: 0.8604

Epoch 21/30
 - 0s - loss: 0.9841 - val_loss: 0.5921
AUC: 0.8602

Epoch 22/30
 - 0s - loss: 0.9828 - val_loss: 0.6246
AUC: 0.8607

Epoch 23/30
 - 0s - loss: 0.9813 - val_loss: 0.6118
AUC: 0.8606

Epoch 24/30
 - 0s - loss: 0.9833 - val_loss: 0.6237
AUC: 0.8609

Epoch 25/30
 - 0s - loss: 0.9761 - val_loss: 0.6232
AUC: 0.8610

Epoch 26/30
 - 0s - loss: 0.9744 - val_loss: 0.6090
AUC: 0.8612

Epoch 27/30
 - 0s - loss: 0.9745 - val_loss: 0.6070
AUC: 0.8612

Epoch 28/30
 - 0s - loss: 0.9717 - val_loss: 0.6050
AUC: 0.8614

Epoch 29/30
 - 0s - loss: 0.9753 - val_loss: 0.6118
AUC: 0.8617

Epoch 30/30
 - 0s - loss: 0.9696 - val_loss: 0.5796
Using TensorFlow backend.
AUC: 0.8614

2019-03-08 03:15:13.268607: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:15:13.433910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:15:13.433952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:15:13.727659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:15:13.727708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:15:13.727717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:15:13.727973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6906
Epoch 2/80
 - 2s - loss: 0.1316
Epoch 3/80
 - 2s - loss: 0.0726
Epoch 4/80
 - 2s - loss: 0.0662
Epoch 5/80
 - 2s - loss: 0.0637
Epoch 6/80
 - 2s - loss: 0.0617
Epoch 7/80
 - 2s - loss: 0.0594
Epoch 8/80
 - 2s - loss: 0.0568
Epoch 9/80
 - 2s - loss: 0.0538
Epoch 10/80
 - 2s - loss: 0.0503
Epoch 11/80
 - 2s - loss: 0.0463
Epoch 12/80
 - 2s - loss: 0.0423
Epoch 13/80
 - 2s - loss: 0.0387
Epoch 14/80
 - 2s - loss: 0.0355
Epoch 15/80
 - 2s - loss: 0.0328
Epoch 16/80
 - 2s - loss: 0.0306
Epoch 17/80
 - 2s - loss: 0.0287
Epoch 18/80
 - 2s - loss: 0.0270
Epoch 19/80
 - 2s - loss: 0.0256
Epoch 20/80
 - 2s - loss: 0.0244
Epoch 21/80
 - 2s - loss: 0.0234
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0217
Epoch 24/80
 - 2s - loss: 0.0211
Epoch 25/80
 - 2s - loss: 0.0205
Epoch 26/80
 - 2s - loss: 0.0200
Epoch 27/80
 - 2s - loss: 0.0195
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0172
Epoch 39/80
 - 2s - loss: 0.0171
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0169
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0167
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0165
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.5925 - val_loss: 1.8795
AUC: 0.7949

Epoch 2/80
 - 0s - loss: 2.8855 - val_loss: 0.9328
AUC: 0.8188

Epoch 3/80
 - 0s - loss: 1.8889 - val_loss: 0.7708
AUC: 0.8331

Epoch 4/80
 - 0s - loss: 1.4200 - val_loss: 0.6620
AUC: 0.8341

Epoch 5/80
 - 0s - loss: 1.2657 - val_loss: 0.7157
AUC: 0.8385

Epoch 6/80
 - 0s - loss: 1.1998 - val_loss: 0.7042
AUC: 0.8431

Epoch 7/80
 - 0s - loss: 1.1558 - val_loss: 0.6699
AUC: 0.8454

Epoch 8/80
 - 0s - loss: 1.1187 - val_loss: 0.6283
AUC: 0.8482

Epoch 9/80
 - 0s - loss: 1.1260 - val_loss: 0.6664
AUC: 0.8501

Epoch 10/80
 - 0s - loss: 1.1007 - val_loss: 0.6619
AUC: 0.8512

Epoch 11/80
 - 0s - loss: 1.0942 - val_loss: 0.6546
AUC: 0.8524

Epoch 12/80
 - 0s - loss: 1.0845 - val_loss: 0.6182
AUC: 0.8528

Epoch 13/80
 - 0s - loss: 1.0782 - val_loss: 0.6841
AUC: 0.8549

Epoch 14/80
 - 0s - loss: 1.0725 - val_loss: 0.6593
AUC: 0.8558

Epoch 15/80
 - 0s - loss: 1.0623 - val_loss: 0.6490
AUC: 0.8566

Epoch 16/80
 - 0s - loss: 1.0620 - val_loss: 0.6938
AUC: 0.8576

Epoch 17/80
 - 0s - loss: 1.0552 - val_loss: 0.7199
AUC: 0.8579

Epoch 18/80
 - 0s - loss: 1.0487 - val_loss: 0.6489
AUC: 0.8578

Epoch 19/80
 - 0s - loss: 1.0475 - val_loss: 0.6081
AUC: 0.8589

Epoch 20/80
 - 0s - loss: 1.0454 - val_loss: 0.6332
AUC: 0.8579

Epoch 21/80
 - 0s - loss: 1.0425 - val_loss: 0.5913
AUC: 0.8590

Epoch 22/80
 - 0s - loss: 1.0362 - val_loss: 0.6595
AUC: 0.8602

Epoch 23/80
 - 0s - loss: 1.0341 - val_loss: 0.6496
AUC: 0.8601

Epoch 24/80
 - 0s - loss: 1.0325 - val_loss: 0.6893
AUC: 0.8612

Epoch 25/80
 - 0s - loss: 1.0305 - val_loss: 0.6535
AUC: 0.8600

Epoch 26/80
 - 0s - loss: 1.0250 - val_loss: 0.6118
AUC: 0.8606

Epoch 27/80
 - 0s - loss: 1.0229 - val_loss: 0.6311
AUC: 0.8611

Epoch 28/80
 - 0s - loss: 1.0190 - val_loss: 0.5832
AUC: 0.8612

Epoch 29/80
 - 0s - loss: 1.0201 - val_loss: 0.6234
AUC: 0.8625

Epoch 30/80
 - 0s - loss: 1.0251 - val_loss: 0.6045
AUC: 0.8617

Epoch 31/80
 - 0s - loss: 1.0178 - val_loss: 0.6405
AUC: 0.8625

Epoch 32/80
 - 0s - loss: 1.0145 - val_loss: 0.6345
AUC: 0.8626

Epoch 33/80
 - 0s - loss: 1.0117 - val_loss: 0.6785
AUC: 0.8628

Epoch 34/80
 - 0s - loss: 1.0132 - val_loss: 0.5763
AUC: 0.8625

Epoch 35/80
 - 0s - loss: 1.0076 - val_loss: 0.6225
AUC: 0.8625

Epoch 36/80
 - 0s - loss: 1.0065 - val_loss: 0.5407
AUC: 0.8630

Epoch 37/80
 - 0s - loss: 1.0045 - val_loss: 0.6122
AUC: 0.8640

Epoch 38/80
 - 0s - loss: 0.9983 - val_loss: 0.6844
AUC: 0.8641

Epoch 39/80
 - 0s - loss: 1.0009 - val_loss: 0.6195
AUC: 0.8640

Epoch 40/80
 - 0s - loss: 0.9956 - val_loss: 0.6335
AUC: 0.8642

Epoch 41/80
 - 0s - loss: 1.0005 - val_loss: 0.5688
AUC: 0.8648

Epoch 42/80
 - 0s - loss: 0.9942 - val_loss: 0.5607
AUC: 0.8646

Epoch 43/80
 - 0s - loss: 0.9886 - val_loss: 0.5864
AUC: 0.8654

Epoch 44/80
 - 0s - loss: 0.9920 - val_loss: 0.6178
AUC: 0.8653

Epoch 45/80
 - 0s - loss: 0.9866 - val_loss: 0.6621
AUC: 0.8658

Epoch 46/80
 - 0s - loss: 0.9873 - val_loss: 0.5727
AUC: 0.8645

Epoch 47/80
 - 0s - loss: 0.9876 - val_loss: 0.5958
AUC: 0.8658

Epoch 48/80
 - 0s - loss: 0.9762 - val_loss: 0.6052
AUC: 0.8658

Epoch 49/80
 - 0s - loss: 0.9793 - val_loss: 0.6021
AUC: 0.8659

Epoch 50/80
 - 0s - loss: 0.9788 - val_loss: 0.6104
AUC: 0.8660

Epoch 51/80
 - 0s - loss: 0.9772 - val_loss: 0.6121
AUC: 0.8660

Epoch 52/80
 - 0s - loss: 0.9780 - val_loss: 0.6185
AUC: 0.8662

Epoch 53/80
 - 0s - loss: 0.9779 - val_loss: 0.6033
AUC: 0.8662

Epoch 54/80
 - 0s - loss: 0.9768 - val_loss: 0.5867
AUC: 0.8660

Epoch 55/80
 - 0s - loss: 0.9738 - val_loss: 0.6292
AUC: 0.8665

Epoch 56/80
 - 0s - loss: 0.9766 - val_loss: 0.6206
AUC: 0.8662

Epoch 57/80
 - 0s - loss: 0.9739 - val_loss: 0.6020
AUC: 0.8661

Epoch 58/80
 - 0s - loss: 0.9745 - val_loss: 0.6026
AUC: 0.8661

Epoch 59/80
 - 0s - loss: 0.9687 - val_loss: 0.6057
AUC: 0.8662

Epoch 60/80
 - 0s - loss: 0.9703 - val_loss: 0.6015
AUC: 0.8662

Epoch 61/80
 - 0s - loss: 0.9747 - val_loss: 0.6034
AUC: 0.8662

Epoch 62/80
 - 0s - loss: 0.9754 - val_loss: 0.6024
AUC: 0.8662

Epoch 63/80
 - 0s - loss: 0.9662 - val_loss: 0.6133
AUC: 0.8662

Epoch 64/80
 - 0s - loss: 0.9748 - val_loss: 0.6059
AUC: 0.8663

Epoch 65/80
 - 0s - loss: 0.9692 - val_loss: 0.6050
AUC: 0.8663

Epoch 66/80
 - 0s - loss: 0.9728 - val_loss: 0.6040
AUC: 0.8663

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9757 - val_loss: 0.6070
AUC: 0.8664

Epoch 2/30
 - 0s - loss: 0.9746 - val_loss: 0.5974
AUC: 0.8666

Epoch 3/30
 - 0s - loss: 0.9727 - val_loss: 0.6097
AUC: 0.8666

Epoch 4/30
 - 0s - loss: 0.9694 - val_loss: 0.5859
AUC: 0.8667

Epoch 5/30
 - 0s - loss: 0.9717 - val_loss: 0.6051
AUC: 0.8668

Epoch 6/30
 - 0s - loss: 0.9642 - val_loss: 0.6030
AUC: 0.8670

Epoch 7/30
 - 0s - loss: 0.9679 - val_loss: 0.6115
AUC: 0.8670

Epoch 8/30
 - 0s - loss: 0.9608 - val_loss: 0.5909
AUC: 0.8672

Epoch 9/30
 - 0s - loss: 0.9612 - val_loss: 0.5908
AUC: 0.8673

Epoch 10/30
 - 0s - loss: 0.9642 - val_loss: 0.5976
AUC: 0.8674

Epoch 11/30
 - 0s - loss: 0.9593 - val_loss: 0.5873
AUC: 0.8674

Epoch 12/30
 - 0s - loss: 0.9579 - val_loss: 0.5890
AUC: 0.8674

Epoch 13/30
 - 0s - loss: 0.9602 - val_loss: 0.5885
AUC: 0.8677

Epoch 14/30
 - 0s - loss: 0.9512 - val_loss: 0.5916
AUC: 0.8678

Epoch 15/30
 - 0s - loss: 0.9574 - val_loss: 0.5953
AUC: 0.8678

Epoch 16/30
 - 0s - loss: 0.9562 - val_loss: 0.5946
AUC: 0.8678

Epoch 17/30
 - 0s - loss: 0.9527 - val_loss: 0.5958
AUC: 0.8678

Epoch 18/30
 - 0s - loss: 0.9566 - val_loss: 0.5961
AUC: 0.8678

Epoch 19/30
 - 0s - loss: 0.9572 - val_loss: 0.5960
AUC: 0.8678

Epoch 20/30
 - 0s - loss: 0.9563 - val_loss: 0.5956
AUC: 0.8679

Epoch 21/30
 - 0s - loss: 0.9517 - val_loss: 0.5948
AUC: 0.8679

Epoch 22/30
 - 0s - loss: 0.9521 - val_loss: 0.5952
AUC: 0.8679

Epoch 23/30
 - 0s - loss: 0.9494 - val_loss: 0.5949
AUC: 0.8679

Epoch 24/30
 - 0s - loss: 0.9483 - val_loss: 0.5922
AUC: 0.8679

Epoch 25/30
 - 0s - loss: 0.9544 - val_loss: 0.5936
AUC: 0.8679

Epoch 26/30
 - 0s - loss: 0.9537 - val_loss: 0.5940
AUC: 0.8679

Epoch 27/30
 - 0s - loss: 0.9523 - val_loss: 0.5948
AUC: 0.8679

Epoch 28/30
 - 0s - loss: 0.9505 - val_loss: 0.5949
AUC: 0.8679

Epoch 29/30
 - 0s - loss: 0.9496 - val_loss: 0.5947
AUC: 0.8679

Epoch 30/30
 - 0s - loss: 0.9488 - val_loss: 0.5944
Using TensorFlow backend.
AUC: 0.8679

2019-03-08 03:18:41.148255: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:18:41.318570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:18:41.318615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:18:41.623553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:18:41.623599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:18:41.623608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:18:41.623859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6914
Epoch 2/80
 - 2s - loss: 0.1317
Epoch 3/80
 - 2s - loss: 0.0721
Epoch 4/80
 - 2s - loss: 0.0657
Epoch 5/80
 - 2s - loss: 0.0628
Epoch 6/80
 - 2s - loss: 0.0600
Epoch 7/80
 - 2s - loss: 0.0566
Epoch 8/80
 - 2s - loss: 0.0527
Epoch 9/80
 - 2s - loss: 0.0491
Epoch 10/80
 - 2s - loss: 0.0457
Epoch 11/80
 - 2s - loss: 0.0427
Epoch 12/80
 - 2s - loss: 0.0399
Epoch 13/80
 - 2s - loss: 0.0372
Epoch 14/80
 - 2s - loss: 0.0348
Epoch 15/80
 - 2s - loss: 0.0326
Epoch 16/80
 - 2s - loss: 0.0306
Epoch 17/80
 - 2s - loss: 0.0288
Epoch 18/80
 - 2s - loss: 0.0272
Epoch 19/80
 - 2s - loss: 0.0258
Epoch 20/80
 - 2s - loss: 0.0246
Epoch 21/80
 - 2s - loss: 0.0235
Epoch 22/80
 - 2s - loss: 0.0226
Epoch 23/80
 - 2s - loss: 0.0217
Epoch 24/80
 - 2s - loss: 0.0210
Epoch 25/80
 - 2s - loss: 0.0204
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0195
Epoch 28/80
 - 2s - loss: 0.0191
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0172
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0161
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.1563 - val_loss: 1.7119
AUC: 0.8098

Epoch 2/80
 - 0s - loss: 2.6292 - val_loss: 0.9055
AUC: 0.8257

Epoch 3/80
 - 0s - loss: 1.7794 - val_loss: 0.8697
AUC: 0.8368

Epoch 4/80
 - 0s - loss: 1.3686 - val_loss: 0.6905
AUC: 0.8402

Epoch 5/80
 - 0s - loss: 1.2141 - val_loss: 0.6330
AUC: 0.8416

Epoch 6/80
 - 0s - loss: 1.1587 - val_loss: 0.6592
AUC: 0.8440

Epoch 7/80
 - 0s - loss: 1.1333 - val_loss: 0.6632
AUC: 0.8477

Epoch 8/80
 - 0s - loss: 1.1011 - val_loss: 0.6898
AUC: 0.8480

Epoch 9/80
 - 0s - loss: 1.0995 - val_loss: 0.6424
AUC: 0.8501

Epoch 10/80
 - 0s - loss: 1.0848 - val_loss: 0.6833
AUC: 0.8522

Epoch 11/80
 - 0s - loss: 1.0775 - val_loss: 0.7161
AUC: 0.8543

Epoch 12/80
 - 0s - loss: 1.0714 - val_loss: 0.6546
AUC: 0.8543

Epoch 13/80
 - 0s - loss: 1.0641 - val_loss: 0.6483
AUC: 0.8551

Epoch 14/80
 - 0s - loss: 1.0543 - val_loss: 0.6994
AUC: 0.8562

Epoch 15/80
 - 0s - loss: 1.0499 - val_loss: 0.5959
AUC: 0.8549

Epoch 16/80
 - 0s - loss: 1.0405 - val_loss: 0.6558
AUC: 0.8576

Epoch 17/80
 - 0s - loss: 1.0342 - val_loss: 0.6956
AUC: 0.8562

Epoch 18/80
 - 0s - loss: 1.0316 - val_loss: 0.7156
AUC: 0.8588

Epoch 19/80
 - 0s - loss: 1.0364 - val_loss: 0.6456
AUC: 0.8575

Epoch 20/80
 - 0s - loss: 1.0289 - val_loss: 0.6680
AUC: 0.8585

Epoch 21/80
 - 0s - loss: 1.0213 - val_loss: 0.5898
AUC: 0.8579

Epoch 22/80
 - 0s - loss: 1.0165 - val_loss: 0.6255
AUC: 0.8592

Epoch 23/80
 - 0s - loss: 1.0221 - val_loss: 0.6412
AUC: 0.8604

Epoch 24/80
 - 0s - loss: 1.0093 - val_loss: 0.6106
AUC: 0.8595

Epoch 25/80
 - 0s - loss: 1.0084 - val_loss: 0.6161
AUC: 0.8593

Epoch 26/80
 - 0s - loss: 1.0154 - val_loss: 0.6574
AUC: 0.8611

Epoch 27/80
 - 0s - loss: 1.0070 - val_loss: 0.6520
AUC: 0.8608

Epoch 28/80
 - 0s - loss: 1.0072 - val_loss: 0.6867
AUC: 0.8612

Epoch 29/80
 - 0s - loss: 1.0028 - val_loss: 0.5962
AUC: 0.8612

Epoch 30/80
 - 0s - loss: 1.0024 - val_loss: 0.5415
AUC: 0.8596

Epoch 31/80
 - 0s - loss: 0.9983 - val_loss: 0.6763
AUC: 0.8623

Epoch 32/80
 - 0s - loss: 1.0001 - val_loss: 0.6744
AUC: 0.8621

Epoch 33/80
 - 0s - loss: 0.9924 - val_loss: 0.6676
AUC: 0.8624

Epoch 34/80
 - 0s - loss: 0.9930 - val_loss: 0.6117
AUC: 0.8613

Epoch 35/80
 - 0s - loss: 0.9851 - val_loss: 0.5988
AUC: 0.8617

Epoch 36/80
 - 0s - loss: 0.9852 - val_loss: 0.6126
AUC: 0.8631

Epoch 37/80
 - 0s - loss: 0.9872 - val_loss: 0.6920
AUC: 0.8640

Epoch 38/80
 - 0s - loss: 0.9814 - val_loss: 0.6422
AUC: 0.8637

Epoch 39/80
 - 0s - loss: 0.9742 - val_loss: 0.6482
AUC: 0.8639

Epoch 40/80
 - 0s - loss: 0.9794 - val_loss: 0.5585
AUC: 0.8629

Epoch 41/80
 - 0s - loss: 0.9723 - val_loss: 0.6097
AUC: 0.8636

Epoch 42/80
 - 0s - loss: 0.9718 - val_loss: 0.5947
AUC: 0.8634

Epoch 43/80
 - 0s - loss: 0.9699 - val_loss: 0.5971
AUC: 0.8634

Epoch 44/80
 - 0s - loss: 0.9680 - val_loss: 0.6077
AUC: 0.8637

Epoch 45/80
 - 0s - loss: 0.9691 - val_loss: 0.5995
AUC: 0.8635

Epoch 46/80
 - 0s - loss: 0.9718 - val_loss: 0.6197
AUC: 0.8640

Epoch 47/80
 - 0s - loss: 0.9686 - val_loss: 0.6252
AUC: 0.8641

Epoch 48/80
 - 0s - loss: 0.9637 - val_loss: 0.6188
AUC: 0.8641

Epoch 49/80
 - 0s - loss: 0.9608 - val_loss: 0.5879
AUC: 0.8635

Epoch 50/80
 - 0s - loss: 0.9632 - val_loss: 0.6309
AUC: 0.8641

Epoch 51/80
 - 0s - loss: 0.9632 - val_loss: 0.5984
AUC: 0.8636

Epoch 52/80
 - 0s - loss: 0.9642 - val_loss: 0.6023
AUC: 0.8637

Epoch 53/80
 - 0s - loss: 0.9580 - val_loss: 0.5976
AUC: 0.8636

Epoch 54/80
 - 0s - loss: 0.9677 - val_loss: 0.5969
AUC: 0.8636

Epoch 55/80
 - 0s - loss: 0.9658 - val_loss: 0.5972
AUC: 0.8636

Epoch 56/80
 - 0s - loss: 0.9623 - val_loss: 0.6013
AUC: 0.8637

Epoch 57/80
 - 0s - loss: 0.9653 - val_loss: 0.5990
AUC: 0.8636

Epoch 58/80
 - 0s - loss: 0.9602 - val_loss: 0.6006
AUC: 0.8636

Epoch 59/80
 - 0s - loss: 0.9610 - val_loss: 0.5972
AUC: 0.8636

Epoch 60/80
 - 0s - loss: 0.9623 - val_loss: 0.6067
AUC: 0.8638

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9669 - val_loss: 0.6040
AUC: 0.8639

Epoch 2/30
 - 0s - loss: 0.9668 - val_loss: 0.5960
AUC: 0.8639

Epoch 3/30
 - 0s - loss: 0.9667 - val_loss: 0.6114
AUC: 0.8643

Epoch 4/30
 - 0s - loss: 0.9585 - val_loss: 0.6081
AUC: 0.8642

Epoch 5/30
 - 0s - loss: 0.9590 - val_loss: 0.6175
AUC: 0.8643

Epoch 6/30
 - 0s - loss: 0.9599 - val_loss: 0.6118
AUC: 0.8643

Epoch 7/30
 - 0s - loss: 0.9547 - val_loss: 0.5968
AUC: 0.8642

Epoch 8/30
 - 0s - loss: 0.9577 - val_loss: 0.5960
AUC: 0.8644

Epoch 9/30
 - 0s - loss: 0.9513 - val_loss: 0.5865
AUC: 0.8643

Epoch 10/30
 - 0s - loss: 0.9549 - val_loss: 0.5972
AUC: 0.8646

Epoch 11/30
 - 0s - loss: 0.9549 - val_loss: 0.5991
AUC: 0.8648

Epoch 12/30
 - 0s - loss: 0.9513 - val_loss: 0.6110
AUC: 0.8649

Epoch 13/30
 - 0s - loss: 0.9507 - val_loss: 0.5876
AUC: 0.8649

Epoch 14/30
 - 0s - loss: 0.9504 - val_loss: 0.5881
AUC: 0.8647

Epoch 15/30
 - 0s - loss: 0.9516 - val_loss: 0.5943
AUC: 0.8650

Epoch 16/30
 - 0s - loss: 0.9533 - val_loss: 0.5998
AUC: 0.8652

Epoch 17/30
 - 0s - loss: 0.9458 - val_loss: 0.5951
AUC: 0.8653

Epoch 18/30
 - 0s - loss: 0.9490 - val_loss: 0.5839
AUC: 0.8652

Epoch 19/30
 - 0s - loss: 0.9448 - val_loss: 0.5939
AUC: 0.8654

Epoch 20/30
 - 0s - loss: 0.9494 - val_loss: 0.5768
AUC: 0.8652

Epoch 21/30
 - 0s - loss: 0.9450 - val_loss: 0.5795
AUC: 0.8654

Epoch 22/30
 - 0s - loss: 0.9416 - val_loss: 0.5697
AUC: 0.8653

Epoch 23/30
 - 0s - loss: 0.9364 - val_loss: 0.5932
AUC: 0.8656

Epoch 24/30
 - 0s - loss: 0.9372 - val_loss: 0.5919
AUC: 0.8656

Epoch 25/30
 - 0s - loss: 0.9363 - val_loss: 0.6009
AUC: 0.8659

Epoch 26/30
 - 0s - loss: 0.9388 - val_loss: 0.5939
AUC: 0.8660

Epoch 27/30
 - 0s - loss: 0.9405 - val_loss: 0.6006
AUC: 0.8662

Epoch 28/30
 - 0s - loss: 0.9351 - val_loss: 0.5803
AUC: 0.8661

Epoch 29/30
 - 0s - loss: 0.9361 - val_loss: 0.6042
AUC: 0.8662

Epoch 30/30
 - 0s - loss: 0.9345 - val_loss: 0.6053
Using TensorFlow backend.
AUC: 0.8664

2019-03-08 03:22:03.584840: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:22:03.750413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:22:03.750470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:22:04.046541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:22:04.046590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:22:04.046599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:22:04.046849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3851
Epoch 2/80
 - 2s - loss: 0.3538
Epoch 3/80
 - 2s - loss: 0.3074
Epoch 4/80
 - 2s - loss: 0.2919
Epoch 5/80
 - 2s - loss: 0.2735
Epoch 6/80
 - 2s - loss: 0.2541
Epoch 7/80
 - 2s - loss: 0.2366
Epoch 8/80
 - 2s - loss: 0.2203
Epoch 9/80
 - 2s - loss: 0.2047
Epoch 10/80
 - 2s - loss: 0.1907
Epoch 11/80
 - 2s - loss: 0.1789
Epoch 12/80
 - 2s - loss: 0.1694
Epoch 13/80
 - 2s - loss: 0.1616
Epoch 14/80
 - 2s - loss: 0.1550
Epoch 15/80
 - 2s - loss: 0.1494
Epoch 16/80
 - 2s - loss: 0.1445
Epoch 17/80
 - 2s - loss: 0.1402
Epoch 18/80
 - 2s - loss: 0.1366
Epoch 19/80
 - 2s - loss: 0.1335
Epoch 20/80
 - 2s - loss: 0.1309
Epoch 21/80
 - 2s - loss: 0.1287
Epoch 22/80
 - 2s - loss: 0.1267
Epoch 23/80
 - 2s - loss: 0.1251
Epoch 24/80
 - 2s - loss: 0.1237
Epoch 25/80
 - 2s - loss: 0.1224
Epoch 26/80
 - 2s - loss: 0.1213
Epoch 27/80
 - 2s - loss: 0.1204
Epoch 28/80
 - 2s - loss: 0.1196
Epoch 29/80
 - 2s - loss: 0.1189
Epoch 30/80
 - 2s - loss: 0.1183
Epoch 31/80
 - 2s - loss: 0.1178
Epoch 32/80
 - 2s - loss: 0.1174
Epoch 33/80
 - 2s - loss: 0.1170
Epoch 34/80
 - 2s - loss: 0.1166
Epoch 35/80
 - 2s - loss: 0.1163
Epoch 36/80
 - 2s - loss: 0.1161
Epoch 37/80
 - 2s - loss: 0.1158
Epoch 38/80
 - 2s - loss: 0.1156
Epoch 39/80
 - 2s - loss: 0.1154
Epoch 40/80
 - 2s - loss: 0.1152
Epoch 41/80
 - 2s - loss: 0.1151
Epoch 42/80
 - 2s - loss: 0.1150
Epoch 43/80
 - 2s - loss: 0.1148
Epoch 44/80
 - 2s - loss: 0.1147
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:23:35.982723: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:23:36.149413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:23:36.149457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:23:36.442918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:23:36.442963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:23:36.442972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:23:36.443234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3643
Epoch 2/80
 - 2s - loss: 0.3500
Epoch 3/80
 - 2s - loss: 0.3024
Epoch 4/80
 - 2s - loss: 0.2832
Epoch 5/80
 - 2s - loss: 0.2632
Epoch 6/80
 - 2s - loss: 0.2448
Epoch 7/80
 - 2s - loss: 0.2284
Epoch 8/80
 - 2s - loss: 0.2135
Epoch 9/80
 - 2s - loss: 0.2008
Epoch 10/80
 - 2s - loss: 0.1899
Epoch 11/80
 - 2s - loss: 0.1806
Epoch 12/80
 - 2s - loss: 0.1725
Epoch 13/80
 - 2s - loss: 0.1654
Epoch 14/80
 - 2s - loss: 0.1592
Epoch 15/80
 - 2s - loss: 0.1534
Epoch 16/80
 - 2s - loss: 0.1481
Epoch 17/80
 - 2s - loss: 0.1433
Epoch 18/80
 - 2s - loss: 0.1392
Epoch 19/80
 - 2s - loss: 0.1357
Epoch 20/80
 - 2s - loss: 0.1328
Epoch 21/80
 - 2s - loss: 0.1304
Epoch 22/80
 - 2s - loss: 0.1283
Epoch 23/80
 - 2s - loss: 0.1266
Epoch 24/80
 - 2s - loss: 0.1251
Epoch 25/80
 - 2s - loss: 0.1239
Epoch 26/80
 - 2s - loss: 0.1228
Epoch 27/80
 - 2s - loss: 0.1219
Epoch 28/80
 - 2s - loss: 0.1210
Epoch 29/80
 - 2s - loss: 0.1203
Epoch 30/80
 - 2s - loss: 0.1198
Epoch 31/80
 - 2s - loss: 0.1192
Epoch 32/80
 - 2s - loss: 0.1187
Epoch 33/80
 - 2s - loss: 0.1183
Epoch 34/80
 - 2s - loss: 0.1180
Epoch 35/80
 - 2s - loss: 0.1177
Epoch 36/80
 - 2s - loss: 0.1174
Epoch 37/80
 - 2s - loss: 0.1171
Epoch 38/80
 - 2s - loss: 0.1169
Epoch 39/80
 - 2s - loss: 0.1167
Epoch 40/80
 - 2s - loss: 0.1165
Epoch 41/80
 - 2s - loss: 0.1163
Epoch 42/80
 - 2s - loss: 0.1161
Epoch 43/80
 - 2s - loss: 0.1160
Epoch 44/80
 - 2s - loss: 0.1159
Epoch 45/80
 - 2s - loss: 0.1157
Epoch 46/80
 - 2s - loss: 0.1156
Epoch 47/80
 - 2s - loss: 0.1155
Epoch 48/80
 - 2s - loss: 0.1154
Epoch 49/80
 - 2s - loss: 0.1153
Epoch 50/80
 - 2s - loss: 0.1152
Epoch 51/80
 - 2s - loss: 0.1152
Epoch 52/80
 - 2s - loss: 0.1151
Epoch 53/80
 - 2s - loss: 0.1150
Epoch 54/80
 - 2s - loss: 0.1150
Epoch 55/80
 - 2s - loss: 0.1149
Epoch 56/80
 - 2s - loss: 0.1148
Epoch 57/80
 - 2s - loss: 0.1148
Epoch 58/80
 - 2s - loss: 0.1147
Epoch 59/80
 - 2s - loss: 0.1147
Epoch 60/80
 - 2s - loss: 0.1147
Epoch 61/80
 - 2s - loss: 0.1124
Epoch 62/80
 - 2s - loss: 0.1121
Epoch 63/80
 - 2s - loss: 0.1121
Epoch 64/80
 - 2s - loss: 0.1121
Epoch 65/80
 - 2s - loss: 0.1121
Epoch 66/80
 - 2s - loss: 0.1115
Epoch 67/80
 - 2s - loss: 0.1115
Epoch 68/80
 - 2s - loss: 0.1115
Epoch 69/80
 - 2s - loss: 0.1115
Epoch 70/80
 - 2s - loss: 0.1114
Epoch 71/80
 - 2s - loss: 0.1114
Epoch 72/80
 - 2s - loss: 0.1114
Epoch 73/80
 - 2s - loss: 0.1114
Epoch 74/80
 - 2s - loss: 0.1113
Epoch 75/80
 - 2s - loss: 0.1113
Epoch 76/80
 - 2s - loss: 0.1113
Epoch 77/80
 - 2s - loss: 0.1113
Epoch 78/80
 - 2s - loss: 0.1113
Epoch 79/80
 - 2s - loss: 0.1113
Epoch 80/80
 - 2s - loss: 0.1113
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.3449 - val_loss: 1.1366
AUC: 0.8031

Epoch 2/80
 - 0s - loss: 1.8054 - val_loss: 0.7401
AUC: 0.8349

Epoch 3/80
 - 0s - loss: 1.3510 - val_loss: 0.6986
AUC: 0.8467

Epoch 4/80
 - 0s - loss: 1.1927 - val_loss: 0.7177
AUC: 0.8560

Epoch 5/80
 - 0s - loss: 1.1457 - val_loss: 0.6387
AUC: 0.8564

Epoch 6/80
 - 0s - loss: 1.1141 - val_loss: 0.5884
AUC: 0.8578

Epoch 7/80
 - 0s - loss: 1.0928 - val_loss: 0.6320
AUC: 0.8603

Epoch 8/80
 - 0s - loss: 1.0787 - val_loss: 0.6224
AUC: 0.8615

Epoch 9/80
 - 0s - loss: 1.0660 - val_loss: 0.5844
AUC: 0.8598

Epoch 10/80
 - 0s - loss: 1.0613 - val_loss: 0.6662
AUC: 0.8627

Epoch 11/80
 - 0s - loss: 1.0473 - val_loss: 0.6194
AUC: 0.8635

Epoch 12/80
 - 0s - loss: 1.0485 - val_loss: 0.6075
AUC: 0.8641

Epoch 13/80
 - 0s - loss: 1.0381 - val_loss: 0.6286
AUC: 0.8641

Epoch 14/80
 - 0s - loss: 1.0382 - val_loss: 0.6345
AUC: 0.8665

Epoch 15/80
 - 0s - loss: 1.0378 - val_loss: 0.6311
AUC: 0.8659

Epoch 16/80
 - 0s - loss: 1.0283 - val_loss: 0.6192
AUC: 0.8654

Epoch 17/80
 - 0s - loss: 1.0265 - val_loss: 0.5742
AUC: 0.8664

Epoch 18/80
 - 0s - loss: 1.0170 - val_loss: 0.6461
AUC: 0.8661

Epoch 19/80
 - 0s - loss: 1.0172 - val_loss: 0.6013
AUC: 0.8673

Epoch 20/80
 - 0s - loss: 1.0139 - val_loss: 0.6840
AUC: 0.8680

Epoch 21/80
 - 0s - loss: 1.0074 - val_loss: 0.6126
AUC: 0.8680

Epoch 22/80
 - 0s - loss: 1.0062 - val_loss: 0.5820
AUC: 0.8684

Epoch 23/80
 - 0s - loss: 1.0054 - val_loss: 0.6497
AUC: 0.8685

Epoch 24/80
 - 0s - loss: 0.9997 - val_loss: 0.5606
AUC: 0.8680

Epoch 25/80
 - 0s - loss: 0.9964 - val_loss: 0.6658
AUC: 0.8694

Epoch 26/80
 - 0s - loss: 0.9993 - val_loss: 0.6175
AUC: 0.8689

Epoch 27/80
 - 0s - loss: 0.9973 - val_loss: 0.6362
AUC: 0.8682

Epoch 28/80
 - 0s - loss: 0.9874 - val_loss: 0.5733
AUC: 0.8689

Epoch 29/80
 - 0s - loss: 0.9852 - val_loss: 0.6134
AUC: 0.8693

Epoch 30/80
 - 0s - loss: 0.9880 - val_loss: 0.6274
AUC: 0.8690

Epoch 31/80
 - 0s - loss: 0.9861 - val_loss: 0.6011
AUC: 0.8697

Epoch 32/80
 - 0s - loss: 0.9813 - val_loss: 0.5878
AUC: 0.8703

Epoch 33/80
 - 0s - loss: 0.9802 - val_loss: 0.7211
AUC: 0.8698

Epoch 34/80
 - 0s - loss: 0.9808 - val_loss: 0.5951
AUC: 0.8700

Epoch 35/80
 - 0s - loss: 0.9665 - val_loss: 0.6014
AUC: 0.8702

Epoch 36/80
 - 0s - loss: 0.9636 - val_loss: 0.6147
AUC: 0.8707

Epoch 37/80
 - 0s - loss: 0.9750 - val_loss: 0.5719
AUC: 0.8704

Epoch 38/80
 - 0s - loss: 0.9713 - val_loss: 0.6030
AUC: 0.8710

Epoch 39/80
 - 0s - loss: 0.9593 - val_loss: 0.5811
AUC: 0.8706

Epoch 40/80
 - 0s - loss: 0.9686 - val_loss: 0.5772
AUC: 0.8702

Epoch 41/80
 - 0s - loss: 0.9619 - val_loss: 0.5782
AUC: 0.8706

Epoch 42/80
 - 0s - loss: 0.9613 - val_loss: 0.5883
AUC: 0.8707

Epoch 43/80
 - 0s - loss: 0.9597 - val_loss: 0.5894
AUC: 0.8709

Epoch 44/80
 - 0s - loss: 0.9638 - val_loss: 0.5992
AUC: 0.8710

Epoch 45/80
 - 0s - loss: 0.9596 - val_loss: 0.5862
AUC: 0.8709

Epoch 46/80
 - 0s - loss: 0.9586 - val_loss: 0.5839
AUC: 0.8708

Epoch 47/80
 - 0s - loss: 0.9605 - val_loss: 0.5886
AUC: 0.8709

Epoch 48/80
 - 0s - loss: 0.9563 - val_loss: 0.5987
AUC: 0.8710

Epoch 49/80
 - 0s - loss: 0.9526 - val_loss: 0.5743
AUC: 0.8707

Epoch 50/80
 - 0s - loss: 0.9602 - val_loss: 0.5902
AUC: 0.8708

Epoch 51/80
 - 0s - loss: 0.9623 - val_loss: 0.5863
AUC: 0.8709

Epoch 52/80
 - 0s - loss: 0.9590 - val_loss: 0.5894
AUC: 0.8708

Epoch 53/80
 - 0s - loss: 0.9613 - val_loss: 0.5867
AUC: 0.8709

Epoch 54/80
 - 0s - loss: 0.9561 - val_loss: 0.5831
AUC: 0.8709

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9582 - val_loss: 0.5784
AUC: 0.8709

Epoch 2/30
 - 0s - loss: 0.9579 - val_loss: 0.6228
AUC: 0.8715

Epoch 3/30
 - 0s - loss: 0.9591 - val_loss: 0.5913
AUC: 0.8712

Epoch 4/30
 - 0s - loss: 0.9545 - val_loss: 0.5887
AUC: 0.8712

Epoch 5/30
 - 0s - loss: 0.9544 - val_loss: 0.5779
AUC: 0.8712

Epoch 6/30
 - 0s - loss: 0.9530 - val_loss: 0.5692
AUC: 0.8712

Epoch 7/30
 - 0s - loss: 0.9509 - val_loss: 0.6016
AUC: 0.8718

Epoch 8/30
 - 0s - loss: 0.9534 - val_loss: 0.5595
AUC: 0.8714

Epoch 9/30
 - 0s - loss: 0.9512 - val_loss: 0.5924
AUC: 0.8719

Epoch 10/30
 - 0s - loss: 0.9456 - val_loss: 0.5767
AUC: 0.8718

Epoch 11/30
 - 0s - loss: 0.9466 - val_loss: 0.5798
AUC: 0.8718

Epoch 12/30
 - 0s - loss: 0.9465 - val_loss: 0.5833
AUC: 0.8718

Epoch 13/30
 - 0s - loss: 0.9514 - val_loss: 0.5674
AUC: 0.8716

Epoch 14/30
 - 0s - loss: 0.9439 - val_loss: 0.5770
AUC: 0.8720

Epoch 15/30
 - 0s - loss: 0.9443 - val_loss: 0.5846
AUC: 0.8722

Epoch 16/30
 - 0s - loss: 0.9389 - val_loss: 0.5673
AUC: 0.8721

Epoch 17/30
 - 0s - loss: 0.9433 - val_loss: 0.5873
AUC: 0.8723

Epoch 18/30
 - 0s - loss: 0.9373 - val_loss: 0.5765
AUC: 0.8723

Epoch 19/30
 - 0s - loss: 0.9348 - val_loss: 0.5780
AUC: 0.8724

Epoch 20/30
 - 0s - loss: 0.9366 - val_loss: 0.5773
AUC: 0.8724

Epoch 21/30
 - 0s - loss: 0.9361 - val_loss: 0.5727
AUC: 0.8723

Epoch 22/30
 - 0s - loss: 0.9331 - val_loss: 0.5805
AUC: 0.8724

Epoch 23/30
 - 0s - loss: 0.9342 - val_loss: 0.5780
AUC: 0.8724

Epoch 24/30
 - 0s - loss: 0.9379 - val_loss: 0.5775
AUC: 0.8724

Epoch 25/30
 - 0s - loss: 0.9384 - val_loss: 0.5771
AUC: 0.8724

Epoch 26/30
 - 0s - loss: 0.9332 - val_loss: 0.5803
AUC: 0.8725

Epoch 27/30
 - 0s - loss: 0.9351 - val_loss: 0.5717
AUC: 0.8724

Epoch 28/30
 - 0s - loss: 0.9347 - val_loss: 0.5751
AUC: 0.8724

Epoch 29/30
 - 0s - loss: 0.9378 - val_loss: 0.5770
AUC: 0.8725

Epoch 30/30
 - 0s - loss: 0.9327 - val_loss: 0.5767
Using TensorFlow backend.
AUC: 0.8725

2019-03-08 03:26:57.928000: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:26:58.094556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:26:58.094599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:26:58.389822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:26:58.389874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:26:58.389884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:26:58.390213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3533
Epoch 2/80
 - 2s - loss: 0.3510
Epoch 3/80
 - 2s - loss: 0.3061
Epoch 4/80
 - 2s - loss: 0.2889
Epoch 5/80
 - 2s - loss: 0.2661
Epoch 6/80
 - 2s - loss: 0.2432
Epoch 7/80
 - 2s - loss: 0.2256
Epoch 8/80
 - 2s - loss: 0.2120
Epoch 9/80
 - 2s - loss: 0.2005
Epoch 10/80
 - 2s - loss: 0.1903
Epoch 11/80
 - 2s - loss: 0.1810
Epoch 12/80
 - 2s - loss: 0.1723
Epoch 13/80
 - 2s - loss: 0.1645
Epoch 14/80
 - 2s - loss: 0.1576
Epoch 15/80
 - 2s - loss: 0.1513
Epoch 16/80
 - 2s - loss: 0.1458
Epoch 17/80
 - 2s - loss: 0.1412
Epoch 18/80
 - 2s - loss: 0.1374
Epoch 19/80
 - 2s - loss: 0.1342
Epoch 20/80
 - 2s - loss: 0.1315
Epoch 21/80
 - 2s - loss: 0.1293
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:27:50.105385: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:27:50.270043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:27:50.270089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:27:50.566826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:27:50.566879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:27:50.566887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:27:50.567141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3781
Epoch 2/80
 - 2s - loss: 0.3519
Epoch 3/80
 - 2s - loss: 0.3070
Epoch 4/80
 - 2s - loss: 0.2915
Epoch 5/80
 - 2s - loss: 0.2736
Epoch 6/80
 - 2s - loss: 0.2549
Epoch 7/80
 - 2s - loss: 0.2362
Epoch 8/80
 - 2s - loss: 0.2189
Epoch 9/80
 - 2s - loss: 0.2039
Epoch 10/80
 - 2s - loss: 0.1917
Epoch 11/80
 - 2s - loss: 0.1810
Epoch 12/80
 - 2s - loss: 0.1718
Epoch 13/80
 - 2s - loss: 0.1636
Epoch 14/80
 - 2s - loss: 0.1565
Epoch 15/80
 - 2s - loss: 0.1504
Epoch 16/80
 - 2s - loss: 0.1452
Epoch 17/80
 - 2s - loss: 0.1408
Epoch 18/80
 - 2s - loss: 0.1371
Epoch 19/80
 - 2s - loss: 0.1340
Epoch 20/80
 - 2s - loss: 0.1315
Epoch 21/80
 - 2s - loss: 0.1292
Epoch 22/80
 - 2s - loss: 0.1274
Epoch 23/80
 - 2s - loss: 0.1258
Epoch 24/80
 - 2s - loss: 0.1245
Epoch 25/80
 - 2s - loss: 0.1233
Epoch 26/80
 - 2s - loss: 0.1223
Epoch 27/80
 - 2s - loss: 0.1215
Epoch 28/80
 - 2s - loss: 0.1208
Epoch 29/80
 - 2s - loss: 0.1201
Epoch 30/80
 - 2s - loss: 0.1196
Epoch 31/80
 - 2s - loss: 0.1191
Epoch 32/80
 - 2s - loss: 0.1187
Epoch 33/80
 - 2s - loss: 0.1183
Epoch 34/80
 - 2s - loss: 0.1180
Epoch 35/80
 - 2s - loss: 0.1177
Epoch 36/80
 - 2s - loss: 0.1174
Epoch 37/80
 - 2s - loss: 0.1172
Epoch 38/80
 - 2s - loss: 0.1169
Epoch 39/80
 - 2s - loss: 0.1167
Epoch 40/80
 - 2s - loss: 0.1166
Epoch 41/80
 - 2s - loss: 0.1164
Epoch 42/80
 - 2s - loss: 0.1162
Epoch 43/80
 - 2s - loss: 0.1161
Epoch 44/80
 - 2s - loss: 0.1160
Epoch 45/80
 - 2s - loss: 0.1158
Epoch 46/80
 - 2s - loss: 0.1157
Epoch 47/80
 - 2s - loss: 0.1156
Epoch 48/80
 - 2s - loss: 0.1155
Epoch 49/80
 - 2s - loss: 0.1155
Epoch 50/80
 - 2s - loss: 0.1153
Epoch 51/80
 - 2s - loss: 0.1153
Epoch 52/80
 - 2s - loss: 0.1152
Epoch 53/80
 - 2s - loss: 0.1151
Epoch 54/80
 - 2s - loss: 0.1151
Epoch 55/80
 - 2s - loss: 0.1150
Epoch 56/80
 - 2s - loss: 0.1149
Epoch 57/80
 - 2s - loss: 0.1149
Epoch 58/80
 - 2s - loss: 0.1149
Epoch 59/80
 - 2s - loss: 0.1148
Epoch 60/80
 - 2s - loss: 0.1148
Epoch 61/80
 - 2s - loss: 0.1147
Epoch 62/80
 - 2s - loss: 0.1147
Epoch 63/80
 - 2s - loss: 0.1146
Epoch 64/80
 - 2s - loss: 0.1146
Epoch 65/80
 - 2s - loss: 0.1124
Epoch 66/80
 - 2s - loss: 0.1121
Epoch 67/80
 - 2s - loss: 0.1121
Epoch 68/80
 - 2s - loss: 0.1121
Epoch 69/80
 - 2s - loss: 0.1121
Epoch 70/80
 - 2s - loss: 0.1115
Epoch 71/80
 - 2s - loss: 0.1115
Epoch 72/80
 - 2s - loss: 0.1115
Epoch 73/80
 - 2s - loss: 0.1115
Epoch 74/80
 - 2s - loss: 0.1114
Epoch 75/80
 - 2s - loss: 0.1114
Epoch 76/80
 - 2s - loss: 0.1114
Epoch 77/80
 - 2s - loss: 0.1114
Epoch 78/80
 - 2s - loss: 0.1113
Epoch 79/80
 - 2s - loss: 0.1113
Epoch 80/80
 - 2s - loss: 0.1113
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0870 - val_loss: 1.0135
AUC: 0.7929

Epoch 2/80
 - 0s - loss: 1.7531 - val_loss: 0.9175
AUC: 0.8250

Epoch 3/80
 - 0s - loss: 1.3336 - val_loss: 0.7864
AUC: 0.8384

Epoch 4/80
 - 0s - loss: 1.2002 - val_loss: 0.7721
AUC: 0.8439

Epoch 5/80
 - 0s - loss: 1.1465 - val_loss: 0.7311
AUC: 0.8484

Epoch 6/80
 - 0s - loss: 1.1145 - val_loss: 0.6842
AUC: 0.8514

Epoch 7/80
 - 0s - loss: 1.1028 - val_loss: 0.6389
AUC: 0.8528

Epoch 8/80
 - 0s - loss: 1.0781 - val_loss: 0.6749
AUC: 0.8558

Epoch 9/80
 - 0s - loss: 1.0590 - val_loss: 0.6046
AUC: 0.8562

Epoch 10/80
 - 0s - loss: 1.0641 - val_loss: 0.6479
AUC: 0.8597

Epoch 11/80
 - 0s - loss: 1.0428 - val_loss: 0.6120
AUC: 0.8606

Epoch 12/80
 - 0s - loss: 1.0433 - val_loss: 0.6147
AUC: 0.8618

Epoch 13/80
 - 0s - loss: 1.0419 - val_loss: 0.6869
AUC: 0.8625

Epoch 14/80
 - 0s - loss: 1.0292 - val_loss: 0.6546
AUC: 0.8625

Epoch 15/80
 - 0s - loss: 1.0272 - val_loss: 0.5976
AUC: 0.8627

Epoch 16/80
 - 0s - loss: 1.0240 - val_loss: 0.6600
AUC: 0.8649

Epoch 17/80
 - 0s - loss: 1.0196 - val_loss: 0.6102
AUC: 0.8644

Epoch 18/80
 - 0s - loss: 1.0198 - val_loss: 0.6295
AUC: 0.8650

Epoch 19/80
 - 0s - loss: 1.0131 - val_loss: 0.6816
AUC: 0.8664

Epoch 20/80
 - 0s - loss: 1.0105 - val_loss: 0.6010
AUC: 0.8657

Epoch 21/80
 - 0s - loss: 1.0088 - val_loss: 0.6358
AUC: 0.8654

Epoch 22/80
 - 0s - loss: 0.9993 - val_loss: 0.6151
AUC: 0.8645

Epoch 23/80
 - 0s - loss: 0.9976 - val_loss: 0.5343
AUC: 0.8657

Epoch 24/80
 - 0s - loss: 0.9985 - val_loss: 0.5870
AUC: 0.8660

Epoch 25/80
 - 0s - loss: 0.9963 - val_loss: 0.5955
AUC: 0.8663

Epoch 26/80
 - 0s - loss: 0.9930 - val_loss: 0.6678
AUC: 0.8670

Epoch 27/80
 - 0s - loss: 0.9888 - val_loss: 0.5934
AUC: 0.8669

Epoch 28/80
 - 0s - loss: 0.9845 - val_loss: 0.6281
AUC: 0.8674

Epoch 29/80
 - 0s - loss: 0.9827 - val_loss: 0.6286
AUC: 0.8675

Epoch 30/80
 - 0s - loss: 0.9893 - val_loss: 0.6329
AUC: 0.8682

Epoch 31/80
 - 0s - loss: 0.9822 - val_loss: 0.5846
AUC: 0.8671

Epoch 32/80
 - 0s - loss: 0.9811 - val_loss: 0.5762
AUC: 0.8674

Epoch 33/80
 - 0s - loss: 0.9735 - val_loss: 0.5824
AUC: 0.8681

Epoch 34/80
 - 0s - loss: 0.9681 - val_loss: 0.6077
AUC: 0.8686

Epoch 35/80
 - 0s - loss: 0.9645 - val_loss: 0.6137
AUC: 0.8690

Epoch 36/80
 - 0s - loss: 0.9642 - val_loss: 0.6067
AUC: 0.8688

Epoch 37/80
 - 0s - loss: 0.9610 - val_loss: 0.5731
AUC: 0.8683

Epoch 38/80
 - 0s - loss: 0.9629 - val_loss: 0.6095
AUC: 0.8688

Epoch 39/80
 - 0s - loss: 0.9564 - val_loss: 0.5735
AUC: 0.8686

Epoch 40/80
 - 0s - loss: 0.9622 - val_loss: 0.6315
AUC: 0.8690

Epoch 41/80
 - 0s - loss: 0.9610 - val_loss: 0.5764
AUC: 0.8690

Epoch 42/80
 - 0s - loss: 0.9621 - val_loss: 0.6043
AUC: 0.8688

Epoch 43/80
 - 0s - loss: 0.9580 - val_loss: 0.5838
AUC: 0.8688

Epoch 44/80
 - 0s - loss: 0.9582 - val_loss: 0.5979
AUC: 0.8690

Epoch 45/80
 - 0s - loss: 0.9553 - val_loss: 0.5976
AUC: 0.8691

Epoch 46/80
 - 0s - loss: 0.9598 - val_loss: 0.5987
AUC: 0.8691

Epoch 47/80
 - 0s - loss: 0.9548 - val_loss: 0.6027
AUC: 0.8691

Epoch 48/80
 - 0s - loss: 0.9606 - val_loss: 0.6042
AUC: 0.8692

Epoch 49/80
 - 0s - loss: 0.9543 - val_loss: 0.5954
AUC: 0.8692

Epoch 50/80
 - 0s - loss: 0.9559 - val_loss: 0.5929
AUC: 0.8690

Epoch 51/80
 - 0s - loss: 0.9542 - val_loss: 0.5992
AUC: 0.8691

Epoch 52/80
 - 0s - loss: 0.9592 - val_loss: 0.6013
AUC: 0.8692

Epoch 53/80
 - 0s - loss: 0.9566 - val_loss: 0.5929
AUC: 0.8692

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9548 - val_loss: 0.5964
AUC: 0.8692

Epoch 2/30
 - 0s - loss: 0.9563 - val_loss: 0.6065
AUC: 0.8694

Epoch 3/30
 - 0s - loss: 0.9516 - val_loss: 0.5964
AUC: 0.8693

Epoch 4/30
 - 0s - loss: 0.9510 - val_loss: 0.6084
AUC: 0.8696

Epoch 5/30
 - 0s - loss: 0.9544 - val_loss: 0.5855
AUC: 0.8695

Epoch 6/30
 - 0s - loss: 0.9542 - val_loss: 0.5872
AUC: 0.8696

Epoch 7/30
 - 0s - loss: 0.9497 - val_loss: 0.5797
AUC: 0.8694

Epoch 8/30
 - 0s - loss: 0.9496 - val_loss: 0.5861
AUC: 0.8696

Epoch 9/30
 - 0s - loss: 0.9459 - val_loss: 0.5980
AUC: 0.8698

Epoch 10/30
 - 0s - loss: 0.9454 - val_loss: 0.5889
AUC: 0.8698

Epoch 11/30
 - 0s - loss: 0.9472 - val_loss: 0.6078
AUC: 0.8701

Epoch 12/30
 - 0s - loss: 0.9446 - val_loss: 0.6170
AUC: 0.8699

Epoch 13/30
 - 0s - loss: 0.9424 - val_loss: 0.6088
AUC: 0.8700

Epoch 14/30
 - 0s - loss: 0.9417 - val_loss: 0.6032
AUC: 0.8702

Epoch 15/30
 - 0s - loss: 0.9439 - val_loss: 0.5806
AUC: 0.8701

Epoch 16/30
 - 0s - loss: 0.9393 - val_loss: 0.5747
AUC: 0.8701

Epoch 17/30
 - 0s - loss: 0.9428 - val_loss: 0.5998
AUC: 0.8704

Epoch 18/30
 - 0s - loss: 0.9383 - val_loss: 0.6018
AUC: 0.8704

Epoch 19/30
 - 0s - loss: 0.9395 - val_loss: 0.5879
AUC: 0.8705

Epoch 20/30
 - 0s - loss: 0.9359 - val_loss: 0.6141
AUC: 0.8705

Epoch 21/30
 - 0s - loss: 0.9307 - val_loss: 0.5928
AUC: 0.8704

Epoch 22/30
 - 0s - loss: 0.9318 - val_loss: 0.5995
AUC: 0.8706

Epoch 23/30
 - 0s - loss: 0.9319 - val_loss: 0.5845
AUC: 0.8705

Epoch 24/30
 - 0s - loss: 0.9289 - val_loss: 0.5802
AUC: 0.8706

Epoch 25/30
 - 0s - loss: 0.9308 - val_loss: 0.5898
AUC: 0.8706

Epoch 26/30
 - 0s - loss: 0.9275 - val_loss: 0.5927
AUC: 0.8706

Epoch 27/30
 - 0s - loss: 0.9307 - val_loss: 0.5898
AUC: 0.8706

Epoch 28/30
 - 0s - loss: 0.9248 - val_loss: 0.5903
AUC: 0.8707

Epoch 29/30
 - 0s - loss: 0.9228 - val_loss: 0.5874
AUC: 0.8707

Epoch 30/30
 - 0s - loss: 0.9274 - val_loss: 0.5870
Using TensorFlow backend.
AUC: 0.8707

2019-03-08 03:31:16.540513: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:31:16.705271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:31:16.705316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:31:16.994754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:31:16.994808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:31:16.994818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:31:16.995106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1339
Epoch 2/80
 - 2s - loss: 0.2137
Epoch 3/80
 - 2s - loss: 0.1741
Epoch 4/80
 - 2s - loss: 0.1687
Epoch 5/80
 - 2s - loss: 0.1644
Epoch 6/80
 - 2s - loss: 0.1587
Epoch 7/80
 - 2s - loss: 0.1505
Epoch 8/80
 - 2s - loss: 0.1391
Epoch 9/80
 - 2s - loss: 0.1265
Epoch 10/80
 - 2s - loss: 0.1154
Epoch 11/80
 - 2s - loss: 0.1059
Epoch 12/80
 - 2s - loss: 0.0976
Epoch 13/80
 - 2s - loss: 0.0905
Epoch 14/80
 - 2s - loss: 0.0845
Epoch 15/80
 - 2s - loss: 0.0793
Epoch 16/80
 - 2s - loss: 0.0749
Epoch 17/80
 - 2s - loss: 0.0712
Epoch 18/80
 - 2s - loss: 0.0681
Epoch 19/80
 - 2s - loss: 0.0655
Epoch 20/80
 - 2s - loss: 0.0634
Epoch 21/80
 - 2s - loss: 0.0616
Epoch 22/80
 - 2s - loss: 0.0601
Epoch 23/80
 - 2s - loss: 0.0588
Epoch 24/80
 - 2s - loss: 0.0577
Epoch 25/80
 - 2s - loss: 0.0567
Epoch 26/80
 - 2s - loss: 0.0559
Epoch 27/80
 - 2s - loss: 0.0552
Epoch 28/80
 - 2s - loss: 0.0546
Epoch 29/80
 - 2s - loss: 0.0541
Epoch 30/80
 - 2s - loss: 0.0537
Epoch 31/80
 - 2s - loss: 0.0533
Epoch 32/80
 - 2s - loss: 0.0529
Epoch 33/80
 - 2s - loss: 0.0526
Epoch 34/80
 - 2s - loss: 0.0524
Epoch 35/80
 - 2s - loss: 0.0521
Epoch 36/80
 - 2s - loss: 0.0519
Epoch 37/80
 - 2s - loss: 0.0517
Epoch 38/80
 - 2s - loss: 0.0516
Epoch 39/80
 - 2s - loss: 0.0514
Epoch 40/80
 - 2s - loss: 0.0513
Epoch 41/80
 - 2s - loss: 0.0512
Epoch 42/80
 - 2s - loss: 0.0511
Epoch 43/80
 - 2s - loss: 0.0510
Epoch 44/80
 - 2s - loss: 0.0509
Epoch 45/80
 - 2s - loss: 0.0508
Epoch 46/80
 - 2s - loss: 0.0507
Epoch 47/80
 - 2s - loss: 0.0506
Epoch 48/80
 - 2s - loss: 0.0506
Epoch 49/80
 - 2s - loss: 0.0505
Epoch 50/80
 - 2s - loss: 0.0504
Epoch 51/80
 - 2s - loss: 0.0504
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0503
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0502
Epoch 56/80
 - 2s - loss: 0.0502
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0501
Epoch 59/80
 - 2s - loss: 0.0501
Epoch 60/80
 - 2s - loss: 0.0490
Epoch 61/80
 - 2s - loss: 0.0489
Epoch 62/80
 - 2s - loss: 0.0488
Epoch 63/80
 - 2s - loss: 0.0488
Epoch 64/80
 - 2s - loss: 0.0488
Epoch 65/80
 - 2s - loss: 0.0485
Epoch 66/80
 - 2s - loss: 0.0485
Epoch 67/80
 - 2s - loss: 0.0485
Epoch 68/80
 - 2s - loss: 0.0485
Epoch 69/80
 - 2s - loss: 0.0485
Epoch 70/80
 - 2s - loss: 0.0485
Epoch 71/80
 - 2s - loss: 0.0485
Epoch 72/80
 - 2s - loss: 0.0484
Epoch 73/80
 - 2s - loss: 0.0484
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:33:33.258795: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:33:33.423805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:33:33.423935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:33:33.714568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:33:33.714616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:33:33.714625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:33:33.714876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1615
Epoch 2/80
 - 2s - loss: 0.2192
Epoch 3/80
 - 2s - loss: 0.1723
Epoch 4/80
 - 2s - loss: 0.1626
Epoch 5/80
 - 2s - loss: 0.1526
Epoch 6/80
 - 2s - loss: 0.1416
Epoch 7/80
 - 2s - loss: 0.1311
Epoch 8/80
 - 2s - loss: 0.1223
Epoch 9/80
 - 2s - loss: 0.1146
Epoch 10/80
 - 2s - loss: 0.1076
Epoch 11/80
 - 2s - loss: 0.1009
Epoch 12/80
 - 2s - loss: 0.0947
Epoch 13/80
 - 2s - loss: 0.0888
Epoch 14/80
 - 2s - loss: 0.0834
Epoch 15/80
 - 2s - loss: 0.0788
Epoch 16/80
 - 2s - loss: 0.0748
Epoch 17/80
 - 2s - loss: 0.0714
Epoch 18/80
 - 2s - loss: 0.0686
Epoch 19/80
 - 2s - loss: 0.0661
Epoch 20/80
 - 2s - loss: 0.0640
Epoch 21/80
 - 2s - loss: 0.0622
Epoch 22/80
 - 2s - loss: 0.0607
Epoch 23/80
 - 2s - loss: 0.0595
Epoch 24/80
 - 2s - loss: 0.0584
Epoch 25/80
 - 2s - loss: 0.0575
Epoch 26/80
 - 2s - loss: 0.0567
Epoch 27/80
 - 2s - loss: 0.0560
Epoch 28/80
 - 2s - loss: 0.0554
Epoch 29/80
 - 2s - loss: 0.0549
Epoch 30/80
 - 2s - loss: 0.0545
Epoch 31/80
 - 2s - loss: 0.0541
Epoch 32/80
 - 2s - loss: 0.0538
Epoch 33/80
 - 2s - loss: 0.0535
Epoch 34/80
 - 2s - loss: 0.0532
Epoch 35/80
 - 2s - loss: 0.0529
Epoch 36/80
 - 2s - loss: 0.0527
Epoch 37/80
 - 2s - loss: 0.0525
Epoch 38/80
 - 2s - loss: 0.0524
Epoch 39/80
 - 2s - loss: 0.0522
Epoch 40/80
 - 2s - loss: 0.0521
Epoch 41/80
 - 2s - loss: 0.0519
Epoch 42/80
 - 2s - loss: 0.0518
Epoch 43/80
 - 2s - loss: 0.0517
Epoch 44/80
 - 2s - loss: 0.0516
Epoch 45/80
 - 2s - loss: 0.0515
Epoch 46/80
 - 2s - loss: 0.0515
Epoch 47/80
 - 2s - loss: 0.0514
Epoch 48/80
 - 2s - loss: 0.0513
Epoch 49/80
 - 2s - loss: 0.0512
Epoch 50/80
 - 2s - loss: 0.0512
Epoch 51/80
 - 2s - loss: 0.0511
Epoch 52/80
 - 2s - loss: 0.0510
Epoch 53/80
 - 2s - loss: 0.0510
Epoch 54/80
 - 2s - loss: 0.0509
Epoch 55/80
 - 2s - loss: 0.0509
Epoch 56/80
 - 2s - loss: 0.0509
Epoch 57/80
 - 2s - loss: 0.0508
Epoch 58/80
 - 2s - loss: 0.0508
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:35:27.654913: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:35:27.819508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:35:27.819551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:35:28.113570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:35:28.113615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:35:28.113624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:35:28.113880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1592
Epoch 2/80
 - 2s - loss: 0.2162
Epoch 3/80
 - 2s - loss: 0.1706
Epoch 4/80
 - 2s - loss: 0.1614
Epoch 5/80
 - 2s - loss: 0.1535
Epoch 6/80
 - 2s - loss: 0.1450
Epoch 7/80
 - 2s - loss: 0.1359
Epoch 8/80
 - 2s - loss: 0.1262
Epoch 9/80
 - 2s - loss: 0.1165
Epoch 10/80
 - 2s - loss: 0.1076
Epoch 11/80
 - 2s - loss: 0.0995
Epoch 12/80
 - 2s - loss: 0.0923
Epoch 13/80
 - 2s - loss: 0.0862
Epoch 14/80
 - 2s - loss: 0.0811
Epoch 15/80
 - 2s - loss: 0.0769
Epoch 16/80
 - 2s - loss: 0.0733
Epoch 17/80
 - 2s - loss: 0.0702
Epoch 18/80
 - 2s - loss: 0.0676
Epoch 19/80
 - 2s - loss: 0.0653
Epoch 20/80
 - 2s - loss: 0.0633
Epoch 21/80
 - 2s - loss: 0.0616
Epoch 22/80
 - 2s - loss: 0.0602
Epoch 23/80
 - 2s - loss: 0.0590
Epoch 24/80
 - 2s - loss: 0.0579
Epoch 25/80
 - 2s - loss: 0.0570
Epoch 26/80
 - 2s - loss: 0.0562
Epoch 27/80
 - 2s - loss: 0.0555
Epoch 28/80
 - 2s - loss: 0.0549
Epoch 29/80
 - 2s - loss: 0.0544
Epoch 30/80
 - 2s - loss: 0.0539
Epoch 31/80
 - 2s - loss: 0.0535
Epoch 32/80
 - 2s - loss: 0.0532
Epoch 33/80
 - 2s - loss: 0.0529
Epoch 34/80
 - 2s - loss: 0.0526
Epoch 35/80
 - 2s - loss: 0.0524
Epoch 36/80
 - 2s - loss: 0.0522
Epoch 37/80
 - 2s - loss: 0.0520
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0517
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0514
Epoch 42/80
 - 2s - loss: 0.0513
Epoch 43/80
 - 2s - loss: 0.0511
Epoch 44/80
 - 2s - loss: 0.0511
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0509
Epoch 47/80
 - 2s - loss: 0.0508
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0507
Epoch 50/80
 - 2s - loss: 0.0506
Epoch 51/80
 - 2s - loss: 0.0506
Epoch 52/80
 - 2s - loss: 0.0505
Epoch 53/80
 - 2s - loss: 0.0505
Epoch 54/80
 - 2s - loss: 0.0504
Epoch 55/80
 - 2s - loss: 0.0504
Epoch 56/80
 - 2s - loss: 0.0503
Epoch 57/80
 - 2s - loss: 0.0503
Epoch 58/80
 - 2s - loss: 0.0502
Epoch 59/80
 - 2s - loss: 0.0502
Epoch 60/80
 - 2s - loss: 0.0502
Epoch 61/80
 - 2s - loss: 0.0501
Epoch 62/80
 - 2s - loss: 0.0501
Epoch 63/80
 - 2s - loss: 0.0490
Epoch 64/80
 - 2s - loss: 0.0489
Epoch 65/80
 - 2s - loss: 0.0489
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0488
Epoch 68/80
 - 2s - loss: 0.0486
Epoch 69/80
 - 2s - loss: 0.0486
Epoch 70/80
 - 2s - loss: 0.0486
Epoch 71/80
 - 2s - loss: 0.0485
Epoch 72/80
 - 2s - loss: 0.0485
Epoch 73/80
 - 2s - loss: 0.0485
Epoch 74/80
 - 2s - loss: 0.0485
Epoch 75/80
 - 2s - loss: 0.0485
Epoch 76/80
 - 2s - loss: 0.0485
Epoch 77/80
 - 2s - loss: 0.0485
Epoch 78/80
 - 2s - loss: 0.0485
Epoch 79/80
 - 2s - loss: 0.0485
Epoch 80/80
 - 2s - loss: 0.0485
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.1526 - val_loss: 0.9654
AUC: 0.8208

Epoch 2/80
 - 0s - loss: 1.6892 - val_loss: 0.7325
AUC: 0.8391

Epoch 3/80
 - 0s - loss: 1.2862 - val_loss: 0.7135
AUC: 0.8471

Epoch 4/80
 - 0s - loss: 1.1708 - val_loss: 0.6632
AUC: 0.8512

Epoch 5/80
 - 0s - loss: 1.1274 - val_loss: 0.6851
AUC: 0.8554

Epoch 6/80
 - 0s - loss: 1.0940 - val_loss: 0.6873
AUC: 0.8594

Epoch 7/80
 - 0s - loss: 1.0806 - val_loss: 0.6268
AUC: 0.8585

Epoch 8/80
 - 0s - loss: 1.0696 - val_loss: 0.6483
AUC: 0.8626

Epoch 9/80
 - 0s - loss: 1.0530 - val_loss: 0.6645
AUC: 0.8629

Epoch 10/80
 - 0s - loss: 1.0494 - val_loss: 0.6265
AUC: 0.8624

Epoch 11/80
 - 0s - loss: 1.0433 - val_loss: 0.6139
AUC: 0.8628

Epoch 12/80
 - 0s - loss: 1.0312 - val_loss: 0.6052
AUC: 0.8661

Epoch 13/80
 - 0s - loss: 1.0275 - val_loss: 0.5491
AUC: 0.8646

Epoch 14/80
 - 0s - loss: 1.0213 - val_loss: 0.6326
AUC: 0.8668

Epoch 15/80
 - 0s - loss: 1.0210 - val_loss: 0.6382
AUC: 0.8690

Epoch 16/80
 - 0s - loss: 1.0064 - val_loss: 0.6085
AUC: 0.8680

Epoch 17/80
 - 0s - loss: 1.0111 - val_loss: 0.5679
AUC: 0.8688

Epoch 18/80
 - 0s - loss: 1.0090 - val_loss: 0.6325
AUC: 0.8704

Epoch 19/80
 - 0s - loss: 1.0077 - val_loss: 0.5615
AUC: 0.8690

Epoch 20/80
 - 0s - loss: 1.0119 - val_loss: 0.5607
AUC: 0.8691

Epoch 21/80
 - 0s - loss: 0.9995 - val_loss: 0.5836
AUC: 0.8709

Epoch 22/80
 - 0s - loss: 0.9954 - val_loss: 0.5878
AUC: 0.8717

Epoch 23/80
 - 0s - loss: 0.9950 - val_loss: 0.5902
AUC: 0.8704

Epoch 24/80
 - 0s - loss: 0.9820 - val_loss: 0.6198
AUC: 0.8725

Epoch 25/80
 - 0s - loss: 0.9851 - val_loss: 0.5687
AUC: 0.8724

Epoch 26/80
 - 0s - loss: 0.9799 - val_loss: 0.6001
AUC: 0.8727

Epoch 27/80
 - 0s - loss: 0.9737 - val_loss: 0.6147
AUC: 0.8735

Epoch 28/80
 - 0s - loss: 0.9775 - val_loss: 0.5884
AUC: 0.8731

Epoch 29/80
 - 0s - loss: 0.9777 - val_loss: 0.5960
AUC: 0.8736

Epoch 30/80
 - 0s - loss: 0.9733 - val_loss: 0.5968
AUC: 0.8735

Epoch 31/80
 - 0s - loss: 0.9734 - val_loss: 0.6179
AUC: 0.8741

Epoch 32/80
 - 0s - loss: 0.9719 - val_loss: 0.5797
AUC: 0.8738

Epoch 33/80
 - 0s - loss: 0.9708 - val_loss: 0.5981
AUC: 0.8737

Epoch 34/80
 - 0s - loss: 0.9682 - val_loss: 0.5910
AUC: 0.8738

Epoch 35/80
 - 0s - loss: 0.9745 - val_loss: 0.6037
AUC: 0.8740

Epoch 36/80
 - 0s - loss: 0.9728 - val_loss: 0.5984
AUC: 0.8741

Epoch 37/80
 - 0s - loss: 0.9713 - val_loss: 0.5919
AUC: 0.8740

Epoch 38/80
 - 0s - loss: 0.9707 - val_loss: 0.5925
AUC: 0.8740

Epoch 39/80
 - 0s - loss: 0.9717 - val_loss: 0.5969
AUC: 0.8741

Epoch 40/80
 - 0s - loss: 0.9717 - val_loss: 0.5964
AUC: 0.8741

Epoch 41/80
 - 0s - loss: 0.9645 - val_loss: 0.6046
AUC: 0.8743

Epoch 42/80
 - 0s - loss: 0.9682 - val_loss: 0.5953
AUC: 0.8742

Epoch 43/80
 - 0s - loss: 0.9738 - val_loss: 0.5912
AUC: 0.8741

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9676 - val_loss: 0.6072
AUC: 0.8742

Epoch 2/30
 - 0s - loss: 0.9695 - val_loss: 0.6126
AUC: 0.8747

Epoch 3/30
 - 0s - loss: 0.9662 - val_loss: 0.6183
AUC: 0.8748

Epoch 4/30
 - 0s - loss: 0.9632 - val_loss: 0.5801
AUC: 0.8745

Epoch 5/30
 - 0s - loss: 0.9634 - val_loss: 0.6071
AUC: 0.8749

Epoch 6/30
 - 0s - loss: 0.9629 - val_loss: 0.6065
AUC: 0.8750

Epoch 7/30
 - 0s - loss: 0.9643 - val_loss: 0.6075
AUC: 0.8750

Epoch 8/30
 - 0s - loss: 0.9577 - val_loss: 0.5920
AUC: 0.8751

Epoch 9/30
 - 0s - loss: 0.9564 - val_loss: 0.5793
AUC: 0.8750

Epoch 10/30
 - 0s - loss: 0.9544 - val_loss: 0.5940
AUC: 0.8752

Epoch 11/30
 - 0s - loss: 0.9572 - val_loss: 0.5868
AUC: 0.8752

Epoch 12/30
 - 0s - loss: 0.9529 - val_loss: 0.5763
AUC: 0.8753

Epoch 13/30
 - 0s - loss: 0.9534 - val_loss: 0.5726
AUC: 0.8752

Epoch 14/30
 - 0s - loss: 0.9527 - val_loss: 0.5938
AUC: 0.8755

Epoch 15/30
 - 0s - loss: 0.9520 - val_loss: 0.5684
AUC: 0.8757

Epoch 16/30
 - 0s - loss: 0.9521 - val_loss: 0.5957
AUC: 0.8761

Epoch 17/30
 - 0s - loss: 0.9486 - val_loss: 0.5876
AUC: 0.8761

Epoch 18/30
 - 0s - loss: 0.9457 - val_loss: 0.6014
AUC: 0.8765

Epoch 19/30
 - 0s - loss: 0.9479 - val_loss: 0.5908
AUC: 0.8763

Epoch 20/30
 - 0s - loss: 0.9444 - val_loss: 0.5929
AUC: 0.8764

Epoch 21/30
 - 0s - loss: 0.9424 - val_loss: 0.5906
AUC: 0.8765

Epoch 22/30
 - 0s - loss: 0.9430 - val_loss: 0.5782
AUC: 0.8763

Epoch 23/30
 - 0s - loss: 0.9367 - val_loss: 0.5892
AUC: 0.8766

Epoch 24/30
 - 0s - loss: 0.9399 - val_loss: 0.5966
AUC: 0.8768

Epoch 25/30
 - 0s - loss: 0.9456 - val_loss: 0.5865
AUC: 0.8768

Epoch 26/30
 - 0s - loss: 0.9335 - val_loss: 0.5805
AUC: 0.8767

Epoch 27/30
 - 0s - loss: 0.9363 - val_loss: 0.5817
AUC: 0.8767

Epoch 28/30
 - 0s - loss: 0.9386 - val_loss: 0.5810
AUC: 0.8768

Epoch 29/30
 - 0s - loss: 0.9369 - val_loss: 0.5852
AUC: 0.8769

Epoch 30/30
 - 0s - loss: 0.9361 - val_loss: 0.5809
Using TensorFlow backend.
AUC: 0.8769

2019-03-08 03:38:44.966093: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:38:45.132082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:38:45.132195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:38:45.423736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:38:45.423787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:38:45.423795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:38:45.424049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6871
Epoch 2/80
 - 2s - loss: 0.1311
Epoch 3/80
 - 2s - loss: 0.0727
Epoch 4/80
 - 2s - loss: 0.0652
Epoch 5/80
 - 2s - loss: 0.0618
Epoch 6/80
 - 2s - loss: 0.0592
Epoch 7/80
 - 2s - loss: 0.0566
Epoch 8/80
 - 2s - loss: 0.0540
Epoch 9/80
 - 2s - loss: 0.0514
Epoch 10/80
 - 2s - loss: 0.0487
Epoch 11/80
 - 2s - loss: 0.0459
Epoch 12/80
 - 2s - loss: 0.0430
Epoch 13/80
 - 2s - loss: 0.0398
Epoch 14/80
 - 2s - loss: 0.0367
Epoch 15/80
 - 2s - loss: 0.0339
Epoch 16/80
 - 2s - loss: 0.0314
Epoch 17/80
 - 2s - loss: 0.0292
Epoch 18/80
 - 2s - loss: 0.0274
Epoch 19/80
 - 2s - loss: 0.0259
Epoch 20/80
 - 2s - loss: 0.0246
Epoch 21/80
 - 2s - loss: 0.0234
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0217
Epoch 24/80
 - 2s - loss: 0.0210
Epoch 25/80
 - 2s - loss: 0.0204
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0195
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0189
Epoch 30/80
 - 2s - loss: 0.0186
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0180
Epoch 34/80
 - 2s - loss: 0.0178
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0159
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:40:55.456594: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:40:55.620066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:40:55.620108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:40:55.910750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:40:55.910818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:40:55.910826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:40:55.911083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6995
Epoch 2/80
 - 2s - loss: 0.1378
Epoch 3/80
 - 2s - loss: 0.0723
Epoch 4/80
 - 2s - loss: 0.0648
Epoch 5/80
 - 2s - loss: 0.0608
Epoch 6/80
 - 2s - loss: 0.0572
Epoch 7/80
 - 2s - loss: 0.0539
Epoch 8/80
 - 2s - loss: 0.0510
Epoch 9/80
 - 2s - loss: 0.0483
Epoch 10/80
 - 2s - loss: 0.0454
Epoch 11/80
 - 2s - loss: 0.0425
Epoch 12/80
 - 2s - loss: 0.0396
Epoch 13/80
 - 2s - loss: 0.0369
Epoch 14/80
 - 2s - loss: 0.0344
Epoch 15/80
 - 2s - loss: 0.0323
Epoch 16/80
 - 2s - loss: 0.0304
Epoch 17/80
 - 2s - loss: 0.0288
Epoch 18/80
 - 2s - loss: 0.0273
Epoch 19/80
 - 2s - loss: 0.0260
Epoch 20/80
 - 2s - loss: 0.0248
Epoch 21/80
 - 2s - loss: 0.0238
Epoch 22/80
 - 2s - loss: 0.0228
Epoch 23/80
 - 2s - loss: 0.0220
Epoch 24/80
 - 2s - loss: 0.0212
Epoch 25/80
 - 2s - loss: 0.0206
Epoch 26/80
 - 2s - loss: 0.0200
Epoch 27/80
 - 2s - loss: 0.0196
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0172
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0169
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0167
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0160
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0159
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.1908 - val_loss: 1.1027
AUC: 0.7949

Epoch 2/80
 - 0s - loss: 2.3723 - val_loss: 0.9093
AUC: 0.8287

Epoch 3/80
 - 0s - loss: 1.5492 - val_loss: 0.7283
AUC: 0.8316

Epoch 4/80
 - 0s - loss: 1.2890 - val_loss: 0.6776
AUC: 0.8413

Epoch 5/80
 - 0s - loss: 1.1846 - val_loss: 0.7164
AUC: 0.8478

Epoch 6/80
 - 0s - loss: 1.1538 - val_loss: 0.6445
AUC: 0.8514

Epoch 7/80
 - 0s - loss: 1.1165 - val_loss: 0.6729
AUC: 0.8553

Epoch 8/80
 - 0s - loss: 1.0933 - val_loss: 0.6029
AUC: 0.8543

Epoch 9/80
 - 0s - loss: 1.0831 - val_loss: 0.6828
AUC: 0.8581

Epoch 10/80
 - 0s - loss: 1.0684 - val_loss: 0.6844
AUC: 0.8583

Epoch 11/80
 - 0s - loss: 1.0634 - val_loss: 0.6502
AUC: 0.8597

Epoch 12/80
 - 0s - loss: 1.0631 - val_loss: 0.6693
AUC: 0.8620

Epoch 13/80
 - 0s - loss: 1.0477 - val_loss: 0.6548
AUC: 0.8614

Epoch 14/80
 - 0s - loss: 1.0397 - val_loss: 0.6657
AUC: 0.8632

Epoch 15/80
 - 0s - loss: 1.0381 - val_loss: 0.6371
AUC: 0.8628

Epoch 16/80
 - 0s - loss: 1.0400 - val_loss: 0.6152
AUC: 0.8633

Epoch 17/80
 - 0s - loss: 1.0273 - val_loss: 0.5873
AUC: 0.8638

Epoch 18/80
 - 0s - loss: 1.0198 - val_loss: 0.6331
AUC: 0.8655

Epoch 19/80
 - 0s - loss: 1.0287 - val_loss: 0.6832
AUC: 0.8662

Epoch 20/80
 - 0s - loss: 1.0218 - val_loss: 0.6539
AUC: 0.8673

Epoch 21/80
 - 0s - loss: 1.0066 - val_loss: 0.5722
AUC: 0.8652

Epoch 22/80
 - 0s - loss: 1.0068 - val_loss: 0.5734
AUC: 0.8668

Epoch 23/80
 - 0s - loss: 1.0100 - val_loss: 0.6957
AUC: 0.8678

Epoch 24/80
 - 0s - loss: 1.0089 - val_loss: 0.6288
AUC: 0.8672

Epoch 25/80
 - 0s - loss: 1.0042 - val_loss: 0.6150
AUC: 0.8682

Epoch 26/80
 - 0s - loss: 1.0017 - val_loss: 0.5677
AUC: 0.8682

Epoch 27/80
 - 0s - loss: 1.0044 - val_loss: 0.6385
AUC: 0.8684

Epoch 28/80
 - 0s - loss: 0.9938 - val_loss: 0.5429
AUC: 0.8679

Epoch 29/80
 - 0s - loss: 1.0053 - val_loss: 0.6164
AUC: 0.8696

Epoch 30/80
 - 0s - loss: 0.9921 - val_loss: 0.6321
AUC: 0.8697

Epoch 31/80
 - 0s - loss: 0.9919 - val_loss: 0.6512
AUC: 0.8703

Epoch 32/80
 - 0s - loss: 0.9837 - val_loss: 0.5673
AUC: 0.8690

Epoch 33/80
 - 0s - loss: 0.9936 - val_loss: 0.6497
AUC: 0.8703

Epoch 34/80
 - 0s - loss: 0.9801 - val_loss: 0.6118
AUC: 0.8702

Epoch 35/80
 - 0s - loss: 0.9785 - val_loss: 0.6153
AUC: 0.8679

Epoch 36/80
 - 0s - loss: 0.9860 - val_loss: 0.5900
AUC: 0.8707

Epoch 37/80
 - 0s - loss: 0.9781 - val_loss: 0.6441
AUC: 0.8699

Epoch 38/80
 - 0s - loss: 0.9744 - val_loss: 0.6148
AUC: 0.8712

Epoch 39/80
 - 0s - loss: 0.9665 - val_loss: 0.6024
AUC: 0.8713

Epoch 40/80
 - 0s - loss: 0.9642 - val_loss: 0.5899
AUC: 0.8708

Epoch 41/80
 - 0s - loss: 0.9580 - val_loss: 0.5990
AUC: 0.8709

Epoch 42/80
 - 0s - loss: 0.9637 - val_loss: 0.6054
AUC: 0.8714

Epoch 43/80
 - 0s - loss: 0.9620 - val_loss: 0.5986
AUC: 0.8714

Epoch 44/80
 - 0s - loss: 0.9541 - val_loss: 0.6196
AUC: 0.8715

Epoch 45/80
 - 0s - loss: 0.9578 - val_loss: 0.5758
AUC: 0.8713

Epoch 46/80
 - 0s - loss: 0.9557 - val_loss: 0.5890
AUC: 0.8712

Epoch 47/80
 - 0s - loss: 0.9572 - val_loss: 0.5850
AUC: 0.8711

Epoch 48/80
 - 0s - loss: 0.9552 - val_loss: 0.5956
AUC: 0.8715

Epoch 49/80
 - 0s - loss: 0.9549 - val_loss: 0.5909
AUC: 0.8714

Epoch 50/80
 - 0s - loss: 0.9539 - val_loss: 0.5897
AUC: 0.8714

Epoch 51/80
 - 0s - loss: 0.9592 - val_loss: 0.5978
AUC: 0.8715

Epoch 52/80
 - 0s - loss: 0.9534 - val_loss: 0.5842
AUC: 0.8713

Epoch 53/80
 - 0s - loss: 0.9613 - val_loss: 0.5971
AUC: 0.8715

Epoch 54/80
 - 0s - loss: 0.9491 - val_loss: 0.5939
AUC: 0.8715

Epoch 55/80
 - 0s - loss: 0.9496 - val_loss: 0.5959
AUC: 0.8715

Epoch 56/80
 - 0s - loss: 0.9514 - val_loss: 0.5941
AUC: 0.8715

Epoch 57/80
 - 0s - loss: 0.9523 - val_loss: 0.5960
AUC: 0.8715

Epoch 58/80
 - 0s - loss: 0.9539 - val_loss: 0.5990
AUC: 0.8715

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9538 - val_loss: 0.5824
AUC: 0.8714

Epoch 2/30
 - 0s - loss: 0.9554 - val_loss: 0.5943
AUC: 0.8715

Epoch 3/30
 - 0s - loss: 0.9527 - val_loss: 0.5707
AUC: 0.8713

Epoch 4/30
 - 0s - loss: 0.9602 - val_loss: 0.5925
AUC: 0.8716

Epoch 5/30
 - 0s - loss: 0.9540 - val_loss: 0.5854
AUC: 0.8717

Epoch 6/30
 - 0s - loss: 0.9541 - val_loss: 0.5889
AUC: 0.8718

Epoch 7/30
 - 0s - loss: 0.9458 - val_loss: 0.6195
AUC: 0.8721

Epoch 8/30
 - 0s - loss: 0.9480 - val_loss: 0.5942
AUC: 0.8719

Epoch 9/30
 - 0s - loss: 0.9499 - val_loss: 0.5910
AUC: 0.8721

Epoch 10/30
 - 0s - loss: 0.9471 - val_loss: 0.6063
AUC: 0.8721

Epoch 11/30
 - 0s - loss: 0.9434 - val_loss: 0.5845
AUC: 0.8720

Epoch 12/30
 - 0s - loss: 0.9432 - val_loss: 0.5909
AUC: 0.8722

Epoch 13/30
 - 0s - loss: 0.9412 - val_loss: 0.5777
AUC: 0.8722

Epoch 14/30
 - 0s - loss: 0.9350 - val_loss: 0.5857
AUC: 0.8723

Epoch 15/30
 - 0s - loss: 0.9368 - val_loss: 0.5825
AUC: 0.8723

Epoch 16/30
 - 0s - loss: 0.9410 - val_loss: 0.5888
AUC: 0.8723

Epoch 17/30
 - 0s - loss: 0.9383 - val_loss: 0.5895
AUC: 0.8723

Epoch 18/30
 - 0s - loss: 0.9381 - val_loss: 0.5872
AUC: 0.8723

Epoch 19/30
 - 0s - loss: 0.9418 - val_loss: 0.5877
AUC: 0.8724

Epoch 20/30
 - 0s - loss: 0.9440 - val_loss: 0.5909
AUC: 0.8724

Epoch 21/30
 - 0s - loss: 0.9352 - val_loss: 0.5859
AUC: 0.8724

Epoch 22/30
 - 0s - loss: 0.9403 - val_loss: 0.5877
AUC: 0.8724

Epoch 23/30
 - 0s - loss: 0.9401 - val_loss: 0.5907
AUC: 0.8725

Epoch 24/30
 - 0s - loss: 0.9364 - val_loss: 0.5882
AUC: 0.8724

Epoch 25/30
 - 0s - loss: 0.9367 - val_loss: 0.5874
AUC: 0.8724

Epoch 26/30
 - 0s - loss: 0.9321 - val_loss: 0.5870
AUC: 0.8724

Epoch 27/30
 - 0s - loss: 0.9317 - val_loss: 0.5855
AUC: 0.8724

Epoch 28/30
 - 0s - loss: 0.9416 - val_loss: 0.5859
AUC: 0.8724

Epoch 29/30
 - 0s - loss: 0.9361 - val_loss: 0.5855
AUC: 0.8724

Epoch 30/30
 - 0s - loss: 0.9385 - val_loss: 0.5854
Using TensorFlow backend.
AUC: 0.8724

2019-03-08 03:44:19.479395: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:44:19.643636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:44:19.643679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:44:19.933947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:44:19.933993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:44:19.934003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:44:19.934300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.7025
Epoch 2/80
 - 2s - loss: 0.1360
Epoch 3/80
 - 2s - loss: 0.0723
Epoch 4/80
 - 2s - loss: 0.0654
Epoch 5/80
 - 2s - loss: 0.0623
Epoch 6/80
 - 2s - loss: 0.0598
Epoch 7/80
 - 2s - loss: 0.0571
Epoch 8/80
 - 2s - loss: 0.0543
Epoch 9/80
 - 2s - loss: 0.0512
Epoch 10/80
 - 2s - loss: 0.0478
Epoch 11/80
 - 2s - loss: 0.0442
Epoch 12/80
 - 2s - loss: 0.0407
Epoch 13/80
 - 2s - loss: 0.0377
Epoch 14/80
 - 2s - loss: 0.0351
Epoch 15/80
 - 2s - loss: 0.0328
Epoch 16/80
 - 2s - loss: 0.0308
Epoch 17/80
 - 2s - loss: 0.0290
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 03:45:05.232353: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:45:05.398877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:45:05.398920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:45:05.693032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:45:05.693081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:45:05.693090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:45:05.693378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3870
Epoch 2/80
 - 2s - loss: 0.3538
Epoch 3/80
 - 2s - loss: 0.2952
Epoch 4/80
 - 2s - loss: 0.2699
Epoch 5/80
 - 2s - loss: 0.2517
Epoch 6/80
 - 2s - loss: 0.2381
Epoch 7/80
 - 2s - loss: 0.2274
Epoch 8/80
 - 2s - loss: 0.2178
Epoch 9/80
 - 2s - loss: 0.2072
Epoch 10/80
 - 2s - loss: 0.1951
Epoch 11/80
 - 2s - loss: 0.1827
Epoch 12/80
 - 2s - loss: 0.1719
Epoch 13/80
 - 2s - loss: 0.1632
Epoch 14/80
 - 2s - loss: 0.1562
Epoch 15/80
 - 2s - loss: 0.1504
Epoch 16/80
 - 2s - loss: 0.1454
Epoch 17/80
 - 2s - loss: 0.1412
Epoch 18/80
 - 2s - loss: 0.1376
Epoch 19/80
 - 2s - loss: 0.1346
Epoch 20/80
 - 2s - loss: 0.1320
Epoch 21/80
 - 2s - loss: 0.1297
Epoch 22/80
 - 2s - loss: 0.1277
Epoch 23/80
 - 2s - loss: 0.1260
Epoch 24/80
 - 2s - loss: 0.1245
Epoch 25/80
 - 2s - loss: 0.1232
Epoch 26/80
 - 2s - loss: 0.1221
Epoch 27/80
 - 2s - loss: 0.1212
Epoch 28/80
 - 2s - loss: 0.1203
Epoch 29/80
 - 2s - loss: 0.1197
Epoch 30/80
 - 2s - loss: 0.1191
Epoch 31/80
 - 2s - loss: 0.1185
Epoch 32/80
 - 2s - loss: 0.1181
Epoch 33/80
 - 2s - loss: 0.1177
Epoch 34/80
 - 2s - loss: 0.1174
Epoch 35/80
 - 2s - loss: 0.1170
Epoch 36/80
 - 2s - loss: 0.1167
Epoch 37/80
 - 2s - loss: 0.1165
Epoch 38/80
 - 2s - loss: 0.1163
Epoch 39/80
 - 2s - loss: 0.1161
Epoch 40/80
 - 2s - loss: 0.1159
Epoch 41/80
 - 2s - loss: 0.1157
Epoch 42/80
 - 2s - loss: 0.1156
Epoch 43/80
 - 2s - loss: 0.1154
Epoch 44/80
 - 2s - loss: 0.1153
Epoch 45/80
 - 2s - loss: 0.1152
Epoch 46/80
 - 2s - loss: 0.1151
Epoch 47/80
 - 2s - loss: 0.1150
Epoch 48/80
 - 2s - loss: 0.1149
Epoch 49/80
 - 2s - loss: 0.1148
Epoch 50/80
 - 2s - loss: 0.1147
Epoch 51/80
 - 2s - loss: 0.1146
Epoch 52/80
 - 2s - loss: 0.1145
Epoch 53/80
 - 2s - loss: 0.1145
Epoch 54/80
 - 2s - loss: 0.1144
Epoch 55/80
 - 2s - loss: 0.1143
Epoch 56/80
 - 2s - loss: 0.1143
Epoch 57/80
 - 2s - loss: 0.1142
Epoch 58/80
 - 2s - loss: 0.1142
Epoch 59/80
 - 2s - loss: 0.1141
Epoch 60/80
 - 2s - loss: 0.1141
Epoch 61/80
 - 2s - loss: 0.1140
Epoch 62/80
 - 2s - loss: 0.1140
Epoch 63/80
 - 2s - loss: 0.1140
Epoch 64/80
 - 2s - loss: 0.1139
Epoch 65/80
 - 2s - loss: 0.1139
Epoch 66/80
 - 2s - loss: 0.1139
Epoch 67/80
 - 2s - loss: 0.1138
Epoch 68/80
 - 2s - loss: 0.1138
Epoch 69/80
 - 2s - loss: 0.1137
Epoch 70/80
 - 2s - loss: 0.1138
Epoch 71/80
 - 2s - loss: 0.1115
Epoch 72/80
 - 2s - loss: 0.1113
Epoch 73/80
 - 2s - loss: 0.1112
Epoch 74/80
 - 2s - loss: 0.1112
Epoch 75/80
 - 2s - loss: 0.1112
Epoch 76/80
 - 2s - loss: 0.1106
Epoch 77/80
 - 2s - loss: 0.1106
Epoch 78/80
 - 2s - loss: 0.1106
Epoch 79/80
 - 2s - loss: 0.1106
Epoch 80/80
 - 2s - loss: 0.1105
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0432 - val_loss: 0.9964
AUC: 0.8320

Epoch 2/80
 - 0s - loss: 1.5530 - val_loss: 0.7681
AUC: 0.8462

Epoch 3/80
 - 0s - loss: 1.2161 - val_loss: 0.6619
AUC: 0.8512

Epoch 4/80
 - 0s - loss: 1.1542 - val_loss: 0.7085
AUC: 0.8571

Epoch 5/80
 - 0s - loss: 1.1089 - val_loss: 0.6686
AUC: 0.8590

Epoch 6/80
 - 0s - loss: 1.0988 - val_loss: 0.6840
AUC: 0.8627

Epoch 7/80
 - 0s - loss: 1.0868 - val_loss: 0.6242
AUC: 0.8627

Epoch 8/80
 - 0s - loss: 1.0640 - val_loss: 0.6586
AUC: 0.8649

Epoch 9/80
 - 0s - loss: 1.0591 - val_loss: 0.5842
AUC: 0.8660

Epoch 10/80
 - 0s - loss: 1.0571 - val_loss: 0.6688
AUC: 0.8657

Epoch 11/80
 - 0s - loss: 1.0499 - val_loss: 0.6128
AUC: 0.8668

Epoch 12/80
 - 0s - loss: 1.0361 - val_loss: 0.6573
AUC: 0.8680

Epoch 13/80
 - 0s - loss: 1.0307 - val_loss: 0.6184
AUC: 0.8673

Epoch 14/80
 - 0s - loss: 1.0295 - val_loss: 0.5469
AUC: 0.8681

Epoch 15/80
 - 0s - loss: 1.0187 - val_loss: 0.5929
AUC: 0.8700

Epoch 16/80
 - 0s - loss: 1.0244 - val_loss: 0.5853
AUC: 0.8707

Epoch 17/80
 - 0s - loss: 1.0170 - val_loss: 0.6158
AUC: 0.8717

Epoch 18/80
 - 0s - loss: 1.0124 - val_loss: 0.6281
AUC: 0.8717

Epoch 19/80
 - 0s - loss: 1.0032 - val_loss: 0.6982
AUC: 0.8713

Epoch 20/80
 - 0s - loss: 1.0137 - val_loss: 0.5988
AUC: 0.8709

Epoch 21/80
 - 0s - loss: 0.9956 - val_loss: 0.5772
AUC: 0.8724

Epoch 22/80
 - 0s - loss: 0.9982 - val_loss: 0.5879
AUC: 0.8716

Epoch 23/80
 - 0s - loss: 0.9989 - val_loss: 0.6389
AUC: 0.8721

Epoch 24/80
 - 0s - loss: 0.9964 - val_loss: 0.6403
AUC: 0.8733

Epoch 25/80
 - 0s - loss: 0.9859 - val_loss: 0.6061
AUC: 0.8731

Epoch 26/80
 - 0s - loss: 0.9809 - val_loss: 0.6262
AUC: 0.8734

Epoch 27/80
 - 0s - loss: 0.9822 - val_loss: 0.6158
AUC: 0.8736

Epoch 28/80
 - 0s - loss: 0.9822 - val_loss: 0.5884
AUC: 0.8735

Epoch 29/80
 - 0s - loss: 0.9760 - val_loss: 0.6150
AUC: 0.8736

Epoch 30/80
 - 0s - loss: 0.9738 - val_loss: 0.5873
AUC: 0.8735

Epoch 31/80
 - 0s - loss: 0.9728 - val_loss: 0.6041
AUC: 0.8737

Epoch 32/80
 - 0s - loss: 0.9739 - val_loss: 0.6060
AUC: 0.8733

Epoch 33/80
 - 0s - loss: 0.9803 - val_loss: 0.5981
AUC: 0.8735

Epoch 34/80
 - 0s - loss: 0.9710 - val_loss: 0.5922
AUC: 0.8735

Epoch 35/80
 - 0s - loss: 0.9721 - val_loss: 0.6033
AUC: 0.8737

Epoch 36/80
 - 0s - loss: 0.9674 - val_loss: 0.6066
AUC: 0.8737

Epoch 37/80
 - 0s - loss: 0.9723 - val_loss: 0.6062
AUC: 0.8738

Epoch 38/80
 - 0s - loss: 0.9715 - val_loss: 0.6031
AUC: 0.8738

Epoch 39/80
 - 0s - loss: 0.9684 - val_loss: 0.5940
AUC: 0.8738

Epoch 40/80
 - 0s - loss: 0.9696 - val_loss: 0.6032
AUC: 0.8740

Epoch 41/80
 - 0s - loss: 0.9751 - val_loss: 0.6003
AUC: 0.8739

Epoch 42/80
 - 0s - loss: 0.9677 - val_loss: 0.6128
AUC: 0.8739

Epoch 43/80
 - 0s - loss: 0.9679 - val_loss: 0.6050
AUC: 0.8740

Epoch 44/80
 - 0s - loss: 0.9667 - val_loss: 0.5950
AUC: 0.8739

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9722 - val_loss: 0.5942
AUC: 0.8737

Epoch 2/30
 - 0s - loss: 0.9725 - val_loss: 0.5900
AUC: 0.8738

Epoch 3/30
 - 0s - loss: 0.9653 - val_loss: 0.6014
AUC: 0.8736

Epoch 4/30
 - 0s - loss: 0.9676 - val_loss: 0.5966
AUC: 0.8741

Epoch 5/30
 - 0s - loss: 0.9660 - val_loss: 0.5863
AUC: 0.8742

Epoch 6/30
 - 0s - loss: 0.9648 - val_loss: 0.5738
AUC: 0.8739

Epoch 7/30
 - 0s - loss: 0.9654 - val_loss: 0.6081
AUC: 0.8745

Epoch 8/30
 - 0s - loss: 0.9620 - val_loss: 0.5957
AUC: 0.8746

Epoch 9/30
 - 0s - loss: 0.9612 - val_loss: 0.5955
AUC: 0.8747

Epoch 10/30
 - 0s - loss: 0.9565 - val_loss: 0.5776
AUC: 0.8742

Epoch 11/30
 - 0s - loss: 0.9541 - val_loss: 0.5858
AUC: 0.8744

Epoch 12/30
 - 0s - loss: 0.9563 - val_loss: 0.5988
AUC: 0.8747

Epoch 13/30
 - 0s - loss: 0.9546 - val_loss: 0.5923
AUC: 0.8746

Epoch 14/30
 - 0s - loss: 0.9546 - val_loss: 0.6093
AUC: 0.8751

Epoch 15/30
 - 0s - loss: 0.9528 - val_loss: 0.5868
AUC: 0.8749

Epoch 16/30
 - 0s - loss: 0.9528 - val_loss: 0.5939
AUC: 0.8747

Epoch 17/30
 - 0s - loss: 0.9476 - val_loss: 0.5918
AUC: 0.8748

Epoch 18/30
 - 0s - loss: 0.9527 - val_loss: 0.5937
AUC: 0.8748

Epoch 19/30
 - 0s - loss: 0.9489 - val_loss: 0.5948
AUC: 0.8748

Epoch 20/30
 - 0s - loss: 0.9489 - val_loss: 0.5919
AUC: 0.8748

Epoch 21/30
 - 0s - loss: 0.9473 - val_loss: 0.5881
AUC: 0.8748

Epoch 22/30
 - 0s - loss: 0.9486 - val_loss: 0.5954
AUC: 0.8748

Epoch 23/30
 - 0s - loss: 0.9445 - val_loss: 0.5901
AUC: 0.8748

Epoch 24/30
 - 0s - loss: 0.9462 - val_loss: 0.5888
AUC: 0.8748

Epoch 25/30
 - 0s - loss: 0.9430 - val_loss: 0.5934
AUC: 0.8748

Epoch 26/30
 - 0s - loss: 0.9471 - val_loss: 0.5859
AUC: 0.8748

Epoch 27/30
 - 0s - loss: 0.9512 - val_loss: 0.5885
AUC: 0.8748

Epoch 28/30
 - 0s - loss: 0.9505 - val_loss: 0.5904
AUC: 0.8748

Epoch 29/30
 - 0s - loss: 0.9472 - val_loss: 0.5913
AUC: 0.8748

Epoch 30/30
 - 0s - loss: 0.9501 - val_loss: 0.5914
Using TensorFlow backend.
AUC: 0.8748

2019-03-08 03:48:26.807271: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:48:26.971865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:48:26.971908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:48:27.267416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:48:27.267481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:48:27.267490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:48:27.267766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3467
Epoch 2/80
 - 2s - loss: 0.3494
Epoch 3/80
 - 2s - loss: 0.3077
Epoch 4/80
 - 2s - loss: 0.2940
Epoch 5/80
 - 2s - loss: 0.2756
Epoch 6/80
 - 2s - loss: 0.2539
Epoch 7/80
 - 2s - loss: 0.2350
Epoch 8/80
 - 2s - loss: 0.2207
Epoch 9/80
 - 2s - loss: 0.2094
Epoch 10/80
 - 2s - loss: 0.1986
Epoch 11/80
 - 2s - loss: 0.1874
Epoch 12/80
 - 2s - loss: 0.1766
Epoch 13/80
 - 2s - loss: 0.1667
Epoch 14/80
 - 2s - loss: 0.1583
Epoch 15/80
 - 2s - loss: 0.1514
Epoch 16/80
 - 2s - loss: 0.1456
Epoch 17/80
 - 2s - loss: 0.1409
Epoch 18/80
 - 2s - loss: 0.1370
Epoch 19/80
 - 2s - loss: 0.1337
Epoch 20/80
 - 2s - loss: 0.1310
Epoch 21/80
 - 2s - loss: 0.1288
Epoch 22/80
 - 2s - loss: 0.1269
Epoch 23/80
 - 2s - loss: 0.1253
Epoch 24/80
 - 2s - loss: 0.1239
Epoch 25/80
 - 2s - loss: 0.1227
Epoch 26/80
 - 2s - loss: 0.1217
Epoch 27/80
 - 2s - loss: 0.1208
Epoch 28/80
 - 2s - loss: 0.1200
Epoch 29/80
 - 2s - loss: 0.1194
Epoch 30/80
 - 2s - loss: 0.1189
Epoch 31/80
 - 2s - loss: 0.1184
Epoch 32/80
 - 2s - loss: 0.1180
Epoch 33/80
 - 2s - loss: 0.1176
Epoch 34/80
 - 2s - loss: 0.1173
Epoch 35/80
 - 2s - loss: 0.1170
Epoch 36/80
 - 2s - loss: 0.1168
Epoch 37/80
 - 2s - loss: 0.1165
Epoch 38/80
 - 2s - loss: 0.1163
Epoch 39/80
 - 2s - loss: 0.1162
Epoch 40/80
 - 2s - loss: 0.1160
Epoch 41/80
 - 2s - loss: 0.1158
Epoch 42/80
 - 2s - loss: 0.1157
Epoch 43/80
 - 2s - loss: 0.1155
Epoch 44/80
 - 2s - loss: 0.1154
Epoch 45/80
 - 2s - loss: 0.1153
Epoch 46/80
 - 2s - loss: 0.1152
Epoch 47/80
 - 2s - loss: 0.1151
Epoch 48/80
 - 2s - loss: 0.1150
Epoch 49/80
 - 2s - loss: 0.1150
Epoch 50/80
 - 2s - loss: 0.1148
Epoch 51/80
 - 2s - loss: 0.1148
Epoch 52/80
 - 2s - loss: 0.1147
Epoch 53/80
 - 2s - loss: 0.1146
Epoch 54/80
 - 2s - loss: 0.1146
Epoch 55/80
 - 2s - loss: 0.1145
Epoch 56/80
 - 2s - loss: 0.1145
Epoch 57/80
 - 2s - loss: 0.1144
Epoch 58/80
 - 2s - loss: 0.1144
Epoch 59/80
 - 2s - loss: 0.1143
Epoch 60/80
 - 2s - loss: 0.1143
Epoch 61/80
 - 2s - loss: 0.1142
Epoch 62/80
 - 2s - loss: 0.1142
Epoch 63/80
 - 2s - loss: 0.1142
Epoch 64/80
 - 2s - loss: 0.1141
Epoch 65/80
 - 2s - loss: 0.1119
Epoch 66/80
 - 2s - loss: 0.1117
Epoch 67/80
 - 2s - loss: 0.1116
Epoch 68/80
 - 2s - loss: 0.1116
Epoch 69/80
 - 2s - loss: 0.1116
Epoch 70/80
 - 2s - loss: 0.1110
Epoch 71/80
 - 2s - loss: 0.1110
Epoch 72/80
 - 2s - loss: 0.1110
Epoch 73/80
 - 2s - loss: 0.1110
Epoch 74/80
 - 2s - loss: 0.1109
Epoch 75/80
 - 2s - loss: 0.1109
Epoch 76/80
 - 2s - loss: 0.1109
Epoch 77/80
 - 2s - loss: 0.1109
Epoch 78/80
 - 2s - loss: 0.1109
Epoch 79/80
 - 2s - loss: 0.1109
Epoch 80/80
 - 2s - loss: 0.1109
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.4920 - val_loss: 0.9812
AUC: 0.8373

Epoch 2/80
 - 0s - loss: 1.4121 - val_loss: 0.6766
AUC: 0.8434

Epoch 3/80
 - 0s - loss: 1.1933 - val_loss: 0.6818
AUC: 0.8534

Epoch 4/80
 - 0s - loss: 1.1243 - val_loss: 0.6307
AUC: 0.8556

Epoch 5/80
 - 0s - loss: 1.1181 - val_loss: 0.6634
AUC: 0.8593

Epoch 6/80
 - 0s - loss: 1.0734 - val_loss: 0.5929
AUC: 0.8589

Epoch 7/80
 - 0s - loss: 1.0603 - val_loss: 0.6398
AUC: 0.8618

Epoch 8/80
 - 0s - loss: 1.0489 - val_loss: 0.6361
AUC: 0.8642

Epoch 9/80
 - 0s - loss: 1.0477 - val_loss: 0.6154
AUC: 0.8630

Epoch 10/80
 - 0s - loss: 1.0436 - val_loss: 0.5972
AUC: 0.8641

Epoch 11/80
 - 0s - loss: 1.0300 - val_loss: 0.5737
AUC: 0.8653

Epoch 12/80
 - 0s - loss: 1.0236 - val_loss: 0.5686
AUC: 0.8658

Epoch 13/80
 - 0s - loss: 1.0209 - val_loss: 0.6446
AUC: 0.8661

Epoch 14/80
 - 0s - loss: 1.0118 - val_loss: 0.6058
AUC: 0.8663

Epoch 15/80
 - 0s - loss: 1.0154 - val_loss: 0.5932
AUC: 0.8675

Epoch 16/80
 - 0s - loss: 1.0106 - val_loss: 0.5886
AUC: 0.8661

Epoch 17/80
 - 0s - loss: 1.0077 - val_loss: 0.5743
AUC: 0.8667

Epoch 18/80
 - 0s - loss: 1.0074 - val_loss: 0.6222
AUC: 0.8684

Epoch 19/80
 - 0s - loss: 1.0032 - val_loss: 0.6333
AUC: 0.8685

Epoch 20/80
 - 0s - loss: 0.9936 - val_loss: 0.6180
AUC: 0.8684

Epoch 21/80
 - 0s - loss: 0.9843 - val_loss: 0.5462
AUC: 0.8668

Epoch 22/80
 - 0s - loss: 0.9898 - val_loss: 0.5830
AUC: 0.8686

Epoch 23/80
 - 0s - loss: 0.9854 - val_loss: 0.6312
AUC: 0.8704

Epoch 24/80
 - 0s - loss: 0.9834 - val_loss: 0.5868
AUC: 0.8689

Epoch 25/80
 - 0s - loss: 0.9840 - val_loss: 0.6054
AUC: 0.8704

Epoch 26/80
 - 0s - loss: 0.9732 - val_loss: 0.5003
AUC: 0.8685

Epoch 27/80
 - 0s - loss: 0.9788 - val_loss: 0.5456
AUC: 0.8696

Epoch 28/80
 - 0s - loss: 0.9762 - val_loss: 0.5641
AUC: 0.8704

Epoch 29/80
 - 0s - loss: 0.9691 - val_loss: 0.5709
AUC: 0.8704

Epoch 30/80
 - 0s - loss: 0.9723 - val_loss: 0.5807
AUC: 0.8700

Epoch 31/80
 - 0s - loss: 0.9705 - val_loss: 0.5139
AUC: 0.8699

Epoch 32/80
 - 0s - loss: 0.9613 - val_loss: 0.5791
AUC: 0.8704

Epoch 33/80
 - 0s - loss: 0.9578 - val_loss: 0.5226
AUC: 0.8700

Epoch 34/80
 - 0s - loss: 0.9577 - val_loss: 0.5787
AUC: 0.8713

Epoch 35/80
 - 0s - loss: 0.9564 - val_loss: 0.6437
AUC: 0.8719

Epoch 36/80
 - 0s - loss: 0.9544 - val_loss: 0.5566
AUC: 0.8712

Epoch 37/80
 - 0s - loss: 0.9439 - val_loss: 0.5994
AUC: 0.8723

Epoch 38/80
 - 0s - loss: 0.9353 - val_loss: 0.5925
AUC: 0.8723

Epoch 39/80
 - 0s - loss: 0.9336 - val_loss: 0.5863
AUC: 0.8725

Epoch 40/80
 - 0s - loss: 0.9350 - val_loss: 0.5739
AUC: 0.8723

Epoch 41/80
 - 0s - loss: 0.9365 - val_loss: 0.5722
AUC: 0.8722

Epoch 42/80
 - 0s - loss: 0.9328 - val_loss: 0.5974
AUC: 0.8725

Epoch 43/80
 - 0s - loss: 0.9327 - val_loss: 0.5781
AUC: 0.8722

Epoch 44/80
 - 0s - loss: 0.9315 - val_loss: 0.5659
AUC: 0.8720

Epoch 45/80
 - 0s - loss: 0.9322 - val_loss: 0.5803
AUC: 0.8722

Epoch 46/80
 - 0s - loss: 0.9291 - val_loss: 0.6046
AUC: 0.8721

Epoch 47/80
 - 0s - loss: 0.9278 - val_loss: 0.5752
AUC: 0.8721

Epoch 48/80
 - 0s - loss: 0.9250 - val_loss: 0.5609
AUC: 0.8721

Epoch 49/80
 - 0s - loss: 0.9231 - val_loss: 0.5701
AUC: 0.8723

Epoch 50/80
 - 0s - loss: 0.9254 - val_loss: 0.5684
AUC: 0.8723

Epoch 51/80
 - 0s - loss: 0.9250 - val_loss: 0.5769
AUC: 0.8722

Epoch 52/80
 - 0s - loss: 0.9271 - val_loss: 0.5750
AUC: 0.8722

Epoch 53/80
 - 0s - loss: 0.9245 - val_loss: 0.5788
AUC: 0.8723

Epoch 54/80
 - 0s - loss: 0.9237 - val_loss: 0.5651
AUC: 0.8723

Epoch 55/80
 - 0s - loss: 0.9228 - val_loss: 0.5804
AUC: 0.8725

Epoch 56/80
 - 0s - loss: 0.9268 - val_loss: 0.5696
AUC: 0.8723

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9323 - val_loss: 0.5824
AUC: 0.8726

Epoch 2/30
 - 0s - loss: 0.9297 - val_loss: 0.5836
AUC: 0.8727

Epoch 3/30
 - 0s - loss: 0.9295 - val_loss: 0.5718
AUC: 0.8724

Epoch 4/30
 - 0s - loss: 0.9269 - val_loss: 0.5637
AUC: 0.8724

Epoch 5/30
 - 0s - loss: 0.9230 - val_loss: 0.5744
AUC: 0.8727

Epoch 6/30
 - 0s - loss: 0.9228 - val_loss: 0.5843
AUC: 0.8726

Epoch 7/30
 - 0s - loss: 0.9239 - val_loss: 0.5773
AUC: 0.8728

Epoch 8/30
 - 0s - loss: 0.9243 - val_loss: 0.5795
AUC: 0.8730

Epoch 9/30
 - 0s - loss: 0.9219 - val_loss: 0.5625
AUC: 0.8728

Epoch 10/30
 - 0s - loss: 0.9169 - val_loss: 0.5978
AUC: 0.8731

Epoch 11/30
 - 0s - loss: 0.9185 - val_loss: 0.5703
AUC: 0.8732

Epoch 12/30
 - 0s - loss: 0.9172 - val_loss: 0.5648
AUC: 0.8730

Epoch 13/30
 - 0s - loss: 0.9125 - val_loss: 0.5440
AUC: 0.8727

Epoch 14/30
 - 0s - loss: 0.9181 - val_loss: 0.5736
AUC: 0.8731

Epoch 15/30
 - 0s - loss: 0.9155 - val_loss: 0.5774
AUC: 0.8734

Epoch 16/30
 - 0s - loss: 0.9136 - val_loss: 0.5808
AUC: 0.8734

Epoch 17/30
 - 0s - loss: 0.9123 - val_loss: 0.5870
AUC: 0.8735

Epoch 18/30
 - 0s - loss: 0.9095 - val_loss: 0.5717
AUC: 0.8733

Epoch 19/30
 - 0s - loss: 0.9036 - val_loss: 0.5694
AUC: 0.8733

Epoch 20/30
 - 0s - loss: 0.9053 - val_loss: 0.5690
AUC: 0.8732

Epoch 21/30
 - 0s - loss: 0.9049 - val_loss: 0.5605
AUC: 0.8733

Epoch 22/30
 - 0s - loss: 0.9116 - val_loss: 0.5621
AUC: 0.8734

Epoch 23/30
 - 0s - loss: 0.9043 - val_loss: 0.5814
AUC: 0.8736

Epoch 24/30
 - 0s - loss: 0.9018 - val_loss: 0.5616
AUC: 0.8734

Epoch 25/30
 - 0s - loss: 0.9007 - val_loss: 0.5638
AUC: 0.8734

Epoch 26/30
 - 0s - loss: 0.8981 - val_loss: 0.5620
AUC: 0.8735

Epoch 27/30
 - 0s - loss: 0.9012 - val_loss: 0.5662
AUC: 0.8735

Epoch 28/30
 - 0s - loss: 0.8988 - val_loss: 0.5610
AUC: 0.8734

Epoch 29/30
 - 0s - loss: 0.8990 - val_loss: 0.5684
AUC: 0.8735

Epoch 30/30
 - 0s - loss: 0.9017 - val_loss: 0.5640
Using TensorFlow backend.
AUC: 0.8734

2019-03-08 03:51:55.468681: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:51:55.634966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:51:55.635010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:51:55.930223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:51:55.930273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:51:55.930282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:51:55.930558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3599
Epoch 2/80
 - 2s - loss: 0.3504
Epoch 3/80
 - 2s - loss: 0.3112
Epoch 4/80
 - 2s - loss: 0.3018
Epoch 5/80
 - 2s - loss: 0.2906
Epoch 6/80
 - 2s - loss: 0.2747
Epoch 7/80
 - 2s - loss: 0.2546
Epoch 8/80
 - 2s - loss: 0.2349
Epoch 9/80
 - 2s - loss: 0.2177
Epoch 10/80
 - 2s - loss: 0.2021
Epoch 11/80
 - 2s - loss: 0.1884
Epoch 12/80
 - 2s - loss: 0.1766
Epoch 13/80
 - 2s - loss: 0.1668
Epoch 14/80
 - 2s - loss: 0.1587
Epoch 15/80
 - 2s - loss: 0.1521
Epoch 16/80
 - 2s - loss: 0.1466
Epoch 17/80
 - 2s - loss: 0.1421
Epoch 18/80
 - 2s - loss: 0.1384
Epoch 19/80
 - 2s - loss: 0.1353
Epoch 20/80
 - 2s - loss: 0.1327
Epoch 21/80
 - 2s - loss: 0.1305
Epoch 22/80
 - 2s - loss: 0.1285
Epoch 23/80
 - 2s - loss: 0.1268
Epoch 24/80
 - 2s - loss: 0.1252
Epoch 25/80
 - 2s - loss: 0.1239
Epoch 26/80
 - 2s - loss: 0.1228
Epoch 27/80
 - 2s - loss: 0.1219
Epoch 28/80
 - 2s - loss: 0.1210
Epoch 29/80
 - 2s - loss: 0.1203
Epoch 30/80
 - 2s - loss: 0.1197
Epoch 31/80
 - 2s - loss: 0.1192
Epoch 32/80
 - 2s - loss: 0.1187
Epoch 33/80
 - 2s - loss: 0.1183
Epoch 34/80
 - 2s - loss: 0.1179
Epoch 35/80
 - 2s - loss: 0.1176
Epoch 36/80
 - 2s - loss: 0.1174
Epoch 37/80
 - 2s - loss: 0.1171
Epoch 38/80
 - 2s - loss: 0.1169
Epoch 39/80
 - 2s - loss: 0.1167
Epoch 40/80
 - 2s - loss: 0.1165
Epoch 41/80
 - 2s - loss: 0.1163
Epoch 42/80
 - 2s - loss: 0.1161
Epoch 43/80
 - 2s - loss: 0.1160
Epoch 44/80
 - 2s - loss: 0.1159
Epoch 45/80
 - 2s - loss: 0.1157
Epoch 46/80
 - 2s - loss: 0.1156
Epoch 47/80
 - 2s - loss: 0.1155
Epoch 48/80
 - 2s - loss: 0.1154
Epoch 49/80
 - 2s - loss: 0.1154
Epoch 50/80
 - 2s - loss: 0.1152
Epoch 51/80
 - 2s - loss: 0.1152
Epoch 52/80
 - 2s - loss: 0.1151
Epoch 53/80
 - 2s - loss: 0.1150
Epoch 54/80
 - 2s - loss: 0.1150
Epoch 55/80
 - 2s - loss: 0.1149
Epoch 56/80
 - 2s - loss: 0.1149
Epoch 57/80
 - 2s - loss: 0.1148
Epoch 58/80
 - 2s - loss: 0.1147
Epoch 59/80
 - 2s - loss: 0.1147
Epoch 60/80
 - 2s - loss: 0.1146
Epoch 61/80
 - 2s - loss: 0.1146
Epoch 62/80
 - 2s - loss: 0.1145
Epoch 63/80
 - 2s - loss: 0.1145
Epoch 64/80
 - 2s - loss: 0.1145
Epoch 65/80
 - 2s - loss: 0.1144
Epoch 66/80
 - 2s - loss: 0.1144
Epoch 67/80
 - 2s - loss: 0.1121
Epoch 68/80
 - 2s - loss: 0.1119
Epoch 69/80
 - 2s - loss: 0.1119
Epoch 70/80
 - 2s - loss: 0.1119
Epoch 71/80
 - 2s - loss: 0.1119
Epoch 72/80
 - 2s - loss: 0.1113
Epoch 73/80
 - 2s - loss: 0.1113
Epoch 74/80
 - 2s - loss: 0.1113
Epoch 75/80
 - 2s - loss: 0.1113
Epoch 76/80
 - 2s - loss: 0.1111
Epoch 77/80
 - 2s - loss: 0.1111
Epoch 78/80
 - 2s - loss: 0.1111
Epoch 79/80
 - 2s - loss: 0.1111
Epoch 80/80
 - 2s - loss: 0.1111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.5429 - val_loss: 1.0550
AUC: 0.7945

Epoch 2/80
 - 0s - loss: 1.7010 - val_loss: 0.7433
AUC: 0.8295

Epoch 3/80
 - 0s - loss: 1.2633 - val_loss: 0.7460
AUC: 0.8447

Epoch 4/80
 - 0s - loss: 1.1619 - val_loss: 0.7220
AUC: 0.8527

Epoch 5/80
 - 0s - loss: 1.1322 - val_loss: 0.5917
AUC: 0.8489

Epoch 6/80
 - 0s - loss: 1.0987 - val_loss: 0.6682
AUC: 0.8560

Epoch 7/80
 - 0s - loss: 1.0797 - val_loss: 0.6403
AUC: 0.8568

Epoch 8/80
 - 0s - loss: 1.0759 - val_loss: 0.6189
AUC: 0.8573

Epoch 9/80
 - 0s - loss: 1.0599 - val_loss: 0.6139
AUC: 0.8597

Epoch 10/80
 - 0s - loss: 1.0596 - val_loss: 0.6491
AUC: 0.8597

Epoch 11/80
 - 0s - loss: 1.0407 - val_loss: 0.6271
AUC: 0.8612

Epoch 12/80
 - 0s - loss: 1.0438 - val_loss: 0.6291
AUC: 0.8605

Epoch 13/80
 - 0s - loss: 1.0394 - val_loss: 0.6584
AUC: 0.8625

Epoch 14/80
 - 0s - loss: 1.0323 - val_loss: 0.6687
AUC: 0.8642

Epoch 15/80
 - 0s - loss: 1.0281 - val_loss: 0.6158
AUC: 0.8632

Epoch 16/80
 - 0s - loss: 1.0184 - val_loss: 0.6267
AUC: 0.8635

Epoch 17/80
 - 0s - loss: 1.0152 - val_loss: 0.6221
AUC: 0.8635

Epoch 18/80
 - 0s - loss: 1.0115 - val_loss: 0.6294
AUC: 0.8638

Epoch 19/80
 - 0s - loss: 1.0075 - val_loss: 0.6275
AUC: 0.8638

Epoch 20/80
 - 0s - loss: 1.0080 - val_loss: 0.6266
AUC: 0.8640

Epoch 21/80
 - 0s - loss: 1.0114 - val_loss: 0.6219
AUC: 0.8643

Epoch 22/80
 - 0s - loss: 1.0060 - val_loss: 0.6204
AUC: 0.8641

Epoch 23/80
 - 0s - loss: 1.0070 - val_loss: 0.6190
AUC: 0.8641

Epoch 24/80
 - 0s - loss: 1.0074 - val_loss: 0.6286
AUC: 0.8643

Epoch 25/80
 - 0s - loss: 1.0048 - val_loss: 0.6377
AUC: 0.8649

Epoch 26/80
 - 0s - loss: 0.9956 - val_loss: 0.6277
AUC: 0.8646

Epoch 27/80
 - 0s - loss: 1.0008 - val_loss: 0.6228
AUC: 0.8645

Epoch 28/80
 - 0s - loss: 1.0021 - val_loss: 0.6276
AUC: 0.8646

Epoch 29/80
 - 0s - loss: 1.0004 - val_loss: 0.6225
AUC: 0.8645

Epoch 30/80
 - 0s - loss: 1.0031 - val_loss: 0.6271
AUC: 0.8646

Epoch 31/80
 - 0s - loss: 0.9981 - val_loss: 0.6178
AUC: 0.8644

Epoch 32/80
 - 0s - loss: 0.9969 - val_loss: 0.6145
AUC: 0.8643

Epoch 33/80
 - 0s - loss: 0.9981 - val_loss: 0.6299
AUC: 0.8646

Epoch 34/80
 - 0s - loss: 0.9959 - val_loss: 0.6170
AUC: 0.8645

Epoch 35/80
 - 0s - loss: 1.0032 - val_loss: 0.6198
AUC: 0.8644

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0041 - val_loss: 0.6045
AUC: 0.8645

Epoch 2/30
 - 0s - loss: 0.9988 - val_loss: 0.6398
AUC: 0.8649

Epoch 3/30
 - 0s - loss: 1.0030 - val_loss: 0.6185
AUC: 0.8649

Epoch 4/30
 - 0s - loss: 1.0006 - val_loss: 0.6002
AUC: 0.8647

Epoch 5/30
 - 0s - loss: 0.9968 - val_loss: 0.6084
AUC: 0.8651

Epoch 6/30
 - 0s - loss: 1.0014 - val_loss: 0.6104
AUC: 0.8651

Epoch 7/30
 - 0s - loss: 0.9931 - val_loss: 0.6225
AUC: 0.8652

Epoch 8/30
 - 0s - loss: 0.9912 - val_loss: 0.6151
AUC: 0.8655

Epoch 9/30
 - 0s - loss: 0.9905 - val_loss: 0.6087
AUC: 0.8659

Epoch 10/30
 - 0s - loss: 0.9886 - val_loss: 0.6275
AUC: 0.8664

Epoch 11/30
 - 0s - loss: 0.9869 - val_loss: 0.6132
AUC: 0.8663

Epoch 12/30
 - 0s - loss: 0.9837 - val_loss: 0.6088
AUC: 0.8660

Epoch 13/30
 - 0s - loss: 0.9898 - val_loss: 0.5974
AUC: 0.8664

Epoch 14/30
 - 0s - loss: 0.9855 - val_loss: 0.5899
AUC: 0.8662

Epoch 15/30
 - 0s - loss: 0.9778 - val_loss: 0.6169
AUC: 0.8667

Epoch 16/30
 - 0s - loss: 0.9828 - val_loss: 0.6171
AUC: 0.8671

Epoch 17/30
 - 0s - loss: 0.9816 - val_loss: 0.6108
AUC: 0.8671

Epoch 18/30
 - 0s - loss: 0.9773 - val_loss: 0.6187
AUC: 0.8673

Epoch 19/30
 - 0s - loss: 0.9768 - val_loss: 0.6266
AUC: 0.8676

Epoch 20/30
 - 0s - loss: 0.9776 - val_loss: 0.6177
AUC: 0.8676

Epoch 21/30
 - 0s - loss: 0.9695 - val_loss: 0.6080
AUC: 0.8676

Epoch 22/30
 - 0s - loss: 0.9732 - val_loss: 0.6220
AUC: 0.8677

Epoch 23/30
 - 0s - loss: 0.9666 - val_loss: 0.6130
AUC: 0.8678

Epoch 24/30
 - 0s - loss: 0.9685 - val_loss: 0.5997
AUC: 0.8679

Epoch 25/30
 - 0s - loss: 0.9670 - val_loss: 0.6066
AUC: 0.8679

Epoch 26/30
 - 0s - loss: 0.9647 - val_loss: 0.6060
AUC: 0.8679

Epoch 27/30
 - 0s - loss: 0.9666 - val_loss: 0.6094
AUC: 0.8679

Epoch 28/30
 - 0s - loss: 0.9681 - val_loss: 0.5989
AUC: 0.8677

Epoch 29/30
 - 0s - loss: 0.9674 - val_loss: 0.6103
AUC: 0.8680

Epoch 30/30
 - 0s - loss: 0.9685 - val_loss: 0.6026
Using TensorFlow backend.
AUC: 0.8679

2019-03-08 03:55:10.495413: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:55:10.658915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:55:10.658961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:55:10.954219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:55:10.954271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:55:10.954281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:55:10.954560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3806
Epoch 2/80
 - 2s - loss: 0.3526
Epoch 3/80
 - 2s - loss: 0.3008
Epoch 4/80
 - 2s - loss: 0.2804
Epoch 5/80
 - 2s - loss: 0.2597
Epoch 6/80
 - 2s - loss: 0.2396
Epoch 7/80
 - 2s - loss: 0.2232
Epoch 8/80
 - 2s - loss: 0.2109
Epoch 9/80
 - 2s - loss: 0.1997
Epoch 10/80
 - 2s - loss: 0.1888
Epoch 11/80
 - 2s - loss: 0.1787
Epoch 12/80
 - 2s - loss: 0.1699
Epoch 13/80
 - 2s - loss: 0.1622
Epoch 14/80
 - 2s - loss: 0.1554
Epoch 15/80
 - 2s - loss: 0.1494
Epoch 16/80
 - 2s - loss: 0.1441
Epoch 17/80
 - 2s - loss: 0.1394
Epoch 18/80
 - 2s - loss: 0.1354
Epoch 19/80
 - 2s - loss: 0.1321
Epoch 20/80
 - 2s - loss: 0.1294
Epoch 21/80
 - 2s - loss: 0.1272
Epoch 22/80
 - 2s - loss: 0.1255
Epoch 23/80
 - 2s - loss: 0.1240
Epoch 24/80
 - 2s - loss: 0.1228
Epoch 25/80
 - 2s - loss: 0.1218
Epoch 26/80
 - 2s - loss: 0.1210
Epoch 27/80
 - 2s - loss: 0.1203
Epoch 28/80
 - 2s - loss: 0.1197
Epoch 29/80
 - 2s - loss: 0.1192
Epoch 30/80
 - 2s - loss: 0.1187
Epoch 31/80
 - 2s - loss: 0.1183
Epoch 32/80
 - 2s - loss: 0.1180
Epoch 33/80
 - 2s - loss: 0.1177
Epoch 34/80
 - 2s - loss: 0.1174
Epoch 35/80
 - 2s - loss: 0.1172
Epoch 36/80
 - 2s - loss: 0.1169
Epoch 37/80
 - 2s - loss: 0.1167
Epoch 38/80
 - 2s - loss: 0.1165
Epoch 39/80
 - 2s - loss: 0.1164
Epoch 40/80
 - 2s - loss: 0.1163
Epoch 41/80
 - 2s - loss: 0.1161
Epoch 42/80
 - 2s - loss: 0.1160
Epoch 43/80
 - 2s - loss: 0.1158
Epoch 44/80
 - 2s - loss: 0.1157
Epoch 45/80
 - 2s - loss: 0.1156
Epoch 46/80
 - 2s - loss: 0.1155
Epoch 47/80
 - 2s - loss: 0.1154
Epoch 48/80
 - 2s - loss: 0.1154
Epoch 49/80
 - 2s - loss: 0.1153
Epoch 50/80
 - 2s - loss: 0.1152
Epoch 51/80
 - 2s - loss: 0.1151
Epoch 52/80
 - 2s - loss: 0.1151
Epoch 53/80
 - 2s - loss: 0.1150
Epoch 54/80
 - 2s - loss: 0.1149
Epoch 55/80
 - 2s - loss: 0.1149
Epoch 56/80
 - 2s - loss: 0.1148
Epoch 57/80
 - 2s - loss: 0.1148
Epoch 58/80
 - 2s - loss: 0.1148
Epoch 59/80
 - 2s - loss: 0.1147
Epoch 60/80
 - 2s - loss: 0.1147
Epoch 61/80
 - 2s - loss: 0.1146
Epoch 62/80
 - 2s - loss: 0.1146
Epoch 63/80
 - 2s - loss: 0.1124
Epoch 64/80
 - 2s - loss: 0.1121
Epoch 65/80
 - 2s - loss: 0.1121
Epoch 66/80
 - 2s - loss: 0.1121
Epoch 67/80
 - 2s - loss: 0.1121
Epoch 68/80
 - 2s - loss: 0.1115
Epoch 69/80
 - 2s - loss: 0.1115
Epoch 70/80
 - 2s - loss: 0.1115
Epoch 71/80
 - 2s - loss: 0.1115
Epoch 72/80
 - 2s - loss: 0.1114
Epoch 73/80
 - 2s - loss: 0.1114
Epoch 74/80
 - 2s - loss: 0.1114
Epoch 75/80
 - 2s - loss: 0.1114
Epoch 76/80
 - 2s - loss: 0.1113
Epoch 77/80
 - 2s - loss: 0.1113
Epoch 78/80
 - 2s - loss: 0.1113
Epoch 79/80
 - 2s - loss: 0.1113
Epoch 80/80
 - 2s - loss: 0.1113
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.6424 - val_loss: 1.3640
AUC: 0.8130

Epoch 2/80
 - 0s - loss: 1.9227 - val_loss: 0.7872
AUC: 0.8383

Epoch 3/80
 - 0s - loss: 1.3570 - val_loss: 0.6553
AUC: 0.8492

Epoch 4/80
 - 0s - loss: 1.1925 - val_loss: 0.7016
AUC: 0.8520

Epoch 5/80
 - 0s - loss: 1.1319 - val_loss: 0.6653
AUC: 0.8533

Epoch 6/80
 - 0s - loss: 1.1091 - val_loss: 0.5765
AUC: 0.8537

Epoch 7/80
 - 0s - loss: 1.0953 - val_loss: 0.6454
AUC: 0.8565

Epoch 8/80
 - 0s - loss: 1.0767 - val_loss: 0.5972
AUC: 0.8563

Epoch 9/80
 - 0s - loss: 1.0701 - val_loss: 0.7125
AUC: 0.8589

Epoch 10/80
 - 0s - loss: 1.0621 - val_loss: 0.6262
AUC: 0.8592

Epoch 11/80
 - 0s - loss: 1.0536 - val_loss: 0.6530
AUC: 0.8600

Epoch 12/80
 - 0s - loss: 1.0432 - val_loss: 0.6640
AUC: 0.8601

Epoch 13/80
 - 0s - loss: 1.0404 - val_loss: 0.6480
AUC: 0.8596

Epoch 14/80
 - 0s - loss: 1.0330 - val_loss: 0.6011
AUC: 0.8612

Epoch 15/80
 - 0s - loss: 1.0265 - val_loss: 0.6273
AUC: 0.8623

Epoch 16/80
 - 0s - loss: 1.0312 - val_loss: 0.6467
AUC: 0.8631

Epoch 17/80
 - 0s - loss: 1.0125 - val_loss: 0.6680
AUC: 0.8629

Epoch 18/80
 - 0s - loss: 1.0168 - val_loss: 0.6509
AUC: 0.8625

Epoch 19/80
 - 0s - loss: 1.0071 - val_loss: 0.6311
AUC: 0.8626

Epoch 20/80
 - 0s - loss: 1.0080 - val_loss: 0.6354
AUC: 0.8630

Epoch 21/80
 - 0s - loss: 1.0107 - val_loss: 0.6337
AUC: 0.8636

Epoch 22/80
 - 0s - loss: 1.0079 - val_loss: 0.6304
AUC: 0.8632

Epoch 23/80
 - 0s - loss: 1.0049 - val_loss: 0.6239
AUC: 0.8629

Epoch 24/80
 - 0s - loss: 1.0060 - val_loss: 0.6086
AUC: 0.8632

Epoch 25/80
 - 0s - loss: 1.0061 - val_loss: 0.6334
AUC: 0.8635

Epoch 26/80
 - 0s - loss: 1.0033 - val_loss: 0.6293
AUC: 0.8640

Epoch 27/80
 - 0s - loss: 0.9971 - val_loss: 0.6290
AUC: 0.8637

Epoch 28/80
 - 0s - loss: 0.9983 - val_loss: 0.6154
AUC: 0.8635

Epoch 29/80
 - 0s - loss: 0.9991 - val_loss: 0.6089
AUC: 0.8634

Epoch 30/80
 - 0s - loss: 0.9977 - val_loss: 0.6212
AUC: 0.8636

Epoch 31/80
 - 0s - loss: 0.9967 - val_loss: 0.6176
AUC: 0.8636

Epoch 32/80
 - 0s - loss: 0.9968 - val_loss: 0.6230
AUC: 0.8636

Epoch 33/80
 - 0s - loss: 0.9900 - val_loss: 0.6329
AUC: 0.8637

Epoch 34/80
 - 0s - loss: 0.9984 - val_loss: 0.6241
AUC: 0.8637

Epoch 35/80
 - 0s - loss: 0.9975 - val_loss: 0.6252
AUC: 0.8636

Epoch 36/80
 - 0s - loss: 0.9954 - val_loss: 0.6228
AUC: 0.8636

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0029 - val_loss: 0.6028
AUC: 0.8632

Epoch 2/30
 - 0s - loss: 0.9981 - val_loss: 0.5972
AUC: 0.8634

Epoch 3/30
 - 0s - loss: 0.9969 - val_loss: 0.6284
AUC: 0.8639

Epoch 4/30
 - 0s - loss: 0.9953 - val_loss: 0.6310
AUC: 0.8639

Epoch 5/30
 - 0s - loss: 0.9966 - val_loss: 0.6054
AUC: 0.8639

Epoch 6/30
 - 0s - loss: 0.9912 - val_loss: 0.6265
AUC: 0.8648

Epoch 7/30
 - 0s - loss: 0.9935 - val_loss: 0.6157
AUC: 0.8643

Epoch 8/30
 - 0s - loss: 0.9936 - val_loss: 0.6251
AUC: 0.8645

Epoch 9/30
 - 0s - loss: 0.9915 - val_loss: 0.6290
AUC: 0.8652

Epoch 10/30
 - 0s - loss: 0.9838 - val_loss: 0.6240
AUC: 0.8652

Epoch 11/30
 - 0s - loss: 0.9830 - val_loss: 0.6265
AUC: 0.8652

Epoch 12/30
 - 0s - loss: 0.9834 - val_loss: 0.6232
AUC: 0.8653

Epoch 13/30
 - 0s - loss: 0.9847 - val_loss: 0.6095
AUC: 0.8653

Epoch 14/30
 - 0s - loss: 0.9776 - val_loss: 0.6155
AUC: 0.8653

Epoch 15/30
 - 0s - loss: 0.9752 - val_loss: 0.6131
AUC: 0.8652

Epoch 16/30
 - 0s - loss: 0.9787 - val_loss: 0.6127
AUC: 0.8654

Epoch 17/30
 - 0s - loss: 0.9841 - val_loss: 0.6144
AUC: 0.8654

Epoch 18/30
 - 0s - loss: 0.9805 - val_loss: 0.6144
AUC: 0.8655

Epoch 19/30
 - 0s - loss: 0.9815 - val_loss: 0.6100
AUC: 0.8654

Epoch 20/30
 - 0s - loss: 0.9816 - val_loss: 0.6121
AUC: 0.8655

Epoch 21/30
 - 0s - loss: 0.9820 - val_loss: 0.6155
AUC: 0.8656

Epoch 22/30
 - 0s - loss: 0.9712 - val_loss: 0.6136
AUC: 0.8655

Epoch 23/30
 - 0s - loss: 0.9768 - val_loss: 0.6140
AUC: 0.8655

Epoch 24/30
 - 0s - loss: 0.9770 - val_loss: 0.6122
AUC: 0.8655

Epoch 25/30
 - 0s - loss: 0.9797 - val_loss: 0.6118
AUC: 0.8656

Epoch 26/30
 - 0s - loss: 0.9767 - val_loss: 0.6132
AUC: 0.8656

Epoch 27/30
 - 0s - loss: 0.9803 - val_loss: 0.6128
AUC: 0.8656

Epoch 28/30
 - 0s - loss: 0.9732 - val_loss: 0.6134
AUC: 0.8656

Epoch 29/30
 - 0s - loss: 0.9775 - val_loss: 0.6137
AUC: 0.8656

Epoch 30/30
 - 0s - loss: 0.9770 - val_loss: 0.6128
Using TensorFlow backend.
AUC: 0.8656

2019-03-08 03:58:27.026263: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 03:58:27.190527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 03:58:27.190570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 03:58:27.486006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 03:58:27.486054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 03:58:27.486063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 03:58:27.486321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1376
Epoch 2/80
 - 2s - loss: 0.2136
Epoch 3/80
 - 2s - loss: 0.1741
Epoch 4/80
 - 2s - loss: 0.1677
Epoch 5/80
 - 2s - loss: 0.1622
Epoch 6/80
 - 2s - loss: 0.1550
Epoch 7/80
 - 2s - loss: 0.1459
Epoch 8/80
 - 2s - loss: 0.1351
Epoch 9/80
 - 2s - loss: 0.1239
Epoch 10/80
 - 2s - loss: 0.1138
Epoch 11/80
 - 2s - loss: 0.1049
Epoch 12/80
 - 2s - loss: 0.0971
Epoch 13/80
 - 2s - loss: 0.0902
Epoch 14/80
 - 2s - loss: 0.0844
Epoch 15/80
 - 2s - loss: 0.0795
Epoch 16/80
 - 2s - loss: 0.0753
Epoch 17/80
 - 2s - loss: 0.0717
Epoch 18/80
 - 2s - loss: 0.0685
Epoch 19/80
 - 2s - loss: 0.0658
Epoch 20/80
 - 2s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0616
Epoch 22/80
 - 2s - loss: 0.0601
Epoch 23/80
 - 2s - loss: 0.0588
Epoch 24/80
 - 2s - loss: 0.0577
Epoch 25/80
 - 2s - loss: 0.0568
Epoch 26/80
 - 2s - loss: 0.0560
Epoch 27/80
 - 2s - loss: 0.0554
Epoch 28/80
 - 2s - loss: 0.0548
Epoch 29/80
 - 2s - loss: 0.0543
Epoch 30/80
 - 2s - loss: 0.0538
Epoch 31/80
 - 2s - loss: 0.0534
Epoch 32/80
 - 2s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0526
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0519
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0516
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0513
Epoch 42/80
 - 2s - loss: 0.0512
Epoch 43/80
 - 2s - loss: 0.0511
Epoch 44/80
 - 2s - loss: 0.0510
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0509
Epoch 47/80
 - 2s - loss: 0.0508
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0507
Epoch 50/80
 - 2s - loss: 0.0506
Epoch 51/80
 - 2s - loss: 0.0506
Epoch 52/80
 - 2s - loss: 0.0505
Epoch 53/80
 - 2s - loss: 0.0505
Epoch 54/80
 - 2s - loss: 0.0504
Epoch 55/80
 - 2s - loss: 0.0504
Epoch 56/80
 - 2s - loss: 0.0503
Epoch 57/80
 - 2s - loss: 0.0503
Epoch 58/80
 - 2s - loss: 0.0503
Epoch 59/80
 - 2s - loss: 0.0502
Epoch 60/80
 - 2s - loss: 0.0502
Epoch 61/80
 - 2s - loss: 0.0502
Epoch 62/80
 - 2s - loss: 0.0491
Epoch 63/80
 - 2s - loss: 0.0489
Epoch 64/80
 - 2s - loss: 0.0489
Epoch 65/80
 - 2s - loss: 0.0489
Epoch 66/80
 - 2s - loss: 0.0489
Epoch 67/80
 - 2s - loss: 0.0486
Epoch 68/80
 - 2s - loss: 0.0486
Epoch 69/80
 - 2s - loss: 0.0486
Epoch 70/80
 - 2s - loss: 0.0486
Epoch 71/80
 - 2s - loss: 0.0486
Epoch 72/80
 - 2s - loss: 0.0486
Epoch 73/80
 - 2s - loss: 0.0486
Epoch 74/80
 - 2s - loss: 0.0485
Epoch 75/80
 - 2s - loss: 0.0485
Epoch 76/80
 - 2s - loss: 0.0485
Epoch 77/80
 - 2s - loss: 0.0485
Epoch 78/80
 - 2s - loss: 0.0485
Epoch 79/80
 - 2s - loss: 0.0485
Epoch 80/80
 - 2s - loss: 0.0485
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.8740 - val_loss: 0.9459
AUC: 0.7833

Epoch 2/80
 - 0s - loss: 1.9765 - val_loss: 0.7034
AUC: 0.8236

Epoch 3/80
 - 0s - loss: 1.3731 - val_loss: 0.7057
AUC: 0.8367

Epoch 4/80
 - 0s - loss: 1.2085 - val_loss: 0.6699
AUC: 0.8432

Epoch 5/80
 - 0s - loss: 1.1472 - val_loss: 0.6958
AUC: 0.8469

Epoch 6/80
 - 0s - loss: 1.1134 - val_loss: 0.6784
AUC: 0.8515

Epoch 7/80
 - 0s - loss: 1.0954 - val_loss: 0.7103
AUC: 0.8532

Epoch 8/80
 - 0s - loss: 1.0770 - val_loss: 0.6676
AUC: 0.8543

Epoch 9/80
 - 0s - loss: 1.0596 - val_loss: 0.6735
AUC: 0.8546

Epoch 10/80
 - 0s - loss: 1.0561 - val_loss: 0.6658
AUC: 0.8588

Epoch 11/80
 - 0s - loss: 1.0443 - val_loss: 0.6337
AUC: 0.8581

Epoch 12/80
 - 0s - loss: 1.0426 - val_loss: 0.6200
AUC: 0.8583

Epoch 13/80
 - 0s - loss: 1.0271 - val_loss: 0.6579
AUC: 0.8605

Epoch 14/80
 - 0s - loss: 1.0274 - val_loss: 0.6201
AUC: 0.8595

Epoch 15/80
 - 0s - loss: 1.0183 - val_loss: 0.5968
AUC: 0.8604

Epoch 16/80
 - 0s - loss: 1.0084 - val_loss: 0.5916
AUC: 0.8623

Epoch 17/80
 - 0s - loss: 1.0112 - val_loss: 0.5401
AUC: 0.8608

Epoch 18/80
 - 0s - loss: 1.0099 - val_loss: 0.5899
AUC: 0.8619

Epoch 19/80
 - 0s - loss: 1.0031 - val_loss: 0.6415
AUC: 0.8637

Epoch 20/80
 - 0s - loss: 1.0061 - val_loss: 0.5704
AUC: 0.8639

Epoch 21/80
 - 0s - loss: 0.9986 - val_loss: 0.6044
AUC: 0.8646

Epoch 22/80
 - 0s - loss: 0.9889 - val_loss: 0.5988
AUC: 0.8632

Epoch 23/80
 - 0s - loss: 0.9931 - val_loss: 0.5697
AUC: 0.8640

Epoch 24/80
 - 0s - loss: 0.9894 - val_loss: 0.5646
AUC: 0.8639

Epoch 25/80
 - 0s - loss: 0.9898 - val_loss: 0.6381
AUC: 0.8656

Epoch 26/80
 - 0s - loss: 0.9841 - val_loss: 0.6066
AUC: 0.8655

Epoch 27/80
 - 0s - loss: 0.9790 - val_loss: 0.6042
AUC: 0.8651

Epoch 28/80
 - 0s - loss: 0.9690 - val_loss: 0.6197
AUC: 0.8658

Epoch 29/80
 - 0s - loss: 0.9708 - val_loss: 0.6100
AUC: 0.8658

Epoch 30/80
 - 0s - loss: 0.9716 - val_loss: 0.6004
AUC: 0.8658

Epoch 31/80
 - 0s - loss: 0.9691 - val_loss: 0.6091
AUC: 0.8660

Epoch 32/80
 - 0s - loss: 0.9653 - val_loss: 0.5995
AUC: 0.8661

Epoch 33/80
 - 0s - loss: 0.9708 - val_loss: 0.6103
AUC: 0.8667

Epoch 34/80
 - 0s - loss: 0.9647 - val_loss: 0.5893
AUC: 0.8659

Epoch 35/80
 - 0s - loss: 0.9692 - val_loss: 0.5858
AUC: 0.8658

Epoch 36/80
 - 0s - loss: 0.9678 - val_loss: 0.6046
AUC: 0.8667

Epoch 37/80
 - 0s - loss: 0.9633 - val_loss: 0.6067
AUC: 0.8669

Epoch 38/80
 - 0s - loss: 0.9621 - val_loss: 0.5987
AUC: 0.8667

Epoch 39/80
 - 0s - loss: 0.9601 - val_loss: 0.5939
AUC: 0.8666

Epoch 40/80
 - 0s - loss: 0.9585 - val_loss: 0.5954
AUC: 0.8666

Epoch 41/80
 - 0s - loss: 0.9523 - val_loss: 0.5971
AUC: 0.8667

Epoch 42/80
 - 0s - loss: 0.9595 - val_loss: 0.6071
AUC: 0.8669

Epoch 43/80
 - 0s - loss: 0.9570 - val_loss: 0.6047
AUC: 0.8669

Epoch 44/80
 - 0s - loss: 0.9603 - val_loss: 0.6039
AUC: 0.8668

Epoch 45/80
 - 0s - loss: 0.9596 - val_loss: 0.6056
AUC: 0.8668

Epoch 46/80
 - 0s - loss: 0.9593 - val_loss: 0.5990
AUC: 0.8667

Epoch 47/80
 - 0s - loss: 0.9592 - val_loss: 0.6088
AUC: 0.8668

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9586 - val_loss: 0.6061
AUC: 0.8669

Epoch 2/30
 - 0s - loss: 0.9596 - val_loss: 0.6118
AUC: 0.8668

Epoch 3/30
 - 0s - loss: 0.9536 - val_loss: 0.5902
AUC: 0.8666

Epoch 4/30
 - 0s - loss: 0.9597 - val_loss: 0.5816
AUC: 0.8663

Epoch 5/30
 - 0s - loss: 0.9547 - val_loss: 0.5974
AUC: 0.8669

Epoch 6/30
 - 0s - loss: 0.9529 - val_loss: 0.5938
AUC: 0.8671

Epoch 7/30
 - 0s - loss: 0.9584 - val_loss: 0.5792
AUC: 0.8669

Epoch 8/30
 - 0s - loss: 0.9531 - val_loss: 0.6071
AUC: 0.8675

Epoch 9/30
 - 0s - loss: 0.9525 - val_loss: 0.6116
AUC: 0.8679

Epoch 10/30
 - 0s - loss: 0.9502 - val_loss: 0.6077
AUC: 0.8677

Epoch 11/30
 - 0s - loss: 0.9490 - val_loss: 0.5960
AUC: 0.8673

Epoch 12/30
 - 0s - loss: 0.9499 - val_loss: 0.6039
AUC: 0.8679

Epoch 13/30
 - 0s - loss: 0.9507 - val_loss: 0.5706
AUC: 0.8672

Epoch 14/30
 - 0s - loss: 0.9489 - val_loss: 0.5890
AUC: 0.8673

Epoch 15/30
 - 0s - loss: 0.9458 - val_loss: 0.6107
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.9446 - val_loss: 0.6185
AUC: 0.8682

Epoch 17/30
 - 0s - loss: 0.9439 - val_loss: 0.5787
AUC: 0.8678

Epoch 18/30
 - 0s - loss: 0.9407 - val_loss: 0.5910
AUC: 0.8680

Epoch 19/30
 - 0s - loss: 0.9420 - val_loss: 0.5896
AUC: 0.8681

Epoch 20/30
 - 0s - loss: 0.9379 - val_loss: 0.5967
AUC: 0.8683

Epoch 21/30
 - 0s - loss: 0.9363 - val_loss: 0.5904
AUC: 0.8684

Epoch 22/30
 - 0s - loss: 0.9342 - val_loss: 0.5718
AUC: 0.8682

Epoch 23/30
 - 0s - loss: 0.9333 - val_loss: 0.6010
AUC: 0.8685

Epoch 24/30
 - 0s - loss: 0.9368 - val_loss: 0.5913
AUC: 0.8684

Epoch 25/30
 - 0s - loss: 0.9348 - val_loss: 0.5955
AUC: 0.8686

Epoch 26/30
 - 0s - loss: 0.9329 - val_loss: 0.5864
AUC: 0.8684

Epoch 27/30
 - 0s - loss: 0.9329 - val_loss: 0.5867
AUC: 0.8684

Epoch 28/30
 - 0s - loss: 0.9351 - val_loss: 0.5847
AUC: 0.8684

Epoch 29/30
 - 0s - loss: 0.9274 - val_loss: 0.5890
AUC: 0.8685

Epoch 30/30
 - 0s - loss: 0.9327 - val_loss: 0.5881
Using TensorFlow backend.
AUC: 0.8686

2019-03-08 04:01:49.077471: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:01:49.242686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:01:49.242728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:01:49.536344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:01:49.536395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:01:49.536404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:01:49.536715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1531
Epoch 2/80
 - 2s - loss: 0.2170
Epoch 3/80
 - 2s - loss: 0.1744
Epoch 4/80
 - 2s - loss: 0.1678
Epoch 5/80
 - 2s - loss: 0.1618
Epoch 6/80
 - 2s - loss: 0.1537
Epoch 7/80
 - 2s - loss: 0.1423
Epoch 8/80
 - 2s - loss: 0.1296
Epoch 9/80
 - 2s - loss: 0.1183
Epoch 10/80
 - 2s - loss: 0.1089
Epoch 11/80
 - 2s - loss: 0.1009
Epoch 12/80
 - 2s - loss: 0.0939
Epoch 13/80
 - 2s - loss: 0.0878
Epoch 14/80
 - 2s - loss: 0.0827
Epoch 15/80
 - 2s - loss: 0.0784
Epoch 16/80
 - 2s - loss: 0.0748
Epoch 17/80
 - 2s - loss: 0.0716
Epoch 18/80
 - 2s - loss: 0.0688
Epoch 19/80
 - 2s - loss: 0.0663
Epoch 20/80
 - 2s - loss: 0.0642
Epoch 21/80
 - 2s - loss: 0.0624
Epoch 22/80
 - 2s - loss: 0.0608
Epoch 23/80
 - 2s - loss: 0.0595
Epoch 24/80
 - 2s - loss: 0.0584
Epoch 25/80
 - 2s - loss: 0.0574
Epoch 26/80
 - 2s - loss: 0.0565
Epoch 27/80
 - 2s - loss: 0.0558
Epoch 28/80
 - 2s - loss: 0.0552
Epoch 29/80
 - 2s - loss: 0.0546
Epoch 30/80
 - 2s - loss: 0.0541
Epoch 31/80
 - 2s - loss: 0.0537
Epoch 32/80
 - 2s - loss: 0.0534
Epoch 33/80
 - 2s - loss: 0.0530
Epoch 34/80
 - 2s - loss: 0.0527
Epoch 35/80
 - 2s - loss: 0.0525
Epoch 36/80
 - 2s - loss: 0.0523
Epoch 37/80
 - 2s - loss: 0.0521
Epoch 38/80
 - 2s - loss: 0.0519
Epoch 39/80
 - 2s - loss: 0.0518
Epoch 40/80
 - 2s - loss: 0.0516
Epoch 41/80
 - 2s - loss: 0.0515
Epoch 42/80
 - 2s - loss: 0.0514
Epoch 43/80
 - 2s - loss: 0.0513
Epoch 44/80
 - 2s - loss: 0.0512
Epoch 45/80
 - 2s - loss: 0.0511
Epoch 46/80
 - 2s - loss: 0.0510
Epoch 47/80
 - 2s - loss: 0.0509
Epoch 48/80
 - 2s - loss: 0.0509
Epoch 49/80
 - 2s - loss: 0.0508
Epoch 50/80
 - 2s - loss: 0.0507
Epoch 51/80
 - 2s - loss: 0.0507
Epoch 52/80
 - 2s - loss: 0.0506
Epoch 53/80
 - 2s - loss: 0.0506
Epoch 54/80
 - 2s - loss: 0.0505
Epoch 55/80
 - 2s - loss: 0.0505
Epoch 56/80
 - 2s - loss: 0.0504
Epoch 57/80
 - 2s - loss: 0.0504
Epoch 58/80
 - 2s - loss: 0.0504
Epoch 59/80
 - 2s - loss: 0.0503
Epoch 60/80
 - 2s - loss: 0.0503
Epoch 61/80
 - 2s - loss: 0.0503
Epoch 62/80
 - 2s - loss: 0.0492
Epoch 63/80
 - 2s - loss: 0.0490
Epoch 64/80
 - 2s - loss: 0.0490
Epoch 65/80
 - 2s - loss: 0.0490
Epoch 66/80
 - 2s - loss: 0.0490
Epoch 67/80
 - 2s - loss: 0.0487
Epoch 68/80
 - 2s - loss: 0.0487
Epoch 69/80
 - 2s - loss: 0.0487
Epoch 70/80
 - 2s - loss: 0.0487
Epoch 71/80
 - 2s - loss: 0.0487
Epoch 72/80
 - 2s - loss: 0.0487
Epoch 73/80
 - 2s - loss: 0.0487
Epoch 74/80
 - 2s - loss: 0.0486
Epoch 75/80
 - 2s - loss: 0.0486
Epoch 76/80
 - 2s - loss: 0.0486
Epoch 77/80
 - 2s - loss: 0.0486
Epoch 78/80
 - 2s - loss: 0.0486
Epoch 79/80
 - 2s - loss: 0.0486
Epoch 80/80
 - 2s - loss: 0.0486
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.4016 - val_loss: 1.1514
AUC: 0.8134

Epoch 2/80
 - 0s - loss: 2.3560 - val_loss: 0.9752
AUC: 0.8473

Epoch 3/80
 - 0s - loss: 1.5585 - val_loss: 0.6813
AUC: 0.8474

Epoch 4/80
 - 0s - loss: 1.2557 - val_loss: 0.6477
AUC: 0.8549

Epoch 5/80
 - 0s - loss: 1.1746 - val_loss: 0.6001
AUC: 0.8570

Epoch 6/80
 - 0s - loss: 1.1396 - val_loss: 0.6558
AUC: 0.8640

Epoch 7/80
 - 0s - loss: 1.1067 - val_loss: 0.6929
AUC: 0.8651

Epoch 8/80
 - 0s - loss: 1.0917 - val_loss: 0.5992
AUC: 0.8657

Epoch 9/80
 - 0s - loss: 1.0707 - val_loss: 0.6324
AUC: 0.8692

Epoch 10/80
 - 0s - loss: 1.0673 - val_loss: 0.5792
AUC: 0.8674

Epoch 11/80
 - 0s - loss: 1.0656 - val_loss: 0.6836
AUC: 0.8719

Epoch 12/80
 - 0s - loss: 1.0514 - val_loss: 0.5657
AUC: 0.8687

Epoch 13/80
 - 0s - loss: 1.0414 - val_loss: 0.7037
AUC: 0.8733

Epoch 14/80
 - 0s - loss: 1.0346 - val_loss: 0.6243
AUC: 0.8719

Epoch 15/80
 - 0s - loss: 1.0348 - val_loss: 0.5537
AUC: 0.8708

Epoch 16/80
 - 0s - loss: 1.0339 - val_loss: 0.6397
AUC: 0.8733

Epoch 17/80
 - 0s - loss: 1.0294 - val_loss: 0.6902
AUC: 0.8756

Epoch 18/80
 - 0s - loss: 1.0200 - val_loss: 0.5790
AUC: 0.8735

Epoch 19/80
 - 0s - loss: 1.0195 - val_loss: 0.5884
AUC: 0.8721

Epoch 20/80
 - 0s - loss: 1.0124 - val_loss: 0.5822
AUC: 0.8746

Epoch 21/80
 - 0s - loss: 1.0059 - val_loss: 0.5654
AUC: 0.8750

Epoch 22/80
 - 0s - loss: 1.0115 - val_loss: 0.6330
AUC: 0.8757

Epoch 23/80
 - 0s - loss: 1.0064 - val_loss: 0.6162
AUC: 0.8756

Epoch 24/80
 - 0s - loss: 1.0005 - val_loss: 0.6215
AUC: 0.8768

Epoch 25/80
 - 0s - loss: 0.9966 - val_loss: 0.6627
AUC: 0.8763

Epoch 26/80
 - 0s - loss: 0.9878 - val_loss: 0.5903
AUC: 0.8765

Epoch 27/80
 - 0s - loss: 0.9859 - val_loss: 0.6134
AUC: 0.8770

Epoch 28/80
 - 0s - loss: 0.9773 - val_loss: 0.5725
AUC: 0.8759

Epoch 29/80
 - 0s - loss: 0.9782 - val_loss: 0.6018
AUC: 0.8767

Epoch 30/80
 - 0s - loss: 0.9769 - val_loss: 0.6380
AUC: 0.8774

Epoch 31/80
 - 0s - loss: 0.9833 - val_loss: 0.6167
AUC: 0.8771

Epoch 32/80
 - 0s - loss: 0.9751 - val_loss: 0.5836
AUC: 0.8762

Epoch 33/80
 - 0s - loss: 0.9838 - val_loss: 0.5862
AUC: 0.8762

Epoch 34/80
 - 0s - loss: 0.9773 - val_loss: 0.6108
AUC: 0.8770

Epoch 35/80
 - 0s - loss: 0.9756 - val_loss: 0.6214
AUC: 0.8772

Epoch 36/80
 - 0s - loss: 0.9775 - val_loss: 0.6050
AUC: 0.8771

Epoch 37/80
 - 0s - loss: 0.9739 - val_loss: 0.6091
AUC: 0.8772

Epoch 38/80
 - 0s - loss: 0.9725 - val_loss: 0.6051
AUC: 0.8771

Epoch 39/80
 - 0s - loss: 0.9714 - val_loss: 0.6051
AUC: 0.8770

Epoch 40/80
 - 0s - loss: 0.9711 - val_loss: 0.6017
AUC: 0.8770

Epoch 41/80
 - 0s - loss: 0.9716 - val_loss: 0.5939
AUC: 0.8769

Epoch 42/80
 - 0s - loss: 0.9730 - val_loss: 0.6075
AUC: 0.8771

Epoch 43/80
 - 0s - loss: 0.9714 - val_loss: 0.5991
AUC: 0.8768

Epoch 44/80
 - 0s - loss: 0.9654 - val_loss: 0.6149
AUC: 0.8772

Epoch 45/80
 - 0s - loss: 0.9700 - val_loss: 0.6105
AUC: 0.8772

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9827 - val_loss: 0.5850
AUC: 0.8765

Epoch 2/30
 - 0s - loss: 0.9807 - val_loss: 0.6054
AUC: 0.8767

Epoch 3/30
 - 0s - loss: 0.9707 - val_loss: 0.6307
AUC: 0.8776

Epoch 4/30
 - 0s - loss: 0.9771 - val_loss: 0.5958
AUC: 0.8770

Epoch 5/30
 - 0s - loss: 0.9727 - val_loss: 0.6022
AUC: 0.8770

Epoch 6/30
 - 0s - loss: 0.9713 - val_loss: 0.6053
AUC: 0.8775

Epoch 7/30
 - 0s - loss: 0.9685 - val_loss: 0.5938
AUC: 0.8773

Epoch 8/30
 - 0s - loss: 0.9655 - val_loss: 0.6175
AUC: 0.8777

Epoch 9/30
 - 0s - loss: 0.9661 - val_loss: 0.5835
AUC: 0.8773

Epoch 10/30
 - 0s - loss: 0.9571 - val_loss: 0.5929
AUC: 0.8775

Epoch 11/30
 - 0s - loss: 0.9631 - val_loss: 0.5978
AUC: 0.8776

Epoch 12/30
 - 0s - loss: 0.9540 - val_loss: 0.5953
AUC: 0.8777

Epoch 13/30
 - 0s - loss: 0.9587 - val_loss: 0.5861
AUC: 0.8778

Epoch 14/30
 - 0s - loss: 0.9559 - val_loss: 0.5739
AUC: 0.8778

Epoch 15/30
 - 0s - loss: 0.9703 - val_loss: 0.5993
AUC: 0.8781

Epoch 16/30
 - 0s - loss: 0.9616 - val_loss: 0.5789
AUC: 0.8777

Epoch 17/30
 - 0s - loss: 0.9548 - val_loss: 0.5868
AUC: 0.8780

Epoch 18/30
 - 0s - loss: 0.9554 - val_loss: 0.6062
AUC: 0.8783

Epoch 19/30
 - 0s - loss: 0.9549 - val_loss: 0.5910
AUC: 0.8781

Epoch 20/30
 - 0s - loss: 0.9520 - val_loss: 0.5939
AUC: 0.8783

Epoch 21/30
 - 0s - loss: 0.9523 - val_loss: 0.5832
AUC: 0.8782

Epoch 22/30
 - 0s - loss: 0.9533 - val_loss: 0.5657
AUC: 0.8779

Epoch 23/30
 - 0s - loss: 0.9501 - val_loss: 0.5787
AUC: 0.8780

Epoch 24/30
 - 0s - loss: 0.9495 - val_loss: 0.6041
AUC: 0.8785

Epoch 25/30
 - 0s - loss: 0.9464 - val_loss: 0.5949
AUC: 0.8782

Epoch 26/30
 - 0s - loss: 0.9428 - val_loss: 0.5619
AUC: 0.8783

Epoch 27/30
 - 0s - loss: 0.9462 - val_loss: 0.6005
AUC: 0.8788

Epoch 28/30
 - 0s - loss: 0.9512 - val_loss: 0.5881
AUC: 0.8784

Epoch 29/30
 - 0s - loss: 0.9394 - val_loss: 0.5674
AUC: 0.8786

Epoch 30/30
 - 0s - loss: 0.9410 - val_loss: 0.5868
Using TensorFlow backend.
AUC: 0.8790

2019-03-08 04:05:09.463273: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:05:09.628590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:05:09.628629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:05:09.920274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:05:09.920324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:05:09.920333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:05:09.920589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1383
Epoch 2/80
 - 2s - loss: 0.2135
Epoch 3/80
 - 2s - loss: 0.1721
Epoch 4/80
 - 2s - loss: 0.1648
Epoch 5/80
 - 2s - loss: 0.1581
Epoch 6/80
 - 2s - loss: 0.1504
Epoch 7/80
 - 2s - loss: 0.1422
Epoch 8/80
 - 2s - loss: 0.1336
Epoch 9/80
 - 2s - loss: 0.1239
Epoch 10/80
 - 2s - loss: 0.1138
Epoch 11/80
 - 2s - loss: 0.1046
Epoch 12/80
 - 2s - loss: 0.0968
Epoch 13/80
 - 2s - loss: 0.0902
Epoch 14/80
 - 2s - loss: 0.0848
Epoch 15/80
 - 2s - loss: 0.0801
Epoch 16/80
 - 2s - loss: 0.0761
Epoch 17/80
 - 2s - loss: 0.0725
Epoch 18/80
 - 2s - loss: 0.0695
Epoch 19/80
 - 2s - loss: 0.0668
Epoch 20/80
 - 2s - loss: 0.0646
Epoch 21/80
 - 2s - loss: 0.0626
Epoch 22/80
 - 2s - loss: 0.0610
Epoch 23/80
 - 2s - loss: 0.0596
Epoch 24/80
 - 2s - loss: 0.0584
Epoch 25/80
 - 2s - loss: 0.0574
Epoch 26/80
 - 2s - loss: 0.0565
Epoch 27/80
 - 2s - loss: 0.0558
Epoch 28/80
 - 2s - loss: 0.0551
Epoch 29/80
 - 2s - loss: 0.0546
Epoch 30/80
 - 2s - loss: 0.0541
Epoch 31/80
 - 2s - loss: 0.0537
Epoch 32/80
 - 2s - loss: 0.0533
Epoch 33/80
 - 2s - loss: 0.0530
Epoch 34/80
 - 2s - loss: 0.0527
Epoch 35/80
 - 2s - loss: 0.0524
Epoch 36/80
 - 2s - loss: 0.0522
Epoch 37/80
 - 2s - loss: 0.0520
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0516
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0513
Epoch 42/80
 - 2s - loss: 0.0512
Epoch 43/80
 - 2s - loss: 0.0511
Epoch 44/80
 - 2s - loss: 0.0510
Epoch 45/80
 - 2s - loss: 0.0509
Epoch 46/80
 - 2s - loss: 0.0508
Epoch 47/80
 - 2s - loss: 0.0507
Epoch 48/80
 - 2s - loss: 0.0507
Epoch 49/80
 - 2s - loss: 0.0506
Epoch 50/80
 - 2s - loss: 0.0505
Epoch 51/80
 - 2s - loss: 0.0505
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0504
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0503
Epoch 56/80
 - 2s - loss: 0.0503
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0502
Epoch 59/80
 - 2s - loss: 0.0491
Epoch 60/80
 - 2s - loss: 0.0490
Epoch 61/80
 - 2s - loss: 0.0489
Epoch 62/80
 - 2s - loss: 0.0489
Epoch 63/80
 - 2s - loss: 0.0489
Epoch 64/80
 - 2s - loss: 0.0486
Epoch 65/80
 - 2s - loss: 0.0486
Epoch 66/80
 - 2s - loss: 0.0486
Epoch 67/80
 - 2s - loss: 0.0486
Epoch 68/80
 - 2s - loss: 0.0486
Epoch 69/80
 - 2s - loss: 0.0486
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 04:07:20.126833: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:07:20.290361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:07:20.290406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:07:20.581135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:07:20.581223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:07:20.581248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:07:20.581582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6967
Epoch 2/80
 - 2s - loss: 0.1349
Epoch 3/80
 - 2s - loss: 0.0720
Epoch 4/80
 - 2s - loss: 0.0655
Epoch 5/80
 - 2s - loss: 0.0627
Epoch 6/80
 - 2s - loss: 0.0601
Epoch 7/80
 - 2s - loss: 0.0571
Epoch 8/80
 - 2s - loss: 0.0537
Epoch 9/80
 - 2s - loss: 0.0502
Epoch 10/80
 - 2s - loss: 0.0468
Epoch 11/80
 - 2s - loss: 0.0435
Epoch 12/80
 - 2s - loss: 0.0404
Epoch 13/80
 - 2s - loss: 0.0375
Epoch 14/80
 - 2s - loss: 0.0348
Epoch 15/80
 - 2s - loss: 0.0324
Epoch 16/80
 - 2s - loss: 0.0303
Epoch 17/80
 - 2s - loss: 0.0284
Epoch 18/80
 - 2s - loss: 0.0268
Epoch 19/80
 - 2s - loss: 0.0254
Epoch 20/80
 - 2s - loss: 0.0242
Epoch 21/80
 - 2s - loss: 0.0232
Epoch 22/80
 - 2s - loss: 0.0223
Epoch 23/80
 - 2s - loss: 0.0216
Epoch 24/80
 - 2s - loss: 0.0209
Epoch 25/80
 - 2s - loss: 0.0203
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0194
Epoch 28/80
 - 2s - loss: 0.0191
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0182
Epoch 32/80
 - 2s - loss: 0.0180
Epoch 33/80
 - 2s - loss: 0.0178
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0175
Epoch 36/80
 - 2s - loss: 0.0174
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0172
Epoch 39/80
 - 2s - loss: 0.0171
Epoch 40/80
 - 2s - loss: 0.0170
Epoch 41/80
 - 2s - loss: 0.0169
Epoch 42/80
 - 2s - loss: 0.0168
Epoch 43/80
 - 2s - loss: 0.0168
Epoch 44/80
 - 2s - loss: 0.0167
Epoch 45/80
 - 2s - loss: 0.0167
Epoch 46/80
 - 2s - loss: 0.0166
Epoch 47/80
 - 2s - loss: 0.0166
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0165
Epoch 50/80
 - 2s - loss: 0.0165
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0164
Epoch 53/80
 - 2s - loss: 0.0160
Epoch 54/80
 - 2s - loss: 0.0160
Epoch 55/80
 - 2s - loss: 0.0160
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0159
Epoch 58/80
 - 2s - loss: 0.0159
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0158
Epoch 61/80
 - 2s - loss: 0.0158
Epoch 62/80
 - 2s - loss: 0.0158
Epoch 63/80
 - 2s - loss: 0.0158
Epoch 64/80
 - 2s - loss: 0.0158
Epoch 65/80
 - 2s - loss: 0.0158
Epoch 66/80
 - 2s - loss: 0.0158
Epoch 67/80
 - 2s - loss: 0.0158
Epoch 68/80
 - 2s - loss: 0.0158
Epoch 69/80
 - 2s - loss: 0.0158
Epoch 70/80
 - 2s - loss: 0.0158
Epoch 71/80
 - 2s - loss: 0.0158
Epoch 72/80
 - 2s - loss: 0.0158
Epoch 73/80
 - 2s - loss: 0.0158
Epoch 74/80
 - 2s - loss: 0.0158
Epoch 75/80
 - 2s - loss: 0.0158
Epoch 76/80
 - 2s - loss: 0.0158
Epoch 77/80
 - 2s - loss: 0.0158
Epoch 78/80
 - 2s - loss: 0.0158
Epoch 79/80
 - 2s - loss: 0.0158
Epoch 80/80
 - 2s - loss: 0.0158
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 108, in train_glove
    model.load_weights(cache_path+'glove_temp.h5')
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1161, in load_weights
    f, self.layers, reshape=reshape)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 908, in load_weights_from_hdf5_group
    weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 908, in <listcomp>
    weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 177, in __getitem__
    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5o.pyx", line 190, in h5py.h5o.open
KeyError: 'Unable to open object (bad local heap signature)'
2019-03-08 04:09:47.907711: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:09:48.072906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:09:48.072948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:09:48.366563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:09:48.366610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:09:48.366619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:09:48.366875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.7101
Epoch 2/80
 - 2s - loss: 0.1406
Epoch 3/80
 - 2s - loss: 0.0734
Epoch 4/80
 - 2s - loss: 0.0657
Epoch 5/80
 - 2s - loss: 0.0628
Epoch 6/80
 - 2s - loss: 0.0609
Epoch 7/80
 - 2s - loss: 0.0588
Epoch 8/80
 - 2s - loss: 0.0561
Epoch 9/80
 - 2s - loss: 0.0527
Epoch 10/80
 - 2s - loss: 0.0487
Epoch 11/80
 - 2s - loss: 0.0445
Epoch 12/80
 - 2s - loss: 0.0405
Epoch 13/80
 - 2s - loss: 0.0372
Epoch 14/80
 - 2s - loss: 0.0343
Epoch 15/80
 - 2s - loss: 0.0318
Epoch 16/80
 - 2s - loss: 0.0298
Epoch 17/80
 - 2s - loss: 0.0280
Epoch 18/80
 - 2s - loss: 0.0264
Epoch 19/80
 - 2s - loss: 0.0251
Epoch 20/80
 - 2s - loss: 0.0239
Epoch 21/80
 - 2s - loss: 0.0230
Epoch 22/80
 - 2s - loss: 0.0222
Epoch 23/80
 - 2s - loss: 0.0215
Epoch 24/80
 - 2s - loss: 0.0209
Epoch 25/80
 - 2s - loss: 0.0204
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0195
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0186
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0178
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Epoch 53/80
 - 2s - loss: 0.0162
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0160
Epoch 60/80
 - 2s - loss: 0.0160
Epoch 61/80
 - 2s - loss: 0.0160
Epoch 62/80
 - 2s - loss: 0.0160
Epoch 63/80
 - 2s - loss: 0.0160
Epoch 64/80
 - 2s - loss: 0.0160
Epoch 65/80
 - 2s - loss: 0.0160
Epoch 66/80
 - 2s - loss: 0.0160
Epoch 67/80
 - 2s - loss: 0.0160
Epoch 68/80
 - 2s - loss: 0.0160
Epoch 69/80
 - 2s - loss: 0.0160
Epoch 70/80
 - 2s - loss: 0.0160
Epoch 71/80
 - 2s - loss: 0.0160
Epoch 72/80
 - 2s - loss: 0.0160
Epoch 73/80
 - 2s - loss: 0.0160
Epoch 74/80
 - 2s - loss: 0.0160
Epoch 75/80
 - 2s - loss: 0.0160
Epoch 76/80
 - 2s - loss: 0.0160
Epoch 77/80
 - 2s - loss: 0.0160
Epoch 78/80
 - 2s - loss: 0.0160
Epoch 79/80
 - 2s - loss: 0.0160
Epoch 80/80
 - 2s - loss: 0.0160
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.2379 - val_loss: 1.0417
AUC: 0.8107

Epoch 2/80
 - 0s - loss: 1.6810 - val_loss: 0.6975
AUC: 0.8342

Epoch 3/80
 - 0s - loss: 1.2476 - val_loss: 0.6936
AUC: 0.8435

Epoch 4/80
 - 0s - loss: 1.1669 - val_loss: 0.6729
AUC: 0.8487

Epoch 5/80
 - 0s - loss: 1.1220 - val_loss: 0.6853
AUC: 0.8516

Epoch 6/80
 - 0s - loss: 1.0918 - val_loss: 0.6129
AUC: 0.8539

Epoch 7/80
 - 0s - loss: 1.0884 - val_loss: 0.6656
AUC: 0.8588

Epoch 8/80
 - 0s - loss: 1.0640 - val_loss: 0.5662
AUC: 0.8569

Epoch 9/80
 - 0s - loss: 1.0571 - val_loss: 0.6724
AUC: 0.8602

Epoch 10/80
 - 0s - loss: 1.0468 - val_loss: 0.6420
AUC: 0.8601

Epoch 11/80
 - 0s - loss: 1.0379 - val_loss: 0.5622
AUC: 0.8590

Epoch 12/80
 - 0s - loss: 1.0388 - val_loss: 0.6480
AUC: 0.8617

Epoch 13/80
 - 0s - loss: 1.0299 - val_loss: 0.6277
AUC: 0.8627

Epoch 14/80
 - 0s - loss: 1.0244 - val_loss: 0.6478
AUC: 0.8642

Epoch 15/80
 - 0s - loss: 1.0206 - val_loss: 0.6275
AUC: 0.8634

Epoch 16/80
 - 0s - loss: 1.0195 - val_loss: 0.6995
AUC: 0.8646

Epoch 17/80
 - 0s - loss: 1.0174 - val_loss: 0.5806
AUC: 0.8638

Epoch 18/80
 - 0s - loss: 1.0081 - val_loss: 0.6629
AUC: 0.8651

Epoch 19/80
 - 0s - loss: 1.0020 - val_loss: 0.5505
AUC: 0.8651

Epoch 20/80
 - 0s - loss: 1.0077 - val_loss: 0.5751
AUC: 0.8651

Epoch 21/80
 - 0s - loss: 0.9990 - val_loss: 0.5596
AUC: 0.8658

Epoch 22/80
 - 0s - loss: 0.9951 - val_loss: 0.7218
AUC: 0.8671

Epoch 23/80
 - 0s - loss: 1.0014 - val_loss: 0.6418
AUC: 0.8679

Epoch 24/80
 - 0s - loss: 0.9930 - val_loss: 0.5935
AUC: 0.8665

Epoch 25/80
 - 0s - loss: 0.9873 - val_loss: 0.5842
AUC: 0.8671

Epoch 26/80
 - 0s - loss: 0.9818 - val_loss: 0.5840
AUC: 0.8670

Epoch 27/80
 - 0s - loss: 0.9817 - val_loss: 0.6370
AUC: 0.8685

Epoch 28/80
 - 0s - loss: 0.9756 - val_loss: 0.5916
AUC: 0.8671

Epoch 29/80
 - 0s - loss: 0.9775 - val_loss: 0.6493
AUC: 0.8673

Epoch 30/80
 - 0s - loss: 0.9666 - val_loss: 0.6119
AUC: 0.8687

Epoch 31/80
 - 0s - loss: 0.9641 - val_loss: 0.6001
AUC: 0.8684

Epoch 32/80
 - 0s - loss: 0.9607 - val_loss: 0.6023
AUC: 0.8688

Epoch 33/80
 - 0s - loss: 0.9611 - val_loss: 0.6112
AUC: 0.8684

Epoch 34/80
 - 0s - loss: 0.9622 - val_loss: 0.6271
AUC: 0.8684

Epoch 35/80
 - 0s - loss: 0.9598 - val_loss: 0.5999
AUC: 0.8685

Epoch 36/80
 - 0s - loss: 0.9610 - val_loss: 0.5921
AUC: 0.8683

Epoch 37/80
 - 0s - loss: 0.9570 - val_loss: 0.5775
AUC: 0.8681

Epoch 38/80
 - 0s - loss: 0.9536 - val_loss: 0.6249
AUC: 0.8689

Epoch 39/80
 - 0s - loss: 0.9594 - val_loss: 0.6164
AUC: 0.8690

Epoch 40/80
 - 0s - loss: 0.9541 - val_loss: 0.6063
AUC: 0.8691

Epoch 41/80
 - 0s - loss: 0.9544 - val_loss: 0.5970
AUC: 0.8689

Epoch 42/80
 - 0s - loss: 0.9486 - val_loss: 0.6044
AUC: 0.8691

Epoch 43/80
 - 0s - loss: 0.9523 - val_loss: 0.6012
AUC: 0.8689

Epoch 44/80
 - 0s - loss: 0.9499 - val_loss: 0.5952
AUC: 0.8689

Epoch 45/80
 - 0s - loss: 0.9540 - val_loss: 0.5945
AUC: 0.8689

Epoch 46/80
 - 0s - loss: 0.9480 - val_loss: 0.5945
AUC: 0.8689

Epoch 47/80
 - 0s - loss: 0.9517 - val_loss: 0.6031
AUC: 0.8689

Epoch 48/80
 - 0s - loss: 0.9502 - val_loss: 0.5908
AUC: 0.8688

Epoch 49/80
 - 0s - loss: 0.9490 - val_loss: 0.5936
AUC: 0.8688

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9532 - val_loss: 0.5872
AUC: 0.8687

Epoch 2/30
 - 0s - loss: 0.9548 - val_loss: 0.5865
AUC: 0.8688

Epoch 3/30
 - 0s - loss: 0.9496 - val_loss: 0.6087
AUC: 0.8689

Epoch 4/30
 - 0s - loss: 0.9485 - val_loss: 0.6113
AUC: 0.8693

Epoch 5/30
 - 0s - loss: 0.9494 - val_loss: 0.6095
AUC: 0.8694

Epoch 6/30
 - 0s - loss: 0.9466 - val_loss: 0.6000
AUC: 0.8693

Epoch 7/30
 - 0s - loss: 0.9460 - val_loss: 0.5882
AUC: 0.8692

Epoch 8/30
 - 0s - loss: 0.9422 - val_loss: 0.5997
AUC: 0.8692

Epoch 9/30
 - 0s - loss: 0.9374 - val_loss: 0.5791
AUC: 0.8694

Epoch 10/30
 - 0s - loss: 0.9416 - val_loss: 0.5801
AUC: 0.8696

Epoch 11/30
 - 0s - loss: 0.9394 - val_loss: 0.5895
AUC: 0.8696

Epoch 12/30
 - 0s - loss: 0.9376 - val_loss: 0.5963
AUC: 0.8696

Epoch 13/30
 - 0s - loss: 0.9410 - val_loss: 0.5870
AUC: 0.8698

Epoch 14/30
 - 0s - loss: 0.9368 - val_loss: 0.5820
AUC: 0.8696

Epoch 15/30
 - 0s - loss: 0.9358 - val_loss: 0.6075
AUC: 0.8700

Epoch 16/30
 - 0s - loss: 0.9315 - val_loss: 0.5813
AUC: 0.8697

Epoch 17/30
 - 0s - loss: 0.9348 - val_loss: 0.5808
AUC: 0.8697

Epoch 18/30
 - 0s - loss: 0.9323 - val_loss: 0.6062
AUC: 0.8702

Epoch 19/30
 - 0s - loss: 0.9304 - val_loss: 0.5967
AUC: 0.8701

Epoch 20/30
 - 0s - loss: 0.9288 - val_loss: 0.5947
AUC: 0.8701

Epoch 21/30
 - 0s - loss: 0.9322 - val_loss: 0.5836
AUC: 0.8699

Epoch 22/30
 - 0s - loss: 0.9273 - val_loss: 0.5851
AUC: 0.8699

Epoch 23/30
 - 0s - loss: 0.9275 - val_loss: 0.5951
AUC: 0.8700

Epoch 24/30
 - 0s - loss: 0.9320 - val_loss: 0.5898
AUC: 0.8699

Epoch 25/30
 - 0s - loss: 0.9307 - val_loss: 0.5876
AUC: 0.8700

Epoch 26/30
 - 0s - loss: 0.9247 - val_loss: 0.5911
AUC: 0.8700

Epoch 27/30
 - 0s - loss: 0.9254 - val_loss: 0.5833
AUC: 0.8700

Epoch 28/30
 - 0s - loss: 0.9295 - val_loss: 0.5823
AUC: 0.8700

Epoch 29/30
 - 0s - loss: 0.9282 - val_loss: 0.5845
AUC: 0.8700

Epoch 30/30
 - 0s - loss: 0.9272 - val_loss: 0.5861
Using TensorFlow backend.
AUC: 0.8700

2019-03-08 04:13:11.879971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:13:12.055586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:13:12.055629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:13:12.349395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:13:12.349446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:13:12.349455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:13:12.349722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.7156
Epoch 2/80
 - 2s - loss: 0.1445
Epoch 3/80
 - 2s - loss: 0.0699
Epoch 4/80
 - 2s - loss: 0.0608
Epoch 5/80
 - 2s - loss: 0.0562
Epoch 6/80
 - 2s - loss: 0.0528
Epoch 7/80
 - 2s - loss: 0.0498
Epoch 8/80
 - 2s - loss: 0.0469
Epoch 9/80
 - 2s - loss: 0.0442
Epoch 10/80
 - 2s - loss: 0.0414
Epoch 11/80
 - 2s - loss: 0.0389
Epoch 12/80
 - 2s - loss: 0.0366
Epoch 13/80
 - 2s - loss: 0.0345
Epoch 14/80
 - 2s - loss: 0.0326
Epoch 15/80
 - 2s - loss: 0.0308
Epoch 16/80
 - 2s - loss: 0.0291
Epoch 17/80
 - 2s - loss: 0.0275
Epoch 18/80
 - 2s - loss: 0.0261
Epoch 19/80
 - 2s - loss: 0.0249
Epoch 20/80
 - 2s - loss: 0.0238
Epoch 21/80
 - 2s - loss: 0.0228
Epoch 22/80
 - 2s - loss: 0.0220
Epoch 23/80
 - 2s - loss: 0.0213
Epoch 24/80
 - 2s - loss: 0.0207
Epoch 25/80
 - 2s - loss: 0.0202
Epoch 26/80
 - 2s - loss: 0.0197
Epoch 27/80
 - 2s - loss: 0.0193
Epoch 28/80
 - 2s - loss: 0.0190
Epoch 29/80
 - 2s - loss: 0.0187
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0182
Epoch 32/80
 - 2s - loss: 0.0180
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0167
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Epoch 53/80
 - 2s - loss: 0.0162
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0160
Epoch 60/80
 - 2s - loss: 0.0160
Epoch 61/80
 - 2s - loss: 0.0160
Epoch 62/80
 - 2s - loss: 0.0160
Epoch 63/80
 - 2s - loss: 0.0160
Epoch 64/80
 - 2s - loss: 0.0160
Epoch 65/80
 - 2s - loss: 0.0160
Epoch 66/80
 - 2s - loss: 0.0160
Epoch 67/80
 - 2s - loss: 0.0160
Epoch 68/80
 - 2s - loss: 0.0160
Epoch 69/80
 - 2s - loss: 0.0160
Epoch 70/80
 - 2s - loss: 0.0160
Epoch 71/80
 - 2s - loss: 0.0160
Epoch 72/80
 - 2s - loss: 0.0160
Epoch 73/80
 - 2s - loss: 0.0160
Epoch 74/80
 - 2s - loss: 0.0160
Epoch 75/80
 - 2s - loss: 0.0160
Epoch 76/80
 - 2s - loss: 0.0160
Epoch 77/80
 - 2s - loss: 0.0160
Epoch 78/80
 - 2s - loss: 0.0160
Epoch 79/80
 - 2s - loss: 0.0160
Epoch 80/80
 - 2s - loss: 0.0160
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.9873 - val_loss: 0.6893
AUC: 0.8300

Epoch 2/80
 - 0s - loss: 1.5298 - val_loss: 0.8347
AUC: 0.8431

Epoch 3/80
 - 0s - loss: 1.2246 - val_loss: 0.6916
AUC: 0.8472

Epoch 4/80
 - 0s - loss: 1.1407 - val_loss: 0.6590
AUC: 0.8493

Epoch 5/80
 - 0s - loss: 1.1049 - val_loss: 0.7011
AUC: 0.8539

Epoch 6/80
 - 0s - loss: 1.0787 - val_loss: 0.7005
AUC: 0.8529

Epoch 7/80
 - 0s - loss: 1.0773 - val_loss: 0.7298
AUC: 0.8583

Epoch 8/80
 - 0s - loss: 1.0605 - val_loss: 0.6201
AUC: 0.8582

Epoch 9/80
 - 0s - loss: 1.0493 - val_loss: 0.6231
AUC: 0.8594

Epoch 10/80
 - 0s - loss: 1.0421 - val_loss: 0.6572
AUC: 0.8601

Epoch 11/80
 - 0s - loss: 1.0385 - val_loss: 0.6065
AUC: 0.8608

Epoch 12/80
 - 0s - loss: 1.0361 - val_loss: 0.5877
AUC: 0.8603

Epoch 13/80
 - 0s - loss: 1.0194 - val_loss: 0.6077
AUC: 0.8601

Epoch 14/80
 - 0s - loss: 1.0218 - val_loss: 0.5445
AUC: 0.8598

Epoch 15/80
 - 0s - loss: 1.0095 - val_loss: 0.6651
AUC: 0.8631

Epoch 16/80
 - 0s - loss: 1.0061 - val_loss: 0.6742
AUC: 0.8639

Epoch 17/80
 - 0s - loss: 0.9968 - val_loss: 0.6543
AUC: 0.8634

Epoch 18/80
 - 0s - loss: 1.0050 - val_loss: 0.5389
AUC: 0.8611

Epoch 19/80
 - 0s - loss: 1.0022 - val_loss: 0.5949
AUC: 0.8632

Epoch 20/80
 - 0s - loss: 0.9871 - val_loss: 0.6095
AUC: 0.8634

Epoch 21/80
 - 0s - loss: 0.9895 - val_loss: 0.5954
AUC: 0.8640

Epoch 22/80
 - 0s - loss: 0.9878 - val_loss: 0.5929
AUC: 0.8654

Epoch 23/80
 - 0s - loss: 0.9845 - val_loss: 0.6138
AUC: 0.8652

Epoch 24/80
 - 0s - loss: 0.9865 - val_loss: 0.5336
AUC: 0.8645

Epoch 25/80
 - 0s - loss: 0.9869 - val_loss: 0.6133
AUC: 0.8643

Epoch 26/80
 - 0s - loss: 0.9830 - val_loss: 0.5909
AUC: 0.8660

Epoch 27/80
 - 0s - loss: 0.9743 - val_loss: 0.6045
AUC: 0.8665

Epoch 28/80
 - 0s - loss: 0.9698 - val_loss: 0.5666
AUC: 0.8667

Epoch 29/80
 - 0s - loss: 0.9743 - val_loss: 0.6357
AUC: 0.8658

Epoch 30/80
 - 0s - loss: 0.9659 - val_loss: 0.5907
AUC: 0.8669

Epoch 31/80
 - 0s - loss: 0.9678 - val_loss: 0.5757
AUC: 0.8670

Epoch 32/80
 - 0s - loss: 0.9581 - val_loss: 0.6391
AUC: 0.8668

Epoch 33/80
 - 0s - loss: 0.9628 - val_loss: 0.6551
AUC: 0.8683

Epoch 34/80
 - 0s - loss: 0.9613 - val_loss: 0.6111
AUC: 0.8680

Epoch 35/80
 - 0s - loss: 0.9499 - val_loss: 0.5899
AUC: 0.8681

Epoch 36/80
 - 0s - loss: 0.9455 - val_loss: 0.5910
AUC: 0.8678

Epoch 37/80
 - 0s - loss: 0.9384 - val_loss: 0.6334
AUC: 0.8680

Epoch 38/80
 - 0s - loss: 0.9423 - val_loss: 0.5935
AUC: 0.8681

Epoch 39/80
 - 0s - loss: 0.9412 - val_loss: 0.6089
AUC: 0.8682

Epoch 40/80
 - 0s - loss: 0.9343 - val_loss: 0.5955
AUC: 0.8685

Epoch 41/80
 - 0s - loss: 0.9372 - val_loss: 0.5922
AUC: 0.8682

Epoch 42/80
 - 0s - loss: 0.9382 - val_loss: 0.6142
AUC: 0.8686

Epoch 43/80
 - 0s - loss: 0.9387 - val_loss: 0.5741
AUC: 0.8681

Epoch 44/80
 - 0s - loss: 0.9354 - val_loss: 0.6019
AUC: 0.8685

Epoch 45/80
 - 0s - loss: 0.9322 - val_loss: 0.5960
AUC: 0.8685

Epoch 46/80
 - 0s - loss: 0.9338 - val_loss: 0.5966
AUC: 0.8684

Epoch 47/80
 - 0s - loss: 0.9287 - val_loss: 0.5898
AUC: 0.8683

Epoch 48/80
 - 0s - loss: 0.9309 - val_loss: 0.5888
AUC: 0.8682

Epoch 49/80
 - 0s - loss: 0.9258 - val_loss: 0.5808
AUC: 0.8681

Epoch 50/80
 - 0s - loss: 0.9249 - val_loss: 0.5793
AUC: 0.8681

Epoch 51/80
 - 0s - loss: 0.9301 - val_loss: 0.6058
AUC: 0.8684

Epoch 52/80
 - 0s - loss: 0.9334 - val_loss: 0.5848
AUC: 0.8682

Epoch 53/80
 - 0s - loss: 0.9274 - val_loss: 0.5818
AUC: 0.8682

Epoch 54/80
 - 0s - loss: 0.9242 - val_loss: 0.5796
AUC: 0.8682

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9385 - val_loss: 0.5838
AUC: 0.8683

Epoch 2/30
 - 0s - loss: 0.9285 - val_loss: 0.5910
AUC: 0.8684

Epoch 3/30
 - 0s - loss: 0.9299 - val_loss: 0.5772
AUC: 0.8684

Epoch 4/30
 - 0s - loss: 0.9259 - val_loss: 0.5821
AUC: 0.8686

Epoch 5/30
 - 0s - loss: 0.9306 - val_loss: 0.5860
AUC: 0.8686

Epoch 6/30
 - 0s - loss: 0.9264 - val_loss: 0.5809
AUC: 0.8688

Epoch 7/30
 - 0s - loss: 0.9280 - val_loss: 0.5957
AUC: 0.8689

Epoch 8/30
 - 0s - loss: 0.9246 - val_loss: 0.5680
AUC: 0.8687

Epoch 9/30
 - 0s - loss: 0.9219 - val_loss: 0.5714
AUC: 0.8691

Epoch 10/30
 - 0s - loss: 0.9259 - val_loss: 0.5773
AUC: 0.8693

Epoch 11/30
 - 0s - loss: 0.9202 - val_loss: 0.5771
AUC: 0.8692

Epoch 12/30
 - 0s - loss: 0.9201 - val_loss: 0.5758
AUC: 0.8692

Epoch 13/30
 - 0s - loss: 0.9201 - val_loss: 0.5834
AUC: 0.8695

Epoch 14/30
 - 0s - loss: 0.9196 - val_loss: 0.5834
AUC: 0.8694

Epoch 15/30
 - 0s - loss: 0.9143 - val_loss: 0.5654
AUC: 0.8693

Epoch 16/30
 - 0s - loss: 0.9170 - val_loss: 0.5495
AUC: 0.8694

Epoch 17/30
 - 0s - loss: 0.9172 - val_loss: 0.5980
AUC: 0.8697

Epoch 18/30
 - 0s - loss: 0.9148 - val_loss: 0.5742
AUC: 0.8695

Epoch 19/30
 - 0s - loss: 0.9125 - val_loss: 0.5814
AUC: 0.8694

Epoch 20/30
 - 0s - loss: 0.9132 - val_loss: 0.5846
AUC: 0.8698

Epoch 21/30
 - 0s - loss: 0.9079 - val_loss: 0.5975
AUC: 0.8701

Epoch 22/30
 - 0s - loss: 0.9048 - val_loss: 0.5717
AUC: 0.8697

Epoch 23/30
 - 0s - loss: 0.9068 - val_loss: 0.5888
AUC: 0.8699

Epoch 24/30
 - 0s - loss: 0.9034 - val_loss: 0.5750
AUC: 0.8696

Epoch 25/30
 - 0s - loss: 0.9024 - val_loss: 0.5632
AUC: 0.8697

Epoch 26/30
 - 0s - loss: 0.9047 - val_loss: 0.5592
AUC: 0.8696

Epoch 27/30
 - 0s - loss: 0.9010 - val_loss: 0.5772
AUC: 0.8698

Epoch 28/30
 - 0s - loss: 0.9077 - val_loss: 0.5750
AUC: 0.8698

Epoch 29/30
 - 0s - loss: 0.8958 - val_loss: 0.5781
AUC: 0.8698

Epoch 30/30
 - 0s - loss: 0.8993 - val_loss: 0.5791
Using TensorFlow backend.
AUC: 0.8698

2019-03-08 04:16:38.403137: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:16:38.567855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:16:38.567900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:16:38.860267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:16:38.860321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:16:38.860330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:16:38.860633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.4033
Epoch 2/80
 - 2s - loss: 0.3546
Epoch 3/80
 - 2s - loss: 0.3068
Epoch 4/80
 - 2s - loss: 0.2900
Epoch 5/80
 - 2s - loss: 0.2689
Epoch 6/80
 - 2s - loss: 0.2479
Epoch 7/80
 - 2s - loss: 0.2293
Epoch 8/80
 - 2s - loss: 0.2126
Epoch 9/80
 - 2s - loss: 0.1984
Epoch 10/80
 - 2s - loss: 0.1867
Epoch 11/80
 - 2s - loss: 0.1770
Epoch 12/80
 - 2s - loss: 0.1688
Epoch 13/80
 - 2s - loss: 0.1615
Epoch 14/80
 - 2s - loss: 0.1550
Epoch 15/80
 - 2s - loss: 0.1490
Epoch 16/80
 - 2s - loss: 0.1437
Epoch 17/80
 - 2s - loss: 0.1390
Epoch 18/80
 - 2s - loss: 0.1350
Epoch 19/80
 - 2s - loss: 0.1318
Epoch 20/80
 - 2s - loss: 0.1291
Epoch 21/80
 - 2s - loss: 0.1269
Epoch 22/80
 - 2s - loss: 0.1250
Epoch 23/80
 - 2s - loss: 0.1235
Epoch 24/80
 - 2s - loss: 0.1222
Epoch 25/80
 - 2s - loss: 0.1211
Epoch 26/80
 - 2s - loss: 0.1202
Epoch 27/80
 - 2s - loss: 0.1195
Epoch 28/80
 - 2s - loss: 0.1188
Epoch 29/80
 - 2s - loss: 0.1183
Epoch 30/80
 - 2s - loss: 0.1178
Epoch 31/80
 - 2s - loss: 0.1174
Epoch 32/80
 - 2s - loss: 0.1170
Epoch 33/80
 - 2s - loss: 0.1167
Epoch 34/80
 - 2s - loss: 0.1164
Epoch 35/80
 - 2s - loss: 0.1162
Epoch 36/80
 - 2s - loss: 0.1160
Epoch 37/80
 - 2s - loss: 0.1158
Epoch 38/80
 - 2s - loss: 0.1156
Epoch 39/80
 - 2s - loss: 0.1154
Epoch 40/80
 - 2s - loss: 0.1153
Epoch 41/80
 - 2s - loss: 0.1152
Epoch 42/80
 - 2s - loss: 0.1150
Epoch 43/80
 - 2s - loss: 0.1149
Epoch 44/80
 - 2s - loss: 0.1148
Epoch 45/80
 - 2s - loss: 0.1147
Epoch 46/80
 - 2s - loss: 0.1147
Epoch 47/80
 - 2s - loss: 0.1146
Epoch 48/80
 - 2s - loss: 0.1145
Epoch 49/80
 - 2s - loss: 0.1144
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b4303343668>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 04:18:17.894350: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:18:18.056830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:18:18.056874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:18:18.348791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:18:18.348839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:18:18.348848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:18:18.349107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3889
Epoch 2/80
 - 2s - loss: 0.3533
Epoch 3/80
 - 2s - loss: 0.3092
Epoch 4/80
 - 2s - loss: 0.2967
Epoch 5/80
 - 2s - loss: 0.2811
Epoch 6/80
 - 2s - loss: 0.2603
Epoch 7/80
 - 2s - loss: 0.2375
Epoch 8/80
 - 2s - loss: 0.2185
Epoch 9/80
 - 2s - loss: 0.2039
Epoch 10/80
 - 2s - loss: 0.1912
Epoch 11/80
 - 2s - loss: 0.1797
Epoch 12/80
 - 2s - loss: 0.1699
Epoch 13/80
 - 2s - loss: 0.1618
Epoch 14/80
 - 2s - loss: 0.1552
Epoch 15/80
 - 2s - loss: 0.1495
Epoch 16/80
 - 2s - loss: 0.1446
Epoch 17/80
 - 2s - loss: 0.1403
Epoch 18/80
 - 2s - loss: 0.1366
Epoch 19/80
 - 2s - loss: 0.1334
Epoch 20/80
 - 2s - loss: 0.1308
Epoch 21/80
 - 2s - loss: 0.1285
Epoch 22/80
 - 2s - loss: 0.1266
Epoch 23/80
 - 2s - loss: 0.1251
Epoch 24/80
 - 2s - loss: 0.1238
Epoch 25/80
 - 2s - loss: 0.1226
Epoch 26/80
 - 2s - loss: 0.1217
Epoch 27/80
 - 2s - loss: 0.1209
Epoch 28/80
 - 2s - loss: 0.1202
Epoch 29/80
 - 2s - loss: 0.1196
Epoch 30/80
 - 2s - loss: 0.1191
Epoch 31/80
 - 2s - loss: 0.1187
Epoch 32/80
 - 2s - loss: 0.1182
Epoch 33/80
 - 2s - loss: 0.1179
Epoch 34/80
 - 2s - loss: 0.1176
Epoch 35/80
 - 2s - loss: 0.1173
Epoch 36/80
 - 2s - loss: 0.1171
Epoch 37/80
 - 2s - loss: 0.1168
Epoch 38/80
 - 2s - loss: 0.1166
Epoch 39/80
 - 2s - loss: 0.1164
Epoch 40/80
 - 2s - loss: 0.1163
Epoch 41/80
 - 2s - loss: 0.1162
Epoch 42/80
 - 2s - loss: 0.1160
Epoch 43/80
 - 2s - loss: 0.1158
Epoch 44/80
 - 2s - loss: 0.1157
Epoch 45/80
 - 2s - loss: 0.1156
Epoch 46/80
 - 2s - loss: 0.1155
Epoch 47/80
 - 2s - loss: 0.1154
Epoch 48/80
 - 2s - loss: 0.1153
Epoch 49/80
 - 2s - loss: 0.1152
Epoch 50/80
 - 2s - loss: 0.1151
Epoch 51/80
 - 2s - loss: 0.1151
Epoch 52/80
 - 2s - loss: 0.1150
Epoch 53/80
 - 2s - loss: 0.1149
Epoch 54/80
 - 2s - loss: 0.1149
Epoch 55/80
 - 2s - loss: 0.1148
Epoch 56/80
 - 2s - loss: 0.1148
Epoch 57/80
 - 2s - loss: 0.1147
Epoch 58/80
 - 2s - loss: 0.1147
Epoch 59/80
 - 2s - loss: 0.1146
Epoch 60/80
 - 2s - loss: 0.1146
Epoch 61/80
 - 2s - loss: 0.1146
Epoch 62/80
 - 2s - loss: 0.1145
Epoch 63/80
 - 2s - loss: 0.1145
Epoch 64/80
 - 2s - loss: 0.1145
Epoch 65/80
 - 2s - loss: 0.1144
Epoch 66/80
 - 2s - loss: 0.1144
Epoch 67/80
 - 2s - loss: 0.1122
Epoch 68/80
 - 2s - loss: 0.1119
Epoch 69/80
 - 2s - loss: 0.1119
Epoch 70/80
 - 2s - loss: 0.1119
Epoch 71/80
 - 2s - loss: 0.1119
Epoch 72/80
 - 2s - loss: 0.1113
Epoch 73/80
 - 2s - loss: 0.1113
Epoch 74/80
 - 2s - loss: 0.1113
Epoch 75/80
 - 2s - loss: 0.1113
Epoch 76/80
 - 2s - loss: 0.1112
Epoch 77/80
 - 2s - loss: 0.1112
Epoch 78/80
 - 2s - loss: 0.1112
Epoch 79/80
 - 2s - loss: 0.1112
Epoch 80/80
 - 2s - loss: 0.1111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.2813 - val_loss: 1.3281
AUC: 0.8130

Epoch 2/80
 - 0s - loss: 2.2525 - val_loss: 0.8911
AUC: 0.8386

Epoch 3/80
 - 0s - loss: 1.6443 - val_loss: 0.7859
AUC: 0.8510

Epoch 4/80
 - 0s - loss: 1.3324 - val_loss: 0.6991
AUC: 0.8550

Epoch 5/80
 - 0s - loss: 1.1883 - val_loss: 0.5949
AUC: 0.8585

Epoch 6/80
 - 0s - loss: 1.1396 - val_loss: 0.6450
AUC: 0.8612

Epoch 7/80
 - 0s - loss: 1.1007 - val_loss: 0.6240
AUC: 0.8594

Epoch 8/80
 - 0s - loss: 1.0775 - val_loss: 0.6328
AUC: 0.8632

Epoch 9/80
 - 0s - loss: 1.0610 - val_loss: 0.6081
AUC: 0.8610

Epoch 10/80
 - 0s - loss: 1.0523 - val_loss: 0.6088
AUC: 0.8634

Epoch 11/80
 - 0s - loss: 1.0423 - val_loss: 0.6237
AUC: 0.8640

Epoch 12/80
 - 0s - loss: 1.0434 - val_loss: 0.6773
AUC: 0.8655

Epoch 13/80
 - 0s - loss: 1.0294 - val_loss: 0.6143
AUC: 0.8658

Epoch 14/80
 - 0s - loss: 1.0272 - val_loss: 0.5755
AUC: 0.8661

Epoch 15/80
 - 0s - loss: 1.0186 - val_loss: 0.6320
AUC: 0.8665

Epoch 16/80
 - 0s - loss: 1.0143 - val_loss: 0.5566
AUC: 0.8665

Epoch 17/80
 - 0s - loss: 1.0159 - val_loss: 0.6082
AUC: 0.8673

Epoch 18/80
 - 0s - loss: 1.0072 - val_loss: 0.6286
AUC: 0.8676

Epoch 19/80
 - 0s - loss: 1.0099 - val_loss: 0.6644
AUC: 0.8678

Epoch 20/80
 - 0s - loss: 1.0008 - val_loss: 0.6256
AUC: 0.8668

Epoch 21/80
 - 0s - loss: 0.9994 - val_loss: 0.6240
AUC: 0.8674

Epoch 22/80
 - 0s - loss: 1.0015 - val_loss: 0.5547
AUC: 0.8676

Epoch 23/80
 - 0s - loss: 0.9961 - val_loss: 0.6541
AUC: 0.8689

Epoch 24/80
 - 0s - loss: 0.9941 - val_loss: 0.7048
AUC: 0.8697

Epoch 25/80
 - 0s - loss: 0.9928 - val_loss: 0.5380
AUC: 0.8678

Epoch 26/80
 - 0s - loss: 0.9864 - val_loss: 0.6155
AUC: 0.8697

Epoch 27/80
 - 0s - loss: 0.9801 - val_loss: 0.5750
AUC: 0.8692

Epoch 28/80
 - 0s - loss: 0.9837 - val_loss: 0.5568
AUC: 0.8694

Epoch 29/80
 - 0s - loss: 0.9813 - val_loss: 0.6048
AUC: 0.8698

Epoch 30/80
 - 0s - loss: 0.9718 - val_loss: 0.6307
AUC: 0.8699

Epoch 31/80
 - 0s - loss: 0.9779 - val_loss: 0.6182
AUC: 0.8687

Epoch 32/80
 - 0s - loss: 0.9728 - val_loss: 0.5761
AUC: 0.8705

Epoch 33/80
 - 0s - loss: 0.9732 - val_loss: 0.5837
AUC: 0.8707

Epoch 34/80
 - 0s - loss: 0.9749 - val_loss: 0.6945
AUC: 0.8702

Epoch 35/80
 - 0s - loss: 0.9653 - val_loss: 0.5822
AUC: 0.8687

Epoch 36/80
 - 0s - loss: 0.9541 - val_loss: 0.5820
AUC: 0.8703

Epoch 37/80
 - 0s - loss: 0.9555 - val_loss: 0.5854
AUC: 0.8704

Epoch 38/80
 - 0s - loss: 0.9541 - val_loss: 0.5975
AUC: 0.8706

Epoch 39/80
 - 0s - loss: 0.9537 - val_loss: 0.5844
AUC: 0.8705

Epoch 40/80
 - 0s - loss: 0.9521 - val_loss: 0.5811
AUC: 0.8707

Epoch 41/80
 - 0s - loss: 0.9553 - val_loss: 0.5747
AUC: 0.8705

Epoch 42/80
 - 0s - loss: 0.9495 - val_loss: 0.5834
AUC: 0.8706

Epoch 43/80
 - 0s - loss: 0.9531 - val_loss: 0.5619
AUC: 0.8704

Epoch 44/80
 - 0s - loss: 0.9462 - val_loss: 0.5697
AUC: 0.8703

Epoch 45/80
 - 0s - loss: 0.9495 - val_loss: 0.6025
AUC: 0.8708

Epoch 46/80
 - 0s - loss: 0.9430 - val_loss: 0.5795
AUC: 0.8708

Epoch 47/80
 - 0s - loss: 0.9481 - val_loss: 0.5814
AUC: 0.8708

Epoch 48/80
 - 0s - loss: 0.9502 - val_loss: 0.5787
AUC: 0.8709

Epoch 49/80
 - 0s - loss: 0.9428 - val_loss: 0.5767
AUC: 0.8709

Epoch 50/80
 - 0s - loss: 0.9478 - val_loss: 0.5880
AUC: 0.8709

Epoch 51/80
 - 0s - loss: 0.9469 - val_loss: 0.5981
AUC: 0.8709

Epoch 52/80
 - 0s - loss: 0.9458 - val_loss: 0.5750
AUC: 0.8708

Epoch 53/80
 - 0s - loss: 0.9501 - val_loss: 0.5836
AUC: 0.8708

Epoch 54/80
 - 0s - loss: 0.9440 - val_loss: 0.5977
AUC: 0.8709

Epoch 55/80
 - 0s - loss: 0.9456 - val_loss: 0.5816
AUC: 0.8708

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9505 - val_loss: 0.5870
AUC: 0.8708

Epoch 2/30
 - 0s - loss: 0.9457 - val_loss: 0.5841
AUC: 0.8710

Epoch 3/30
 - 0s - loss: 0.9485 - val_loss: 0.6043
AUC: 0.8711

Epoch 4/30
 - 0s - loss: 0.9476 - val_loss: 0.5817
AUC: 0.8714

Epoch 5/30
 - 0s - loss: 0.9423 - val_loss: 0.5922
AUC: 0.8714

Epoch 6/30
 - 0s - loss: 0.9436 - val_loss: 0.5815
AUC: 0.8714

Epoch 7/30
 - 0s - loss: 0.9375 - val_loss: 0.5660
AUC: 0.8713

Epoch 8/30
 - 0s - loss: 0.9374 - val_loss: 0.5906
AUC: 0.8713

Epoch 9/30
 - 0s - loss: 0.9357 - val_loss: 0.5811
AUC: 0.8715

Epoch 10/30
 - 0s - loss: 0.9381 - val_loss: 0.5691
AUC: 0.8715

Epoch 11/30
 - 0s - loss: 0.9382 - val_loss: 0.5737
AUC: 0.8717

Epoch 12/30
 - 0s - loss: 0.9321 - val_loss: 0.5961
AUC: 0.8717

Epoch 13/30
 - 0s - loss: 0.9358 - val_loss: 0.5980
AUC: 0.8720

Epoch 14/30
 - 0s - loss: 0.9270 - val_loss: 0.6003
AUC: 0.8721

Epoch 15/30
 - 0s - loss: 0.9344 - val_loss: 0.5885
AUC: 0.8721

Epoch 16/30
 - 0s - loss: 0.9281 - val_loss: 0.5698
AUC: 0.8721

Epoch 17/30
 - 0s - loss: 0.9317 - val_loss: 0.5985
AUC: 0.8723

Epoch 18/30
 - 0s - loss: 0.9248 - val_loss: 0.5702
AUC: 0.8723

Epoch 19/30
 - 0s - loss: 0.9251 - val_loss: 0.5734
AUC: 0.8723

Epoch 20/30
 - 0s - loss: 0.9253 - val_loss: 0.5698
AUC: 0.8723

Epoch 21/30
 - 0s - loss: 0.9248 - val_loss: 0.5717
AUC: 0.8723

Epoch 22/30
 - 0s - loss: 0.9249 - val_loss: 0.5744
AUC: 0.8723

Epoch 23/30
 - 0s - loss: 0.9206 - val_loss: 0.5754
AUC: 0.8724

Epoch 24/30
 - 0s - loss: 0.9223 - val_loss: 0.5669
AUC: 0.8724

Epoch 25/30
 - 0s - loss: 0.9247 - val_loss: 0.5732
AUC: 0.8725

Epoch 26/30
 - 0s - loss: 0.9222 - val_loss: 0.5734
AUC: 0.8725

Epoch 27/30
 - 0s - loss: 0.9234 - val_loss: 0.5702
AUC: 0.8725

Epoch 28/30
 - 0s - loss: 0.9215 - val_loss: 0.5714
AUC: 0.8725

Epoch 29/30
 - 0s - loss: 0.9263 - val_loss: 0.5702
AUC: 0.8725

Epoch 30/30
 - 0s - loss: 0.9257 - val_loss: 0.5711
Using TensorFlow backend.
AUC: 0.8725

2019-03-08 04:21:39.676537: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:21:39.841722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:21:39.841765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:21:40.138395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:21:40.138448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:21:40.138473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:21:40.138741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3541
Epoch 2/80
 - 2s - loss: 0.3499
Epoch 3/80
 - 2s - loss: 0.3081
Epoch 4/80
 - 2s - loss: 0.2950
Epoch 5/80
 - 2s - loss: 0.2805
Epoch 6/80
 - 2s - loss: 0.2635
Epoch 7/80
 - 2s - loss: 0.2443
Epoch 8/80
 - 2s - loss: 0.2254
Epoch 9/80
 - 2s - loss: 0.2095
Epoch 10/80
 - 2s - loss: 0.1957
Epoch 11/80
 - 2s - loss: 0.1833
Epoch 12/80
 - 2s - loss: 0.1723
Epoch 13/80
 - 2s - loss: 0.1633
Epoch 14/80
 - 2s - loss: 0.1558
Epoch 15/80
 - 2s - loss: 0.1497
Epoch 16/80
 - 2s - loss: 0.1447
Epoch 17/80
 - 2s - loss: 0.1404
Epoch 18/80
 - 2s - loss: 0.1369
Epoch 19/80
 - 2s - loss: 0.1339
Epoch 20/80
 - 2s - loss: 0.1313
Epoch 21/80
 - 2s - loss: 0.1292
Epoch 22/80
 - 2s - loss: 0.1273
Epoch 23/80
 - 2s - loss: 0.1258
Epoch 24/80
 - 2s - loss: 0.1244
Epoch 25/80
 - 2s - loss: 0.1233
Epoch 26/80
 - 2s - loss: 0.1223
Epoch 27/80
 - 2s - loss: 0.1214
Epoch 28/80
 - 2s - loss: 0.1207
Epoch 29/80
 - 2s - loss: 0.1200
Epoch 30/80
 - 2s - loss: 0.1195
Epoch 31/80
 - 2s - loss: 0.1190
Epoch 32/80
 - 2s - loss: 0.1185
Epoch 33/80
 - 2s - loss: 0.1182
Epoch 34/80
 - 2s - loss: 0.1178
Epoch 35/80
 - 2s - loss: 0.1175
Epoch 36/80
 - 2s - loss: 0.1172
Epoch 37/80
 - 2s - loss: 0.1170
Epoch 38/80
 - 2s - loss: 0.1167
Epoch 39/80
 - 2s - loss: 0.1166
Epoch 40/80
 - 2s - loss: 0.1164
Epoch 41/80
 - 2s - loss: 0.1162
Epoch 42/80
 - 2s - loss: 0.1160
Epoch 43/80
 - 2s - loss: 0.1158
Epoch 44/80
 - 2s - loss: 0.1157
Epoch 45/80
 - 2s - loss: 0.1156
Epoch 46/80
 - 2s - loss: 0.1155
Epoch 47/80
 - 2s - loss: 0.1153
Epoch 48/80
 - 2s - loss: 0.1153
Epoch 49/80
 - 2s - loss: 0.1152
Epoch 50/80
 - 2s - loss: 0.1151
Epoch 51/80
 - 2s - loss: 0.1150
Epoch 52/80
 - 2s - loss: 0.1149
Epoch 53/80
 - 2s - loss: 0.1148
Epoch 54/80
 - 2s - loss: 0.1148
Epoch 55/80
 - 2s - loss: 0.1147
Epoch 56/80
 - 2s - loss: 0.1146
Epoch 57/80
 - 2s - loss: 0.1146
Epoch 58/80
 - 2s - loss: 0.1145
Epoch 59/80
 - 2s - loss: 0.1144
Epoch 60/80
 - 2s - loss: 0.1144
Epoch 61/80
 - 2s - loss: 0.1144
Epoch 62/80
 - 2s - loss: 0.1143
Epoch 63/80
 - 2s - loss: 0.1143
Epoch 64/80
 - 2s - loss: 0.1142
Epoch 65/80
 - 2s - loss: 0.1142
Epoch 66/80
 - 2s - loss: 0.1141
Epoch 67/80
 - 2s - loss: 0.1141
Epoch 68/80
 - 2s - loss: 0.1141
Epoch 69/80
 - 2s - loss: 0.1141
Epoch 70/80
 - 2s - loss: 0.1140
Epoch 71/80
 - 2s - loss: 0.1140
Epoch 72/80
 - 2s - loss: 0.1140
Epoch 73/80
 - 2s - loss: 0.1139
Epoch 74/80
 - 2s - loss: 0.1139
Epoch 75/80
 - 2s - loss: 0.1117
Epoch 76/80
 - 2s - loss: 0.1114
Epoch 77/80
 - 2s - loss: 0.1114
Epoch 78/80
 - 2s - loss: 0.1114
Epoch 79/80
 - 2s - loss: 0.1114
Epoch 80/80
 - 2s - loss: 0.1108
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.7663 - val_loss: 1.6347
AUC: 0.8011

Epoch 2/80
 - 0s - loss: 2.4967 - val_loss: 1.3523
AUC: 0.8264

Epoch 3/80
 - 0s - loss: 1.8619 - val_loss: 0.7793
AUC: 0.8381

Epoch 4/80
 - 0s - loss: 1.5298 - val_loss: 0.7175
AUC: 0.8428

Epoch 5/80
 - 0s - loss: 1.2934 - val_loss: 0.6922
AUC: 0.8460

Epoch 6/80
 - 0s - loss: 1.1960 - val_loss: 0.6451
AUC: 0.8469

Epoch 7/80
 - 0s - loss: 1.1261 - val_loss: 0.6615
AUC: 0.8487

Epoch 8/80
 - 0s - loss: 1.1159 - val_loss: 0.6507
AUC: 0.8476

Epoch 9/80
 - 0s - loss: 1.0907 - val_loss: 0.7138
AUC: 0.8525

Epoch 10/80
 - 0s - loss: 1.0920 - val_loss: 0.7024
AUC: 0.8538

Epoch 11/80
 - 0s - loss: 1.0627 - val_loss: 0.6446
AUC: 0.8544

Epoch 12/80
 - 0s - loss: 1.0587 - val_loss: 0.6694
AUC: 0.8556

Epoch 13/80
 - 0s - loss: 1.0549 - val_loss: 0.6534
AUC: 0.8567

Epoch 14/80
 - 0s - loss: 1.0498 - val_loss: 0.6325
AUC: 0.8574

Epoch 15/80
 - 0s - loss: 1.0391 - val_loss: 0.6274
AUC: 0.8587

Epoch 16/80
 - 0s - loss: 1.0323 - val_loss: 0.6444
AUC: 0.8588

Epoch 17/80
 - 0s - loss: 1.0284 - val_loss: 0.6520
AUC: 0.8602

Epoch 18/80
 - 0s - loss: 1.0229 - val_loss: 0.6632
AUC: 0.8591

Epoch 19/80
 - 0s - loss: 1.0234 - val_loss: 0.7242
AUC: 0.8600

Epoch 20/80
 - 0s - loss: 1.0165 - val_loss: 0.7056
AUC: 0.8598

Epoch 21/80
 - 0s - loss: 1.0131 - val_loss: 0.6675
AUC: 0.8601

Epoch 22/80
 - 0s - loss: 1.0107 - val_loss: 0.6062
AUC: 0.8599

Epoch 23/80
 - 0s - loss: 1.0097 - val_loss: 0.6871
AUC: 0.8625

Epoch 24/80
 - 0s - loss: 1.0048 - val_loss: 0.5894
AUC: 0.8614

Epoch 25/80
 - 0s - loss: 0.9956 - val_loss: 0.6487
AUC: 0.8622

Epoch 26/80
 - 0s - loss: 1.0041 - val_loss: 0.6258
AUC: 0.8632

Epoch 27/80
 - 0s - loss: 0.9935 - val_loss: 0.6110
AUC: 0.8615

Epoch 28/80
 - 0s - loss: 0.9901 - val_loss: 0.6308
AUC: 0.8637

Epoch 29/80
 - 0s - loss: 0.9908 - val_loss: 0.6071
AUC: 0.8643

Epoch 30/80
 - 0s - loss: 0.9871 - val_loss: 0.6307
AUC: 0.8640

Epoch 31/80
 - 0s - loss: 0.9874 - val_loss: 0.6301
AUC: 0.8644

Epoch 32/80
 - 0s - loss: 0.9821 - val_loss: 0.6277
AUC: 0.8649

Epoch 33/80
 - 0s - loss: 0.9816 - val_loss: 0.6289
AUC: 0.8657

Epoch 34/80
 - 0s - loss: 0.9811 - val_loss: 0.6332
AUC: 0.8651

Epoch 35/80
 - 0s - loss: 0.9703 - val_loss: 0.6014
AUC: 0.8649

Epoch 36/80
 - 0s - loss: 0.9662 - val_loss: 0.6108
AUC: 0.8654

Epoch 37/80
 - 0s - loss: 0.9724 - val_loss: 0.5895
AUC: 0.8650

Epoch 38/80
 - 0s - loss: 0.9723 - val_loss: 0.6151
AUC: 0.8662

Epoch 39/80
 - 0s - loss: 0.9639 - val_loss: 0.6051
AUC: 0.8656

Epoch 40/80
 - 0s - loss: 0.9671 - val_loss: 0.6266
AUC: 0.8659

Epoch 41/80
 - 0s - loss: 0.9585 - val_loss: 0.5777
AUC: 0.8655

Epoch 42/80
 - 0s - loss: 0.9631 - val_loss: 0.6150
AUC: 0.8659

Epoch 43/80
 - 0s - loss: 0.9643 - val_loss: 0.6130
AUC: 0.8658

Epoch 44/80
 - 0s - loss: 0.9670 - val_loss: 0.6166
AUC: 0.8660

Epoch 45/80
 - 0s - loss: 0.9622 - val_loss: 0.5808
AUC: 0.8655

Epoch 46/80
 - 0s - loss: 0.9612 - val_loss: 0.6119
AUC: 0.8659

Epoch 47/80
 - 0s - loss: 0.9591 - val_loss: 0.6368
AUC: 0.8661

Epoch 48/80
 - 0s - loss: 0.9593 - val_loss: 0.5834
AUC: 0.8659

Epoch 49/80
 - 0s - loss: 0.9608 - val_loss: 0.6268
AUC: 0.8660

Epoch 50/80
 - 0s - loss: 0.9588 - val_loss: 0.6147
AUC: 0.8663

Epoch 51/80
 - 0s - loss: 0.9593 - val_loss: 0.6186
AUC: 0.8660

Epoch 52/80
 - 0s - loss: 0.9539 - val_loss: 0.5979
AUC: 0.8658

Epoch 53/80
 - 0s - loss: 0.9590 - val_loss: 0.5988
AUC: 0.8659

Epoch 54/80
 - 0s - loss: 0.9543 - val_loss: 0.6024
AUC: 0.8660

Epoch 55/80
 - 0s - loss: 0.9556 - val_loss: 0.6092
AUC: 0.8661

Epoch 56/80
 - 0s - loss: 0.9579 - val_loss: 0.6043
AUC: 0.8660

Epoch 57/80
 - 0s - loss: 0.9521 - val_loss: 0.5996
AUC: 0.8660

Epoch 58/80
 - 0s - loss: 0.9564 - val_loss: 0.5952
AUC: 0.8660

Epoch 59/80
 - 0s - loss: 0.9555 - val_loss: 0.6093
AUC: 0.8661

Epoch 60/80
 - 0s - loss: 0.9532 - val_loss: 0.6053
AUC: 0.8661

Epoch 61/80
 - 0s - loss: 0.9568 - val_loss: 0.6054
AUC: 0.8661

Epoch 62/80
 - 0s - loss: 0.9520 - val_loss: 0.6040
AUC: 0.8662

Epoch 63/80
 - 0s - loss: 0.9560 - val_loss: 0.6029
AUC: 0.8661

Epoch 64/80
 - 0s - loss: 0.9512 - val_loss: 0.6019
AUC: 0.8661

Epoch 65/80
 - 0s - loss: 0.9514 - val_loss: 0.6036
AUC: 0.8661

Epoch 66/80
 - 0s - loss: 0.9528 - val_loss: 0.6033
AUC: 0.8661

Epoch 67/80
 - 0s - loss: 0.9502 - val_loss: 0.6028
AUC: 0.8661

Epoch 68/80
 - 0s - loss: 0.9526 - val_loss: 0.6039
AUC: 0.8661

Epoch 69/80
 - 0s - loss: 0.9496 - val_loss: 0.6032
AUC: 0.8661

Epoch 70/80
 - 0s - loss: 0.9483 - val_loss: 0.6005
AUC: 0.8660

Epoch 71/80
 - 0s - loss: 0.9529 - val_loss: 0.6030
AUC: 0.8661

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9575 - val_loss: 0.5975
AUC: 0.8660

Epoch 2/30
 - 0s - loss: 0.9564 - val_loss: 0.5890
AUC: 0.8661

Epoch 3/30
 - 0s - loss: 0.9528 - val_loss: 0.6034
AUC: 0.8663

Epoch 4/30
 - 0s - loss: 0.9545 - val_loss: 0.5902
AUC: 0.8662

Epoch 5/30
 - 0s - loss: 0.9514 - val_loss: 0.6017
AUC: 0.8661

Epoch 6/30
 - 0s - loss: 0.9525 - val_loss: 0.6236
AUC: 0.8667

Epoch 7/30
 - 0s - loss: 0.9495 - val_loss: 0.6108
AUC: 0.8668

Epoch 8/30
 - 0s - loss: 0.9454 - val_loss: 0.5791
AUC: 0.8666

Epoch 9/30
 - 0s - loss: 0.9485 - val_loss: 0.5857
AUC: 0.8670

Epoch 10/30
 - 0s - loss: 0.9460 - val_loss: 0.5817
AUC: 0.8669

Epoch 11/30
 - 0s - loss: 0.9448 - val_loss: 0.5957
AUC: 0.8673

Epoch 12/30
 - 0s - loss: 0.9421 - val_loss: 0.6026
AUC: 0.8674

Epoch 13/30
 - 0s - loss: 0.9426 - val_loss: 0.6071
AUC: 0.8675

Epoch 14/30
 - 0s - loss: 0.9408 - val_loss: 0.6121
AUC: 0.8673

Epoch 15/30
 - 0s - loss: 0.9411 - val_loss: 0.6125
AUC: 0.8675

Epoch 16/30
 - 0s - loss: 0.9354 - val_loss: 0.6051
AUC: 0.8677

Epoch 17/30
 - 0s - loss: 0.9399 - val_loss: 0.6025
AUC: 0.8677

Epoch 18/30
 - 0s - loss: 0.9345 - val_loss: 0.5839
AUC: 0.8676

Epoch 19/30
 - 0s - loss: 0.9315 - val_loss: 0.5932
AUC: 0.8677

Epoch 20/30
 - 0s - loss: 0.9299 - val_loss: 0.5926
AUC: 0.8678

Epoch 21/30
 - 0s - loss: 0.9311 - val_loss: 0.5939
AUC: 0.8678

Epoch 22/30
 - 0s - loss: 0.9334 - val_loss: 0.5944
AUC: 0.8678

Epoch 23/30
 - 0s - loss: 0.9349 - val_loss: 0.5981
AUC: 0.8679

Epoch 24/30
 - 0s - loss: 0.9259 - val_loss: 0.5913
AUC: 0.8678

Epoch 25/30
 - 0s - loss: 0.9356 - val_loss: 0.5928
AUC: 0.8679

Epoch 26/30
 - 0s - loss: 0.9325 - val_loss: 0.5918
AUC: 0.8679

Epoch 27/30
 - 0s - loss: 0.9348 - val_loss: 0.5927
AUC: 0.8679

Epoch 28/30
 - 0s - loss: 0.9286 - val_loss: 0.5959
AUC: 0.8680

Epoch 29/30
 - 0s - loss: 0.9314 - val_loss: 0.5946
AUC: 0.8680

Epoch 30/30
 - 0s - loss: 0.9280 - val_loss: 0.5939
Using TensorFlow backend.
AUC: 0.8680

2019-03-08 04:25:12.252330: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:25:12.418082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:25:12.418125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:25:12.715088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:25:12.715139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:25:12.715148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:25:12.715476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3820
Epoch 2/80
 - 2s - loss: 0.3513
Epoch 3/80
 - 2s - loss: 0.2935
Epoch 4/80
 - 2s - loss: 0.2676
Epoch 5/80
 - 2s - loss: 0.2451
Epoch 6/80
 - 2s - loss: 0.2281
Epoch 7/80
 - 2s - loss: 0.2153
Epoch 8/80
 - 2s - loss: 0.2053
Epoch 9/80
 - 2s - loss: 0.1967
Epoch 10/80
 - 2s - loss: 0.1881
Epoch 11/80
 - 2s - loss: 0.1795
Epoch 12/80
 - 2s - loss: 0.1710
Epoch 13/80
 - 2s - loss: 0.1630
Epoch 14/80
 - 2s - loss: 0.1559
Epoch 15/80
 - 2s - loss: 0.1497
Epoch 16/80
 - 2s - loss: 0.1445
Epoch 17/80
 - 2s - loss: 0.1400
Epoch 18/80
 - 2s - loss: 0.1364
Epoch 19/80
 - 2s - loss: 0.1333
Epoch 20/80
 - 2s - loss: 0.1307
Epoch 21/80
 - 2s - loss: 0.1286
Epoch 22/80
 - 2s - loss: 0.1267
Epoch 23/80
 - 2s - loss: 0.1252
Epoch 24/80
 - 2s - loss: 0.1238
Epoch 25/80
 - 2s - loss: 0.1227
Epoch 26/80
 - 2s - loss: 0.1217
Epoch 27/80
 - 2s - loss: 0.1209
Epoch 28/80
 - 2s - loss: 0.1201
Epoch 29/80
 - 2s - loss: 0.1196
Epoch 30/80
 - 2s - loss: 0.1191
Epoch 31/80
 - 2s - loss: 0.1186
Epoch 32/80
 - 2s - loss: 0.1182
Epoch 33/80
 - 2s - loss: 0.1179
Epoch 34/80
 - 2s - loss: 0.1176
Epoch 35/80
 - 2s - loss: 0.1173
Epoch 36/80
 - 2s - loss: 0.1170
Epoch 37/80
 - 2s - loss: 0.1168
Epoch 38/80
 - 2s - loss: 0.1166
Epoch 39/80
 - 2s - loss: 0.1165
Epoch 40/80
 - 2s - loss: 0.1163
Epoch 41/80
 - 2s - loss: 0.1161
Epoch 42/80
 - 2s - loss: 0.1160
Epoch 43/80
 - 2s - loss: 0.1159
Epoch 44/80
 - 2s - loss: 0.1158
Epoch 45/80
 - 2s - loss: 0.1157
Epoch 46/80
 - 2s - loss: 0.1156
Epoch 47/80
 - 2s - loss: 0.1155
Epoch 48/80
 - 2s - loss: 0.1154
Epoch 49/80
 - 2s - loss: 0.1153
Epoch 50/80
 - 2s - loss: 0.1153
Epoch 51/80
 - 2s - loss: 0.1152
Epoch 52/80
 - 2s - loss: 0.1151
Epoch 53/80
 - 2s - loss: 0.1151
Epoch 54/80
 - 2s - loss: 0.1150
Epoch 55/80
 - 2s - loss: 0.1149
Epoch 56/80
 - 2s - loss: 0.1149
Epoch 57/80
 - 2s - loss: 0.1149
Epoch 58/80
 - 2s - loss: 0.1148
Epoch 59/80
 - 2s - loss: 0.1148
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 04:27:07.308483: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:27:07.472067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:27:07.472109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:27:07.764213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:27:07.764263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:27:07.764272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:27:07.764573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1718
Epoch 2/80
 - 2s - loss: 0.2236
Epoch 3/80
 - 2s - loss: 0.1676
Epoch 4/80
 - 2s - loss: 0.1533
Epoch 5/80
 - 2s - loss: 0.1414
Epoch 6/80
 - 2s - loss: 0.1306
Epoch 7/80
 - 2s - loss: 0.1214
Epoch 8/80
 - 2s - loss: 0.1133
Epoch 9/80
 - 2s - loss: 0.1064
Epoch 10/80
 - 2s - loss: 0.1004
Epoch 11/80
 - 2s - loss: 0.0950
Epoch 12/80
 - 2s - loss: 0.0897
Epoch 13/80
 - 2s - loss: 0.0848
Epoch 14/80
 - 2s - loss: 0.0802
Epoch 15/80
 - 2s - loss: 0.0761
Epoch 16/80
 - 2s - loss: 0.0725
Epoch 17/80
 - 2s - loss: 0.0695
Epoch 18/80
 - 2s - loss: 0.0669
Epoch 19/80
 - 2s - loss: 0.0646
Epoch 20/80
 - 2s - loss: 0.0628
Epoch 21/80
 - 2s - loss: 0.0612
Epoch 22/80
 - 2s - loss: 0.0598
Epoch 23/80
 - 2s - loss: 0.0587
Epoch 24/80
 - 2s - loss: 0.0577
Epoch 25/80
 - 2s - loss: 0.0568
Epoch 26/80
 - 2s - loss: 0.0560
Epoch 27/80
 - 2s - loss: 0.0553
Epoch 28/80
 - 2s - loss: 0.0548
Epoch 29/80
 - 2s - loss: 0.0542
Epoch 30/80
 - 2s - loss: 0.0538
Epoch 31/80
 - 2s - loss: 0.0534
Epoch 32/80
 - 2s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0525
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0519
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0517
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0514
Epoch 42/80
 - 2s - loss: 0.0513
Epoch 43/80
 - 2s - loss: 0.0512
Epoch 44/80
 - 2s - loss: 0.0511
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0510
Epoch 47/80
 - 2s - loss: 0.0509
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0508
Epoch 50/80
 - 2s - loss: 0.0507
Epoch 51/80
 - 2s - loss: 0.0507
Epoch 52/80
 - 2s - loss: 0.0506
Epoch 53/80
 - 2s - loss: 0.0506
Epoch 54/80
 - 2s - loss: 0.0505
Epoch 55/80
 - 2s - loss: 0.0505
Epoch 56/80
 - 2s - loss: 0.0504
Epoch 57/80
 - 2s - loss: 0.0504
Epoch 58/80
 - 2s - loss: 0.0504
Epoch 59/80
 - 2s - loss: 0.0504
Epoch 60/80
 - 2s - loss: 0.0503
Epoch 61/80
 - 2s - loss: 0.0492
Epoch 62/80
 - 2s - loss: 0.0491
Epoch 63/80
 - 2s - loss: 0.0491
Epoch 64/80
 - 2s - loss: 0.0491
Epoch 65/80
 - 2s - loss: 0.0491
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0488
Epoch 68/80
 - 2s - loss: 0.0488
Epoch 69/80
 - 2s - loss: 0.0488
Epoch 70/80
 - 2s - loss: 0.0487
Epoch 71/80
 - 2s - loss: 0.0487
Epoch 72/80
 - 2s - loss: 0.0487
Epoch 73/80
 - 2s - loss: 0.0487
Epoch 74/80
 - 2s - loss: 0.0487
Epoch 75/80
 - 2s - loss: 0.0487
Epoch 76/80
 - 2s - loss: 0.0487
Epoch 77/80
 - 2s - loss: 0.0487
Epoch 78/80
 - 2s - loss: 0.0487
Epoch 79/80
 - 2s - loss: 0.0487
Epoch 80/80
 - 2s - loss: 0.0487
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4863 - val_loss: 0.8916
AUC: 0.8093

Epoch 2/80
 - 0s - loss: 2.2779 - val_loss: 1.1222
AUC: 0.8366

Epoch 3/80
 - 0s - loss: 1.6594 - val_loss: 0.8627
AUC: 0.8398

Epoch 4/80
 - 0s - loss: 1.3282 - val_loss: 0.7722
AUC: 0.8437

Epoch 5/80
 - 0s - loss: 1.1994 - val_loss: 0.6339
AUC: 0.8457

Epoch 6/80
 - 0s - loss: 1.1392 - val_loss: 0.6581
AUC: 0.8483

Epoch 7/80
 - 0s - loss: 1.0961 - val_loss: 0.6992
AUC: 0.8516

Epoch 8/80
 - 0s - loss: 1.0747 - val_loss: 0.6855
AUC: 0.8508

Epoch 9/80
 - 0s - loss: 1.0700 - val_loss: 0.7027
AUC: 0.8545

Epoch 10/80
 - 0s - loss: 1.0572 - val_loss: 0.6389
AUC: 0.8548

Epoch 11/80
 - 0s - loss: 1.0450 - val_loss: 0.6503
AUC: 0.8556

Epoch 12/80
 - 0s - loss: 1.0346 - val_loss: 0.5906
AUC: 0.8561

Epoch 13/80
 - 0s - loss: 1.0354 - val_loss: 0.6752
AUC: 0.8575

Epoch 14/80
 - 0s - loss: 1.0297 - val_loss: 0.5921
AUC: 0.8563

Epoch 15/80
 - 0s - loss: 1.0291 - val_loss: 0.6919
AUC: 0.8576

Epoch 16/80
 - 0s - loss: 1.0216 - val_loss: 0.5600
AUC: 0.8566

Epoch 17/80
 - 0s - loss: 1.0139 - val_loss: 0.5795
AUC: 0.8585

Epoch 18/80
 - 0s - loss: 1.0077 - val_loss: 0.6344
AUC: 0.8602

Epoch 19/80
 - 0s - loss: 1.0037 - val_loss: 0.5762
AUC: 0.8600

Epoch 20/80
 - 0s - loss: 1.0047 - val_loss: 0.6341
AUC: 0.8598

Epoch 21/80
 - 0s - loss: 1.0024 - val_loss: 0.6437
AUC: 0.8619

Epoch 22/80
 - 0s - loss: 0.9976 - val_loss: 0.5848
AUC: 0.8596

Epoch 23/80
 - 0s - loss: 0.9931 - val_loss: 0.6308
AUC: 0.8625

Epoch 24/80
 - 0s - loss: 0.9936 - val_loss: 0.6245
AUC: 0.8615

Epoch 25/80
 - 0s - loss: 0.9901 - val_loss: 0.5809
AUC: 0.8624

Epoch 26/80
 - 0s - loss: 0.9906 - val_loss: 0.6228
AUC: 0.8629

Epoch 27/80
 - 0s - loss: 0.9773 - val_loss: 0.6320
AUC: 0.8632

Epoch 28/80
 - 0s - loss: 0.9729 - val_loss: 0.5775
AUC: 0.8626

Epoch 29/80
 - 0s - loss: 0.9754 - val_loss: 0.5952
AUC: 0.8627

Epoch 30/80
 - 0s - loss: 0.9770 - val_loss: 0.6509
AUC: 0.8637

Epoch 31/80
 - 0s - loss: 0.9691 - val_loss: 0.6393
AUC: 0.8638

Epoch 32/80
 - 0s - loss: 0.9668 - val_loss: 0.6011
AUC: 0.8635

Epoch 33/80
 - 0s - loss: 0.9686 - val_loss: 0.6152
AUC: 0.8636

Epoch 34/80
 - 0s - loss: 0.9702 - val_loss: 0.6072
AUC: 0.8634

Epoch 35/80
 - 0s - loss: 0.9709 - val_loss: 0.6135
AUC: 0.8636

Epoch 36/80
 - 0s - loss: 0.9712 - val_loss: 0.6029
AUC: 0.8634

Epoch 37/80
 - 0s - loss: 0.9646 - val_loss: 0.6151
AUC: 0.8638

Epoch 38/80
 - 0s - loss: 0.9684 - val_loss: 0.6120
AUC: 0.8638

Epoch 39/80
 - 0s - loss: 0.9663 - val_loss: 0.5994
AUC: 0.8636

Epoch 40/80
 - 0s - loss: 0.9699 - val_loss: 0.6124
AUC: 0.8639

Epoch 41/80
 - 0s - loss: 0.9629 - val_loss: 0.6123
AUC: 0.8638

Epoch 42/80
 - 0s - loss: 0.9659 - val_loss: 0.6113
AUC: 0.8639

Epoch 43/80
 - 0s - loss: 0.9671 - val_loss: 0.6048
AUC: 0.8638

Epoch 44/80
 - 0s - loss: 0.9623 - val_loss: 0.6112
AUC: 0.8638

Epoch 45/80
 - 0s - loss: 0.9570 - val_loss: 0.6009
AUC: 0.8637

Epoch 46/80
 - 0s - loss: 0.9654 - val_loss: 0.6072
AUC: 0.8639

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9669 - val_loss: 0.6049
AUC: 0.8639

Epoch 2/30
 - 0s - loss: 0.9659 - val_loss: 0.5882
AUC: 0.8638

Epoch 3/30
 - 0s - loss: 0.9680 - val_loss: 0.6056
AUC: 0.8643

Epoch 4/30
 - 0s - loss: 0.9621 - val_loss: 0.6100
AUC: 0.8643

Epoch 5/30
 - 0s - loss: 0.9602 - val_loss: 0.6239
AUC: 0.8647

Epoch 6/30
 - 0s - loss: 0.9567 - val_loss: 0.5886
AUC: 0.8645

Epoch 7/30
 - 0s - loss: 0.9575 - val_loss: 0.6358
AUC: 0.8649

Epoch 8/30
 - 0s - loss: 0.9564 - val_loss: 0.5911
AUC: 0.8647

Epoch 9/30
 - 0s - loss: 0.9578 - val_loss: 0.6220
AUC: 0.8651

Epoch 10/30
 - 0s - loss: 0.9531 - val_loss: 0.6022
AUC: 0.8649

Epoch 11/30
 - 0s - loss: 0.9527 - val_loss: 0.5866
AUC: 0.8652

Epoch 12/30
 - 0s - loss: 0.9469 - val_loss: 0.6147
AUC: 0.8655

Epoch 13/30
 - 0s - loss: 0.9537 - val_loss: 0.5736
AUC: 0.8653

Epoch 14/30
 - 0s - loss: 0.9501 - val_loss: 0.6007
AUC: 0.8656

Epoch 15/30
 - 0s - loss: 0.9505 - val_loss: 0.5947
AUC: 0.8656

Epoch 16/30
 - 0s - loss: 0.9484 - val_loss: 0.5983
AUC: 0.8658

Epoch 17/30
 - 0s - loss: 0.9419 - val_loss: 0.6072
AUC: 0.8660

Epoch 18/30
 - 0s - loss: 0.9463 - val_loss: 0.6050
AUC: 0.8662

Epoch 19/30
 - 0s - loss: 0.9438 - val_loss: 0.6004
AUC: 0.8665

Epoch 20/30
 - 0s - loss: 0.9434 - val_loss: 0.6099
AUC: 0.8667

Epoch 21/30
 - 0s - loss: 0.9413 - val_loss: 0.6155
AUC: 0.8665

Epoch 22/30
 - 0s - loss: 0.9350 - val_loss: 0.6153
AUC: 0.8667

Epoch 23/30
 - 0s - loss: 0.9442 - val_loss: 0.5876
AUC: 0.8665

Epoch 24/30
 - 0s - loss: 0.9371 - val_loss: 0.5989
AUC: 0.8667

Epoch 25/30
 - 0s - loss: 0.9384 - val_loss: 0.5950
AUC: 0.8667

Epoch 26/30
 - 0s - loss: 0.9411 - val_loss: 0.5971
AUC: 0.8668

Epoch 27/30
 - 0s - loss: 0.9387 - val_loss: 0.5983
AUC: 0.8669

Epoch 28/30
 - 0s - loss: 0.9353 - val_loss: 0.5945
AUC: 0.8668

Epoch 29/30
 - 0s - loss: 0.9346 - val_loss: 0.5922
AUC: 0.8668

Epoch 30/30
 - 0s - loss: 0.9349 - val_loss: 0.5925
Using TensorFlow backend.
AUC: 0.8668

2019-03-08 04:30:22.917595: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:30:23.082329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:30:23.082373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:30:23.376389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:30:23.376441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:30:23.376451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:30:23.376741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1585
Epoch 2/80
 - 2s - loss: 0.2187
Epoch 3/80
 - 2s - loss: 0.1710
Epoch 4/80
 - 2s - loss: 0.1591
Epoch 5/80
 - 2s - loss: 0.1486
Epoch 6/80
 - 2s - loss: 0.1391
Epoch 7/80
 - 2s - loss: 0.1300
Epoch 8/80
 - 2s - loss: 0.1214
Epoch 9/80
 - 2s - loss: 0.1135
Epoch 10/80
 - 2s - loss: 0.1064
Epoch 11/80
 - 2s - loss: 0.1001
Epoch 12/80
 - 2s - loss: 0.0945
Epoch 13/80
 - 2s - loss: 0.0895
Epoch 14/80
 - 2s - loss: 0.0850
Epoch 15/80
 - 2s - loss: 0.0808
Epoch 16/80
 - 2s - loss: 0.0769
Epoch 17/80
 - 2s - loss: 0.0733
Epoch 18/80
 - 2s - loss: 0.0701
Epoch 19/80
 - 2s - loss: 0.0674
Epoch 20/80
 - 2s - loss: 0.0650
Epoch 21/80
 - 2s - loss: 0.0630
Epoch 22/80
 - 2s - loss: 0.0614
Epoch 23/80
 - 2s - loss: 0.0599
Epoch 24/80
 - 2s - loss: 0.0587
Epoch 25/80
 - 2s - loss: 0.0577
Epoch 26/80
 - 2s - loss: 0.0568
Epoch 27/80
 - 2s - loss: 0.0561
Epoch 28/80
 - 2s - loss: 0.0554
Epoch 29/80
 - 2s - loss: 0.0548
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 04:31:31.508012: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:31:31.675029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:31:31.675073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:31:31.974834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:31:31.974884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:31:31.974893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:31:31.975144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1306
Epoch 2/80
 - 2s - loss: 0.2125
Epoch 3/80
 - 2s - loss: 0.1709
Epoch 4/80
 - 2s - loss: 0.1615
Epoch 5/80
 - 2s - loss: 0.1529
Epoch 6/80
 - 2s - loss: 0.1444
Epoch 7/80
 - 2s - loss: 0.1365
Epoch 8/80
 - 2s - loss: 0.1287
Epoch 9/80
 - 2s - loss: 0.1204
Epoch 10/80
 - 2s - loss: 0.1118
Epoch 11/80
 - 2s - loss: 0.1037
Epoch 12/80
 - 2s - loss: 0.0965
Epoch 13/80
 - 2s - loss: 0.0898
Epoch 14/80
 - 2s - loss: 0.0838
Epoch 15/80
 - 2s - loss: 0.0786
Epoch 16/80
 - 2s - loss: 0.0742
Epoch 17/80
 - 2s - loss: 0.0706
Epoch 18/80
 - 2s - loss: 0.0677
Epoch 19/80
 - 2s - loss: 0.0653
Epoch 20/80
 - 2s - loss: 0.0632
Epoch 21/80
 - 2s - loss: 0.0615
Epoch 22/80
 - 2s - loss: 0.0601
Epoch 23/80
 - 2s - loss: 0.0589
Epoch 24/80
 - 2s - loss: 0.0578
Epoch 25/80
 - 2s - loss: 0.0569
Epoch 26/80
 - 2s - loss: 0.0561
Epoch 27/80
 - 2s - loss: 0.0554
Epoch 28/80
 - 2s - loss: 0.0548
Epoch 29/80
 - 2s - loss: 0.0543
Epoch 30/80
 - 2s - loss: 0.0539
Epoch 31/80
 - 2s - loss: 0.0535
Epoch 32/80
 - 2s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0525
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0519
Epoch 38/80
 - 2s - loss: 0.0517
Epoch 39/80
 - 2s - loss: 0.0515
Epoch 40/80
 - 2s - loss: 0.0514
Epoch 41/80
 - 2s - loss: 0.0513
Epoch 42/80
 - 2s - loss: 0.0512
Epoch 43/80
 - 2s - loss: 0.0510
Epoch 44/80
 - 2s - loss: 0.0509
Epoch 45/80
 - 2s - loss: 0.0509
Epoch 46/80
 - 2s - loss: 0.0508
Epoch 47/80
 - 2s - loss: 0.0507
Epoch 48/80
 - 2s - loss: 0.0506
Epoch 49/80
 - 2s - loss: 0.0505
Epoch 50/80
 - 2s - loss: 0.0505
Epoch 51/80
 - 2s - loss: 0.0504
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0503
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0502
Epoch 56/80
 - 2s - loss: 0.0502
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0501
Epoch 59/80
 - 2s - loss: 0.0501
Epoch 60/80
 - 2s - loss: 0.0501
Epoch 61/80
 - 2s - loss: 0.0500
Epoch 62/80
 - 2s - loss: 0.0500
Epoch 63/80
 - 2s - loss: 0.0489
Epoch 64/80
 - 2s - loss: 0.0488
Epoch 65/80
 - 2s - loss: 0.0488
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0488
Epoch 68/80
 - 2s - loss: 0.0485
Epoch 69/80
 - 2s - loss: 0.0485
Epoch 70/80
 - 2s - loss: 0.0485
Epoch 71/80
 - 2s - loss: 0.0485
Epoch 72/80
 - 2s - loss: 0.0484
Epoch 73/80
 - 2s - loss: 0.0484
Epoch 74/80
 - 2s - loss: 0.0484
Epoch 75/80
 - 2s - loss: 0.0484
Epoch 76/80
 - 2s - loss: 0.0484
Epoch 77/80
 - 2s - loss: 0.0484
Epoch 78/80
 - 2s - loss: 0.0484
Epoch 79/80
 - 2s - loss: 0.0484
Epoch 80/80
 - 2s - loss: 0.0484
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.7915 - val_loss: 1.5626
AUC: 0.7887

Epoch 2/80
 - 0s - loss: 3.2927 - val_loss: 1.0887
AUC: 0.8193

Epoch 3/80
 - 0s - loss: 2.5757 - val_loss: 1.0822
AUC: 0.8396

Epoch 4/80
 - 0s - loss: 1.9814 - val_loss: 0.8619
AUC: 0.8492

Epoch 5/80
 - 0s - loss: 1.6085 - val_loss: 0.7145
AUC: 0.8529

Epoch 6/80
 - 0s - loss: 1.3648 - val_loss: 0.6823
AUC: 0.8555

Epoch 7/80
 - 0s - loss: 1.2261 - val_loss: 0.6661
AUC: 0.8573

Epoch 8/80
 - 0s - loss: 1.1501 - val_loss: 0.6224
AUC: 0.8585

Epoch 9/80
 - 0s - loss: 1.1091 - val_loss: 0.5850
AUC: 0.8587

Epoch 10/80
 - 0s - loss: 1.0853 - val_loss: 0.6278
AUC: 0.8604

Epoch 11/80
 - 0s - loss: 1.0740 - val_loss: 0.6870
AUC: 0.8637

Epoch 12/80
 - 0s - loss: 1.0578 - val_loss: 0.6123
AUC: 0.8639

Epoch 13/80
 - 0s - loss: 1.0514 - val_loss: 0.6119
AUC: 0.8640

Epoch 14/80
 - 0s - loss: 1.0316 - val_loss: 0.5808
AUC: 0.8634

Epoch 15/80
 - 0s - loss: 1.0289 - val_loss: 0.5494
AUC: 0.8645

Epoch 16/80
 - 0s - loss: 1.0290 - val_loss: 0.6561
AUC: 0.8669

Epoch 17/80
 - 0s - loss: 1.0239 - val_loss: 0.6127
AUC: 0.8667

Epoch 18/80
 - 0s - loss: 1.0125 - val_loss: 0.5874
AUC: 0.8675

Epoch 19/80
 - 0s - loss: 1.0094 - val_loss: 0.6089
AUC: 0.8685

Epoch 20/80
 - 0s - loss: 1.0044 - val_loss: 0.5971
AUC: 0.8691

Epoch 21/80
 - 0s - loss: 1.0108 - val_loss: 0.6279
AUC: 0.8700

Epoch 22/80
 - 0s - loss: 0.9948 - val_loss: 0.5805
AUC: 0.8701

Epoch 23/80
 - 0s - loss: 0.9987 - val_loss: 0.6049
AUC: 0.8704

Epoch 24/80
 - 0s - loss: 0.9870 - val_loss: 0.6114
AUC: 0.8701

Epoch 25/80
 - 0s - loss: 0.9863 - val_loss: 0.5630
AUC: 0.8699

Epoch 26/80
 - 0s - loss: 0.9801 - val_loss: 0.6069
AUC: 0.8714

Epoch 27/80
 - 0s - loss: 0.9817 - val_loss: 0.6013
AUC: 0.8714

Epoch 28/80
 - 0s - loss: 0.9815 - val_loss: 0.5943
AUC: 0.8716

Epoch 29/80
 - 0s - loss: 0.9755 - val_loss: 0.5944
AUC: 0.8718

Epoch 30/80
 - 0s - loss: 0.9765 - val_loss: 0.5998
AUC: 0.8717

Epoch 31/80
 - 0s - loss: 0.9786 - val_loss: 0.6067
AUC: 0.8724

Epoch 32/80
 - 0s - loss: 0.9768 - val_loss: 0.5844
AUC: 0.8721

Epoch 33/80
 - 0s - loss: 0.9759 - val_loss: 0.6030
AUC: 0.8726

Epoch 34/80
 - 0s - loss: 0.9736 - val_loss: 0.5971
AUC: 0.8724

Epoch 35/80
 - 0s - loss: 0.9750 - val_loss: 0.5888
AUC: 0.8719

Epoch 36/80
 - 0s - loss: 0.9714 - val_loss: 0.5956
AUC: 0.8722

Epoch 37/80
 - 0s - loss: 0.9671 - val_loss: 0.5880
AUC: 0.8723

Epoch 38/80
 - 0s - loss: 0.9756 - val_loss: 0.5942
AUC: 0.8724

Epoch 39/80
 - 0s - loss: 0.9706 - val_loss: 0.6020
AUC: 0.8726

Epoch 40/80
 - 0s - loss: 0.9670 - val_loss: 0.5944
AUC: 0.8725

Epoch 41/80
 - 0s - loss: 0.9747 - val_loss: 0.6019
AUC: 0.8726

Epoch 42/80
 - 0s - loss: 0.9697 - val_loss: 0.5925
AUC: 0.8725

Epoch 43/80
 - 0s - loss: 0.9697 - val_loss: 0.6026
AUC: 0.8726

Epoch 44/80
 - 0s - loss: 0.9744 - val_loss: 0.6033
AUC: 0.8727

Epoch 45/80
 - 0s - loss: 0.9665 - val_loss: 0.6011
AUC: 0.8727

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9709 - val_loss: 0.6184
AUC: 0.8731

Epoch 2/30
 - 0s - loss: 0.9718 - val_loss: 0.6191
AUC: 0.8729

Epoch 3/30
 - 0s - loss: 0.9701 - val_loss: 0.6121
AUC: 0.8729

Epoch 4/30
 - 0s - loss: 0.9622 - val_loss: 0.6143
AUC: 0.8733

Epoch 5/30
 - 0s - loss: 0.9603 - val_loss: 0.5981
AUC: 0.8733

Epoch 6/30
 - 0s - loss: 0.9615 - val_loss: 0.5575
AUC: 0.8728

Epoch 7/30
 - 0s - loss: 0.9623 - val_loss: 0.5984
AUC: 0.8736

Epoch 8/30
 - 0s - loss: 0.9553 - val_loss: 0.5775
AUC: 0.8736

Epoch 9/30
 - 0s - loss: 0.9549 - val_loss: 0.5843
AUC: 0.8737

Epoch 10/30
 - 0s - loss: 0.9612 - val_loss: 0.6014
AUC: 0.8740

Epoch 11/30
 - 0s - loss: 0.9562 - val_loss: 0.5778
AUC: 0.8739

Epoch 12/30
 - 0s - loss: 0.9593 - val_loss: 0.5958
AUC: 0.8743

Epoch 13/30
 - 0s - loss: 0.9489 - val_loss: 0.5847
AUC: 0.8743

Epoch 14/30
 - 0s - loss: 0.9499 - val_loss: 0.5837
AUC: 0.8743

Epoch 15/30
 - 0s - loss: 0.9491 - val_loss: 0.6093
AUC: 0.8749

Epoch 16/30
 - 0s - loss: 0.9480 - val_loss: 0.5970
AUC: 0.8748

Epoch 17/30
 - 0s - loss: 0.9430 - val_loss: 0.5843
AUC: 0.8746

Epoch 18/30
 - 0s - loss: 0.9423 - val_loss: 0.5881
AUC: 0.8747

Epoch 19/30
 - 0s - loss: 0.9457 - val_loss: 0.5907
AUC: 0.8747

Epoch 20/30
 - 0s - loss: 0.9452 - val_loss: 0.5868
AUC: 0.8747

Epoch 21/30
 - 0s - loss: 0.9447 - val_loss: 0.5831
AUC: 0.8747

Epoch 22/30
 - 0s - loss: 0.9480 - val_loss: 0.5788
AUC: 0.8747

Epoch 23/30
 - 0s - loss: 0.9409 - val_loss: 0.5902
AUC: 0.8748

Epoch 24/30
 - 0s - loss: 0.9443 - val_loss: 0.5905
AUC: 0.8749

Epoch 25/30
 - 0s - loss: 0.9437 - val_loss: 0.5844
AUC: 0.8748

Epoch 26/30
 - 0s - loss: 0.9413 - val_loss: 0.5898
AUC: 0.8749

Epoch 27/30
 - 0s - loss: 0.9406 - val_loss: 0.5870
AUC: 0.8749

Epoch 28/30
 - 0s - loss: 0.9427 - val_loss: 0.5852
AUC: 0.8749

Epoch 29/30
 - 0s - loss: 0.9446 - val_loss: 0.5842
AUC: 0.8749

Epoch 30/30
 - 0s - loss: 0.9376 - val_loss: 0.5825
Using TensorFlow backend.
AUC: 0.8748

2019-03-08 04:34:48.600415: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:34:48.767489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:34:48.767535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:34:49.061890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:34:49.061942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:34:49.061951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:34:49.062253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6972
Epoch 2/80
 - 2s - loss: 0.1340
Epoch 3/80
 - 2s - loss: 0.0719
Epoch 4/80
 - 2s - loss: 0.0653
Epoch 5/80
 - 2s - loss: 0.0626
Epoch 6/80
 - 2s - loss: 0.0605
Epoch 7/80
 - 2s - loss: 0.0580
Epoch 8/80
 - 2s - loss: 0.0552
Epoch 9/80
 - 2s - loss: 0.0519
Epoch 10/80
 - 2s - loss: 0.0482
Epoch 11/80
 - 2s - loss: 0.0444
Epoch 12/80
 - 2s - loss: 0.0408
Epoch 13/80
 - 2s - loss: 0.0378
Epoch 14/80
 - 2s - loss: 0.0352
Epoch 15/80
 - 2s - loss: 0.0328
Epoch 16/80
 - 2s - loss: 0.0306
Epoch 17/80
 - 2s - loss: 0.0287
Epoch 18/80
 - 2s - loss: 0.0270
Epoch 19/80
 - 2s - loss: 0.0256
Epoch 20/80
 - 2s - loss: 0.0243
Epoch 21/80
 - 2s - loss: 0.0233
Epoch 22/80
 - 2s - loss: 0.0224
Epoch 23/80
 - 2s - loss: 0.0216
Epoch 24/80
 - 2s - loss: 0.0209
Epoch 25/80
 - 2s - loss: 0.0203
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0194
Epoch 28/80
 - 2s - loss: 0.0191
Epoch 29/80
 - 2s - loss: 0.0187
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0182
Epoch 32/80
 - 2s - loss: 0.0180
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0174
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0172
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0169
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0167
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0161
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0160
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0159
Epoch 58/80
 - 2s - loss: 0.0159
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.3716 - val_loss: 1.0993
AUC: 0.7978

Epoch 2/80
 - 0s - loss: 2.2826 - val_loss: 1.0601
AUC: 0.8272

Epoch 3/80
 - 0s - loss: 1.6697 - val_loss: 0.7831
AUC: 0.8338

Epoch 4/80
 - 0s - loss: 1.3566 - val_loss: 0.6763
AUC: 0.8365

Epoch 5/80
 - 0s - loss: 1.2327 - val_loss: 0.6820
AUC: 0.8415

Epoch 6/80
 - 0s - loss: 1.1481 - val_loss: 0.7166
AUC: 0.8444

Epoch 7/80
 - 0s - loss: 1.1197 - val_loss: 0.7194
AUC: 0.8474

Epoch 8/80
 - 0s - loss: 1.0924 - val_loss: 0.6197
AUC: 0.8482

Epoch 9/80
 - 0s - loss: 1.0809 - val_loss: 0.6480
AUC: 0.8493

Epoch 10/80
 - 0s - loss: 1.0646 - val_loss: 0.6820
AUC: 0.8517

Epoch 11/80
 - 0s - loss: 1.0551 - val_loss: 0.6837
AUC: 0.8516

Epoch 12/80
 - 0s - loss: 1.0495 - val_loss: 0.6492
AUC: 0.8538

Epoch 13/80
 - 0s - loss: 1.0372 - val_loss: 0.7601
AUC: 0.8535

Epoch 14/80
 - 0s - loss: 1.0261 - val_loss: 0.6447
AUC: 0.8527

Epoch 15/80
 - 0s - loss: 1.0288 - val_loss: 0.7037
AUC: 0.8560

Epoch 16/80
 - 0s - loss: 1.0197 - val_loss: 0.6287
AUC: 0.8549

Epoch 17/80
 - 0s - loss: 1.0217 - val_loss: 0.6168
AUC: 0.8562

Epoch 18/80
 - 0s - loss: 1.0196 - val_loss: 0.7007
AUC: 0.8555

Epoch 19/80
 - 0s - loss: 1.0157 - val_loss: 0.5598
AUC: 0.8548

Epoch 20/80
 - 0s - loss: 1.0120 - val_loss: 0.6044
AUC: 0.8571

Epoch 21/80
 - 0s - loss: 1.0030 - val_loss: 0.5958
AUC: 0.8573

Epoch 22/80
 - 0s - loss: 0.9951 - val_loss: 0.6546
AUC: 0.8574

Epoch 23/80
 - 0s - loss: 0.9921 - val_loss: 0.6037
AUC: 0.8554

Epoch 24/80
 - 0s - loss: 0.9914 - val_loss: 0.6352
AUC: 0.8575

Epoch 25/80
 - 0s - loss: 0.9911 - val_loss: 0.5764
AUC: 0.8570

Epoch 26/80
 - 0s - loss: 0.9922 - val_loss: 0.5669
AUC: 0.8561

Epoch 27/80
 - 0s - loss: 0.9837 - val_loss: 0.5898
AUC: 0.8578

Epoch 28/80
 - 0s - loss: 0.9723 - val_loss: 0.6483
AUC: 0.8568

Epoch 29/80
 - 0s - loss: 0.9828 - val_loss: 0.5940
AUC: 0.8572

Epoch 30/80
 - 0s - loss: 0.9702 - val_loss: 0.5906
AUC: 0.8585

Epoch 31/80
 - 0s - loss: 0.9678 - val_loss: 0.6050
AUC: 0.8587

Epoch 32/80
 - 0s - loss: 0.9738 - val_loss: 0.5749
AUC: 0.8588

Epoch 33/80
 - 0s - loss: 0.9708 - val_loss: 0.6107
AUC: 0.8590

Epoch 34/80
 - 0s - loss: 0.9662 - val_loss: 0.5852
AUC: 0.8588

Epoch 35/80
 - 0s - loss: 0.9679 - val_loss: 0.6130
AUC: 0.8590

Epoch 36/80
 - 0s - loss: 0.9633 - val_loss: 0.5896
AUC: 0.8591

Epoch 37/80
 - 0s - loss: 0.9627 - val_loss: 0.6272
AUC: 0.8591

Epoch 38/80
 - 0s - loss: 0.9631 - val_loss: 0.5867
AUC: 0.8590

Epoch 39/80
 - 0s - loss: 0.9637 - val_loss: 0.6174
AUC: 0.8592

Epoch 40/80
 - 0s - loss: 0.9599 - val_loss: 0.6160
AUC: 0.8593

Epoch 41/80
 - 0s - loss: 0.9623 - val_loss: 0.6103
AUC: 0.8593

Epoch 42/80
 - 0s - loss: 0.9601 - val_loss: 0.6178
AUC: 0.8594

Epoch 43/80
 - 0s - loss: 0.9615 - val_loss: 0.6081
AUC: 0.8593

Epoch 44/80
 - 0s - loss: 0.9668 - val_loss: 0.6149
AUC: 0.8593

Epoch 45/80
 - 0s - loss: 0.9630 - val_loss: 0.6041
AUC: 0.8594

Epoch 46/80
 - 0s - loss: 0.9592 - val_loss: 0.6082
AUC: 0.8594

Epoch 47/80
 - 0s - loss: 0.9578 - val_loss: 0.6108
AUC: 0.8594

Epoch 48/80
 - 0s - loss: 0.9605 - val_loss: 0.6045
AUC: 0.8594

Epoch 49/80
 - 0s - loss: 0.9583 - val_loss: 0.6091
AUC: 0.8595

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9616 - val_loss: 0.6098
AUC: 0.8597

Epoch 2/30
 - 0s - loss: 0.9567 - val_loss: 0.6079
AUC: 0.8599

Epoch 3/30
 - 0s - loss: 0.9583 - val_loss: 0.6025
AUC: 0.8599

Epoch 4/30
 - 0s - loss: 0.9535 - val_loss: 0.6018
AUC: 0.8599

Epoch 5/30
 - 0s - loss: 0.9535 - val_loss: 0.6091
AUC: 0.8601

Epoch 6/30
 - 0s - loss: 0.9514 - val_loss: 0.6143
AUC: 0.8602

Epoch 7/30
 - 0s - loss: 0.9539 - val_loss: 0.6116
AUC: 0.8603

Epoch 8/30
 - 0s - loss: 0.9480 - val_loss: 0.6061
AUC: 0.8603

Epoch 9/30
 - 0s - loss: 0.9493 - val_loss: 0.6055
AUC: 0.8603

Epoch 10/30
 - 0s - loss: 0.9466 - val_loss: 0.5972
AUC: 0.8606

Epoch 11/30
 - 0s - loss: 0.9440 - val_loss: 0.6035
AUC: 0.8607

Epoch 12/30
 - 0s - loss: 0.9476 - val_loss: 0.6039
AUC: 0.8608

Epoch 13/30
 - 0s - loss: 0.9461 - val_loss: 0.5929
AUC: 0.8608

Epoch 14/30
 - 0s - loss: 0.9433 - val_loss: 0.6225
AUC: 0.8610

Epoch 15/30
 - 0s - loss: 0.9430 - val_loss: 0.6002
AUC: 0.8609

Epoch 16/30
 - 0s - loss: 0.9409 - val_loss: 0.5983
AUC: 0.8610

Epoch 17/30
 - 0s - loss: 0.9395 - val_loss: 0.6005
AUC: 0.8608

Epoch 18/30
 - 0s - loss: 0.9354 - val_loss: 0.6062
AUC: 0.8611

Epoch 19/30
 - 0s - loss: 0.9322 - val_loss: 0.5999
AUC: 0.8612

Epoch 20/30
 - 0s - loss: 0.9356 - val_loss: 0.6082
AUC: 0.8614

Epoch 21/30
 - 0s - loss: 0.9337 - val_loss: 0.6123
AUC: 0.8614

Epoch 22/30
 - 0s - loss: 0.9319 - val_loss: 0.6102
AUC: 0.8616

Epoch 23/30
 - 0s - loss: 0.9321 - val_loss: 0.5994
AUC: 0.8615

Epoch 24/30
 - 0s - loss: 0.9303 - val_loss: 0.5970
AUC: 0.8615

Epoch 25/30
 - 0s - loss: 0.9259 - val_loss: 0.5913
AUC: 0.8616

Epoch 26/30
 - 0s - loss: 0.9295 - val_loss: 0.5919
AUC: 0.8616

Epoch 27/30
 - 0s - loss: 0.9303 - val_loss: 0.5903
AUC: 0.8616

Epoch 28/30
 - 0s - loss: 0.9314 - val_loss: 0.5934
AUC: 0.8616

Epoch 29/30
 - 0s - loss: 0.9263 - val_loss: 0.5912
AUC: 0.8615

Epoch 30/30
 - 0s - loss: 0.9300 - val_loss: 0.5896
Using TensorFlow backend.
AUC: 0.8616

2019-03-08 04:38:06.743968: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:38:06.908910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:38:06.908953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:38:07.205955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:38:07.206007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:38:07.206016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:38:07.206288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6918
Epoch 2/80
 - 2s - loss: 0.1351
Epoch 3/80
 - 2s - loss: 0.0731
Epoch 4/80
 - 2s - loss: 0.0658
Epoch 5/80
 - 2s - loss: 0.0625
Epoch 6/80
 - 2s - loss: 0.0594
Epoch 7/80
 - 2s - loss: 0.0558
Epoch 8/80
 - 2s - loss: 0.0520
Epoch 9/80
 - 2s - loss: 0.0484
Epoch 10/80
 - 2s - loss: 0.0453
Epoch 11/80
 - 2s - loss: 0.0426
Epoch 12/80
 - 2s - loss: 0.0400
Epoch 13/80
 - 2s - loss: 0.0375
Epoch 14/80
 - 2s - loss: 0.0352
Epoch 15/80
 - 2s - loss: 0.0329
Epoch 16/80
 - 2s - loss: 0.0309
Epoch 17/80
 - 2s - loss: 0.0291
Epoch 18/80
 - 2s - loss: 0.0274
Epoch 19/80
 - 2s - loss: 0.0260
Epoch 20/80
 - 2s - loss: 0.0247
Epoch 21/80
 - 2s - loss: 0.0237
Epoch 22/80
 - 2s - loss: 0.0227
Epoch 23/80
 - 2s - loss: 0.0219
Epoch 24/80
 - 2s - loss: 0.0212
Epoch 25/80
 - 2s - loss: 0.0206
Epoch 26/80
 - 2s - loss: 0.0201
Epoch 27/80
 - 2s - loss: 0.0197
Epoch 28/80
 - 2s - loss: 0.0193
Epoch 29/80
 - 2s - loss: 0.0190
Epoch 30/80
 - 2s - loss: 0.0187
Epoch 31/80
 - 2s - loss: 0.0184
Epoch 32/80
 - 2s - loss: 0.0182
Epoch 33/80
 - 2s - loss: 0.0180
Epoch 34/80
 - 2s - loss: 0.0179
Epoch 35/80
 - 2s - loss: 0.0177
Epoch 36/80
 - 2s - loss: 0.0176
Epoch 37/80
 - 2s - loss: 0.0175
Epoch 38/80
 - 2s - loss: 0.0174
Epoch 39/80
 - 2s - loss: 0.0173
Epoch 40/80
 - 2s - loss: 0.0172
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0170
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0169
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0161
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0161
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0160
Epoch 60/80
 - 2s - loss: 0.0160
Epoch 61/80
 - 2s - loss: 0.0160
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.8904 - val_loss: 1.3183
AUC: 0.8173

Epoch 2/80
 - 0s - loss: 1.9710 - val_loss: 0.8174
AUC: 0.8378

Epoch 3/80
 - 0s - loss: 1.5060 - val_loss: 0.9529
AUC: 0.8498

Epoch 4/80
 - 0s - loss: 1.2701 - val_loss: 0.6506
AUC: 0.8485

Epoch 5/80
 - 0s - loss: 1.1720 - val_loss: 0.6843
AUC: 0.8542

Epoch 6/80
 - 0s - loss: 1.1276 - val_loss: 0.6749
AUC: 0.8575

Epoch 7/80
 - 0s - loss: 1.0975 - val_loss: 0.6959
AUC: 0.8597

Epoch 8/80
 - 0s - loss: 1.0811 - val_loss: 0.7031
AUC: 0.8614

Epoch 9/80
 - 0s - loss: 1.0696 - val_loss: 0.6759
AUC: 0.8621

Epoch 10/80
 - 0s - loss: 1.0515 - val_loss: 0.6416
AUC: 0.8644

Epoch 11/80
 - 0s - loss: 1.0445 - val_loss: 0.6666
AUC: 0.8654

Epoch 12/80
 - 0s - loss: 1.0339 - val_loss: 0.6273
AUC: 0.8662

Epoch 13/80
 - 0s - loss: 1.0260 - val_loss: 0.5799
AUC: 0.8654

Epoch 14/80
 - 0s - loss: 1.0322 - val_loss: 0.6688
AUC: 0.8675

Epoch 15/80
 - 0s - loss: 1.0199 - val_loss: 0.6452
AUC: 0.8673

Epoch 16/80
 - 0s - loss: 1.0190 - val_loss: 0.5941
AUC: 0.8668

Epoch 17/80
 - 0s - loss: 1.0178 - val_loss: 0.6847
AUC: 0.8685

Epoch 18/80
 - 0s - loss: 1.0089 - val_loss: 0.6398
AUC: 0.8682

Epoch 19/80
 - 0s - loss: 1.0047 - val_loss: 0.5709
AUC: 0.8690

Epoch 20/80
 - 0s - loss: 1.0012 - val_loss: 0.6102
AUC: 0.8682

Epoch 21/80
 - 0s - loss: 1.0010 - val_loss: 0.6438
AUC: 0.8696

Epoch 22/80
 - 0s - loss: 0.9923 - val_loss: 0.5463
AUC: 0.8689

Epoch 23/80
 - 0s - loss: 0.9924 - val_loss: 0.6481
AUC: 0.8699

Epoch 24/80
 - 0s - loss: 0.9906 - val_loss: 0.5357
AUC: 0.8694

Epoch 25/80
 - 0s - loss: 0.9900 - val_loss: 0.5452
AUC: 0.8687

Epoch 26/80
 - 0s - loss: 0.9801 - val_loss: 0.5623
AUC: 0.8688

Epoch 27/80
 - 0s - loss: 0.9846 - val_loss: 0.5849
AUC: 0.8697

Epoch 28/80
 - 0s - loss: 0.9745 - val_loss: 0.6423
AUC: 0.8708

Epoch 29/80
 - 0s - loss: 0.9788 - val_loss: 0.6190
AUC: 0.8702

Epoch 30/80
 - 0s - loss: 0.9749 - val_loss: 0.6213
AUC: 0.8705

Epoch 31/80
 - 0s - loss: 0.9746 - val_loss: 0.6225
AUC: 0.8703

Epoch 32/80
 - 0s - loss: 0.9726 - val_loss: 0.6834
AUC: 0.8714

Epoch 33/80
 - 0s - loss: 0.9707 - val_loss: 0.6282
AUC: 0.8715

Epoch 34/80
 - 0s - loss: 0.9683 - val_loss: 0.5314
AUC: 0.8707

Epoch 35/80
 - 0s - loss: 0.9616 - val_loss: 0.5848
AUC: 0.8717

Epoch 36/80
 - 0s - loss: 0.9599 - val_loss: 0.6115
AUC: 0.8717

Epoch 37/80
 - 0s - loss: 0.9615 - val_loss: 0.6121
AUC: 0.8706

Epoch 38/80
 - 0s - loss: 0.9612 - val_loss: 0.6080
AUC: 0.8708

Epoch 39/80
 - 0s - loss: 0.9589 - val_loss: 0.5968
AUC: 0.8711

Epoch 40/80
 - 0s - loss: 0.9572 - val_loss: 0.6276
AUC: 0.8716

Epoch 41/80
 - 0s - loss: 0.9584 - val_loss: 0.5837
AUC: 0.8722

Epoch 42/80
 - 0s - loss: 0.9525 - val_loss: 0.5640
AUC: 0.8713

Epoch 43/80
 - 0s - loss: 0.9553 - val_loss: 0.5029
AUC: 0.8704

Epoch 44/80
 - 0s - loss: 0.9538 - val_loss: 0.5618
AUC: 0.8710

Epoch 45/80
 - 0s - loss: 0.9513 - val_loss: 0.6321
AUC: 0.8722

Epoch 46/80
 - 0s - loss: 0.9423 - val_loss: 0.6081
AUC: 0.8708

Epoch 47/80
 - 0s - loss: 0.9501 - val_loss: 0.6456
AUC: 0.8715

Epoch 48/80
 - 0s - loss: 0.9484 - val_loss: 0.5913
AUC: 0.8717

Epoch 49/80
 - 0s - loss: 0.9397 - val_loss: 0.5737
AUC: 0.8723

Epoch 50/80
 - 0s - loss: 0.9372 - val_loss: 0.5825
AUC: 0.8726

Epoch 51/80
 - 0s - loss: 0.9432 - val_loss: 0.5648
AUC: 0.8722

Epoch 52/80
 - 0s - loss: 0.9376 - val_loss: 0.5291
AUC: 0.8718

Epoch 53/80
 - 0s - loss: 0.9368 - val_loss: 0.6415
AUC: 0.8726

Epoch 54/80
 - 0s - loss: 0.9319 - val_loss: 0.5896
AUC: 0.8728

Epoch 55/80
 - 0s - loss: 0.9228 - val_loss: 0.5850
AUC: 0.8725

Epoch 56/80
 - 0s - loss: 0.9211 - val_loss: 0.5645
AUC: 0.8725

Epoch 57/80
 - 0s - loss: 0.9170 - val_loss: 0.6056
AUC: 0.8726

Epoch 58/80
 - 0s - loss: 0.9195 - val_loss: 0.5604
AUC: 0.8723

Epoch 59/80
 - 0s - loss: 0.9176 - val_loss: 0.5771
AUC: 0.8726

Epoch 60/80
 - 0s - loss: 0.9188 - val_loss: 0.5787
AUC: 0.8724

Epoch 61/80
 - 0s - loss: 0.9152 - val_loss: 0.5590
AUC: 0.8723

Epoch 62/80
 - 0s - loss: 0.9189 - val_loss: 0.6106
AUC: 0.8724

Epoch 63/80
 - 0s - loss: 0.9174 - val_loss: 0.5778
AUC: 0.8723

Epoch 64/80
 - 0s - loss: 0.9143 - val_loss: 0.5773
AUC: 0.8723

Epoch 65/80
 - 0s - loss: 0.9129 - val_loss: 0.5795
AUC: 0.8723

Epoch 66/80
 - 0s - loss: 0.9147 - val_loss: 0.5834
AUC: 0.8723

Epoch 67/80
 - 0s - loss: 0.9141 - val_loss: 0.5730
AUC: 0.8722

Epoch 68/80
 - 0s - loss: 0.9133 - val_loss: 0.5771
AUC: 0.8723

Epoch 69/80
 - 0s - loss: 0.9037 - val_loss: 0.5809
AUC: 0.8723

Epoch 70/80
 - 0s - loss: 0.9117 - val_loss: 0.5728
AUC: 0.8722

Epoch 71/80
 - 0s - loss: 0.9106 - val_loss: 0.5803
AUC: 0.8722

Epoch 72/80
 - 0s - loss: 0.9105 - val_loss: 0.5720
AUC: 0.8722

Epoch 73/80
 - 0s - loss: 0.9137 - val_loss: 0.5852
AUC: 0.8723

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9196 - val_loss: 0.5806
AUC: 0.8726

Epoch 2/30
 - 0s - loss: 0.9181 - val_loss: 0.5807
AUC: 0.8727

Epoch 3/30
 - 0s - loss: 0.9165 - val_loss: 0.5785
AUC: 0.8726

Epoch 4/30
 - 0s - loss: 0.9152 - val_loss: 0.5691
AUC: 0.8724

Epoch 5/30
 - 0s - loss: 0.9113 - val_loss: 0.5615
AUC: 0.8725

Epoch 6/30
 - 0s - loss: 0.9173 - val_loss: 0.5835
AUC: 0.8729

Epoch 7/30
 - 0s - loss: 0.9130 - val_loss: 0.5788
AUC: 0.8727

Epoch 8/30
 - 0s - loss: 0.9073 - val_loss: 0.5903
AUC: 0.8728

Epoch 9/30
 - 0s - loss: 0.9138 - val_loss: 0.5627
AUC: 0.8728

Epoch 10/30
 - 0s - loss: 0.9083 - val_loss: 0.5984
AUC: 0.8729

Epoch 11/30
 - 0s - loss: 0.9063 - val_loss: 0.5701
AUC: 0.8728

Epoch 12/30
 - 0s - loss: 0.9011 - val_loss: 0.5608
AUC: 0.8729

Epoch 13/30
 - 0s - loss: 0.9096 - val_loss: 0.5686
AUC: 0.8727

Epoch 14/30
 - 0s - loss: 0.9053 - val_loss: 0.5766
AUC: 0.8728

Epoch 15/30
 - 0s - loss: 0.9026 - val_loss: 0.5812
AUC: 0.8731

Epoch 16/30
 - 0s - loss: 0.8989 - val_loss: 0.5756
AUC: 0.8731

Epoch 17/30
 - 0s - loss: 0.9004 - val_loss: 0.5479
AUC: 0.8729

Epoch 18/30
 - 0s - loss: 0.8974 - val_loss: 0.5811
AUC: 0.8730

Epoch 19/30
 - 0s - loss: 0.8981 - val_loss: 0.6005
AUC: 0.8731

Epoch 20/30
 - 0s - loss: 0.8955 - val_loss: 0.5898
AUC: 0.8731

Epoch 21/30
 - 0s - loss: 0.8955 - val_loss: 0.5792
AUC: 0.8731

Epoch 22/30
 - 0s - loss: 0.8927 - val_loss: 0.5655
AUC: 0.8731

Epoch 23/30
 - 0s - loss: 0.8925 - val_loss: 0.5896
AUC: 0.8732

Epoch 24/30
 - 0s - loss: 0.8921 - val_loss: 0.5608
AUC: 0.8731

Epoch 25/30
 - 0s - loss: 0.8935 - val_loss: 0.5761
AUC: 0.8730

Epoch 26/30
 - 0s - loss: 0.8872 - val_loss: 0.5694
AUC: 0.8731

Epoch 27/30
 - 0s - loss: 0.8880 - val_loss: 0.5633
AUC: 0.8732

Epoch 28/30
 - 0s - loss: 0.8884 - val_loss: 0.5658
AUC: 0.8732

Epoch 29/30
 - 0s - loss: 0.8851 - val_loss: 0.5637
AUC: 0.8732

Epoch 30/30
 - 0s - loss: 0.8870 - val_loss: 0.5643
Using TensorFlow backend.
AUC: 0.8732

2019-03-08 04:41:37.468421: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:41:37.633848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:41:37.633891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:41:37.927335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:41:37.927386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:41:37.927396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:41:37.927700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.7018
Epoch 2/80
 - 2s - loss: 0.1383
Epoch 3/80
 - 2s - loss: 0.0720
Epoch 4/80
 - 2s - loss: 0.0639
Epoch 5/80
 - 2s - loss: 0.0601
Epoch 6/80
 - 2s - loss: 0.0571
Epoch 7/80
 - 2s - loss: 0.0540
Epoch 8/80
 - 2s - loss: 0.0510
Epoch 9/80
 - 2s - loss: 0.0479
Epoch 10/80
 - 2s - loss: 0.0447
Epoch 11/80
 - 2s - loss: 0.0413
Epoch 12/80
 - 2s - loss: 0.0381
Epoch 13/80
 - 2s - loss: 0.0353
Epoch 14/80
 - 2s - loss: 0.0329
Epoch 15/80
 - 2s - loss: 0.0309
Epoch 16/80
 - 2s - loss: 0.0291
Epoch 17/80
 - 2s - loss: 0.0276
Epoch 18/80
 - 2s - loss: 0.0263
Epoch 19/80
 - 2s - loss: 0.0251
Epoch 20/80
 - 2s - loss: 0.0241
Epoch 21/80
 - 2s - loss: 0.0233
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0218
Epoch 24/80
 - 2s - loss: 0.0212
Epoch 25/80
 - 2s - loss: 0.0207
Epoch 26/80
 - 2s - loss: 0.0202
Epoch 27/80
 - 2s - loss: 0.0198
Epoch 28/80
 - 2s - loss: 0.0194
Epoch 29/80
 - 2s - loss: 0.0191
Epoch 30/80
 - 2s - loss: 0.0188
Epoch 31/80
 - 2s - loss: 0.0185
Epoch 32/80
 - 2s - loss: 0.0183
Epoch 33/80
 - 2s - loss: 0.0181
Epoch 34/80
 - 2s - loss: 0.0179
Epoch 35/80
 - 2s - loss: 0.0178
Epoch 36/80
 - 2s - loss: 0.0176
Epoch 37/80
 - 2s - loss: 0.0175
Epoch 38/80
 - 2s - loss: 0.0174
Epoch 39/80
 - 2s - loss: 0.0173
Epoch 40/80
 - 2s - loss: 0.0172
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0171
Epoch 43/80
 - 2s - loss: 0.0170
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0169
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0168
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0167
Epoch 51/80
 - 2s - loss: 0.0166
Epoch 52/80
 - 2s - loss: 0.0166
Epoch 53/80
 - 2s - loss: 0.0166
Epoch 54/80
 - 2s - loss: 0.0165
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0161
Epoch 57/80
 - 2s - loss: 0.0161
Epoch 58/80
 - 2s - loss: 0.0161
Epoch 59/80
 - 2s - loss: 0.0160
Epoch 60/80
 - 2s - loss: 0.0160
Epoch 61/80
 - 2s - loss: 0.0160
Epoch 62/80
 - 2s - loss: 0.0160
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2ae59ec246d8>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 04:43:59.814369: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:43:59.979088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:43:59.979131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:44:00.278542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:44:00.278592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:44:00.278601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:44:00.278853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3924
Epoch 2/80
 - 2s - loss: 0.3522
Epoch 3/80
 - 2s - loss: 0.2903
Epoch 4/80
 - 2s - loss: 0.2651
Epoch 5/80
 - 2s - loss: 0.2481
Epoch 6/80
 - 2s - loss: 0.2348
Epoch 7/80
 - 2s - loss: 0.2227
Epoch 8/80
 - 2s - loss: 0.2113
Epoch 9/80
 - 2s - loss: 0.2005
Epoch 10/80
 - 2s - loss: 0.1895
Epoch 11/80
 - 2s - loss: 0.1787
Epoch 12/80
 - 2s - loss: 0.1690
Epoch 13/80
 - 2s - loss: 0.1609
Epoch 14/80
 - 2s - loss: 0.1543
Epoch 15/80
 - 2s - loss: 0.1489
Epoch 16/80
 - 2s - loss: 0.1441
Epoch 17/80
 - 2s - loss: 0.1400
Epoch 18/80
 - 2s - loss: 0.1364
Epoch 19/80
 - 2s - loss: 0.1332
Epoch 20/80
 - 2s - loss: 0.1305
Epoch 21/80
 - 2s - loss: 0.1281
Epoch 22/80
 - 2s - loss: 0.1262
Epoch 23/80
 - 2s - loss: 0.1246
Epoch 24/80
 - 2s - loss: 0.1232
Epoch 25/80
 - 2s - loss: 0.1220
Epoch 26/80
 - 2s - loss: 0.1210
Epoch 27/80
 - 2s - loss: 0.1201
Epoch 28/80
 - 2s - loss: 0.1193
Epoch 29/80
 - 2s - loss: 0.1187
Epoch 30/80
 - 2s - loss: 0.1182
Epoch 31/80
 - 2s - loss: 0.1177
Epoch 32/80
 - 2s - loss: 0.1173
Epoch 33/80
 - 2s - loss: 0.1169
Epoch 34/80
 - 2s - loss: 0.1166
Epoch 35/80
 - 2s - loss: 0.1163
Epoch 36/80
 - 2s - loss: 0.1161
Epoch 37/80
 - 2s - loss: 0.1158
Epoch 38/80
 - 2s - loss: 0.1156
Epoch 39/80
 - 2s - loss: 0.1154
Epoch 40/80
 - 2s - loss: 0.1153
Epoch 41/80
 - 2s - loss: 0.1152
Epoch 42/80
 - 2s - loss: 0.1150
Epoch 43/80
 - 2s - loss: 0.1149
Epoch 44/80
 - 2s - loss: 0.1148
Epoch 45/80
 - 2s - loss: 0.1146
Epoch 46/80
 - 2s - loss: 0.1146
Epoch 47/80
 - 2s - loss: 0.1144
Epoch 48/80
 - 2s - loss: 0.1144
Epoch 49/80
 - 2s - loss: 0.1143
Epoch 50/80
 - 2s - loss: 0.1142
Epoch 51/80
 - 2s - loss: 0.1142
Epoch 52/80
 - 2s - loss: 0.1141
Epoch 53/80
 - 2s - loss: 0.1140
Epoch 54/80
 - 2s - loss: 0.1140
Epoch 55/80
 - 2s - loss: 0.1139
Epoch 56/80
 - 2s - loss: 0.1139
Epoch 57/80
 - 2s - loss: 0.1138
Epoch 58/80
 - 2s - loss: 0.1138
Epoch 59/80
 - 2s - loss: 0.1137
Epoch 60/80
 - 2s - loss: 0.1137
Epoch 61/80
 - 2s - loss: 0.1136
Epoch 62/80
 - 2s - loss: 0.1136
Epoch 63/80
 - 2s - loss: 0.1136
Epoch 64/80
 - 2s - loss: 0.1136
Epoch 65/80
 - 2s - loss: 0.1135
Epoch 66/80
 - 2s - loss: 0.1135
Epoch 67/80
 - 2s - loss: 0.1113
Epoch 68/80
 - 2s - loss: 0.1110
Epoch 69/80
 - 2s - loss: 0.1110
Epoch 70/80
 - 2s - loss: 0.1110
Epoch 71/80
 - 2s - loss: 0.1110
Epoch 72/80
 - 2s - loss: 0.1104
Epoch 73/80
 - 2s - loss: 0.1104
Epoch 74/80
 - 2s - loss: 0.1104
Epoch 75/80
 - 2s - loss: 0.1104
Epoch 76/80
 - 2s - loss: 0.1103
Epoch 77/80
 - 2s - loss: 0.1103
Epoch 78/80
 - 2s - loss: 0.1103
Epoch 79/80
 - 2s - loss: 0.1103
Epoch 80/80
 - 2s - loss: 0.1103
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4716 - val_loss: 1.5075
AUC: 0.8185

Epoch 2/80
 - 0s - loss: 2.2119 - val_loss: 0.9494
AUC: 0.8398

Epoch 3/80
 - 0s - loss: 1.5602 - val_loss: 0.7946
AUC: 0.8462

Epoch 4/80
 - 0s - loss: 1.2949 - val_loss: 0.7003
AUC: 0.8518

Epoch 5/80
 - 0s - loss: 1.1797 - val_loss: 0.6599
AUC: 0.8547

Epoch 6/80
 - 0s - loss: 1.1289 - val_loss: 0.7610
AUC: 0.8569

Epoch 7/80
 - 0s - loss: 1.1255 - val_loss: 0.6190
AUC: 0.8595

Epoch 8/80
 - 0s - loss: 1.0881 - val_loss: 0.6289
AUC: 0.8582

Epoch 9/80
 - 0s - loss: 1.0812 - val_loss: 0.6731
AUC: 0.8623

Epoch 10/80
 - 0s - loss: 1.0693 - val_loss: 0.6126
AUC: 0.8643

Epoch 11/80
 - 0s - loss: 1.0606 - val_loss: 0.6491
AUC: 0.8659

Epoch 12/80
 - 0s - loss: 1.0512 - val_loss: 0.6596
AUC: 0.8666

Epoch 13/80
 - 0s - loss: 1.0374 - val_loss: 0.6449
AUC: 0.8672

Epoch 14/80
 - 0s - loss: 1.0327 - val_loss: 0.7674
AUC: 0.8677

Epoch 15/80
 - 0s - loss: 1.0327 - val_loss: 0.6496
AUC: 0.8682

Epoch 16/80
 - 0s - loss: 1.0239 - val_loss: 0.6442
AUC: 0.8681

Epoch 17/80
 - 0s - loss: 1.0275 - val_loss: 0.5924
AUC: 0.8693

Epoch 18/80
 - 0s - loss: 1.0217 - val_loss: 0.5871
AUC: 0.8695

Epoch 19/80
 - 0s - loss: 1.0165 - val_loss: 0.5900
AUC: 0.8685

Epoch 20/80
 - 0s - loss: 1.0097 - val_loss: 0.6034
AUC: 0.8696

Epoch 21/80
 - 0s - loss: 1.0057 - val_loss: 0.5980
AUC: 0.8708

Epoch 22/80
 - 0s - loss: 0.9996 - val_loss: 0.6159
AUC: 0.8719

Epoch 23/80
 - 0s - loss: 0.9924 - val_loss: 0.5952
AUC: 0.8712

Epoch 24/80
 - 0s - loss: 0.9923 - val_loss: 0.6574
AUC: 0.8702

Epoch 25/80
 - 0s - loss: 0.9953 - val_loss: 0.5651
AUC: 0.8708

Epoch 26/80
 - 0s - loss: 0.9913 - val_loss: 0.6625
AUC: 0.8714

Epoch 27/80
 - 0s - loss: 0.9844 - val_loss: 0.6377
AUC: 0.8728

Epoch 28/80
 - 0s - loss: 0.9839 - val_loss: 0.5201
AUC: 0.8700

Epoch 29/80
 - 0s - loss: 0.9833 - val_loss: 0.6080
AUC: 0.8702

Epoch 30/80
 - 0s - loss: 0.9760 - val_loss: 0.6055
AUC: 0.8730

Epoch 31/80
 - 0s - loss: 0.9762 - val_loss: 0.5918
AUC: 0.8714

Epoch 32/80
 - 0s - loss: 0.9712 - val_loss: 0.6094
AUC: 0.8719

Epoch 33/80
 - 0s - loss: 0.9676 - val_loss: 0.5979
AUC: 0.8718

Epoch 34/80
 - 0s - loss: 0.9610 - val_loss: 0.6606
AUC: 0.8723

Epoch 35/80
 - 0s - loss: 0.9647 - val_loss: 0.5284
AUC: 0.8701

Epoch 36/80
 - 0s - loss: 0.9631 - val_loss: 0.5115
AUC: 0.8722

Epoch 37/80
 - 0s - loss: 0.9678 - val_loss: 0.5447
AUC: 0.8720

Epoch 38/80
 - 0s - loss: 0.9600 - val_loss: 0.5802
AUC: 0.8740

Epoch 39/80
 - 0s - loss: 0.9544 - val_loss: 0.5526
AUC: 0.8722

Epoch 40/80
 - 0s - loss: 0.9543 - val_loss: 0.6287
AUC: 0.8731

Epoch 41/80
 - 0s - loss: 0.9496 - val_loss: 0.6251
AUC: 0.8734

Epoch 42/80
 - 0s - loss: 0.9519 - val_loss: 0.6452
AUC: 0.8730

Epoch 43/80
 - 0s - loss: 0.9510 - val_loss: 0.6259
AUC: 0.8736

Epoch 44/80
 - 0s - loss: 0.9436 - val_loss: 0.6136
AUC: 0.8712

Epoch 45/80
 - 0s - loss: 0.9427 - val_loss: 0.6121
AUC: 0.8723

Epoch 46/80
 - 0s - loss: 0.9395 - val_loss: 0.5836
AUC: 0.8728

Epoch 47/80
 - 0s - loss: 0.9350 - val_loss: 0.5667
AUC: 0.8722

Epoch 48/80
 - 0s - loss: 0.9295 - val_loss: 0.5970
AUC: 0.8726

Epoch 49/80
 - 0s - loss: 0.9252 - val_loss: 0.5843
AUC: 0.8725

Epoch 50/80
 - 0s - loss: 0.9179 - val_loss: 0.5624
AUC: 0.8725

Epoch 51/80
 - 0s - loss: 0.9229 - val_loss: 0.6109
AUC: 0.8726

Epoch 52/80
 - 0s - loss: 0.9233 - val_loss: 0.6048
AUC: 0.8725

Epoch 53/80
 - 0s - loss: 0.9211 - val_loss: 0.6081
AUC: 0.8725

Epoch 54/80
 - 0s - loss: 0.9278 - val_loss: 0.5733
AUC: 0.8721

Epoch 55/80
 - 0s - loss: 0.9200 - val_loss: 0.5739
AUC: 0.8726

Epoch 56/80
 - 0s - loss: 0.9211 - val_loss: 0.5861
AUC: 0.8724

Epoch 57/80
 - 0s - loss: 0.9171 - val_loss: 0.5785
AUC: 0.8723

Epoch 58/80
 - 0s - loss: 0.9167 - val_loss: 0.5876
AUC: 0.8724

Epoch 59/80
 - 0s - loss: 0.9133 - val_loss: 0.5802
AUC: 0.8723

Epoch 60/80
 - 0s - loss: 0.9121 - val_loss: 0.5804
AUC: 0.8723

Epoch 61/80
 - 0s - loss: 0.9202 - val_loss: 0.5838
AUC: 0.8722

Epoch 62/80
 - 0s - loss: 0.9143 - val_loss: 0.5767
AUC: 0.8722

Epoch 63/80
 - 0s - loss: 0.9164 - val_loss: 0.5834
AUC: 0.8723

Epoch 64/80
 - 0s - loss: 0.9147 - val_loss: 0.5831
AUC: 0.8723

Epoch 65/80
 - 0s - loss: 0.9113 - val_loss: 0.5821
AUC: 0.8723

Epoch 66/80
 - 0s - loss: 0.9167 - val_loss: 0.5831
AUC: 0.8723

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9460 - val_loss: 0.5957
AUC: 0.8740

Epoch 2/30
 - 0s - loss: 0.9459 - val_loss: 0.5943
AUC: 0.8734

Epoch 3/30
 - 0s - loss: 0.9395 - val_loss: 0.5666
AUC: 0.8731

Epoch 4/30
 - 0s - loss: 0.9401 - val_loss: 0.6137
AUC: 0.8736

Epoch 5/30
 - 0s - loss: 0.9376 - val_loss: 0.5867
AUC: 0.8732

Epoch 6/30
 - 0s - loss: 0.9325 - val_loss: 0.5756
AUC: 0.8726

Epoch 7/30
 - 0s - loss: 0.9348 - val_loss: 0.6099
AUC: 0.8732

Epoch 8/30
 - 0s - loss: 0.9295 - val_loss: 0.5956
AUC: 0.8733

Epoch 9/30
 - 0s - loss: 0.9315 - val_loss: 0.6070
AUC: 0.8731

Epoch 10/30
 - 0s - loss: 0.9323 - val_loss: 0.6116
AUC: 0.8731

Epoch 11/30
 - 0s - loss: 0.9286 - val_loss: 0.5738
AUC: 0.8733

Epoch 12/30
 - 0s - loss: 0.9345 - val_loss: 0.5700
AUC: 0.8730

Epoch 13/30
 - 0s - loss: 0.9237 - val_loss: 0.5809
AUC: 0.8730

Epoch 14/30
 - 0s - loss: 0.9237 - val_loss: 0.5932
AUC: 0.8731

Epoch 15/30
 - 0s - loss: 0.9275 - val_loss: 0.5803
AUC: 0.8730

Epoch 16/30
 - 0s - loss: 0.9240 - val_loss: 0.5800
AUC: 0.8731

Epoch 17/30
 - 0s - loss: 0.9256 - val_loss: 0.5848
AUC: 0.8732

Epoch 18/30
 - 0s - loss: 0.9245 - val_loss: 0.5831
AUC: 0.8731

Epoch 19/30
 - 0s - loss: 0.9252 - val_loss: 0.5873
AUC: 0.8731

Epoch 20/30
 - 0s - loss: 0.9184 - val_loss: 0.5823
AUC: 0.8731

Epoch 21/30
 - 0s - loss: 0.9188 - val_loss: 0.5857
AUC: 0.8730

Epoch 22/30
 - 0s - loss: 0.9212 - val_loss: 0.5837
AUC: 0.8730

Epoch 23/30
 - 0s - loss: 0.9217 - val_loss: 0.5835
AUC: 0.8731

Epoch 24/30
 - 0s - loss: 0.9214 - val_loss: 0.5829
AUC: 0.8730

Epoch 25/30
 - 0s - loss: 0.9249 - val_loss: 0.5837
AUC: 0.8731

Epoch 26/30
 - 0s - loss: 0.9214 - val_loss: 0.5842
AUC: 0.8730

Epoch 27/30
 - 0s - loss: 0.9218 - val_loss: 0.5850
AUC: 0.8731

Epoch 28/30
 - 0s - loss: 0.9213 - val_loss: 0.5833
AUC: 0.8731

Epoch 29/30
 - 0s - loss: 0.9221 - val_loss: 0.5838
AUC: 0.8731

Epoch 30/30
 - 0s - loss: 0.9210 - val_loss: 0.5839
Using TensorFlow backend.
AUC: 0.8731

2019-03-08 04:47:29.312117: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:47:29.478613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:47:29.478673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:47:29.771679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:47:29.771727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:47:29.771736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:47:29.771988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3726
Epoch 2/80
 - 2s - loss: 0.3512
Epoch 3/80
 - 2s - loss: 0.3087
Epoch 4/80
 - 2s - loss: 0.2962
Epoch 5/80
 - 2s - loss: 0.2813
Epoch 6/80
 - 2s - loss: 0.2613
Epoch 7/80
 - 2s - loss: 0.2393
Epoch 8/80
 - 2s - loss: 0.2214
Epoch 9/80
 - 2s - loss: 0.2080
Epoch 10/80
 - 2s - loss: 0.1961
Epoch 11/80
 - 2s - loss: 0.1845
Epoch 12/80
 - 2s - loss: 0.1736
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 04:48:06.603765: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:48:06.769168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:48:06.769229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:48:07.068786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:48:07.068835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:48:07.068843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:48:07.069103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3810
Epoch 2/80
 - 2s - loss: 0.3532
Epoch 3/80
 - 2s - loss: 0.3010
Epoch 4/80
 - 2s - loss: 0.2807
Epoch 5/80
 - 2s - loss: 0.2617
Epoch 6/80
 - 2s - loss: 0.2434
Epoch 7/80
 - 2s - loss: 0.2267
Epoch 8/80
 - 2s - loss: 0.2120
Epoch 9/80
 - 2s - loss: 0.1982
Epoch 10/80
 - 2s - loss: 0.1854
Epoch 11/80
 - 2s - loss: 0.1745
Epoch 12/80
 - 2s - loss: 0.1656
Epoch 13/80
 - 2s - loss: 0.1586
Epoch 14/80
 - 2s - loss: 0.1528
Epoch 15/80
 - 2s - loss: 0.1479
Epoch 16/80
 - 2s - loss: 0.1439
Epoch 17/80
 - 2s - loss: 0.1404
Epoch 18/80
 - 2s - loss: 0.1374
Epoch 19/80
 - 2s - loss: 0.1349
Epoch 20/80
 - 2s - loss: 0.1325
Epoch 21/80
 - 2s - loss: 0.1305
Epoch 22/80
 - 2s - loss: 0.1286
Epoch 23/80
 - 2s - loss: 0.1268
Epoch 24/80
 - 2s - loss: 0.1253
Epoch 25/80
 - 2s - loss: 0.1239
Epoch 26/80
 - 2s - loss: 0.1228
Epoch 27/80
 - 2s - loss: 0.1217
Epoch 28/80
 - 2s - loss: 0.1208
Epoch 29/80
 - 2s - loss: 0.1201
Epoch 30/80
 - 2s - loss: 0.1194
Epoch 31/80
 - 2s - loss: 0.1189
Epoch 32/80
 - 2s - loss: 0.1183
Epoch 33/80
 - 2s - loss: 0.1179
Epoch 34/80
 - 2s - loss: 0.1175
Epoch 35/80
 - 2s - loss: 0.1172
Epoch 36/80
 - 2s - loss: 0.1169
Epoch 37/80
 - 2s - loss: 0.1166
Epoch 38/80
 - 2s - loss: 0.1164
Epoch 39/80
 - 2s - loss: 0.1162
Epoch 40/80
 - 2s - loss: 0.1160
Epoch 41/80
 - 2s - loss: 0.1158
Epoch 42/80
 - 2s - loss: 0.1156
Epoch 43/80
 - 2s - loss: 0.1155
Epoch 44/80
 - 2s - loss: 0.1153
Epoch 45/80
 - 2s - loss: 0.1152
Epoch 46/80
 - 2s - loss: 0.1151
Epoch 47/80
 - 2s - loss: 0.1150
Epoch 48/80
 - 2s - loss: 0.1149
Epoch 49/80
 - 2s - loss: 0.1148
Epoch 50/80
 - 2s - loss: 0.1148
Epoch 51/80
 - 2s - loss: 0.1147
Epoch 52/80
 - 2s - loss: 0.1146
Epoch 53/80
 - 2s - loss: 0.1145
Epoch 54/80
 - 2s - loss: 0.1145
Epoch 55/80
 - 2s - loss: 0.1144
Epoch 56/80
 - 2s - loss: 0.1143
Epoch 57/80
 - 2s - loss: 0.1143
Epoch 58/80
 - 2s - loss: 0.1143
Epoch 59/80
 - 2s - loss: 0.1143
Epoch 60/80
 - 2s - loss: 0.1142
Epoch 61/80
 - 2s - loss: 0.1141
Epoch 62/80
 - 2s - loss: 0.1141
Epoch 63/80
 - 2s - loss: 0.1141
Epoch 64/80
 - 2s - loss: 0.1140
Epoch 65/80
 - 2s - loss: 0.1118
Epoch 66/80
 - 2s - loss: 0.1116
Epoch 67/80
 - 2s - loss: 0.1115
Epoch 68/80
 - 2s - loss: 0.1115
Epoch 69/80
 - 2s - loss: 0.1115
Epoch 70/80
 - 2s - loss: 0.1109
Epoch 71/80
 - 2s - loss: 0.1109
Epoch 72/80
 - 2s - loss: 0.1109
Epoch 73/80
 - 2s - loss: 0.1109
Epoch 74/80
 - 2s - loss: 0.1108
Epoch 75/80
 - 2s - loss: 0.1108
Epoch 76/80
 - 2s - loss: 0.1108
Epoch 77/80
 - 2s - loss: 0.1108
Epoch 78/80
 - 2s - loss: 0.1108
Epoch 79/80
 - 2s - loss: 0.1108
Epoch 80/80
 - 2s - loss: 0.1108
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.9398 - val_loss: 1.1969
AUC: 0.8121

Epoch 2/80
 - 0s - loss: 1.8276 - val_loss: 0.6977
AUC: 0.8332

Epoch 3/80
 - 0s - loss: 1.3242 - val_loss: 0.8311
AUC: 0.8476

Epoch 4/80
 - 0s - loss: 1.2005 - val_loss: 0.7190
AUC: 0.8495

Epoch 5/80
 - 0s - loss: 1.1442 - val_loss: 0.6539
AUC: 0.8514

Epoch 6/80
 - 0s - loss: 1.1089 - val_loss: 0.7014
AUC: 0.8553

Epoch 7/80
 - 0s - loss: 1.0873 - val_loss: 0.7259
AUC: 0.8566

Epoch 8/80
 - 0s - loss: 1.0754 - val_loss: 0.7005
AUC: 0.8570

Epoch 9/80
 - 0s - loss: 1.0639 - val_loss: 0.6715
AUC: 0.8574

Epoch 10/80
 - 0s - loss: 1.0511 - val_loss: 0.6862
AUC: 0.8567

Epoch 11/80
 - 0s - loss: 1.0421 - val_loss: 0.6338
AUC: 0.8598

Epoch 12/80
 - 0s - loss: 1.0274 - val_loss: 0.6332
AUC: 0.8587

Epoch 13/80
 - 0s - loss: 1.0336 - val_loss: 0.6948
AUC: 0.8599

Epoch 14/80
 - 0s - loss: 1.0272 - val_loss: 0.5272
AUC: 0.8589

Epoch 15/80
 - 0s - loss: 1.0219 - val_loss: 0.6280
AUC: 0.8613

Epoch 16/80
 - 0s - loss: 1.0144 - val_loss: 0.6641
AUC: 0.8631

Epoch 17/80
 - 0s - loss: 1.0071 - val_loss: 0.5473
AUC: 0.8612

Epoch 18/80
 - 0s - loss: 1.0087 - val_loss: 0.6935
AUC: 0.8628

Epoch 19/80
 - 0s - loss: 1.0040 - val_loss: 0.6054
AUC: 0.8626

Epoch 20/80
 - 0s - loss: 0.9938 - val_loss: 0.6026
AUC: 0.8634

Epoch 21/80
 - 0s - loss: 0.9928 - val_loss: 0.6387
AUC: 0.8620

Epoch 22/80
 - 0s - loss: 0.9893 - val_loss: 0.5330
AUC: 0.8631

Epoch 23/80
 - 0s - loss: 0.9917 - val_loss: 0.5678
AUC: 0.8629

Epoch 24/80
 - 0s - loss: 0.9895 - val_loss: 0.6101
AUC: 0.8651

Epoch 25/80
 - 0s - loss: 0.9694 - val_loss: 0.6618
AUC: 0.8652

Epoch 26/80
 - 0s - loss: 0.9724 - val_loss: 0.5863
AUC: 0.8651

Epoch 27/80
 - 0s - loss: 0.9651 - val_loss: 0.6091
AUC: 0.8648

Epoch 28/80
 - 0s - loss: 0.9630 - val_loss: 0.6379
AUC: 0.8653

Epoch 29/80
 - 0s - loss: 0.9590 - val_loss: 0.5944
AUC: 0.8649

Epoch 30/80
 - 0s - loss: 0.9587 - val_loss: 0.6032
AUC: 0.8653

Epoch 31/80
 - 0s - loss: 0.9666 - val_loss: 0.5934
AUC: 0.8651

Epoch 32/80
 - 0s - loss: 0.9686 - val_loss: 0.6002
AUC: 0.8659

Epoch 33/80
 - 0s - loss: 0.9633 - val_loss: 0.6372
AUC: 0.8659

Epoch 34/80
 - 0s - loss: 0.9624 - val_loss: 0.6189
AUC: 0.8658

Epoch 35/80
 - 0s - loss: 0.9568 - val_loss: 0.5992
AUC: 0.8657

Epoch 36/80
 - 0s - loss: 0.9586 - val_loss: 0.5986
AUC: 0.8655

Epoch 37/80
 - 0s - loss: 0.9597 - val_loss: 0.6083
AUC: 0.8655

Epoch 38/80
 - 0s - loss: 0.9597 - val_loss: 0.6004
AUC: 0.8656

Epoch 39/80
 - 0s - loss: 0.9593 - val_loss: 0.5898
AUC: 0.8655

Epoch 40/80
 - 0s - loss: 0.9554 - val_loss: 0.6172
AUC: 0.8658

Epoch 41/80
 - 0s - loss: 0.9537 - val_loss: 0.5933
AUC: 0.8655

Epoch 42/80
 - 0s - loss: 0.9569 - val_loss: 0.6037
AUC: 0.8658

Epoch 43/80
 - 0s - loss: 0.9546 - val_loss: 0.6074
AUC: 0.8658

Epoch 44/80
 - 0s - loss: 0.9548 - val_loss: 0.6092
AUC: 0.8658

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9558 - val_loss: 0.6018
AUC: 0.8654

Epoch 2/30
 - 0s - loss: 0.9519 - val_loss: 0.6057
AUC: 0.8658

Epoch 3/30
 - 0s - loss: 0.9579 - val_loss: 0.5917
AUC: 0.8659

Epoch 4/30
 - 0s - loss: 0.9525 - val_loss: 0.6216
AUC: 0.8661

Epoch 5/30
 - 0s - loss: 0.9571 - val_loss: 0.6109
AUC: 0.8663

Epoch 6/30
 - 0s - loss: 0.9545 - val_loss: 0.6057
AUC: 0.8662

Epoch 7/30
 - 0s - loss: 0.9489 - val_loss: 0.6090
AUC: 0.8665

Epoch 8/30
 - 0s - loss: 0.9467 - val_loss: 0.5808
AUC: 0.8660

Epoch 9/30
 - 0s - loss: 0.9479 - val_loss: 0.5868
AUC: 0.8662

Epoch 10/30
 - 0s - loss: 0.9505 - val_loss: 0.5824
AUC: 0.8666

Epoch 11/30
 - 0s - loss: 0.9440 - val_loss: 0.6297
AUC: 0.8670

Epoch 12/30
 - 0s - loss: 0.9426 - val_loss: 0.5963
AUC: 0.8668

Epoch 13/30
 - 0s - loss: 0.9399 - val_loss: 0.5905
AUC: 0.8668

Epoch 14/30
 - 0s - loss: 0.9404 - val_loss: 0.6199
AUC: 0.8672

Epoch 15/30
 - 0s - loss: 0.9438 - val_loss: 0.5933
AUC: 0.8672

Epoch 16/30
 - 0s - loss: 0.9405 - val_loss: 0.6048
AUC: 0.8673

Epoch 17/30
 - 0s - loss: 0.9341 - val_loss: 0.5855
AUC: 0.8673

Epoch 18/30
 - 0s - loss: 0.9351 - val_loss: 0.6054
AUC: 0.8676

Epoch 19/30
 - 0s - loss: 0.9298 - val_loss: 0.5950
AUC: 0.8675

Epoch 20/30
 - 0s - loss: 0.9323 - val_loss: 0.5916
AUC: 0.8674

Epoch 21/30
 - 0s - loss: 0.9333 - val_loss: 0.5956
AUC: 0.8675

Epoch 22/30
 - 0s - loss: 0.9287 - val_loss: 0.5876
AUC: 0.8675

Epoch 23/30
 - 0s - loss: 0.9360 - val_loss: 0.5959
AUC: 0.8676

Epoch 24/30
 - 0s - loss: 0.9314 - val_loss: 0.5947
AUC: 0.8676

Epoch 25/30
 - 0s - loss: 0.9305 - val_loss: 0.5936
AUC: 0.8676

Epoch 26/30
 - 0s - loss: 0.9287 - val_loss: 0.5937
AUC: 0.8676

Epoch 27/30
 - 0s - loss: 0.9292 - val_loss: 0.5917
AUC: 0.8676

Epoch 28/30
 - 0s - loss: 0.9303 - val_loss: 0.5863
AUC: 0.8675

Epoch 29/30
 - 0s - loss: 0.9253 - val_loss: 0.5880
AUC: 0.8675

Epoch 30/30
 - 0s - loss: 0.9278 - val_loss: 0.5904
Using TensorFlow backend.
AUC: 0.8676

2019-03-08 04:51:22.483097: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:51:22.648362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:51:22.648406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:51:22.944147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:51:22.944232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:51:22.944243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:51:22.944532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3756
Epoch 2/80
 - 2s - loss: 0.3524
Epoch 3/80
 - 2s - loss: 0.2964
Epoch 4/80
 - 2s - loss: 0.2700
Epoch 5/80
 - 2s - loss: 0.2478
Epoch 6/80
 - 2s - loss: 0.2311
Epoch 7/80
 - 2s - loss: 0.2185
Epoch 8/80
 - 2s - loss: 0.2077
Epoch 9/80
 - 2s - loss: 0.1974
Epoch 10/80
 - 2s - loss: 0.1872
Epoch 11/80
 - 2s - loss: 0.1779
Epoch 12/80
 - 2s - loss: 0.1696
Epoch 13/80
 - 2s - loss: 0.1625
Epoch 14/80
 - 2s - loss: 0.1562
Epoch 15/80
 - 2s - loss: 0.1504
Epoch 16/80
 - 2s - loss: 0.1453
Epoch 17/80
 - 2s - loss: 0.1408
Epoch 18/80
 - 2s - loss: 0.1369
Epoch 19/80
 - 2s - loss: 0.1336
Epoch 20/80
 - 2s - loss: 0.1309
Epoch 21/80
 - 2s - loss: 0.1286
Epoch 22/80
 - 2s - loss: 0.1267
Epoch 23/80
 - 2s - loss: 0.1250
Epoch 24/80
 - 2s - loss: 0.1237
Epoch 25/80
 - 2s - loss: 0.1225
Epoch 26/80
 - 2s - loss: 0.1215
Epoch 27/80
 - 2s - loss: 0.1207
Epoch 28/80
 - 2s - loss: 0.1199
Epoch 29/80
 - 2s - loss: 0.1193
Epoch 30/80
 - 2s - loss: 0.1188
Epoch 31/80
 - 2s - loss: 0.1183
Epoch 32/80
 - 2s - loss: 0.1180
Epoch 33/80
 - 2s - loss: 0.1176
Epoch 34/80
 - 2s - loss: 0.1173
Epoch 35/80
 - 2s - loss: 0.1170
Epoch 36/80
 - 2s - loss: 0.1168
Epoch 37/80
 - 2s - loss: 0.1166
Epoch 38/80
 - 2s - loss: 0.1164
Epoch 39/80
 - 2s - loss: 0.1163
Epoch 40/80
 - 2s - loss: 0.1161
Epoch 41/80
 - 2s - loss: 0.1159
Epoch 42/80
 - 2s - loss: 0.1158
Epoch 43/80
 - 2s - loss: 0.1157
Epoch 44/80
 - 2s - loss: 0.1156
Epoch 45/80
 - 2s - loss: 0.1155
Epoch 46/80
 - 2s - loss: 0.1154
Epoch 47/80
 - 2s - loss: 0.1153
Epoch 48/80
 - 2s - loss: 0.1152
Epoch 49/80
 - 2s - loss: 0.1151
Epoch 50/80
 - 2s - loss: 0.1151
Epoch 51/80
 - 2s - loss: 0.1150
Epoch 52/80
 - 2s - loss: 0.1149
Epoch 53/80
 - 2s - loss: 0.1149
Epoch 54/80
 - 2s - loss: 0.1148
Epoch 55/80
 - 2s - loss: 0.1148
Epoch 56/80
 - 2s - loss: 0.1147
Epoch 57/80
 - 2s - loss: 0.1147
Epoch 58/80
 - 2s - loss: 0.1146
Epoch 59/80
 - 2s - loss: 0.1146
Epoch 60/80
 - 2s - loss: 0.1146
Epoch 61/80
 - 2s - loss: 0.1145
Epoch 62/80
 - 2s - loss: 0.1123
Epoch 63/80
 - 2s - loss: 0.1120
Epoch 64/80
 - 2s - loss: 0.1120
Epoch 65/80
 - 2s - loss: 0.1120
Epoch 66/80
 - 2s - loss: 0.1120
Epoch 67/80
 - 2s - loss: 0.1114
Epoch 68/80
 - 2s - loss: 0.1114
Epoch 69/80
 - 2s - loss: 0.1114
Epoch 70/80
 - 2s - loss: 0.1114
Epoch 71/80
 - 2s - loss: 0.1113
Epoch 72/80
 - 2s - loss: 0.1113
Epoch 73/80
 - 2s - loss: 0.1113
Epoch 74/80
 - 2s - loss: 0.1113
Epoch 75/80
 - 2s - loss: 0.1112
Epoch 76/80
 - 2s - loss: 0.1112
Epoch 77/80
 - 2s - loss: 0.1112
Epoch 78/80
 - 2s - loss: 0.1112
Epoch 79/80
 - 2s - loss: 0.1112
Epoch 80/80
 - 2s - loss: 0.1112
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.8584 - val_loss: 1.0286
AUC: 0.8278

Epoch 2/80
 - 0s - loss: 1.7862 - val_loss: 0.7597
AUC: 0.8454

Epoch 3/80
 - 0s - loss: 1.3078 - val_loss: 0.7188
AUC: 0.8496

Epoch 4/80
 - 0s - loss: 1.1715 - val_loss: 0.6950
AUC: 0.8519

Epoch 5/80
 - 0s - loss: 1.1113 - val_loss: 0.6934
AUC: 0.8545

Epoch 6/80
 - 0s - loss: 1.0912 - val_loss: 0.6906
AUC: 0.8549

Epoch 7/80
 - 0s - loss: 1.0606 - val_loss: 0.6356
AUC: 0.8553

Epoch 8/80
 - 0s - loss: 1.0554 - val_loss: 0.6596
AUC: 0.8595

Epoch 9/80
 - 0s - loss: 1.0492 - val_loss: 0.6485
AUC: 0.8593

Epoch 10/80
 - 0s - loss: 1.0409 - val_loss: 0.6337
AUC: 0.8606

Epoch 11/80
 - 0s - loss: 1.0333 - val_loss: 0.6319
AUC: 0.8609

Epoch 12/80
 - 0s - loss: 1.0238 - val_loss: 0.6829
AUC: 0.8606

Epoch 13/80
 - 0s - loss: 1.0215 - val_loss: 0.6278
AUC: 0.8598

Epoch 14/80
 - 0s - loss: 1.0155 - val_loss: 0.5919
AUC: 0.8616

Epoch 15/80
 - 0s - loss: 1.0073 - val_loss: 0.6278
AUC: 0.8624

Epoch 16/80
 - 0s - loss: 1.0076 - val_loss: 0.6594
AUC: 0.8628

Epoch 17/80
 - 0s - loss: 1.0028 - val_loss: 0.6008
AUC: 0.8628

Epoch 18/80
 - 0s - loss: 1.0003 - val_loss: 0.5888
AUC: 0.8643

Epoch 19/80
 - 0s - loss: 0.9958 - val_loss: 0.6618
AUC: 0.8633

Epoch 20/80
 - 0s - loss: 0.9901 - val_loss: 0.6281
AUC: 0.8634

Epoch 21/80
 - 0s - loss: 0.9870 - val_loss: 0.6062
AUC: 0.8642

Epoch 22/80
 - 0s - loss: 0.9895 - val_loss: 0.6635
AUC: 0.8674

Epoch 23/80
 - 0s - loss: 0.9805 - val_loss: 0.5496
AUC: 0.8652

Epoch 24/80
 - 0s - loss: 0.9773 - val_loss: 0.5826
AUC: 0.8648

Epoch 25/80
 - 0s - loss: 0.9764 - val_loss: 0.6394
AUC: 0.8669

Epoch 26/80
 - 0s - loss: 0.9721 - val_loss: 0.6025
AUC: 0.8652

Epoch 27/80
 - 0s - loss: 0.9660 - val_loss: 0.6882
AUC: 0.8656

Epoch 28/80
 - 0s - loss: 0.9794 - val_loss: 0.6938
AUC: 0.8677

Epoch 29/80
 - 0s - loss: 0.9697 - val_loss: 0.5822
AUC: 0.8682

Epoch 30/80
 - 0s - loss: 0.9548 - val_loss: 0.6367
AUC: 0.8684

Epoch 31/80
 - 0s - loss: 0.9621 - val_loss: 0.6020
AUC: 0.8678

Epoch 32/80
 - 0s - loss: 0.9576 - val_loss: 0.5253
AUC: 0.8674

Epoch 33/80
 - 0s - loss: 0.9649 - val_loss: 0.6371
AUC: 0.8677

Epoch 34/80
 - 0s - loss: 0.9602 - val_loss: 0.5424
AUC: 0.8660

Epoch 35/80
 - 0s - loss: 0.9495 - val_loss: 0.5512
AUC: 0.8676

Epoch 36/80
 - 0s - loss: 0.9496 - val_loss: 0.6346
AUC: 0.8682

Epoch 37/80
 - 0s - loss: 0.9464 - val_loss: 0.5791
AUC: 0.8669

Epoch 38/80
 - 0s - loss: 0.9481 - val_loss: 0.5208
AUC: 0.8677

Epoch 39/80
 - 0s - loss: 0.9412 - val_loss: 0.5123
AUC: 0.8666

Epoch 40/80
 - 0s - loss: 0.9444 - val_loss: 0.5233
AUC: 0.8665

Epoch 41/80
 - 0s - loss: 0.9399 - val_loss: 0.5275
AUC: 0.8681

Epoch 42/80
 - 0s - loss: 0.9404 - val_loss: 0.5803
AUC: 0.8687

Epoch 43/80
 - 0s - loss: 0.9315 - val_loss: 0.6396
AUC: 0.8679

Epoch 44/80
 - 0s - loss: 0.9322 - val_loss: 0.6314
AUC: 0.8684

Epoch 45/80
 - 0s - loss: 0.9343 - val_loss: 0.5952
AUC: 0.8678

Epoch 46/80
 - 0s - loss: 0.9267 - val_loss: 0.6004
AUC: 0.8681

Epoch 47/80
 - 0s - loss: 0.9259 - val_loss: 0.5978
AUC: 0.8676

Epoch 48/80
 - 0s - loss: 0.9248 - val_loss: 0.5450
AUC: 0.8681

Epoch 49/80
 - 0s - loss: 0.9247 - val_loss: 0.5577
AUC: 0.8675

Epoch 50/80
 - 0s - loss: 0.9103 - val_loss: 0.6070
AUC: 0.8693

Epoch 51/80
 - 0s - loss: 0.9036 - val_loss: 0.6062
AUC: 0.8691

Epoch 52/80
 - 0s - loss: 0.9001 - val_loss: 0.5833
AUC: 0.8686

Epoch 53/80
 - 0s - loss: 0.8984 - val_loss: 0.5768
AUC: 0.8690

Epoch 54/80
 - 0s - loss: 0.8998 - val_loss: 0.5923
AUC: 0.8689

Epoch 55/80
 - 0s - loss: 0.9038 - val_loss: 0.5643
AUC: 0.8686

Epoch 56/80
 - 0s - loss: 0.8997 - val_loss: 0.5733
AUC: 0.8686

Epoch 57/80
 - 0s - loss: 0.8946 - val_loss: 0.5942
AUC: 0.8688

Epoch 58/80
 - 0s - loss: 0.8978 - val_loss: 0.5884
AUC: 0.8687

Epoch 59/80
 - 0s - loss: 0.8986 - val_loss: 0.5858
AUC: 0.8689

Epoch 60/80
 - 0s - loss: 0.8973 - val_loss: 0.5873
AUC: 0.8690

Epoch 61/80
 - 0s - loss: 0.8991 - val_loss: 0.5754
AUC: 0.8690

Epoch 62/80
 - 0s - loss: 0.8942 - val_loss: 0.5711
AUC: 0.8689

Epoch 63/80
 - 0s - loss: 0.8934 - val_loss: 0.5757
AUC: 0.8690

Epoch 64/80
 - 0s - loss: 0.8940 - val_loss: 0.5774
AUC: 0.8689

Epoch 65/80
 - 0s - loss: 0.8955 - val_loss: 0.5808
AUC: 0.8691

Epoch 66/80
 - 0s - loss: 0.8927 - val_loss: 0.5809
AUC: 0.8691

Epoch 67/80
 - 0s - loss: 0.8897 - val_loss: 0.5825
AUC: 0.8691

Epoch 68/80
 - 0s - loss: 0.8915 - val_loss: 0.5695
AUC: 0.8690

Epoch 69/80
 - 0s - loss: 0.8913 - val_loss: 0.5705
AUC: 0.8690

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9075 - val_loss: 0.5696
AUC: 0.8690

Epoch 2/30
 - 0s - loss: 0.9011 - val_loss: 0.5675
AUC: 0.8690

Epoch 3/30
 - 0s - loss: 0.8986 - val_loss: 0.5919
AUC: 0.8692

Epoch 4/30
 - 0s - loss: 0.8955 - val_loss: 0.5976
AUC: 0.8692

Epoch 5/30
 - 0s - loss: 0.8987 - val_loss: 0.6050
AUC: 0.8694

Epoch 6/30
 - 0s - loss: 0.8937 - val_loss: 0.5721
AUC: 0.8693

Epoch 7/30
 - 0s - loss: 0.8934 - val_loss: 0.5763
AUC: 0.8695

Epoch 8/30
 - 0s - loss: 0.8881 - val_loss: 0.5675
AUC: 0.8694

Epoch 9/30
 - 0s - loss: 0.8904 - val_loss: 0.5799
AUC: 0.8697

Epoch 10/30
 - 0s - loss: 0.8903 - val_loss: 0.5727
AUC: 0.8697

Epoch 11/30
 - 0s - loss: 0.8907 - val_loss: 0.5797
AUC: 0.8696

Epoch 12/30
 - 0s - loss: 0.8848 - val_loss: 0.5749
AUC: 0.8697

Epoch 13/30
 - 0s - loss: 0.8835 - val_loss: 0.5784
AUC: 0.8698

Epoch 14/30
 - 0s - loss: 0.8879 - val_loss: 0.5702
AUC: 0.8697

Epoch 15/30
 - 0s - loss: 0.8810 - val_loss: 0.5758
AUC: 0.8698

Epoch 16/30
 - 0s - loss: 0.8849 - val_loss: 0.5725
AUC: 0.8697

Epoch 17/30
 - 0s - loss: 0.8818 - val_loss: 0.5692
AUC: 0.8697

Epoch 18/30
 - 0s - loss: 0.8817 - val_loss: 0.5775
AUC: 0.8698

Epoch 19/30
 - 0s - loss: 0.8869 - val_loss: 0.5781
AUC: 0.8698

Epoch 20/30
 - 0s - loss: 0.8864 - val_loss: 0.5736
AUC: 0.8698

Epoch 21/30
 - 0s - loss: 0.8808 - val_loss: 0.5728
AUC: 0.8698

Epoch 22/30
 - 0s - loss: 0.8795 - val_loss: 0.5747
AUC: 0.8699

Epoch 23/30
 - 0s - loss: 0.8823 - val_loss: 0.5753
AUC: 0.8699

Epoch 24/30
 - 0s - loss: 0.8767 - val_loss: 0.5747
AUC: 0.8699

Epoch 25/30
 - 0s - loss: 0.8759 - val_loss: 0.5743
AUC: 0.8699

Epoch 26/30
 - 0s - loss: 0.8827 - val_loss: 0.5738
AUC: 0.8698

Epoch 27/30
 - 0s - loss: 0.8839 - val_loss: 0.5751
AUC: 0.8698

Epoch 28/30
 - 0s - loss: 0.8791 - val_loss: 0.5740
AUC: 0.8698

Epoch 29/30
 - 0s - loss: 0.8798 - val_loss: 0.5732
AUC: 0.8698

Epoch 30/30
 - 0s - loss: 0.8807 - val_loss: 0.5751
Using TensorFlow backend.
AUC: 0.8699

2019-03-08 04:54:54.422683: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:54:54.589893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:54:54.589936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:54:54.885341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:54:54.885394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:54:54.885404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:54:54.885676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1441
Epoch 2/80
 - 2s - loss: 0.2150
Epoch 3/80
 - 2s - loss: 0.1725
Epoch 4/80
 - 2s - loss: 0.1653
Epoch 5/80
 - 2s - loss: 0.1587
Epoch 6/80
 - 2s - loss: 0.1508
Epoch 7/80
 - 2s - loss: 0.1410
Epoch 8/80
 - 2s - loss: 0.1302
Epoch 9/80
 - 2s - loss: 0.1197
Epoch 10/80
 - 2s - loss: 0.1106
Epoch 11/80
 - 2s - loss: 0.1028
Epoch 12/80
 - 2s - loss: 0.0960
Epoch 13/80
 - 2s - loss: 0.0899
Epoch 14/80
 - 2s - loss: 0.0846
Epoch 15/80
 - 2s - loss: 0.0799
Epoch 16/80
 - 2s - loss: 0.0756
Epoch 17/80
 - 2s - loss: 0.0718
Epoch 18/80
 - 2s - loss: 0.0685
Epoch 19/80
 - 2s - loss: 0.0657
Epoch 20/80
 - 2s - loss: 0.0634
Epoch 21/80
 - 2s - loss: 0.0615
Epoch 22/80
 - 2s - loss: 0.0600
Epoch 23/80
 - 2s - loss: 0.0587
Epoch 24/80
 - 2s - loss: 0.0576
Epoch 25/80
 - 2s - loss: 0.0567
Epoch 26/80
 - 2s - loss: 0.0560
Epoch 27/80
 - 2s - loss: 0.0553
Epoch 28/80
 - 2s - loss: 0.0547
Epoch 29/80
 - 2s - loss: 0.0543
Epoch 30/80
 - 2s - loss: 0.0538
Epoch 31/80
 - 2s - loss: 0.0534
Epoch 32/80
 - 2s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0526
Epoch 35/80
 - 2s - loss: 0.0523
Epoch 36/80
 - 2s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0520
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 2s - loss: 0.0516
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0514
Epoch 42/80
 - 2s - loss: 0.0513
Epoch 43/80
 - 2s - loss: 0.0512
Epoch 44/80
 - 2s - loss: 0.0511
Epoch 45/80
 - 2s - loss: 0.0510
Epoch 46/80
 - 2s - loss: 0.0509
Epoch 47/80
 - 2s - loss: 0.0508
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0507
Epoch 50/80
 - 2s - loss: 0.0506
Epoch 51/80
 - 2s - loss: 0.0506
Epoch 52/80
 - 2s - loss: 0.0505
Epoch 53/80
 - 2s - loss: 0.0505
Epoch 54/80
 - 2s - loss: 0.0505
Epoch 55/80
 - 2s - loss: 0.0504
Epoch 56/80
 - 2s - loss: 0.0504
Epoch 57/80
 - 2s - loss: 0.0503
Epoch 58/80
 - 2s - loss: 0.0503
Epoch 59/80
 - 2s - loss: 0.0503
Epoch 60/80
 - 2s - loss: 0.0492
Epoch 61/80
 - 2s - loss: 0.0490
Epoch 62/80
 - 2s - loss: 0.0490
Epoch 63/80
 - 2s - loss: 0.0490
Epoch 64/80
 - 2s - loss: 0.0490
Epoch 65/80
 - 2s - loss: 0.0487
Epoch 66/80
 - 2s - loss: 0.0487
Epoch 67/80
 - 2s - loss: 0.0487
Epoch 68/80
 - 2s - loss: 0.0487
Epoch 69/80
 - 2s - loss: 0.0486
Epoch 70/80
 - 2s - loss: 0.0486
Epoch 71/80
 - 2s - loss: 0.0486
Epoch 72/80
 - 2s - loss: 0.0486
Epoch 73/80
 - 2s - loss: 0.0486
Epoch 74/80
 - 2s - loss: 0.0486
Epoch 75/80
 - 2s - loss: 0.0486
Epoch 76/80
 - 2s - loss: 0.0486
Epoch 77/80
 - 2s - loss: 0.0486
Epoch 78/80
 - 2s - loss: 0.0486
Epoch 79/80
 - 2s - loss: 0.0486
Epoch 80/80
 - 2s - loss: 0.0486
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4296 - val_loss: 1.0280
AUC: 0.8029

Epoch 2/80
 - 0s - loss: 2.2294 - val_loss: 0.8479
AUC: 0.8375

Epoch 3/80
 - 0s - loss: 1.5936 - val_loss: 0.7384
AUC: 0.8438

Epoch 4/80
 - 0s - loss: 1.3099 - val_loss: 0.6434
AUC: 0.8463

Epoch 5/80
 - 0s - loss: 1.1750 - val_loss: 0.7240
AUC: 0.8508

Epoch 6/80
 - 0s - loss: 1.1103 - val_loss: 0.7209
AUC: 0.8549

Epoch 7/80
 - 0s - loss: 1.0959 - val_loss: 0.6111
AUC: 0.8546

Epoch 8/80
 - 0s - loss: 1.0731 - val_loss: 0.6560
AUC: 0.8564

Epoch 9/80
 - 0s - loss: 1.0493 - val_loss: 0.6806
AUC: 0.8576

Epoch 10/80
 - 0s - loss: 1.0440 - val_loss: 0.5551
AUC: 0.8561

Epoch 11/80
 - 0s - loss: 1.0336 - val_loss: 0.6372
AUC: 0.8602

Epoch 12/80
 - 0s - loss: 1.0314 - val_loss: 0.8148
AUC: 0.8613

Epoch 13/80
 - 0s - loss: 1.0190 - val_loss: 0.6280
AUC: 0.8610

Epoch 14/80
 - 0s - loss: 1.0208 - val_loss: 0.6489
AUC: 0.8623

Epoch 15/80
 - 0s - loss: 1.0111 - val_loss: 0.6673
AUC: 0.8627

Epoch 16/80
 - 0s - loss: 1.0028 - val_loss: 0.6312
AUC: 0.8627

Epoch 17/80
 - 0s - loss: 1.0043 - val_loss: 0.5698
AUC: 0.8607

Epoch 18/80
 - 0s - loss: 0.9943 - val_loss: 0.5430
AUC: 0.8615

Epoch 19/80
 - 0s - loss: 0.9916 - val_loss: 0.7086
AUC: 0.8641

Epoch 20/80
 - 0s - loss: 0.9844 - val_loss: 0.5966
AUC: 0.8633

Epoch 21/80
 - 0s - loss: 0.9825 - val_loss: 0.5818
AUC: 0.8633

Epoch 22/80
 - 0s - loss: 0.9782 - val_loss: 0.5849
AUC: 0.8643

Epoch 23/80
 - 0s - loss: 0.9728 - val_loss: 0.5587
AUC: 0.8645

Epoch 24/80
 - 0s - loss: 0.9758 - val_loss: 0.6102
AUC: 0.8641

Epoch 25/80
 - 0s - loss: 0.9664 - val_loss: 0.6341
AUC: 0.8657

Epoch 26/80
 - 0s - loss: 0.9726 - val_loss: 0.5519
AUC: 0.8624

Epoch 27/80
 - 0s - loss: 0.9666 - val_loss: 0.5870
AUC: 0.8647

Epoch 28/80
 - 0s - loss: 0.9628 - val_loss: 0.5928
AUC: 0.8659

Epoch 29/80
 - 0s - loss: 0.9523 - val_loss: 0.5829
AUC: 0.8657

Epoch 30/80
 - 0s - loss: 0.9492 - val_loss: 0.6089
AUC: 0.8663

Epoch 31/80
 - 0s - loss: 0.9501 - val_loss: 0.6033
AUC: 0.8667

Epoch 32/80
 - 0s - loss: 0.9476 - val_loss: 0.5722
AUC: 0.8660

Epoch 33/80
 - 0s - loss: 0.9423 - val_loss: 0.5725
AUC: 0.8657

Epoch 34/80
 - 0s - loss: 0.9445 - val_loss: 0.6253
AUC: 0.8662

Epoch 35/80
 - 0s - loss: 0.9468 - val_loss: 0.5904
AUC: 0.8664

Epoch 36/80
 - 0s - loss: 0.9475 - val_loss: 0.6134
AUC: 0.8663

Epoch 37/80
 - 0s - loss: 0.9432 - val_loss: 0.6152
AUC: 0.8665

Epoch 38/80
 - 0s - loss: 0.9412 - val_loss: 0.6007
AUC: 0.8663

Epoch 39/80
 - 0s - loss: 0.9413 - val_loss: 0.5939
AUC: 0.8663

Epoch 40/80
 - 0s - loss: 0.9375 - val_loss: 0.6008
AUC: 0.8664

Epoch 41/80
 - 0s - loss: 0.9389 - val_loss: 0.6072
AUC: 0.8664

Epoch 42/80
 - 0s - loss: 0.9356 - val_loss: 0.6001
AUC: 0.8662

Epoch 43/80
 - 0s - loss: 0.9406 - val_loss: 0.6002
AUC: 0.8662

Epoch 44/80
 - 0s - loss: 0.9353 - val_loss: 0.5949
AUC: 0.8661

Epoch 45/80
 - 0s - loss: 0.9410 - val_loss: 0.6127
AUC: 0.8663

Epoch 46/80
 - 0s - loss: 0.9397 - val_loss: 0.6011
AUC: 0.8663

Epoch 47/80
 - 0s - loss: 0.9395 - val_loss: 0.5958
AUC: 0.8662

Epoch 48/80
 - 0s - loss: 0.9357 - val_loss: 0.5948
AUC: 0.8662

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9499 - val_loss: 0.5778
AUC: 0.8662

Epoch 2/30
 - 0s - loss: 0.9464 - val_loss: 0.5982
AUC: 0.8664

Epoch 3/30
 - 0s - loss: 0.9406 - val_loss: 0.5835
AUC: 0.8659

Epoch 4/30
 - 0s - loss: 0.9417 - val_loss: 0.5969
AUC: 0.8667

Epoch 5/30
 - 0s - loss: 0.9341 - val_loss: 0.6257
AUC: 0.8670

Epoch 6/30
 - 0s - loss: 0.9464 - val_loss: 0.5883
AUC: 0.8666

Epoch 7/30
 - 0s - loss: 0.9362 - val_loss: 0.5877
AUC: 0.8667

Epoch 8/30
 - 0s - loss: 0.9347 - val_loss: 0.5857
AUC: 0.8664

Epoch 9/30
 - 0s - loss: 0.9365 - val_loss: 0.5898
AUC: 0.8666

Epoch 10/30
 - 0s - loss: 0.9329 - val_loss: 0.6281
AUC: 0.8672

Epoch 11/30
 - 0s - loss: 0.9317 - val_loss: 0.5758
AUC: 0.8667

Epoch 12/30
 - 0s - loss: 0.9276 - val_loss: 0.5946
AUC: 0.8670

Epoch 13/30
 - 0s - loss: 0.9282 - val_loss: 0.5806
AUC: 0.8668

Epoch 14/30
 - 0s - loss: 0.9281 - val_loss: 0.6175
AUC: 0.8675

Epoch 15/30
 - 0s - loss: 0.9291 - val_loss: 0.5799
AUC: 0.8670

Epoch 16/30
 - 0s - loss: 0.9266 - val_loss: 0.5956
AUC: 0.8670

Epoch 17/30
 - 0s - loss: 0.9191 - val_loss: 0.5812
AUC: 0.8673

Epoch 18/30
 - 0s - loss: 0.9197 - val_loss: 0.5919
AUC: 0.8673

Epoch 19/30
 - 0s - loss: 0.9196 - val_loss: 0.5763
AUC: 0.8672

Epoch 20/30
 - 0s - loss: 0.9225 - val_loss: 0.5971
AUC: 0.8674

Epoch 21/30
 - 0s - loss: 0.9162 - val_loss: 0.5705
AUC: 0.8670

Epoch 22/30
 - 0s - loss: 0.9199 - val_loss: 0.5924
AUC: 0.8675

Epoch 23/30
 - 0s - loss: 0.9180 - val_loss: 0.5854
AUC: 0.8672

Epoch 24/30
 - 0s - loss: 0.9168 - val_loss: 0.5962
AUC: 0.8677

Epoch 25/30
 - 0s - loss: 0.9131 - val_loss: 0.6068
AUC: 0.8678

Epoch 26/30
 - 0s - loss: 0.9118 - val_loss: 0.5678
AUC: 0.8673

Epoch 27/30
 - 0s - loss: 0.9122 - val_loss: 0.5897
AUC: 0.8675

Epoch 28/30
 - 0s - loss: 0.9069 - val_loss: 0.5977
AUC: 0.8678

Epoch 29/30
 - 0s - loss: 0.9112 - val_loss: 0.5641
AUC: 0.8673

Epoch 30/30
 - 0s - loss: 0.9129 - val_loss: 0.5996
Using TensorFlow backend.
AUC: 0.8680

2019-03-08 04:58:12.345997: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 04:58:12.509781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 04:58:12.509824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 04:58:12.805794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 04:58:12.805845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 04:58:12.805853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 04:58:12.806106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1394
Epoch 2/80
 - 2s - loss: 0.2159
Epoch 3/80
 - 2s - loss: 0.1748
Epoch 4/80
 - 2s - loss: 0.1678
Epoch 5/80
 - 2s - loss: 0.1625
Epoch 6/80
 - 2s - loss: 0.1559
Epoch 7/80
 - 2s - loss: 0.1468
Epoch 8/80
 - 2s - loss: 0.1349
Epoch 9/80
 - 2s - loss: 0.1226
Epoch 10/80
 - 2s - loss: 0.1119
Epoch 11/80
 - 2s - loss: 0.1029
Epoch 12/80
 - 2s - loss: 0.0950
Epoch 13/80
 - 2s - loss: 0.0882
Epoch 14/80
 - 2s - loss: 0.0828
Epoch 15/80
 - 2s - loss: 0.0784
Epoch 16/80
 - 2s - loss: 0.0747
Epoch 17/80
 - 2s - loss: 0.0714
Epoch 18/80
 - 2s - loss: 0.0685
Epoch 19/80
 - 2s - loss: 0.0659
Epoch 20/80
 - 2s - loss: 0.0637
Epoch 21/80
 - 2s - loss: 0.0619
Epoch 22/80
 - 2s - loss: 0.0603
Epoch 23/80
 - 2s - loss: 0.0590
Epoch 24/80
 - 2s - loss: 0.0580
Epoch 25/80
 - 2s - loss: 0.0570
Epoch 26/80
 - 2s - loss: 0.0562
Epoch 27/80
 - 2s - loss: 0.0555
Epoch 28/80
 - 2s - loss: 0.0550
Epoch 29/80
 - 2s - loss: 0.0545
Epoch 30/80
 - 2s - loss: 0.0540
Epoch 31/80
 - 2s - loss: 0.0536
Epoch 32/80
 - 2s - loss: 0.0533
Epoch 33/80
 - 2s - loss: 0.0530
Epoch 34/80
 - 2s - loss: 0.0528
Epoch 35/80
 - 2s - loss: 0.0526
Epoch 36/80
 - 2s - loss: 0.0523
Epoch 37/80
 - 2s - loss: 0.0522
Epoch 38/80
 - 2s - loss: 0.0520
Epoch 39/80
 - 2s - loss: 0.0518
Epoch 40/80
 - 2s - loss: 0.0517
Epoch 41/80
 - 2s - loss: 0.0516
Epoch 42/80
 - 2s - loss: 0.0515
Epoch 43/80
 - 2s - loss: 0.0514
Epoch 44/80
 - 2s - loss: 0.0513
Epoch 45/80
 - 2s - loss: 0.0512
Epoch 46/80
 - 2s - loss: 0.0512
Epoch 47/80
 - 2s - loss: 0.0511
Epoch 48/80
 - 2s - loss: 0.0510
Epoch 49/80
 - 2s - loss: 0.0509
Epoch 50/80
 - 2s - loss: 0.0509
Epoch 51/80
 - 2s - loss: 0.0508
Epoch 52/80
 - 2s - loss: 0.0508
Epoch 53/80
 - 2s - loss: 0.0507
Epoch 54/80
 - 2s - loss: 0.0507
Epoch 55/80
 - 2s - loss: 0.0507
Epoch 56/80
 - 2s - loss: 0.0506
Epoch 57/80
 - 2s - loss: 0.0506
Epoch 58/80
 - 2s - loss: 0.0505
Epoch 59/80
 - 2s - loss: 0.0505
Epoch 60/80
 - 2s - loss: 0.0505
Epoch 61/80
 - 2s - loss: 0.0504
Epoch 62/80
 - 2s - loss: 0.0504
Epoch 63/80
 - 2s - loss: 0.0493
Epoch 64/80
 - 2s - loss: 0.0492
Epoch 65/80
 - 2s - loss: 0.0492
Epoch 66/80
 - 2s - loss: 0.0492
Epoch 67/80
 - 2s - loss: 0.0492
Epoch 68/80
 - 2s - loss: 0.0489
Epoch 69/80
 - 2s - loss: 0.0489
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:00:24.089867: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:00:24.255229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:00:24.255274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:00:24.552103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:00:24.552152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:00:24.552161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:00:24.552424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1380
Epoch 2/80
 - 2s - loss: 0.2143
Epoch 3/80
 - 2s - loss: 0.1735
Epoch 4/80
 - 2s - loss: 0.1664
Epoch 5/80
 - 2s - loss: 0.1578
Epoch 6/80
 - 2s - loss: 0.1480
Epoch 7/80
 - 2s - loss: 0.1393
Epoch 8/80
 - 2s - loss: 0.1310
Epoch 9/80
 - 2s - loss: 0.1222
Epoch 10/80
 - 2s - loss: 0.1132
Epoch 11/80
 - 2s - loss: 0.1046
Epoch 12/80
 - 2s - loss: 0.0969
Epoch 13/80
 - 2s - loss: 0.0903
Epoch 14/80
 - 2s - loss: 0.0845
Epoch 15/80
 - 2s - loss: 0.0795
Epoch 16/80
 - 2s - loss: 0.0752
Epoch 17/80
 - 2s - loss: 0.0715
Epoch 18/80
 - 2s - loss: 0.0684
Epoch 19/80
 - 2s - loss: 0.0657
Epoch 20/80
 - 2s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0616
Epoch 22/80
 - 2s - loss: 0.0600
Epoch 23/80
 - 2s - loss: 0.0587
Epoch 24/80
 - 2s - loss: 0.0575
Epoch 25/80
 - 2s - loss: 0.0565
Epoch 26/80
 - 2s - loss: 0.0557
Epoch 27/80
 - 2s - loss: 0.0550
Epoch 28/80
 - 2s - loss: 0.0544
Epoch 29/80
 - 2s - loss: 0.0539
Epoch 30/80
 - 2s - loss: 0.0535
Epoch 31/80
 - 2s - loss: 0.0531
Epoch 32/80
 - 2s - loss: 0.0528
Epoch 33/80
 - 2s - loss: 0.0525
Epoch 34/80
 - 2s - loss: 0.0522
Epoch 35/80
 - 2s - loss: 0.0520
Epoch 36/80
 - 2s - loss: 0.0518
Epoch 37/80
 - 2s - loss: 0.0516
Epoch 38/80
 - 2s - loss: 0.0515
Epoch 39/80
 - 2s - loss: 0.0513
Epoch 40/80
 - 2s - loss: 0.0512
Epoch 41/80
 - 2s - loss: 0.0511
Epoch 42/80
 - 2s - loss: 0.0510
Epoch 43/80
 - 2s - loss: 0.0509
Epoch 44/80
 - 2s - loss: 0.0508
Epoch 45/80
 - 2s - loss: 0.0507
Epoch 46/80
 - 2s - loss: 0.0506
Epoch 47/80
 - 2s - loss: 0.0505
Epoch 48/80
 - 2s - loss: 0.0505
Epoch 49/80
 - 2s - loss: 0.0504
Epoch 50/80
 - 2s - loss: 0.0503
Epoch 51/80
 - 2s - loss: 0.0503
Epoch 52/80
 - 2s - loss: 0.0502
Epoch 53/80
 - 2s - loss: 0.0502
Epoch 54/80
 - 2s - loss: 0.0501
Epoch 55/80
 - 2s - loss: 0.0501
Epoch 56/80
 - 2s - loss: 0.0501
Epoch 57/80
 - 2s - loss: 0.0500
Epoch 58/80
 - 2s - loss: 0.0500
Epoch 59/80
 - 2s - loss: 0.0500
Epoch 60/80
 - 2s - loss: 0.0499
Epoch 61/80
 - 2s - loss: 0.0488
Epoch 62/80
 - 2s - loss: 0.0487
Epoch 63/80
 - 2s - loss: 0.0487
Epoch 64/80
 - 2s - loss: 0.0487
Epoch 65/80
 - 2s - loss: 0.0487
Epoch 66/80
 - 2s - loss: 0.0484
Epoch 67/80
 - 2s - loss: 0.0484
Epoch 68/80
 - 2s - loss: 0.0484
Epoch 69/80
 - 2s - loss: 0.0484
Epoch 70/80
 - 2s - loss: 0.0483
Epoch 71/80
 - 2s - loss: 0.0483
Epoch 72/80
 - 2s - loss: 0.0483
Epoch 73/80
 - 2s - loss: 0.0483
Epoch 74/80
 - 2s - loss: 0.0483
Epoch 75/80
 - 2s - loss: 0.0483
Epoch 76/80
 - 2s - loss: 0.0483
Epoch 77/80
 - 2s - loss: 0.0483
Epoch 78/80
 - 2s - loss: 0.0483
Epoch 79/80
 - 2s - loss: 0.0483
Epoch 80/80
 - 2s - loss: 0.0483
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.9574 - val_loss: 1.2451
AUC: 0.7543

Epoch 2/80
 - 0s - loss: 2.7377 - val_loss: 1.0890
AUC: 0.8188

Epoch 3/80
 - 0s - loss: 2.1042 - val_loss: 0.7782
AUC: 0.8386

Epoch 4/80
 - 0s - loss: 1.7140 - val_loss: 0.8309
AUC: 0.8462

Epoch 5/80
 - 0s - loss: 1.4090 - val_loss: 0.7070
AUC: 0.8532

Epoch 6/80
 - 0s - loss: 1.2535 - val_loss: 0.6656
AUC: 0.8571

Epoch 7/80
 - 0s - loss: 1.1646 - val_loss: 0.6726
AUC: 0.8598

Epoch 8/80
 - 0s - loss: 1.1158 - val_loss: 0.6559
AUC: 0.8609

Epoch 9/80
 - 0s - loss: 1.0864 - val_loss: 0.6255
AUC: 0.8625

Epoch 10/80
 - 0s - loss: 1.0759 - val_loss: 0.6501
AUC: 0.8637

Epoch 11/80
 - 0s - loss: 1.0476 - val_loss: 0.5856
AUC: 0.8656

Epoch 12/80
 - 0s - loss: 1.0388 - val_loss: 0.6121
AUC: 0.8649

Epoch 13/80
 - 0s - loss: 1.0285 - val_loss: 0.6462
AUC: 0.8683

Epoch 14/80
 - 0s - loss: 1.0244 - val_loss: 0.6294
AUC: 0.8689

Epoch 15/80
 - 0s - loss: 1.0208 - val_loss: 0.5367
AUC: 0.8670

Epoch 16/80
 - 0s - loss: 1.0127 - val_loss: 0.6739
AUC: 0.8704

Epoch 17/80
 - 0s - loss: 1.0041 - val_loss: 0.6083
AUC: 0.8697

Epoch 18/80
 - 0s - loss: 0.9991 - val_loss: 0.6343
AUC: 0.8709

Epoch 19/80
 - 0s - loss: 0.9888 - val_loss: 0.5771
AUC: 0.8700

Epoch 20/80
 - 0s - loss: 0.9991 - val_loss: 0.6243
AUC: 0.8716

Epoch 21/80
 - 0s - loss: 0.9868 - val_loss: 0.5945
AUC: 0.8717

Epoch 22/80
 - 0s - loss: 0.9836 - val_loss: 0.5938
AUC: 0.8728

Epoch 23/80
 - 0s - loss: 0.9818 - val_loss: 0.5775
AUC: 0.8721

Epoch 24/80
 - 0s - loss: 0.9787 - val_loss: 0.6657
AUC: 0.8733

Epoch 25/80
 - 0s - loss: 0.9758 - val_loss: 0.5914
AUC: 0.8738

Epoch 26/80
 - 0s - loss: 0.9651 - val_loss: 0.5785
AUC: 0.8736

Epoch 27/80
 - 0s - loss: 0.9608 - val_loss: 0.6028
AUC: 0.8742

Epoch 28/80
 - 0s - loss: 0.9590 - val_loss: 0.5817
AUC: 0.8741

Epoch 29/80
 - 0s - loss: 0.9562 - val_loss: 0.5780
AUC: 0.8738

Epoch 30/80
 - 0s - loss: 0.9589 - val_loss: 0.5822
AUC: 0.8744

Epoch 31/80
 - 0s - loss: 0.9526 - val_loss: 0.6238
AUC: 0.8746

Epoch 32/80
 - 0s - loss: 0.9523 - val_loss: 0.5836
AUC: 0.8745

Epoch 33/80
 - 0s - loss: 0.9563 - val_loss: 0.5754
AUC: 0.8743

Epoch 34/80
 - 0s - loss: 0.9582 - val_loss: 0.6025
AUC: 0.8747

Epoch 35/80
 - 0s - loss: 0.9504 - val_loss: 0.5924
AUC: 0.8747

Epoch 36/80
 - 0s - loss: 0.9493 - val_loss: 0.5889
AUC: 0.8747

Epoch 37/80
 - 0s - loss: 0.9520 - val_loss: 0.5852
AUC: 0.8748

Epoch 38/80
 - 0s - loss: 0.9498 - val_loss: 0.5973
AUC: 0.8748

Epoch 39/80
 - 0s - loss: 0.9552 - val_loss: 0.5830
AUC: 0.8746

Epoch 40/80
 - 0s - loss: 0.9554 - val_loss: 0.5920
AUC: 0.8748

Epoch 41/80
 - 0s - loss: 0.9496 - val_loss: 0.5898
AUC: 0.8748

Epoch 42/80
 - 0s - loss: 0.9489 - val_loss: 0.5818
AUC: 0.8747

Epoch 43/80
 - 0s - loss: 0.9481 - val_loss: 0.5913
AUC: 0.8748

Epoch 44/80
 - 0s - loss: 0.9448 - val_loss: 0.5994
AUC: 0.8749

Epoch 45/80
 - 0s - loss: 0.9472 - val_loss: 0.5932
AUC: 0.8749

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9503 - val_loss: 0.5775
AUC: 0.8746

Epoch 2/30
 - 0s - loss: 0.9456 - val_loss: 0.6035
AUC: 0.8751

Epoch 3/30
 - 0s - loss: 0.9424 - val_loss: 0.5859
AUC: 0.8747

Epoch 4/30
 - 0s - loss: 0.9466 - val_loss: 0.6006
AUC: 0.8750

Epoch 5/30
 - 0s - loss: 0.9379 - val_loss: 0.5828
AUC: 0.8751

Epoch 6/30
 - 0s - loss: 0.9403 - val_loss: 0.5721
AUC: 0.8749

Epoch 7/30
 - 0s - loss: 0.9365 - val_loss: 0.5856
AUC: 0.8751

Epoch 8/30
 - 0s - loss: 0.9401 - val_loss: 0.5778
AUC: 0.8753

Epoch 9/30
 - 0s - loss: 0.9346 - val_loss: 0.5650
AUC: 0.8754

Epoch 10/30
 - 0s - loss: 0.9340 - val_loss: 0.5834
AUC: 0.8759

Epoch 11/30
 - 0s - loss: 0.9338 - val_loss: 0.5597
AUC: 0.8758

Epoch 12/30
 - 0s - loss: 0.9425 - val_loss: 0.5690
AUC: 0.8760

Epoch 13/30
 - 0s - loss: 0.9343 - val_loss: 0.5804
AUC: 0.8759

Epoch 14/30
 - 0s - loss: 0.9361 - val_loss: 0.5631
AUC: 0.8759

Epoch 15/30
 - 0s - loss: 0.9283 - val_loss: 0.5739
AUC: 0.8762

Epoch 16/30
 - 0s - loss: 0.9294 - val_loss: 0.5812
AUC: 0.8764

Epoch 17/30
 - 0s - loss: 0.9281 - val_loss: 0.5580
AUC: 0.8762

Epoch 18/30
 - 0s - loss: 0.9215 - val_loss: 0.5992
AUC: 0.8763

Epoch 19/30
 - 0s - loss: 0.9270 - val_loss: 0.5715
AUC: 0.8763

Epoch 20/30
 - 0s - loss: 0.9157 - val_loss: 0.5749
AUC: 0.8765

Epoch 21/30
 - 0s - loss: 0.9186 - val_loss: 0.6028
AUC: 0.8769

Epoch 22/30
 - 0s - loss: 0.9172 - val_loss: 0.5944
AUC: 0.8769

Epoch 23/30
 - 0s - loss: 0.9223 - val_loss: 0.5703
AUC: 0.8769

Epoch 24/30
 - 0s - loss: 0.9205 - val_loss: 0.5692
AUC: 0.8769

Epoch 25/30
 - 0s - loss: 0.9136 - val_loss: 0.5517
AUC: 0.8768

Epoch 26/30
 - 0s - loss: 0.9170 - val_loss: 0.5613
AUC: 0.8770

Epoch 27/30
 - 0s - loss: 0.9139 - val_loss: 0.5755
AUC: 0.8772

Epoch 28/30
 - 0s - loss: 0.9124 - val_loss: 0.5614
AUC: 0.8769

Epoch 29/30
 - 0s - loss: 0.9116 - val_loss: 0.5839
AUC: 0.8772

Epoch 30/30
 - 0s - loss: 0.9083 - val_loss: 0.5478
Using TensorFlow backend.
AUC: 0.8768

2019-03-08 05:03:43.500771: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:03:43.668281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:03:43.668326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:03:43.971449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:03:43.971498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:03:43.971507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:03:43.971760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6794
Epoch 2/80
 - 2s - loss: 0.1274
Epoch 3/80
 - 2s - loss: 0.0717
Epoch 4/80
 - 2s - loss: 0.0656
Epoch 5/80
 - 2s - loss: 0.0631
Epoch 6/80
 - 2s - loss: 0.0611
Epoch 7/80
 - 2s - loss: 0.0589
Epoch 8/80
 - 2s - loss: 0.0564
Epoch 9/80
 - 2s - loss: 0.0534
Epoch 10/80
 - 2s - loss: 0.0497
Epoch 11/80
 - 2s - loss: 0.0456
Epoch 12/80
 - 2s - loss: 0.0416
Epoch 13/80
 - 2s - loss: 0.0383
Epoch 14/80
 - 2s - loss: 0.0354
Epoch 15/80
 - 2s - loss: 0.0330
Epoch 16/80
 - 2s - loss: 0.0308
Epoch 17/80
 - 2s - loss: 0.0289
Epoch 18/80
 - 2s - loss: 0.0273
Epoch 19/80
 - 2s - loss: 0.0259
Epoch 20/80
 - 2s - loss: 0.0246
Epoch 21/80
 - 2s - loss: 0.0234
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0216
Epoch 24/80
 - 2s - loss: 0.0209
Epoch 25/80
 - 2s - loss: 0.0203
Epoch 26/80
 - 2s - loss: 0.0198
Epoch 27/80
 - 2s - loss: 0.0194
Epoch 28/80
 - 2s - loss: 0.0190
Epoch 29/80
 - 2s - loss: 0.0187
Epoch 30/80
 - 2s - loss: 0.0184
Epoch 31/80
 - 2s - loss: 0.0182
Epoch 32/80
 - 2s - loss: 0.0180
Epoch 33/80
 - 2s - loss: 0.0178
Epoch 34/80
 - 2s - loss: 0.0176
Epoch 35/80
 - 2s - loss: 0.0175
Epoch 36/80
 - 2s - loss: 0.0174
Epoch 37/80
 - 2s - loss: 0.0173
Epoch 38/80
 - 2s - loss: 0.0172
Epoch 39/80
 - 2s - loss: 0.0171
Epoch 40/80
 - 2s - loss: 0.0170
Epoch 41/80
 - 2s - loss: 0.0169
Epoch 42/80
 - 2s - loss: 0.0169
Epoch 43/80
 - 2s - loss: 0.0168
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0167
Epoch 46/80
 - 2s - loss: 0.0167
Epoch 47/80
 - 2s - loss: 0.0166
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0165
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0161
Epoch 54/80
 - 2s - loss: 0.0160
Epoch 55/80
 - 2s - loss: 0.0160
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0159
Epoch 58/80
 - 2s - loss: 0.0159
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0159
Epoch 67/80
 - 2s - loss: 0.0159
Epoch 68/80
 - 2s - loss: 0.0159
Epoch 69/80
 - 2s - loss: 0.0159
Epoch 70/80
 - 2s - loss: 0.0159
Epoch 71/80
 - 2s - loss: 0.0159
Epoch 72/80
 - 2s - loss: 0.0159
Epoch 73/80
 - 2s - loss: 0.0159
Epoch 74/80
 - 2s - loss: 0.0159
Epoch 75/80
 - 2s - loss: 0.0159
Epoch 76/80
 - 2s - loss: 0.0159
Epoch 77/80
 - 2s - loss: 0.0159
Epoch 78/80
 - 2s - loss: 0.0159
Epoch 79/80
 - 2s - loss: 0.0159
Epoch 80/80
 - 2s - loss: 0.0159
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.8690 - val_loss: 0.8751
AUC: 0.8171

Epoch 2/80
 - 0s - loss: 1.6698 - val_loss: 0.8077
AUC: 0.8364

Epoch 3/80
 - 0s - loss: 1.3087 - val_loss: 0.7225
AUC: 0.8399

Epoch 4/80
 - 0s - loss: 1.1707 - val_loss: 0.6210
AUC: 0.8430

Epoch 5/80
 - 0s - loss: 1.1152 - val_loss: 0.6815
AUC: 0.8465

Epoch 6/80
 - 0s - loss: 1.0836 - val_loss: 0.7090
AUC: 0.8491

Epoch 7/80
 - 0s - loss: 1.0717 - val_loss: 0.6505
AUC: 0.8502

Epoch 8/80
 - 0s - loss: 1.0527 - val_loss: 0.6076
AUC: 0.8513

Epoch 9/80
 - 0s - loss: 1.0364 - val_loss: 0.6574
AUC: 0.8532

Epoch 10/80
 - 0s - loss: 1.0265 - val_loss: 0.6199
AUC: 0.8533

Epoch 11/80
 - 0s - loss: 1.0263 - val_loss: 0.6561
AUC: 0.8548

Epoch 12/80
 - 0s - loss: 1.0175 - val_loss: 0.6453
AUC: 0.8560

Epoch 13/80
 - 0s - loss: 1.0141 - val_loss: 0.6221
AUC: 0.8571

Epoch 14/80
 - 0s - loss: 1.0135 - val_loss: 0.6215
AUC: 0.8571

Epoch 15/80
 - 0s - loss: 1.0060 - val_loss: 0.6189
AUC: 0.8570

Epoch 16/80
 - 0s - loss: 0.9999 - val_loss: 0.6838
AUC: 0.8593

Epoch 17/80
 - 0s - loss: 0.9999 - val_loss: 0.6104
AUC: 0.8585

Epoch 18/80
 - 0s - loss: 0.9909 - val_loss: 0.6641
AUC: 0.8598

Epoch 19/80
 - 0s - loss: 0.9825 - val_loss: 0.5951
AUC: 0.8600

Epoch 20/80
 - 0s - loss: 0.9825 - val_loss: 0.6320
AUC: 0.8593

Epoch 21/80
 - 0s - loss: 0.9769 - val_loss: 0.6145
AUC: 0.8604

Epoch 22/80
 - 0s - loss: 0.9732 - val_loss: 0.6256
AUC: 0.8605

Epoch 23/80
 - 0s - loss: 0.9707 - val_loss: 0.6474
AUC: 0.8609

Epoch 24/80
 - 0s - loss: 0.9717 - val_loss: 0.6178
AUC: 0.8613

Epoch 25/80
 - 0s - loss: 0.9703 - val_loss: 0.5876
AUC: 0.8601

Epoch 26/80
 - 0s - loss: 0.9695 - val_loss: 0.5915
AUC: 0.8608

Epoch 27/80
 - 0s - loss: 0.9652 - val_loss: 0.6376
AUC: 0.8610

Epoch 28/80
 - 0s - loss: 0.9680 - val_loss: 0.6156
AUC: 0.8612

Epoch 29/80
 - 0s - loss: 0.9631 - val_loss: 0.6313
AUC: 0.8614

Epoch 30/80
 - 0s - loss: 0.9681 - val_loss: 0.6256
AUC: 0.8617

Epoch 31/80
 - 0s - loss: 0.9664 - val_loss: 0.6231
AUC: 0.8613

Epoch 32/80
 - 0s - loss: 0.9626 - val_loss: 0.6348
AUC: 0.8617

Epoch 33/80
 - 0s - loss: 0.9638 - val_loss: 0.6100
AUC: 0.8617

Epoch 34/80
 - 0s - loss: 0.9591 - val_loss: 0.6205
AUC: 0.8620

Epoch 35/80
 - 0s - loss: 0.9607 - val_loss: 0.6313
AUC: 0.8618

Epoch 36/80
 - 0s - loss: 0.9602 - val_loss: 0.5994
AUC: 0.8616

Epoch 37/80
 - 0s - loss: 0.9620 - val_loss: 0.6152
AUC: 0.8618

Epoch 38/80
 - 0s - loss: 0.9530 - val_loss: 0.5996
AUC: 0.8616

Epoch 39/80
 - 0s - loss: 0.9587 - val_loss: 0.6127
AUC: 0.8619

Epoch 40/80
 - 0s - loss: 0.9564 - val_loss: 0.6082
AUC: 0.8619

Epoch 41/80
 - 0s - loss: 0.9610 - val_loss: 0.6088
AUC: 0.8619

Epoch 42/80
 - 0s - loss: 0.9558 - val_loss: 0.6040
AUC: 0.8619

Epoch 43/80
 - 0s - loss: 0.9512 - val_loss: 0.5937
AUC: 0.8618

Epoch 44/80
 - 0s - loss: 0.9568 - val_loss: 0.6126
AUC: 0.8620

Epoch 45/80
 - 0s - loss: 0.9572 - val_loss: 0.5991
AUC: 0.8620

Epoch 46/80
 - 0s - loss: 0.9510 - val_loss: 0.5997
AUC: 0.8620

Epoch 47/80
 - 0s - loss: 0.9532 - val_loss: 0.6013
AUC: 0.8620

Epoch 48/80
 - 0s - loss: 0.9541 - val_loss: 0.6030
AUC: 0.8620

Epoch 49/80
 - 0s - loss: 0.9530 - val_loss: 0.6044
AUC: 0.8620

Epoch 50/80
 - 0s - loss: 0.9503 - val_loss: 0.6045
AUC: 0.8621

Epoch 51/80
 - 0s - loss: 0.9486 - val_loss: 0.6049
AUC: 0.8620

Epoch 52/80
 - 0s - loss: 0.9559 - val_loss: 0.6023
AUC: 0.8620

Epoch 53/80
 - 0s - loss: 0.9560 - val_loss: 0.6068
AUC: 0.8621

Epoch 54/80
 - 0s - loss: 0.9600 - val_loss: 0.6052
AUC: 0.8621

Epoch 55/80
 - 0s - loss: 0.9520 - val_loss: 0.6047
AUC: 0.8621

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9610 - val_loss: 0.6039
AUC: 0.8623

Epoch 2/30
 - 0s - loss: 0.9523 - val_loss: 0.5987
AUC: 0.8622

Epoch 3/30
 - 0s - loss: 0.9512 - val_loss: 0.5921
AUC: 0.8621

Epoch 4/30
 - 0s - loss: 0.9498 - val_loss: 0.5983
AUC: 0.8622

Epoch 5/30
 - 0s - loss: 0.9484 - val_loss: 0.5894
AUC: 0.8625

Epoch 6/30
 - 0s - loss: 0.9493 - val_loss: 0.5788
AUC: 0.8625

Epoch 7/30
 - 0s - loss: 0.9470 - val_loss: 0.5826
AUC: 0.8627

Epoch 8/30
 - 0s - loss: 0.9423 - val_loss: 0.5962
AUC: 0.8629

Epoch 9/30
 - 0s - loss: 0.9456 - val_loss: 0.6150
AUC: 0.8633

Epoch 10/30
 - 0s - loss: 0.9435 - val_loss: 0.5936
AUC: 0.8631

Epoch 11/30
 - 0s - loss: 0.9383 - val_loss: 0.5806
AUC: 0.8631

Epoch 12/30
 - 0s - loss: 0.9384 - val_loss: 0.5887
AUC: 0.8633

Epoch 13/30
 - 0s - loss: 0.9384 - val_loss: 0.5992
AUC: 0.8634

Epoch 14/30
 - 0s - loss: 0.9359 - val_loss: 0.6103
AUC: 0.8635

Epoch 15/30
 - 0s - loss: 0.9357 - val_loss: 0.5956
AUC: 0.8634

Epoch 16/30
 - 0s - loss: 0.9324 - val_loss: 0.6071
AUC: 0.8637

Epoch 17/30
 - 0s - loss: 0.9318 - val_loss: 0.5922
AUC: 0.8636

Epoch 18/30
 - 0s - loss: 0.9297 - val_loss: 0.5943
AUC: 0.8636

Epoch 19/30
 - 0s - loss: 0.9260 - val_loss: 0.5920
AUC: 0.8636

Epoch 20/30
 - 0s - loss: 0.9308 - val_loss: 0.5977
AUC: 0.8637

Epoch 21/30
 - 0s - loss: 0.9324 - val_loss: 0.5899
AUC: 0.8636

Epoch 22/30
 - 0s - loss: 0.9347 - val_loss: 0.5954
AUC: 0.8637

Epoch 23/30
 - 0s - loss: 0.9300 - val_loss: 0.5957
AUC: 0.8638

Epoch 24/30
 - 0s - loss: 0.9328 - val_loss: 0.5864
AUC: 0.8637

Epoch 25/30
 - 0s - loss: 0.9351 - val_loss: 0.5883
AUC: 0.8637

Epoch 26/30
 - 0s - loss: 0.9307 - val_loss: 0.5934
AUC: 0.8638

Epoch 27/30
 - 0s - loss: 0.9256 - val_loss: 0.5928
AUC: 0.8638

Epoch 28/30
 - 0s - loss: 0.9320 - val_loss: 0.5929
AUC: 0.8638

Epoch 29/30
 - 0s - loss: 0.9309 - val_loss: 0.5946
AUC: 0.8638

Epoch 30/30
 - 0s - loss: 0.9287 - val_loss: 0.5911
Using TensorFlow backend.
AUC: 0.8637

2019-03-08 05:07:05.733463: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:07:05.898058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:07:05.898102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:07:06.191027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:07:06.191078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:07:06.191087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:07:06.191402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6937
Epoch 2/80
 - 2s - loss: 0.1327
Epoch 3/80
 - 2s - loss: 0.0713
Epoch 4/80
 - 2s - loss: 0.0642
Epoch 5/80
 - 2s - loss: 0.0605
Epoch 6/80
 - 2s - loss: 0.0565
Epoch 7/80
 - 2s - loss: 0.0524
Epoch 8/80
 - 2s - loss: 0.0490
Epoch 9/80
 - 2s - loss: 0.0463
Epoch 10/80
 - 2s - loss: 0.0439
Epoch 11/80
 - 2s - loss: 0.0415
Epoch 12/80
 - 2s - loss: 0.0391
Epoch 13/80
 - 2s - loss: 0.0368
Epoch 14/80
 - 2s - loss: 0.0345
Epoch 15/80
 - 2s - loss: 0.0323
Epoch 16/80
 - 2s - loss: 0.0303
Epoch 17/80
 - 2s - loss: 0.0284
Epoch 18/80
 - 2s - loss: 0.0268
Epoch 19/80
 - 2s - loss: 0.0255
Epoch 20/80
 - 2s - loss: 0.0243
Epoch 21/80
 - 2s - loss: 0.0233
Epoch 22/80
 - 2s - loss: 0.0224
Epoch 23/80
 - 2s - loss: 0.0217
Epoch 24/80
 - 2s - loss: 0.0211
Epoch 25/80
 - 2s - loss: 0.0205
Epoch 26/80
 - 2s - loss: 0.0200
Epoch 27/80
 - 2s - loss: 0.0196
Epoch 28/80
 - 2s - loss: 0.0192
Epoch 29/80
 - 2s - loss: 0.0189
Epoch 30/80
 - 2s - loss: 0.0186
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0178
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0167
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0166
Epoch 50/80
 - 2s - loss: 0.0166
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0165
Epoch 53/80
 - 2s - loss: 0.0165
Epoch 54/80
 - 2s - loss: 0.0165
Epoch 55/80
 - 2s - loss: 0.0161
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0160
Epoch 58/80
 - 2s - loss: 0.0160
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0159
Epoch 61/80
 - 2s - loss: 0.0159
Epoch 62/80
 - 2s - loss: 0.0159
Epoch 63/80
 - 2s - loss: 0.0159
Epoch 64/80
 - 2s - loss: 0.0159
Epoch 65/80
 - 2s - loss: 0.0159
Epoch 66/80
 - 2s - loss: 0.0158
Epoch 67/80
 - 2s - loss: 0.0158
Epoch 68/80
 - 2s - loss: 0.0158
Epoch 69/80
 - 2s - loss: 0.0158
Epoch 70/80
 - 2s - loss: 0.0158
Epoch 71/80
 - 2s - loss: 0.0158
Epoch 72/80
 - 2s - loss: 0.0158
Epoch 73/80
 - 2s - loss: 0.0158
Epoch 74/80
 - 2s - loss: 0.0158
Epoch 75/80
 - 2s - loss: 0.0158
Epoch 76/80
 - 2s - loss: 0.0158
Epoch 77/80
 - 2s - loss: 0.0158
Epoch 78/80
 - 2s - loss: 0.0158
Epoch 79/80
 - 2s - loss: 0.0158
Epoch 80/80
 - 2s - loss: 0.0158
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.2986 - val_loss: 0.8760
AUC: 0.8116

Epoch 2/80
 - 0s - loss: 2.0304 - val_loss: 0.7756
AUC: 0.8368

Epoch 3/80
 - 0s - loss: 1.4855 - val_loss: 0.7986
AUC: 0.8501

Epoch 4/80
 - 0s - loss: 1.2240 - val_loss: 0.7357
AUC: 0.8509

Epoch 5/80
 - 0s - loss: 1.1439 - val_loss: 0.8641
AUC: 0.8526

Epoch 6/80
 - 0s - loss: 1.1217 - val_loss: 0.7374
AUC: 0.8567

Epoch 7/80
 - 0s - loss: 1.0909 - val_loss: 0.6869
AUC: 0.8578

Epoch 8/80
 - 0s - loss: 1.0683 - val_loss: 0.6456
AUC: 0.8595

Epoch 9/80
 - 0s - loss: 1.0601 - val_loss: 0.6544
AUC: 0.8609

Epoch 10/80
 - 0s - loss: 1.0554 - val_loss: 0.7153
AUC: 0.8624

Epoch 11/80
 - 0s - loss: 1.0398 - val_loss: 0.6690
AUC: 0.8624

Epoch 12/80
 - 0s - loss: 1.0313 - val_loss: 0.6707
AUC: 0.8636

Epoch 13/80
 - 0s - loss: 1.0246 - val_loss: 0.6620
AUC: 0.8638

Epoch 14/80
 - 0s - loss: 1.0239 - val_loss: 0.6208
AUC: 0.8644

Epoch 15/80
 - 0s - loss: 1.0151 - val_loss: 0.6556
AUC: 0.8641

Epoch 16/80
 - 0s - loss: 1.0131 - val_loss: 0.5870
AUC: 0.8655

Epoch 17/80
 - 0s - loss: 1.0103 - val_loss: 0.6486
AUC: 0.8655

Epoch 18/80
 - 0s - loss: 1.0036 - val_loss: 0.6356
AUC: 0.8670

Epoch 19/80
 - 0s - loss: 0.9953 - val_loss: 0.5816
AUC: 0.8671

Epoch 20/80
 - 0s - loss: 0.9952 - val_loss: 0.6608
AUC: 0.8682

Epoch 21/80
 - 0s - loss: 0.9928 - val_loss: 0.6636
AUC: 0.8679

Epoch 22/80
 - 0s - loss: 0.9895 - val_loss: 0.5781
AUC: 0.8663

Epoch 23/80
 - 0s - loss: 0.9854 - val_loss: 0.5820
AUC: 0.8671

Epoch 24/80
 - 0s - loss: 0.9872 - val_loss: 0.6780
AUC: 0.8686

Epoch 25/80
 - 0s - loss: 0.9817 - val_loss: 0.6714
AUC: 0.8696

Epoch 26/80
 - 0s - loss: 0.9815 - val_loss: 0.5757
AUC: 0.8676

Epoch 27/80
 - 0s - loss: 0.9739 - val_loss: 0.5846
AUC: 0.8687

Epoch 28/80
 - 0s - loss: 0.9776 - val_loss: 0.5508
AUC: 0.8664

Epoch 29/80
 - 0s - loss: 0.9713 - val_loss: 0.6104
AUC: 0.8686

Epoch 30/80
 - 0s - loss: 0.9682 - val_loss: 0.5301
AUC: 0.8681

Epoch 31/80
 - 0s - loss: 0.9623 - val_loss: 0.5858
AUC: 0.8695

Epoch 32/80
 - 0s - loss: 0.9626 - val_loss: 0.5806
AUC: 0.8692

Epoch 33/80
 - 0s - loss: 0.9565 - val_loss: 0.5698
AUC: 0.8692

Epoch 34/80
 - 0s - loss: 0.9593 - val_loss: 0.6050
AUC: 0.8691

Epoch 35/80
 - 0s - loss: 0.9615 - val_loss: 0.6327
AUC: 0.8703

Epoch 36/80
 - 0s - loss: 0.9544 - val_loss: 0.5554
AUC: 0.8702

Epoch 37/80
 - 0s - loss: 0.9472 - val_loss: 0.6043
AUC: 0.8697

Epoch 38/80
 - 0s - loss: 0.9455 - val_loss: 0.5575
AUC: 0.8698

Epoch 39/80
 - 0s - loss: 0.9515 - val_loss: 0.5731
AUC: 0.8704

Epoch 40/80
 - 0s - loss: 0.9437 - val_loss: 0.6066
AUC: 0.8701

Epoch 41/80
 - 0s - loss: 0.9315 - val_loss: 0.5893
AUC: 0.8705

Epoch 42/80
 - 0s - loss: 0.9327 - val_loss: 0.5734
AUC: 0.8710

Epoch 43/80
 - 0s - loss: 0.9232 - val_loss: 0.6096
AUC: 0.8708

Epoch 44/80
 - 0s - loss: 0.9269 - val_loss: 0.5985
AUC: 0.8708

Epoch 45/80
 - 0s - loss: 0.9239 - val_loss: 0.5740
AUC: 0.8707

Epoch 46/80
 - 0s - loss: 0.9198 - val_loss: 0.5831
AUC: 0.8710

Epoch 47/80
 - 0s - loss: 0.9251 - val_loss: 0.5962
AUC: 0.8709

Epoch 48/80
 - 0s - loss: 0.9258 - val_loss: 0.5818
AUC: 0.8712

Epoch 49/80
 - 0s - loss: 0.9224 - val_loss: 0.5685
AUC: 0.8707

Epoch 50/80
 - 0s - loss: 0.9175 - val_loss: 0.6063
AUC: 0.8712

Epoch 51/80
 - 0s - loss: 0.9169 - val_loss: 0.5843
AUC: 0.8712

Epoch 52/80
 - 0s - loss: 0.9156 - val_loss: 0.5802
AUC: 0.8711

Epoch 53/80
 - 0s - loss: 0.9205 - val_loss: 0.5772
AUC: 0.8712

Epoch 54/80
 - 0s - loss: 0.9182 - val_loss: 0.5739
AUC: 0.8712

Epoch 55/80
 - 0s - loss: 0.9153 - val_loss: 0.5805
AUC: 0.8712

Epoch 56/80
 - 0s - loss: 0.9171 - val_loss: 0.5802
AUC: 0.8712

Epoch 57/80
 - 0s - loss: 0.9156 - val_loss: 0.5733
AUC: 0.8712

Epoch 58/80
 - 0s - loss: 0.9150 - val_loss: 0.5768
AUC: 0.8711

Epoch 59/80
 - 0s - loss: 0.9160 - val_loss: 0.5796
AUC: 0.8711

Epoch 60/80
 - 0s - loss: 0.9157 - val_loss: 0.5784
AUC: 0.8710

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9201 - val_loss: 0.5899
AUC: 0.8713

Epoch 2/30
 - 0s - loss: 0.9112 - val_loss: 0.5730
AUC: 0.8711

Epoch 3/30
 - 0s - loss: 0.9125 - val_loss: 0.5535
AUC: 0.8710

Epoch 4/30
 - 0s - loss: 0.9123 - val_loss: 0.5738
AUC: 0.8712

Epoch 5/30
 - 0s - loss: 0.9114 - val_loss: 0.5867
AUC: 0.8715

Epoch 6/30
 - 0s - loss: 0.9161 - val_loss: 0.5875
AUC: 0.8717

Epoch 7/30
 - 0s - loss: 0.9138 - val_loss: 0.6086
AUC: 0.8716

Epoch 8/30
 - 0s - loss: 0.9149 - val_loss: 0.5807
AUC: 0.8715

Epoch 9/30
 - 0s - loss: 0.9078 - val_loss: 0.5667
AUC: 0.8714

Epoch 10/30
 - 0s - loss: 0.9023 - val_loss: 0.5787
AUC: 0.8716

Epoch 11/30
 - 0s - loss: 0.9050 - val_loss: 0.5724
AUC: 0.8718

Epoch 12/30
 - 0s - loss: 0.9058 - val_loss: 0.5753
AUC: 0.8716

Epoch 13/30
 - 0s - loss: 0.9036 - val_loss: 0.5744
AUC: 0.8717

Epoch 14/30
 - 0s - loss: 0.9069 - val_loss: 0.5732
AUC: 0.8717

Epoch 15/30
 - 0s - loss: 0.9035 - val_loss: 0.5694
AUC: 0.8717

Epoch 16/30
 - 0s - loss: 0.8970 - val_loss: 0.5723
AUC: 0.8718

Epoch 17/30
 - 0s - loss: 0.8965 - val_loss: 0.5700
AUC: 0.8718

Epoch 18/30
 - 0s - loss: 0.8953 - val_loss: 0.5704
AUC: 0.8718

Epoch 19/30
 - 0s - loss: 0.8992 - val_loss: 0.5747
AUC: 0.8718

Epoch 20/30
 - 0s - loss: 0.8968 - val_loss: 0.5737
AUC: 0.8717

Epoch 21/30
 - 0s - loss: 0.9022 - val_loss: 0.5746
AUC: 0.8717

Epoch 22/30
 - 0s - loss: 0.8989 - val_loss: 0.5776
AUC: 0.8718

Epoch 23/30
 - 0s - loss: 0.9041 - val_loss: 0.5759
AUC: 0.8718

Epoch 24/30
 - 0s - loss: 0.8976 - val_loss: 0.5755
AUC: 0.8718

Epoch 25/30
 - 0s - loss: 0.8956 - val_loss: 0.5743
AUC: 0.8718

Epoch 26/30
 - 0s - loss: 0.8928 - val_loss: 0.5726
AUC: 0.8717

Epoch 27/30
 - 0s - loss: 0.8985 - val_loss: 0.5712
AUC: 0.8718

Epoch 28/30
 - 0s - loss: 0.8991 - val_loss: 0.5722
AUC: 0.8718

Epoch 29/30
 - 0s - loss: 0.8964 - val_loss: 0.5721
AUC: 0.8718

Epoch 30/30
 - 0s - loss: 0.8927 - val_loss: 0.5720
Using TensorFlow backend.
AUC: 0.8718

2019-03-08 05:10:31.091191: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:10:31.258757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:10:31.258801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:10:31.554807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:10:31.554859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:10:31.554867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:10:31.555119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6964
Epoch 2/80
 - 2s - loss: 0.1341
Epoch 3/80
 - 2s - loss: 0.0729
Epoch 4/80
 - 2s - loss: 0.0657
Epoch 5/80
 - 2s - loss: 0.0626
Epoch 6/80
 - 2s - loss: 0.0597
Epoch 7/80
 - 2s - loss: 0.0563
Epoch 8/80
 - 2s - loss: 0.0530
Epoch 9/80
 - 2s - loss: 0.0498
Epoch 10/80
 - 2s - loss: 0.0470
Epoch 11/80
 - 2s - loss: 0.0443
Epoch 12/80
 - 2s - loss: 0.0416
Epoch 13/80
 - 2s - loss: 0.0388
Epoch 14/80
 - 2s - loss: 0.0360
Epoch 15/80
 - 2s - loss: 0.0334
Epoch 16/80
 - 2s - loss: 0.0312
Epoch 17/80
 - 2s - loss: 0.0293
Epoch 18/80
 - 2s - loss: 0.0277
Epoch 19/80
 - 2s - loss: 0.0263
Epoch 20/80
 - 2s - loss: 0.0250
Epoch 21/80
 - 2s - loss: 0.0240
Epoch 22/80
 - 2s - loss: 0.0230
Epoch 23/80
 - 2s - loss: 0.0222
Epoch 24/80
 - 2s - loss: 0.0215
Epoch 25/80
 - 2s - loss: 0.0209
Epoch 26/80
 - 2s - loss: 0.0204
Epoch 27/80
 - 2s - loss: 0.0199
Epoch 28/80
 - 2s - loss: 0.0195
Epoch 29/80
 - 2s - loss: 0.0191
Epoch 30/80
 - 2s - loss: 0.0188
Epoch 31/80
 - 2s - loss: 0.0185
Epoch 32/80
 - 2s - loss: 0.0183
Epoch 33/80
 - 2s - loss: 0.0181
Epoch 34/80
 - 2s - loss: 0.0179
Epoch 35/80
 - 2s - loss: 0.0178
Epoch 36/80
 - 2s - loss: 0.0176
Epoch 37/80
 - 2s - loss: 0.0175
Epoch 38/80
 - 2s - loss: 0.0174
Epoch 39/80
 - 2s - loss: 0.0173
Epoch 40/80
 - 2s - loss: 0.0172
Epoch 41/80
 - 2s - loss: 0.0171
Epoch 42/80
 - 2s - loss: 0.0171
Epoch 43/80
 - 2s - loss: 0.0170
Epoch 44/80
 - 2s - loss: 0.0169
Epoch 45/80
 - 2s - loss: 0.0169
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0168
Epoch 48/80
 - 2s - loss: 0.0167
Epoch 49/80
 - 2s - loss: 0.0167
Epoch 50/80
 - 2s - loss: 0.0167
Epoch 51/80
 - 2s - loss: 0.0166
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:12:13.559971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:12:13.725945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:12:13.725982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:12:14.024645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:12:14.024696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:12:14.024705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:12:14.024957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.4091
Epoch 2/80
 - 2s - loss: 0.3546
Epoch 3/80
 - 2s - loss: 0.2923
Epoch 4/80
 - 2s - loss: 0.2681
Epoch 5/80
 - 2s - loss: 0.2511
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:12:39.595737: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:12:39.758833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:12:39.758875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:12:40.059933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:12:40.059983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:12:40.059992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:12:40.060248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3878
Epoch 2/80
 - 2s - loss: 0.3540
Epoch 3/80
 - 2s - loss: 0.3024
Epoch 4/80
 - 2s - loss: 0.2790
Epoch 5/80
 - 2s - loss: 0.2556
Epoch 6/80
 - 2s - loss: 0.2361
Epoch 7/80
 - 2s - loss: 0.2202
Epoch 8/80
 - 2s - loss: 0.2068
Epoch 9/80
 - 2s - loss: 0.1955
Epoch 10/80
 - 2s - loss: 0.1855
Epoch 11/80
 - 2s - loss: 0.1767
Epoch 12/80
 - 2s - loss: 0.1688
Epoch 13/80
 - 2s - loss: 0.1618
Epoch 14/80
 - 2s - loss: 0.1554
Epoch 15/80
 - 2s - loss: 0.1497
Epoch 16/80
 - 2s - loss: 0.1447
Epoch 17/80
 - 2s - loss: 0.1403
Epoch 18/80
 - 2s - loss: 0.1366
Epoch 19/80
 - 2s - loss: 0.1335
Epoch 20/80
 - 2s - loss: 0.1309
Epoch 21/80
 - 2s - loss: 0.1286
Epoch 22/80
 - 2s - loss: 0.1268
Epoch 23/80
 - 2s - loss: 0.1252
Epoch 24/80
 - 2s - loss: 0.1238
Epoch 25/80
 - 2s - loss: 0.1226
Epoch 26/80
 - 2s - loss: 0.1217
Epoch 27/80
 - 2s - loss: 0.1208
Epoch 28/80
 - 2s - loss: 0.1201
Epoch 29/80
 - 2s - loss: 0.1196
Epoch 30/80
 - 2s - loss: 0.1190
Epoch 31/80
 - 2s - loss: 0.1186
Epoch 32/80
 - 2s - loss: 0.1182
Epoch 33/80
 - 2s - loss: 0.1178
Epoch 34/80
 - 2s - loss: 0.1176
Epoch 35/80
 - 2s - loss: 0.1173
Epoch 36/80
 - 2s - loss: 0.1170
Epoch 37/80
 - 2s - loss: 0.1168
Epoch 38/80
 - 2s - loss: 0.1166
Epoch 39/80
 - 2s - loss: 0.1165
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:14:03.014370: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:14:03.177389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:14:03.177434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:14:03.476761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:14:03.476794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:14:03.476804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:14:03.477055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3958
Epoch 2/80
 - 2s - loss: 0.3538
Epoch 3/80
 - 2s - loss: 0.3091
Epoch 4/80
 - 2s - loss: 0.2948
Epoch 5/80
 - 2s - loss: 0.2761
Epoch 6/80
 - 2s - loss: 0.2526
Epoch 7/80
 - 2s - loss: 0.2310
Epoch 8/80
 - 2s - loss: 0.2142
Epoch 9/80
 - 2s - loss: 0.2003
Epoch 10/80
 - 2s - loss: 0.1878
Epoch 11/80
 - 2s - loss: 0.1765
Epoch 12/80
 - 2s - loss: 0.1667
Epoch 13/80
 - 2s - loss: 0.1586
Epoch 14/80
 - 2s - loss: 0.1519
Epoch 15/80
 - 2s - loss: 0.1464
Epoch 16/80
 - 2s - loss: 0.1418
Epoch 17/80
 - 2s - loss: 0.1380
Epoch 18/80
 - 2s - loss: 0.1349
Epoch 19/80
 - 2s - loss: 0.1322
Epoch 20/80
 - 2s - loss: 0.1299
Epoch 21/80
 - 2s - loss: 0.1280
Epoch 22/80
 - 2s - loss: 0.1263
Epoch 23/80
 - 2s - loss: 0.1248
Epoch 24/80
 - 2s - loss: 0.1234
Epoch 25/80
 - 2s - loss: 0.1223
Epoch 26/80
 - 2s - loss: 0.1213
Epoch 27/80
 - 2s - loss: 0.1205
Epoch 28/80
 - 2s - loss: 0.1198
Epoch 29/80
 - 2s - loss: 0.1192
Epoch 30/80
 - 2s - loss: 0.1188
Epoch 31/80
 - 2s - loss: 0.1183
Epoch 32/80
 - 2s - loss: 0.1179
Epoch 33/80
 - 2s - loss: 0.1176
Epoch 34/80
 - 2s - loss: 0.1173
Epoch 35/80
 - 2s - loss: 0.1170
Epoch 36/80
 - 2s - loss: 0.1168
Epoch 37/80
 - 2s - loss: 0.1166
Epoch 38/80
 - 2s - loss: 0.1164
Epoch 39/80
 - 2s - loss: 0.1162
Epoch 40/80
 - 2s - loss: 0.1161
Epoch 41/80
 - 2s - loss: 0.1159
Epoch 42/80
 - 2s - loss: 0.1158
Epoch 43/80
 - 2s - loss: 0.1157
Epoch 44/80
 - 2s - loss: 0.1155
Epoch 45/80
 - 2s - loss: 0.1155
Epoch 46/80
 - 2s - loss: 0.1154
Epoch 47/80
 - 2s - loss: 0.1153
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:15:39.529640: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:15:39.696849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:15:39.696893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:15:39.991213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:15:39.991262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:15:39.991270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:15:39.991524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3559
Epoch 2/80
 - 2s - loss: 0.3510
Epoch 3/80
 - 2s - loss: 0.3075
Epoch 4/80
 - 2s - loss: 0.2930
Epoch 5/80
 - 2s - loss: 0.2759
Epoch 6/80
 - 2s - loss: 0.2557
Epoch 7/80
 - 2s - loss: 0.2339
Epoch 8/80
 - 2s - loss: 0.2149
Epoch 9/80
 - 2s - loss: 0.2003
Epoch 10/80
 - 2s - loss: 0.1884
Epoch 11/80
 - 2s - loss: 0.1782
Epoch 12/80
 - 2s - loss: 0.1693
Epoch 13/80
 - 2s - loss: 0.1615
Epoch 14/80
 - 2s - loss: 0.1546
Epoch 15/80
 - 2s - loss: 0.1486
Epoch 16/80
 - 2s - loss: 0.1434
Epoch 17/80
 - 2s - loss: 0.1391
Epoch 18/80
 - 2s - loss: 0.1356
Epoch 19/80
 - 2s - loss: 0.1326
Epoch 20/80
 - 2s - loss: 0.1301
Epoch 21/80
 - 2s - loss: 0.1281
Epoch 22/80
 - 2s - loss: 0.1263
Epoch 23/80
 - 2s - loss: 0.1248
Epoch 24/80
 - 2s - loss: 0.1235
Epoch 25/80
 - 2s - loss: 0.1225
Epoch 26/80
 - 2s - loss: 0.1215
Epoch 27/80
 - 2s - loss: 0.1208
Epoch 28/80
 - 2s - loss: 0.1200
Epoch 29/80
 - 2s - loss: 0.1194
Epoch 30/80
 - 2s - loss: 0.1189
Epoch 31/80
 - 2s - loss: 0.1185
Epoch 32/80
 - 2s - loss: 0.1181
Epoch 33/80
 - 2s - loss: 0.1177
Epoch 34/80
 - 2s - loss: 0.1174
Epoch 35/80
 - 2s - loss: 0.1172
Epoch 36/80
 - 2s - loss: 0.1169
Epoch 37/80
 - 2s - loss: 0.1167
Epoch 38/80
 - 2s - loss: 0.1165
Epoch 39/80
 - 2s - loss: 0.1163
Epoch 40/80
 - 2s - loss: 0.1161
Epoch 41/80
 - 2s - loss: 0.1160
Epoch 42/80
 - 2s - loss: 0.1158
Epoch 43/80
 - 2s - loss: 0.1157
Epoch 44/80
 - 2s - loss: 0.1156
Epoch 45/80
 - 2s - loss: 0.1155
Epoch 46/80
 - 2s - loss: 0.1154
Epoch 47/80
 - 2s - loss: 0.1153
Epoch 48/80
 - 2s - loss: 0.1152
Epoch 49/80
 - 2s - loss: 0.1151
Epoch 50/80
 - 2s - loss: 0.1150
Epoch 51/80
 - 2s - loss: 0.1150
Epoch 52/80
 - 2s - loss: 0.1149
Epoch 53/80
 - 2s - loss: 0.1148
Epoch 54/80
 - 2s - loss: 0.1148
Epoch 55/80
 - 2s - loss: 0.1148
Epoch 56/80
 - 2s - loss: 0.1147
Epoch 57/80
 - 2s - loss: 0.1147
Epoch 58/80
 - 2s - loss: 0.1146
Epoch 59/80
 - 2s - loss: 0.1146
Epoch 60/80
 - 2s - loss: 0.1145
Epoch 61/80
 - 2s - loss: 0.1145
Epoch 62/80
 - 2s - loss: 0.1144
Epoch 63/80
 - 2s - loss: 0.1144
Epoch 64/80
 - 2s - loss: 0.1144
Epoch 65/80
 - 2s - loss: 0.1143
Epoch 66/80
 - 2s - loss: 0.1121
Epoch 67/80
 - 2s - loss: 0.1119
Epoch 68/80
 - 2s - loss: 0.1118
Epoch 69/80
 - 2s - loss: 0.1118
Epoch 70/80
 - 2s - loss: 0.1118
Epoch 71/80
 - 2s - loss: 0.1112
Epoch 72/80
 - 2s - loss: 0.1112
Epoch 73/80
 - 2s - loss: 0.1112
Epoch 74/80
 - 2s - loss: 0.1112
Epoch 75/80
 - 2s - loss: 0.1111
Epoch 76/80
 - 2s - loss: 0.1111
Epoch 77/80
 - 2s - loss: 0.1111
Epoch 78/80
 - 2s - loss: 0.1111
Epoch 79/80
 - 2s - loss: 0.1111
Epoch 80/80
 - 2s - loss: 0.1111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.2522 - val_loss: 1.3808
AUC: 0.8051

Epoch 2/80
 - 0s - loss: 1.9275 - val_loss: 0.7869
AUC: 0.8396

Epoch 3/80
 - 0s - loss: 1.4595 - val_loss: 0.9000
AUC: 0.8513

Epoch 4/80
 - 0s - loss: 1.2136 - val_loss: 0.6705
AUC: 0.8508

Epoch 5/80
 - 0s - loss: 1.1369 - val_loss: 0.7692
AUC: 0.8573

Epoch 6/80
 - 0s - loss: 1.1030 - val_loss: 0.6177
AUC: 0.8574

Epoch 7/80
 - 0s - loss: 1.0779 - val_loss: 0.7279
AUC: 0.8602

Epoch 8/80
 - 0s - loss: 1.0606 - val_loss: 0.7100
AUC: 0.8607

Epoch 9/80
 - 0s - loss: 1.0452 - val_loss: 0.6351
AUC: 0.8612

Epoch 10/80
 - 0s - loss: 1.0369 - val_loss: 0.6362
AUC: 0.8612

Epoch 11/80
 - 0s - loss: 1.0388 - val_loss: 0.6422
AUC: 0.8629

Epoch 12/80
 - 0s - loss: 1.0180 - val_loss: 0.6106
AUC: 0.8632

Epoch 13/80
 - 0s - loss: 1.0163 - val_loss: 0.7010
AUC: 0.8646

Epoch 14/80
 - 0s - loss: 1.0084 - val_loss: 0.6846
AUC: 0.8637

Epoch 15/80
 - 0s - loss: 1.0045 - val_loss: 0.6169
AUC: 0.8631

Epoch 16/80
 - 0s - loss: 0.9992 - val_loss: 0.6004
AUC: 0.8629

Epoch 17/80
 - 0s - loss: 1.0004 - val_loss: 0.6234
AUC: 0.8643

Epoch 18/80
 - 0s - loss: 0.9868 - val_loss: 0.6428
AUC: 0.8661

Epoch 19/80
 - 0s - loss: 0.9870 - val_loss: 0.6359
AUC: 0.8648

Epoch 20/80
 - 0s - loss: 0.9881 - val_loss: 0.6701
AUC: 0.8651

Epoch 21/80
 - 0s - loss: 0.9830 - val_loss: 0.6226
AUC: 0.8639

Epoch 22/80
 - 0s - loss: 0.9832 - val_loss: 0.6294
AUC: 0.8663

Epoch 23/80
 - 0s - loss: 0.9729 - val_loss: 0.6514
AUC: 0.8669

Epoch 24/80
 - 0s - loss: 0.9745 - val_loss: 0.5912
AUC: 0.8652

Epoch 25/80
 - 0s - loss: 0.9676 - val_loss: 0.6258
AUC: 0.8665

Epoch 26/80
 - 0s - loss: 0.9645 - val_loss: 0.5988
AUC: 0.8662

Epoch 27/80
 - 0s - loss: 0.9636 - val_loss: 0.6249
AUC: 0.8670

Epoch 28/80
 - 0s - loss: 0.9643 - val_loss: 0.5272
AUC: 0.8658

Epoch 29/80
 - 0s - loss: 0.9578 - val_loss: 0.5473
AUC: 0.8661

Epoch 30/80
 - 0s - loss: 0.9526 - val_loss: 0.5689
AUC: 0.8677

Epoch 31/80
 - 0s - loss: 0.9476 - val_loss: 0.7283
AUC: 0.8673

Epoch 32/80
 - 0s - loss: 0.9453 - val_loss: 0.5624
AUC: 0.8665

Epoch 33/80
 - 0s - loss: 0.9425 - val_loss: 0.5904
AUC: 0.8677

Epoch 34/80
 - 0s - loss: 0.9381 - val_loss: 0.5797
AUC: 0.8676

Epoch 35/80
 - 0s - loss: 0.9427 - val_loss: 0.6462
AUC: 0.8682

Epoch 36/80
 - 0s - loss: 0.9416 - val_loss: 0.5736
AUC: 0.8658

Epoch 37/80
 - 0s - loss: 0.9345 - val_loss: 0.6055
AUC: 0.8685

Epoch 38/80
 - 0s - loss: 0.9347 - val_loss: 0.6511
AUC: 0.8686

Epoch 39/80
 - 0s - loss: 0.9236 - val_loss: 0.5924
AUC: 0.8684

Epoch 40/80
 - 0s - loss: 0.9108 - val_loss: 0.6285
AUC: 0.8686

Epoch 41/80
 - 0s - loss: 0.9130 - val_loss: 0.6071
AUC: 0.8684

Epoch 42/80
 - 0s - loss: 0.9095 - val_loss: 0.5956
AUC: 0.8679

Epoch 43/80
 - 0s - loss: 0.9089 - val_loss: 0.5773
AUC: 0.8680

Epoch 44/80
 - 0s - loss: 0.9058 - val_loss: 0.5799
AUC: 0.8679

Epoch 45/80
 - 0s - loss: 0.9027 - val_loss: 0.5933
AUC: 0.8678

Epoch 46/80
 - 0s - loss: 0.9082 - val_loss: 0.5754
AUC: 0.8676

Epoch 47/80
 - 0s - loss: 0.9034 - val_loss: 0.5793
AUC: 0.8680

Epoch 48/80
 - 0s - loss: 0.9011 - val_loss: 0.5850
AUC: 0.8677

Epoch 49/80
 - 0s - loss: 0.8995 - val_loss: 0.5801
AUC: 0.8679

Epoch 50/80
 - 0s - loss: 0.8985 - val_loss: 0.5884
AUC: 0.8679

Epoch 51/80
 - 0s - loss: 0.9002 - val_loss: 0.5739
AUC: 0.8679

Epoch 52/80
 - 0s - loss: 0.9021 - val_loss: 0.5863
AUC: 0.8679

Epoch 53/80
 - 0s - loss: 0.8943 - val_loss: 0.5968
AUC: 0.8679

Epoch 54/80
 - 0s - loss: 0.9016 - val_loss: 0.5854
AUC: 0.8678

Epoch 55/80
 - 0s - loss: 0.8940 - val_loss: 0.5782
AUC: 0.8678

Epoch 56/80
 - 0s - loss: 0.8972 - val_loss: 0.5872
AUC: 0.8678

Epoch 57/80
 - 0s - loss: 0.9033 - val_loss: 0.5955
AUC: 0.8680

Epoch 58/80
 - 0s - loss: 0.9000 - val_loss: 0.5876
AUC: 0.8679

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9184 - val_loss: 0.5703
AUC: 0.8679

Epoch 2/30
 - 0s - loss: 0.9080 - val_loss: 0.5796
AUC: 0.8681

Epoch 3/30
 - 0s - loss: 0.9090 - val_loss: 0.5977
AUC: 0.8683

Epoch 4/30
 - 0s - loss: 0.9079 - val_loss: 0.5995
AUC: 0.8682

Epoch 5/30
 - 0s - loss: 0.9070 - val_loss: 0.5911
AUC: 0.8681

Epoch 6/30
 - 0s - loss: 0.9076 - val_loss: 0.5630
AUC: 0.8678

Epoch 7/30
 - 0s - loss: 0.9008 - val_loss: 0.5813
AUC: 0.8683

Epoch 8/30
 - 0s - loss: 0.8987 - val_loss: 0.5853
AUC: 0.8684

Epoch 9/30
 - 0s - loss: 0.8984 - val_loss: 0.5893
AUC: 0.8684

Epoch 10/30
 - 0s - loss: 0.8921 - val_loss: 0.5607
AUC: 0.8679

Epoch 11/30
 - 0s - loss: 0.8981 - val_loss: 0.5942
AUC: 0.8684

Epoch 12/30
 - 0s - loss: 0.8904 - val_loss: 0.5960
AUC: 0.8685

Epoch 13/30
 - 0s - loss: 0.8928 - val_loss: 0.5703
AUC: 0.8683

Epoch 14/30
 - 0s - loss: 0.8934 - val_loss: 0.5928
AUC: 0.8684

Epoch 15/30
 - 0s - loss: 0.8918 - val_loss: 0.5645
AUC: 0.8681

Epoch 16/30
 - 0s - loss: 0.8931 - val_loss: 0.5988
AUC: 0.8684

Epoch 17/30
 - 0s - loss: 0.8858 - val_loss: 0.5863
AUC: 0.8682

Epoch 18/30
 - 0s - loss: 0.8865 - val_loss: 0.6054
AUC: 0.8682

Epoch 19/30
 - 0s - loss: 0.8861 - val_loss: 0.5972
AUC: 0.8685

Epoch 20/30
 - 0s - loss: 0.8832 - val_loss: 0.5591
AUC: 0.8679

Epoch 21/30
 - 0s - loss: 0.8824 - val_loss: 0.5724
AUC: 0.8681

Epoch 22/30
 - 0s - loss: 0.8784 - val_loss: 0.5632
AUC: 0.8681

Epoch 23/30
 - 0s - loss: 0.8794 - val_loss: 0.5901
AUC: 0.8684

Epoch 24/30
 - 0s - loss: 0.8783 - val_loss: 0.5510
AUC: 0.8677

Epoch 25/30
 - 0s - loss: 0.8746 - val_loss: 0.5592
AUC: 0.8684

Epoch 26/30
 - 0s - loss: 0.8774 - val_loss: 0.5601
AUC: 0.8682

Epoch 27/30
 - 0s - loss: 0.8770 - val_loss: 0.5593
AUC: 0.8682

Epoch 28/30
 - 0s - loss: 0.8688 - val_loss: 0.5633
AUC: 0.8681

Epoch 29/30
 - 0s - loss: 0.8765 - val_loss: 0.5824
AUC: 0.8684

Epoch 30/30
 - 0s - loss: 0.8714 - val_loss: 0.5752
Using TensorFlow backend.
AUC: 0.8682

2019-03-08 05:19:09.018477: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:19:09.182061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:19:09.182106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:19:09.475894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:19:09.475956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:19:09.475965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:19:09.476243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1275
Epoch 2/80
 - 2s - loss: 0.2138
Epoch 3/80
 - 2s - loss: 0.1737
Epoch 4/80
 - 2s - loss: 0.1665
Epoch 5/80
 - 2s - loss: 0.1600
Epoch 6/80
 - 2s - loss: 0.1517
Epoch 7/80
 - 2s - loss: 0.1419
Epoch 8/80
 - 2s - loss: 0.1315
Epoch 9/80
 - 2s - loss: 0.1214
Epoch 10/80
 - 2s - loss: 0.1124
Epoch 11/80
 - 2s - loss: 0.1048
Epoch 12/80
 - 2s - loss: 0.0981
Epoch 13/80
 - 2s - loss: 0.0918
Epoch 14/80
 - 2s - loss: 0.0860
Epoch 15/80
 - 2s - loss: 0.0810
Epoch 16/80
 - 2s - loss: 0.0767
Epoch 17/80
 - 2s - loss: 0.0730
Epoch 18/80
 - 2s - loss: 0.0699
Epoch 19/80
 - 2s - loss: 0.0672
Epoch 20/80
 - 2s - loss: 0.0648
Epoch 21/80
 - 2s - loss: 0.0628
Epoch 22/80
 - 2s - loss: 0.0611
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:20:02.066035: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:20:02.230037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:20:02.230081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:20:02.525749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:20:02.525831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:20:02.525852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:20:02.526198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1322
Epoch 2/80
 - 2s - loss: 0.2134
Epoch 3/80
 - 2s - loss: 0.1739
Epoch 4/80
 - 2s - loss: 0.1679
Epoch 5/80
 - 2s - loss: 0.1623
Epoch 6/80
 - 2s - loss: 0.1546
Epoch 7/80
 - 2s - loss: 0.1441
Epoch 8/80
 - 2s - loss: 0.1324
Epoch 9/80
 - 2s - loss: 0.1216
Epoch 10/80
 - 2s - loss: 0.1120
Epoch 11/80
 - 2s - loss: 0.1036
Epoch 12/80
 - 2s - loss: 0.0962
Epoch 13/80
 - 2s - loss: 0.0899
Epoch 14/80
 - 2s - loss: 0.0846
Epoch 15/80
 - 2s - loss: 0.0800
Epoch 16/80
 - 2s - loss: 0.0760
Epoch 17/80
 - 2s - loss: 0.0725
Epoch 18/80
 - 2s - loss: 0.0696
Epoch 19/80
 - 2s - loss: 0.0670
Epoch 20/80
 - 2s - loss: 0.0649
Epoch 21/80
 - 2s - loss: 0.0630
Epoch 22/80
 - 2s - loss: 0.0614
Epoch 23/80
 - 2s - loss: 0.0601
Epoch 24/80
 - 2s - loss: 0.0589
Epoch 25/80
 - 2s - loss: 0.0579
Epoch 26/80
 - 2s - loss: 0.0570
Epoch 27/80
 - 2s - loss: 0.0563
Epoch 28/80
 - 2s - loss: 0.0556
Epoch 29/80
 - 2s - loss: 0.0551
Epoch 30/80
 - 2s - loss: 0.0546
Epoch 31/80
 - 2s - loss: 0.0542
Epoch 32/80
 - 2s - loss: 0.0538
Epoch 33/80
 - 2s - loss: 0.0535
Epoch 34/80
 - 2s - loss: 0.0532
Epoch 35/80
 - 2s - loss: 0.0529
Epoch 36/80
 - 2s - loss: 0.0527
Epoch 37/80
 - 2s - loss: 0.0525
Epoch 38/80
 - 2s - loss: 0.0523
Epoch 39/80
 - 2s - loss: 0.0521
Epoch 40/80
 - 2s - loss: 0.0520
Epoch 41/80
 - 2s - loss: 0.0518
Epoch 42/80
 - 2s - loss: 0.0517
Epoch 43/80
 - 2s - loss: 0.0516
Epoch 44/80
 - 2s - loss: 0.0515
Epoch 45/80
 - 2s - loss: 0.0514
Epoch 46/80
 - 2s - loss: 0.0513
Epoch 47/80
 - 2s - loss: 0.0512
Epoch 48/80
 - 2s - loss: 0.0511
Epoch 49/80
 - 2s - loss: 0.0510
Epoch 50/80
 - 2s - loss: 0.0510
Epoch 51/80
 - 2s - loss: 0.0509
Epoch 52/80
 - 2s - loss: 0.0508
Epoch 53/80
 - 2s - loss: 0.0508
Epoch 54/80
 - 2s - loss: 0.0507
Epoch 55/80
 - 2s - loss: 0.0507
Epoch 56/80
 - 2s - loss: 0.0506
Epoch 57/80
 - 2s - loss: 0.0506
Epoch 58/80
 - 2s - loss: 0.0506
Epoch 59/80
 - 2s - loss: 0.0505
Epoch 60/80
 - 2s - loss: 0.0505
Epoch 61/80
 - 2s - loss: 0.0505
Epoch 62/80
 - 2s - loss: 0.0504
Epoch 63/80
 - 2s - loss: 0.0504
Epoch 64/80
 - 2s - loss: 0.0504
Epoch 65/80
 - 2s - loss: 0.0503
Epoch 66/80
 - 2s - loss: 0.0503
Epoch 67/80
 - 2s - loss: 0.0503
Epoch 68/80
 - 2s - loss: 0.0492
Epoch 69/80
 - 2s - loss: 0.0491
Epoch 70/80
 - 2s - loss: 0.0490
Epoch 71/80
 - 2s - loss: 0.0490
Epoch 72/80
 - 2s - loss: 0.0490
Epoch 73/80
 - 2s - loss: 0.0487
Epoch 74/80
 - 2s - loss: 0.0487
Epoch 75/80
 - 2s - loss: 0.0487
Epoch 76/80
 - 2s - loss: 0.0487
Epoch 77/80
 - 2s - loss: 0.0487
Epoch 78/80
 - 2s - loss: 0.0487
Epoch 79/80
 - 2s - loss: 0.0487
Epoch 80/80
 - 2s - loss: 0.0487
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.6225 - val_loss: 0.8518
AUC: 0.8378

Epoch 2/80
 - 0s - loss: 1.5554 - val_loss: 0.6861
AUC: 0.8539

Epoch 3/80
 - 0s - loss: 1.2293 - val_loss: 0.7011
AUC: 0.8613

Epoch 4/80
 - 0s - loss: 1.1256 - val_loss: 0.6425
AUC: 0.8616

Epoch 5/80
 - 0s - loss: 1.1053 - val_loss: 0.6044
AUC: 0.8665

Epoch 6/80
 - 0s - loss: 1.0782 - val_loss: 0.6970
AUC: 0.8691

Epoch 7/80
 - 0s - loss: 1.0613 - val_loss: 0.6371
AUC: 0.8705

Epoch 8/80
 - 0s - loss: 1.0493 - val_loss: 0.6049
AUC: 0.8700

Epoch 9/80
 - 0s - loss: 1.0378 - val_loss: 0.6907
AUC: 0.8723

Epoch 10/80
 - 0s - loss: 1.0404 - val_loss: 0.6338
AUC: 0.8728

Epoch 11/80
 - 0s - loss: 1.0260 - val_loss: 0.6265
AUC: 0.8703

Epoch 12/80
 - 0s - loss: 1.0269 - val_loss: 0.6413
AUC: 0.8748

Epoch 13/80
 - 0s - loss: 1.0105 - val_loss: 0.6023
AUC: 0.8717

Epoch 14/80
 - 0s - loss: 1.0121 - val_loss: 0.7212
AUC: 0.8754

Epoch 15/80
 - 0s - loss: 1.0011 - val_loss: 0.5575
AUC: 0.8735

Epoch 16/80
 - 0s - loss: 1.0034 - val_loss: 0.6014
AUC: 0.8764

Epoch 17/80
 - 0s - loss: 0.9961 - val_loss: 0.5678
AUC: 0.8746

Epoch 18/80
 - 0s - loss: 0.9963 - val_loss: 0.5989
AUC: 0.8747

Epoch 19/80
 - 0s - loss: 0.9855 - val_loss: 0.6754
AUC: 0.8775

Epoch 20/80
 - 0s - loss: 0.9898 - val_loss: 0.5990
AUC: 0.8755

Epoch 21/80
 - 0s - loss: 0.9801 - val_loss: 0.5918
AUC: 0.8773

Epoch 22/80
 - 0s - loss: 0.9742 - val_loss: 0.6261
AUC: 0.8775

Epoch 23/80
 - 0s - loss: 0.9746 - val_loss: 0.5402
AUC: 0.8767

Epoch 24/80
 - 0s - loss: 0.9719 - val_loss: 0.5379
AUC: 0.8763

Epoch 25/80
 - 0s - loss: 0.9683 - val_loss: 0.6671
AUC: 0.8784

Epoch 26/80
 - 0s - loss: 0.9648 - val_loss: 0.5403
AUC: 0.8780

Epoch 27/80
 - 0s - loss: 0.9586 - val_loss: 0.6128
AUC: 0.8781

Epoch 28/80
 - 0s - loss: 0.9624 - val_loss: 0.6588
AUC: 0.8784

Epoch 29/80
 - 0s - loss: 0.9590 - val_loss: 0.5129
AUC: 0.8768

Epoch 30/80
 - 0s - loss: 0.9536 - val_loss: 0.5873
AUC: 0.8782

Epoch 31/80
 - 0s - loss: 0.9497 - val_loss: 0.4941
AUC: 0.8774

Epoch 32/80
 - 0s - loss: 0.9468 - val_loss: 0.6520
AUC: 0.8781

Epoch 33/80
 - 0s - loss: 0.9481 - val_loss: 0.5738
AUC: 0.8787

Epoch 34/80
 - 0s - loss: 0.9372 - val_loss: 0.5205
AUC: 0.8791

Epoch 35/80
 - 0s - loss: 0.9305 - val_loss: 0.6279
AUC: 0.8804

Epoch 36/80
 - 0s - loss: 0.9358 - val_loss: 0.5523
AUC: 0.8791

Epoch 37/80
 - 0s - loss: 0.9332 - val_loss: 0.5266
AUC: 0.8762

Epoch 38/80
 - 0s - loss: 0.9303 - val_loss: 0.6018
AUC: 0.8791

Epoch 39/80
 - 0s - loss: 0.9243 - val_loss: 0.4970
AUC: 0.8769

Epoch 40/80
 - 0s - loss: 0.9273 - val_loss: 0.6326
AUC: 0.8799

Epoch 41/80
 - 0s - loss: 0.9188 - val_loss: 0.5688
AUC: 0.8770

Epoch 42/80
 - 0s - loss: 0.9039 - val_loss: 0.5768
AUC: 0.8791

Epoch 43/80
 - 0s - loss: 0.9045 - val_loss: 0.5447
AUC: 0.8791

Epoch 44/80
 - 0s - loss: 0.9002 - val_loss: 0.5604
AUC: 0.8794

Epoch 45/80
 - 0s - loss: 0.9003 - val_loss: 0.5942
AUC: 0.8798

Epoch 46/80
 - 0s - loss: 0.8953 - val_loss: 0.5642
AUC: 0.8794

Epoch 47/80
 - 0s - loss: 0.8932 - val_loss: 0.5516
AUC: 0.8790

Epoch 48/80
 - 0s - loss: 0.8963 - val_loss: 0.5403
AUC: 0.8788

Epoch 49/80
 - 0s - loss: 0.8946 - val_loss: 0.6031
AUC: 0.8796

Epoch 50/80
 - 0s - loss: 0.8880 - val_loss: 0.5429
AUC: 0.8787

Epoch 51/80
 - 0s - loss: 0.8915 - val_loss: 0.5983
AUC: 0.8794

Epoch 52/80
 - 0s - loss: 0.8942 - val_loss: 0.5677
AUC: 0.8792

Epoch 53/80
 - 0s - loss: 0.8893 - val_loss: 0.5716
AUC: 0.8792

Epoch 54/80
 - 0s - loss: 0.8864 - val_loss: 0.5687
AUC: 0.8791

Epoch 55/80
 - 0s - loss: 0.8850 - val_loss: 0.5569
AUC: 0.8790

Epoch 56/80
 - 0s - loss: 0.8870 - val_loss: 0.5744
AUC: 0.8792

Epoch 57/80
 - 0s - loss: 0.8859 - val_loss: 0.5507
AUC: 0.8789

Epoch 58/80
 - 0s - loss: 0.8894 - val_loss: 0.5648
AUC: 0.8791

Epoch 59/80
 - 0s - loss: 0.8834 - val_loss: 0.5655
AUC: 0.8791

Epoch 60/80
 - 0s - loss: 0.8824 - val_loss: 0.5596
AUC: 0.8791

Epoch 61/80
 - 0s - loss: 0.8857 - val_loss: 0.5615
AUC: 0.8791

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9168 - val_loss: 0.5872
AUC: 0.8801

Epoch 2/30
 - 0s - loss: 0.9204 - val_loss: 0.5495
AUC: 0.8797

Epoch 3/30
 - 0s - loss: 0.9146 - val_loss: 0.5730
AUC: 0.8796

Epoch 4/30
 - 0s - loss: 0.9121 - val_loss: 0.5843
AUC: 0.8799

Epoch 5/30
 - 0s - loss: 0.9102 - val_loss: 0.5658
AUC: 0.8799

Epoch 6/30
 - 0s - loss: 0.9062 - val_loss: 0.5722
AUC: 0.8796

Epoch 7/30
 - 0s - loss: 0.9082 - val_loss: 0.5579
AUC: 0.8796

Epoch 8/30
 - 0s - loss: 0.9068 - val_loss: 0.5597
AUC: 0.8796

Epoch 9/30
 - 0s - loss: 0.9041 - val_loss: 0.5753
AUC: 0.8799

Epoch 10/30
 - 0s - loss: 0.9026 - val_loss: 0.5738
AUC: 0.8798

Epoch 11/30
 - 0s - loss: 0.8992 - val_loss: 0.5637
AUC: 0.8795

Epoch 12/30
 - 0s - loss: 0.9003 - val_loss: 0.5696
AUC: 0.8795

Epoch 13/30
 - 0s - loss: 0.8964 - val_loss: 0.5688
AUC: 0.8797

Epoch 14/30
 - 0s - loss: 0.8953 - val_loss: 0.5648
AUC: 0.8797

Epoch 15/30
 - 0s - loss: 0.9003 - val_loss: 0.5710
AUC: 0.8798

Epoch 16/30
 - 0s - loss: 0.8959 - val_loss: 0.5644
AUC: 0.8797

Epoch 17/30
 - 0s - loss: 0.8986 - val_loss: 0.5617
AUC: 0.8797

Epoch 18/30
 - 0s - loss: 0.8962 - val_loss: 0.5662
AUC: 0.8798

Epoch 19/30
 - 0s - loss: 0.8937 - val_loss: 0.5572
AUC: 0.8797

Epoch 20/30
 - 0s - loss: 0.8936 - val_loss: 0.5642
AUC: 0.8799

Epoch 21/30
 - 0s - loss: 0.8952 - val_loss: 0.5730
AUC: 0.8799

Epoch 22/30
 - 0s - loss: 0.8974 - val_loss: 0.5715
AUC: 0.8799

Epoch 23/30
 - 0s - loss: 0.8954 - val_loss: 0.5700
AUC: 0.8799

Epoch 24/30
 - 0s - loss: 0.8919 - val_loss: 0.5658
AUC: 0.8798

Epoch 25/30
 - 0s - loss: 0.8987 - val_loss: 0.5664
AUC: 0.8798

Epoch 26/30
 - 0s - loss: 0.8963 - val_loss: 0.5655
AUC: 0.8798

Epoch 27/30
 - 0s - loss: 0.8973 - val_loss: 0.5669
AUC: 0.8798

Epoch 28/30
 - 0s - loss: 0.8912 - val_loss: 0.5661
AUC: 0.8798

Epoch 29/30
 - 0s - loss: 0.8975 - val_loss: 0.5666
AUC: 0.8798

Epoch 30/30
 - 0s - loss: 0.8915 - val_loss: 0.5653
Using TensorFlow backend.
AUC: 0.8798

2019-03-08 05:23:34.005262: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:23:34.178604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:23:34.178647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:23:34.477697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:23:34.477733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:23:34.477742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:23:34.478007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1381
Epoch 2/80
 - 2s - loss: 0.2151
Epoch 3/80
 - 2s - loss: 0.1737
Epoch 4/80
 - 2s - loss: 0.1669
Epoch 5/80
 - 2s - loss: 0.1603
Epoch 6/80
 - 2s - loss: 0.1517
Epoch 7/80
 - 2s - loss: 0.1420
Epoch 8/80
 - 2s - loss: 0.1320
Epoch 9/80
 - 2s - loss: 0.1217
Epoch 10/80
 - 2s - loss: 0.1117
Epoch 11/80
 - 2s - loss: 0.1032
Epoch 12/80
 - 2s - loss: 0.0959
Epoch 13/80
 - 2s - loss: 0.0894
Epoch 14/80
 - 2s - loss: 0.0837
Epoch 15/80
 - 2s - loss: 0.0789
Epoch 16/80
 - 2s - loss: 0.0750
Epoch 17/80
 - 2s - loss: 0.0716
Epoch 18/80
 - 2s - loss: 0.0688
Epoch 19/80
 - 2s - loss: 0.0663
Epoch 20/80
 - 2s - loss: 0.0643
Epoch 21/80
 - 2s - loss: 0.0625
Epoch 22/80
 - 2s - loss: 0.0610
Epoch 23/80
 - 2s - loss: 0.0596
Epoch 24/80
 - 2s - loss: 0.0585
Epoch 25/80
 - 2s - loss: 0.0575
Epoch 26/80
 - 2s - loss: 0.0567
Epoch 27/80
 - 2s - loss: 0.0559
Epoch 28/80
 - 2s - loss: 0.0553
Epoch 29/80
 - 2s - loss: 0.0547
Epoch 30/80
 - 2s - loss: 0.0542
Epoch 31/80
 - 2s - loss: 0.0538
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:24:45.693004: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:24:45.855763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:24:45.855806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:24:46.150529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:24:46.150578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:24:46.150587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:24:46.150839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6771
Epoch 2/80
 - 2s - loss: 0.1282
Epoch 3/80
 - 2s - loss: 0.0712
Epoch 4/80
 - 2s - loss: 0.0641
Epoch 5/80
 - 2s - loss: 0.0604
Epoch 6/80
 - 2s - loss: 0.0573
Epoch 7/80
 - 2s - loss: 0.0545
Epoch 8/80
 - 2s - loss: 0.0521
Epoch 9/80
 - 2s - loss: 0.0498
Epoch 10/80
 - 2s - loss: 0.0475
Epoch 11/80
 - 2s - loss: 0.0451
Epoch 12/80
 - 2s - loss: 0.0423
Epoch 13/80
 - 2s - loss: 0.0394
Epoch 14/80
 - 2s - loss: 0.0366
Epoch 15/80
 - 2s - loss: 0.0339
Epoch 16/80
 - 2s - loss: 0.0316
Epoch 17/80
 - 2s - loss: 0.0295
Epoch 18/80
 - 2s - loss: 0.0277
Epoch 19/80
 - 2s - loss: 0.0262
Epoch 20/80
 - 2s - loss: 0.0248
Epoch 21/80
 - 2s - loss: 0.0237
Epoch 22/80
 - 2s - loss: 0.0227
Epoch 23/80
 - 2s - loss: 0.0218
Epoch 24/80
 - 2s - loss: 0.0211
Epoch 25/80
 - 2s - loss: 0.0204
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0194
Epoch 28/80
 - 2s - loss: 0.0190
Epoch 29/80
 - 2s - loss: 0.0187
Epoch 30/80
 - 2s - loss: 0.0184
Epoch 31/80
 - 2s - loss: 0.0182
Epoch 32/80
 - 2s - loss: 0.0179
Epoch 33/80
 - 2s - loss: 0.0178
Epoch 34/80
 - 2s - loss: 0.0176
Epoch 35/80
 - 2s - loss: 0.0175
Epoch 36/80
 - 2s - loss: 0.0173
Epoch 37/80
 - 2s - loss: 0.0172
Epoch 38/80
 - 2s - loss: 0.0171
Epoch 39/80
 - 2s - loss: 0.0170
Epoch 40/80
 - 2s - loss: 0.0170
Epoch 41/80
 - 2s - loss: 0.0169
Epoch 42/80
 - 2s - loss: 0.0168
Epoch 43/80
 - 2s - loss: 0.0168
Epoch 44/80
 - 2s - loss: 0.0167
Epoch 45/80
 - 2s - loss: 0.0167
Epoch 46/80
 - 2s - loss: 0.0166
Epoch 47/80
 - 2s - loss: 0.0166
Epoch 48/80
 - 2s - loss: 0.0166
Epoch 49/80
 - 2s - loss: 0.0165
Epoch 50/80
 - 2s - loss: 0.0165
Epoch 51/80
 - 2s - loss: 0.0165
Epoch 52/80
 - 2s - loss: 0.0164
Epoch 53/80
 - 2s - loss: 0.0160
Epoch 54/80
 - 2s - loss: 0.0160
Epoch 55/80
 - 2s - loss: 0.0160
Epoch 56/80
 - 2s - loss: 0.0160
Epoch 57/80
 - 2s - loss: 0.0159
Epoch 58/80
 - 2s - loss: 0.0159
Epoch 59/80
 - 2s - loss: 0.0159
Epoch 60/80
 - 2s - loss: 0.0158
Epoch 61/80
 - 2s - loss: 0.0158
Epoch 62/80
 - 2s - loss: 0.0158
Epoch 63/80
 - 2s - loss: 0.0158
Epoch 64/80
 - 2s - loss: 0.0158
Epoch 65/80
 - 2s - loss: 0.0158
Epoch 66/80
 - 2s - loss: 0.0158
Epoch 67/80
 - 2s - loss: 0.0158
Epoch 68/80
 - 2s - loss: 0.0158
Epoch 69/80
 - 2s - loss: 0.0158
Epoch 70/80
 - 2s - loss: 0.0158
Epoch 71/80
 - 2s - loss: 0.0158
Epoch 72/80
 - 2s - loss: 0.0158
Epoch 73/80
 - 2s - loss: 0.0158
Epoch 74/80
 - 2s - loss: 0.0158
Epoch 75/80
 - 2s - loss: 0.0158
Epoch 76/80
 - 2s - loss: 0.0158
Epoch 77/80
 - 2s - loss: 0.0158
Epoch 78/80
 - 2s - loss: 0.0158
Epoch 79/80
 - 2s - loss: 0.0158
Epoch 80/80
 - 2s - loss: 0.0158
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.2353 - val_loss: 1.3325
AUC: 0.8039

Epoch 2/80
 - 0s - loss: 2.0219 - val_loss: 0.7633
AUC: 0.8311

Epoch 3/80
 - 0s - loss: 1.4136 - val_loss: 0.6708
AUC: 0.8399

Epoch 4/80
 - 0s - loss: 1.1951 - val_loss: 0.6584
AUC: 0.8440

Epoch 5/80
 - 0s - loss: 1.1178 - val_loss: 0.6352
AUC: 0.8446

Epoch 6/80
 - 0s - loss: 1.0911 - val_loss: 0.6059
AUC: 0.8491

Epoch 7/80
 - 0s - loss: 1.0648 - val_loss: 0.6586
AUC: 0.8530

Epoch 8/80
 - 0s - loss: 1.0485 - val_loss: 0.6084
AUC: 0.8505

Epoch 9/80
 - 0s - loss: 1.0431 - val_loss: 0.6686
AUC: 0.8552

Epoch 10/80
 - 0s - loss: 1.0348 - val_loss: 0.6807
AUC: 0.8569

Epoch 11/80
 - 0s - loss: 1.0262 - val_loss: 0.6067
AUC: 0.8559

Epoch 12/80
 - 0s - loss: 1.0208 - val_loss: 0.6648
AUC: 0.8568

Epoch 13/80
 - 0s - loss: 1.0139 - val_loss: 0.7352
AUC: 0.8593

Epoch 14/80
 - 0s - loss: 1.0062 - val_loss: 0.5849
AUC: 0.8567

Epoch 15/80
 - 0s - loss: 1.0017 - val_loss: 0.6377
AUC: 0.8597

Epoch 16/80
 - 0s - loss: 0.9999 - val_loss: 0.5429
AUC: 0.8578

Epoch 17/80
 - 0s - loss: 0.9936 - val_loss: 0.6054
AUC: 0.8599

Epoch 18/80
 - 0s - loss: 0.9905 - val_loss: 0.6757
AUC: 0.8602

Epoch 19/80
 - 0s - loss: 0.9920 - val_loss: 0.6558
AUC: 0.8603

Epoch 20/80
 - 0s - loss: 0.9822 - val_loss: 0.6382
AUC: 0.8612

Epoch 21/80
 - 0s - loss: 0.9754 - val_loss: 0.6126
AUC: 0.8611

Epoch 22/80
 - 0s - loss: 0.9785 - val_loss: 0.6612
AUC: 0.8608

Epoch 23/80
 - 0s - loss: 0.9783 - val_loss: 0.6828
AUC: 0.8623

Epoch 24/80
 - 0s - loss: 0.9664 - val_loss: 0.6095
AUC: 0.8606

Epoch 25/80
 - 0s - loss: 0.9703 - val_loss: 0.5490
AUC: 0.8608

Epoch 26/80
 - 0s - loss: 0.9649 - val_loss: 0.6192
AUC: 0.8617

Epoch 27/80
 - 0s - loss: 0.9432 - val_loss: 0.5864
AUC: 0.8630

Epoch 28/80
 - 0s - loss: 0.9417 - val_loss: 0.5999
AUC: 0.8632

Epoch 29/80
 - 0s - loss: 0.9367 - val_loss: 0.5870
AUC: 0.8631

Epoch 30/80
 - 0s - loss: 0.9401 - val_loss: 0.6074
AUC: 0.8632

Epoch 31/80
 - 0s - loss: 0.9462 - val_loss: 0.6147
AUC: 0.8633

Epoch 32/80
 - 0s - loss: 0.9384 - val_loss: 0.6321
AUC: 0.8635

Epoch 33/80
 - 0s - loss: 0.9352 - val_loss: 0.5717
AUC: 0.8626

Epoch 34/80
 - 0s - loss: 0.9366 - val_loss: 0.5725
AUC: 0.8631

Epoch 35/80
 - 0s - loss: 0.9380 - val_loss: 0.6252
AUC: 0.8635

Epoch 36/80
 - 0s - loss: 0.9353 - val_loss: 0.5957
AUC: 0.8632

Epoch 37/80
 - 0s - loss: 0.9322 - val_loss: 0.5949
AUC: 0.8632

Epoch 38/80
 - 0s - loss: 0.9329 - val_loss: 0.5931
AUC: 0.8632

Epoch 39/80
 - 0s - loss: 0.9309 - val_loss: 0.5917
AUC: 0.8631

Epoch 40/80
 - 0s - loss: 0.9280 - val_loss: 0.5888
AUC: 0.8631

Epoch 41/80
 - 0s - loss: 0.9292 - val_loss: 0.5866
AUC: 0.8631

Epoch 42/80
 - 0s - loss: 0.9257 - val_loss: 0.5790
AUC: 0.8630

Epoch 43/80
 - 0s - loss: 0.9274 - val_loss: 0.6012
AUC: 0.8632

Epoch 44/80
 - 0s - loss: 0.9256 - val_loss: 0.5818
AUC: 0.8631

Epoch 45/80
 - 0s - loss: 0.9266 - val_loss: 0.5883
AUC: 0.8631

Epoch 46/80
 - 0s - loss: 0.9287 - val_loss: 0.5888
AUC: 0.8632

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9424 - val_loss: 0.5905
AUC: 0.8633

Epoch 2/30
 - 0s - loss: 0.9316 - val_loss: 0.6008
AUC: 0.8634

Epoch 3/30
 - 0s - loss: 0.9283 - val_loss: 0.5758
AUC: 0.8631

Epoch 4/30
 - 0s - loss: 0.9303 - val_loss: 0.6044
AUC: 0.8636

Epoch 5/30
 - 0s - loss: 0.9284 - val_loss: 0.6050
AUC: 0.8635

Epoch 6/30
 - 0s - loss: 0.9299 - val_loss: 0.5891
AUC: 0.8633

Epoch 7/30
 - 0s - loss: 0.9277 - val_loss: 0.5831
AUC: 0.8634

Epoch 8/30
 - 0s - loss: 0.9230 - val_loss: 0.6309
AUC: 0.8640

Epoch 9/30
 - 0s - loss: 0.9217 - val_loss: 0.5829
AUC: 0.8638

Epoch 10/30
 - 0s - loss: 0.9199 - val_loss: 0.5868
AUC: 0.8637

Epoch 11/30
 - 0s - loss: 0.9213 - val_loss: 0.5627
AUC: 0.8636

Epoch 12/30
 - 0s - loss: 0.9199 - val_loss: 0.5976
AUC: 0.8639

Epoch 13/30
 - 0s - loss: 0.9176 - val_loss: 0.5822
AUC: 0.8637

Epoch 14/30
 - 0s - loss: 0.9187 - val_loss: 0.6037
AUC: 0.8642

Epoch 15/30
 - 0s - loss: 0.9148 - val_loss: 0.5830
AUC: 0.8637

Epoch 16/30
 - 0s - loss: 0.9152 - val_loss: 0.5914
AUC: 0.8638

Epoch 17/30
 - 0s - loss: 0.9103 - val_loss: 0.5809
AUC: 0.8636

Epoch 18/30
 - 0s - loss: 0.9104 - val_loss: 0.5945
AUC: 0.8639

Epoch 19/30
 - 0s - loss: 0.9066 - val_loss: 0.5737
AUC: 0.8639

Epoch 20/30
 - 0s - loss: 0.9087 - val_loss: 0.5894
AUC: 0.8640

Epoch 21/30
 - 0s - loss: 0.9088 - val_loss: 0.5814
AUC: 0.8638

Epoch 22/30
 - 0s - loss: 0.8981 - val_loss: 0.5879
AUC: 0.8640

Epoch 23/30
 - 0s - loss: 0.9016 - val_loss: 0.5835
AUC: 0.8640

Epoch 24/30
 - 0s - loss: 0.9031 - val_loss: 0.5832
AUC: 0.8639

Epoch 25/30
 - 0s - loss: 0.8946 - val_loss: 0.5770
AUC: 0.8640

Epoch 26/30
 - 0s - loss: 0.9009 - val_loss: 0.5894
AUC: 0.8641

Epoch 27/30
 - 0s - loss: 0.8972 - val_loss: 0.5719
AUC: 0.8639

Epoch 28/30
 - 0s - loss: 0.9039 - val_loss: 0.5857
AUC: 0.8641

Epoch 29/30
 - 0s - loss: 0.9011 - val_loss: 0.5858
AUC: 0.8641

Epoch 30/30
 - 0s - loss: 0.9023 - val_loss: 0.5835
Using TensorFlow backend.
AUC: 0.8641

2019-03-08 05:28:07.446409: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:28:07.613226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:28:07.613271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:28:07.906825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:28:07.906877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:28:07.906887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:28:07.907141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6824
Epoch 2/80
 - 2s - loss: 0.1282
Epoch 3/80
 - 2s - loss: 0.0733
Epoch 4/80
 - 2s - loss: 0.0664
Epoch 5/80
 - 2s - loss: 0.0637
Epoch 6/80
 - 2s - loss: 0.0618
Epoch 7/80
 - 2s - loss: 0.0597
Epoch 8/80
 - 2s - loss: 0.0572
Epoch 9/80
 - 2s - loss: 0.0542
Epoch 10/80
 - 2s - loss: 0.0508
Epoch 11/80
 - 2s - loss: 0.0472
Epoch 12/80
 - 2s - loss: 0.0436
Epoch 13/80
 - 2s - loss: 0.0401
Epoch 14/80
 - 2s - loss: 0.0369
Epoch 15/80
 - 2s - loss: 0.0340
Epoch 16/80
 - 2s - loss: 0.0314
Epoch 17/80
 - 2s - loss: 0.0293
Epoch 18/80
 - 2s - loss: 0.0274
Epoch 19/80
 - 2s - loss: 0.0259
Epoch 20/80
 - 2s - loss: 0.0246
Epoch 21/80
 - 2s - loss: 0.0235
Epoch 22/80
 - 2s - loss: 0.0225
Epoch 23/80
 - 2s - loss: 0.0217
Epoch 24/80
 - 2s - loss: 0.0210
Epoch 25/80
 - 2s - loss: 0.0204
Epoch 26/80
 - 2s - loss: 0.0199
Epoch 27/80
 - 2s - loss: 0.0195
Epoch 28/80
 - 2s - loss: 0.0191
Epoch 29/80
 - 2s - loss: 0.0188
Epoch 30/80
 - 2s - loss: 0.0185
Epoch 31/80
 - 2s - loss: 0.0183
Epoch 32/80
 - 2s - loss: 0.0181
Epoch 33/80
 - 2s - loss: 0.0179
Epoch 34/80
 - 2s - loss: 0.0177
Epoch 35/80
 - 2s - loss: 0.0176
Epoch 36/80
 - 2s - loss: 0.0175
Epoch 37/80
 - 2s - loss: 0.0174
Epoch 38/80
 - 2s - loss: 0.0173
Epoch 39/80
 - 2s - loss: 0.0172
Epoch 40/80
 - 2s - loss: 0.0171
Epoch 41/80
 - 2s - loss: 0.0170
Epoch 42/80
 - 2s - loss: 0.0170
Epoch 43/80
 - 2s - loss: 0.0169
Epoch 44/80
 - 2s - loss: 0.0168
Epoch 45/80
 - 2s - loss: 0.0168
Epoch 46/80
 - 2s - loss: 0.0168
Epoch 47/80
 - 2s - loss: 0.0167
Epoch 48/80
 - 2s - loss: 0.0167
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:29:45.407273: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:29:45.572820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:29:45.572863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:29:45.870168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:29:45.870219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:29:45.870229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:29:45.870481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6982
Epoch 2/80
 - 2s - loss: 0.1356
Epoch 3/80
 - 2s - loss: 0.0720
Epoch 4/80
 - 2s - loss: 0.0651
Epoch 5/80
 - 2s - loss: 0.0615
Epoch 6/80
 - 2s - loss: 0.0575
Epoch 7/80
 - 2s - loss: 0.0530
Epoch 8/80
 - 2s - loss: 0.0489
Epoch 9/80
 - 2s - loss: 0.0456
Epoch 10/80
 - 2s - loss: 0.0429
Epoch 11/80
 - 2s - loss: 0.0404
Epoch 12/80
 - 2s - loss: 0.0382
Epoch 13/80
 - 2s - loss: 0.0360
Epoch 14/80
 - 2s - loss: 0.0341
Epoch 15/80
 - 2s - loss: 0.0323
Epoch 16/80
 - 2s - loss: 0.0306
Epoch 17/80
 - 2s - loss: 0.0290
Epoch 18/80
 - 2s - loss: 0.0275
Epoch 19/80
 - 2s - loss: 0.0261
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:30:33.827118: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:30:33.996274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:30:33.996321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:30:34.303214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:30:34.303253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:30:34.303263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:30:34.303584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2871
Epoch 2/80
 - 2s - loss: 0.3310
Epoch 3/80
 - 2s - loss: 0.3011
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b5f130b19b0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 05:31:01.774272: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:31:01.936860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:31:01.936901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:31:02.234091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:31:02.234141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:31:02.234149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:31:02.234436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3073
Epoch 2/80
 - 2s - loss: 0.3322
Epoch 3/80
 - 2s - loss: 0.2814
Epoch 4/80
 - 2s - loss: 0.2509
Epoch 5/80
 - 2s - loss: 0.2282
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:31:27.986943: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:31:28.149494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:31:28.149536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:31:28.451788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:31:28.451839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:31:28.451847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:31:28.452100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3067
Epoch 2/80
 - 2s - loss: 0.3337
Epoch 3/80
 - 2s - loss: 0.2916
Epoch 4/80
 - 2s - loss: 0.2556
Epoch 5/80
 - 2s - loss: 0.2282
Epoch 6/80
 - 2s - loss: 0.2104
Epoch 7/80
 - 2s - loss: 0.1964
Epoch 8/80
 - 2s - loss: 0.1841
Epoch 9/80
 - 2s - loss: 0.1736
Epoch 10/80
 - 2s - loss: 0.1640
Epoch 11/80
 - 2s - loss: 0.1554
Epoch 12/80
 - 2s - loss: 0.1478
Epoch 13/80
 - 2s - loss: 0.1411
Epoch 14/80
 - 2s - loss: 0.1355
Epoch 15/80
 - 2s - loss: 0.1307
Epoch 16/80
 - 2s - loss: 0.1267
Epoch 17/80
 - 2s - loss: 0.1232
Epoch 18/80
 - 2s - loss: 0.1204
Epoch 19/80
 - 2s - loss: 0.1180
Epoch 20/80
 - 2s - loss: 0.1159
Epoch 21/80
 - 2s - loss: 0.1141
Epoch 22/80
 - 2s - loss: 0.1126
Epoch 23/80
 - 2s - loss: 0.1113
Epoch 24/80
 - 2s - loss: 0.1101
Epoch 25/80
 - 2s - loss: 0.1091
Epoch 26/80
 - 2s - loss: 0.1082
Epoch 27/80
 - 2s - loss: 0.1075
Epoch 28/80
 - 2s - loss: 0.1069
Epoch 29/80
 - 2s - loss: 0.1063
Epoch 30/80
 - 2s - loss: 0.1058
Epoch 31/80
 - 2s - loss: 0.1054
Epoch 32/80
 - 2s - loss: 0.1050
Epoch 33/80
 - 2s - loss: 0.1046
Epoch 34/80
 - 2s - loss: 0.1044
Epoch 35/80
 - 2s - loss: 0.1041
Epoch 36/80
 - 2s - loss: 0.1038
Epoch 37/80
 - 2s - loss: 0.1036
Epoch 38/80
 - 2s - loss: 0.1034
Epoch 39/80
 - 2s - loss: 0.1032
Epoch 40/80
 - 2s - loss: 0.1031
Epoch 41/80
 - 2s - loss: 0.1029
Epoch 42/80
 - 2s - loss: 0.1028
Epoch 43/80
 - 2s - loss: 0.1026
Epoch 44/80
 - 2s - loss: 0.1025
Epoch 45/80
 - 2s - loss: 0.1024
Epoch 46/80
 - 2s - loss: 0.1023
Epoch 47/80
 - 2s - loss: 0.1022
Epoch 48/80
 - 2s - loss: 0.1021
Epoch 49/80
 - 2s - loss: 0.1020
Epoch 50/80
 - 2s - loss: 0.1020
Epoch 51/80
 - 2s - loss: 0.1019
Epoch 52/80
 - 2s - loss: 0.1018
Epoch 53/80
 - 2s - loss: 0.1017
Epoch 54/80
 - 2s - loss: 0.1017
Epoch 55/80
 - 2s - loss: 0.1016
Epoch 56/80
 - 2s - loss: 0.1016
Epoch 57/80
 - 2s - loss: 0.1015
Epoch 58/80
 - 2s - loss: 0.1015
Epoch 59/80
 - 2s - loss: 0.1014
Epoch 60/80
 - 2s - loss: 0.1014
Epoch 61/80
 - 2s - loss: 0.1013
Epoch 62/80
 - 2s - loss: 0.1013
Epoch 63/80
 - 2s - loss: 0.1013
Epoch 64/80
 - 2s - loss: 0.1012
Epoch 65/80
 - 2s - loss: 0.1012
Epoch 66/80
 - 2s - loss: 0.1011
Epoch 67/80
 - 2s - loss: 0.1011
Epoch 68/80
 - 2s - loss: 0.1011
Epoch 69/80
 - 2s - loss: 0.0984
Epoch 70/80
 - 2s - loss: 0.0981
Epoch 71/80
 - 2s - loss: 0.0981
Epoch 72/80
 - 2s - loss: 0.0981
Epoch 73/80
 - 2s - loss: 0.0981
Epoch 74/80
 - 2s - loss: 0.0974
Epoch 75/80
 - 2s - loss: 0.0974
Epoch 76/80
 - 2s - loss: 0.0974
Epoch 77/80
 - 2s - loss: 0.0974
Epoch 78/80
 - 2s - loss: 0.0973
Epoch 79/80
 - 2s - loss: 0.0973
Epoch 80/80
 - 2s - loss: 0.0973
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.9525 - val_loss: 1.3337
AUC: 0.7812

Epoch 2/80
 - 0s - loss: 2.1674 - val_loss: 0.9646
AUC: 0.7858

Epoch 3/80
 - 0s - loss: 1.4793 - val_loss: 0.8502
AUC: 0.8099

Epoch 4/80
 - 0s - loss: 1.3124 - val_loss: 0.7884
AUC: 0.8244

Epoch 5/80
 - 0s - loss: 1.2408 - val_loss: 0.7149
AUC: 0.8362

Epoch 6/80
 - 0s - loss: 1.1946 - val_loss: 0.6594
AUC: 0.8431

Epoch 7/80
 - 0s - loss: 1.1577 - val_loss: 0.6622
AUC: 0.8472

Epoch 8/80
 - 0s - loss: 1.1311 - val_loss: 0.6255
AUC: 0.8531

Epoch 9/80
 - 0s - loss: 1.1252 - val_loss: 0.6660
AUC: 0.8556

Epoch 10/80
 - 0s - loss: 1.0991 - val_loss: 0.6547
AUC: 0.8570

Epoch 11/80
 - 0s - loss: 1.0944 - val_loss: 0.5796
AUC: 0.8559

Epoch 12/80
 - 0s - loss: 1.0780 - val_loss: 0.6390
AUC: 0.8598

Epoch 13/80
 - 0s - loss: 1.0750 - val_loss: 0.6434
AUC: 0.8612

Epoch 14/80
 - 0s - loss: 1.0616 - val_loss: 0.6441
AUC: 0.8620

Epoch 15/80
 - 0s - loss: 1.0598 - val_loss: 0.6569
AUC: 0.8627

Epoch 16/80
 - 0s - loss: 1.0443 - val_loss: 0.6353
AUC: 0.8623

Epoch 17/80
 - 0s - loss: 1.0447 - val_loss: 0.6247
AUC: 0.8632

Epoch 18/80
 - 0s - loss: 1.0494 - val_loss: 0.6440
AUC: 0.8638

Epoch 19/80
 - 0s - loss: 1.0336 - val_loss: 0.6043
AUC: 0.8632

Epoch 20/80
 - 0s - loss: 1.0437 - val_loss: 0.6144
AUC: 0.8644

Epoch 21/80
 - 0s - loss: 1.0395 - val_loss: 0.6320
AUC: 0.8648

Epoch 22/80
 - 0s - loss: 1.0202 - val_loss: 0.6181
AUC: 0.8647

Epoch 23/80
 - 0s - loss: 1.0260 - val_loss: 0.6103
AUC: 0.8651

Epoch 24/80
 - 0s - loss: 1.0215 - val_loss: 0.6369
AUC: 0.8653

Epoch 25/80
 - 0s - loss: 1.0198 - val_loss: 0.6149
AUC: 0.8651

Epoch 26/80
 - 0s - loss: 1.0278 - val_loss: 0.6323
AUC: 0.8652

Epoch 27/80
 - 0s - loss: 1.0192 - val_loss: 0.6206
AUC: 0.8654

Epoch 28/80
 - 0s - loss: 1.0205 - val_loss: 0.6198
AUC: 0.8658

Epoch 29/80
 - 0s - loss: 1.0202 - val_loss: 0.6356
AUC: 0.8655

Epoch 30/80
 - 0s - loss: 1.0189 - val_loss: 0.6109
AUC: 0.8653

Epoch 31/80
 - 0s - loss: 1.0139 - val_loss: 0.6193
AUC: 0.8651

Epoch 32/80
 - 0s - loss: 1.0198 - val_loss: 0.6227
AUC: 0.8652

Epoch 33/80
 - 0s - loss: 1.0199 - val_loss: 0.6206
AUC: 0.8654

Epoch 34/80
 - 0s - loss: 1.0133 - val_loss: 0.6206
AUC: 0.8654

Epoch 35/80
 - 0s - loss: 1.0176 - val_loss: 0.6177
AUC: 0.8655

Epoch 36/80
 - 0s - loss: 1.0179 - val_loss: 0.6225
AUC: 0.8656

Epoch 37/80
 - 0s - loss: 1.0161 - val_loss: 0.6279
AUC: 0.8657

Epoch 38/80
 - 0s - loss: 1.0130 - val_loss: 0.6158
AUC: 0.8655

Epoch 39/80
 - 0s - loss: 1.0128 - val_loss: 0.6224
AUC: 0.8656

Epoch 40/80
 - 0s - loss: 1.0139 - val_loss: 0.6225
AUC: 0.8656

Epoch 41/80
 - 0s - loss: 1.0180 - val_loss: 0.6214
AUC: 0.8656

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0149 - val_loss: 0.6144
AUC: 0.8657

Epoch 2/30
 - 0s - loss: 1.0214 - val_loss: 0.6235
AUC: 0.8658

Epoch 3/30
 - 0s - loss: 1.0133 - val_loss: 0.6236
AUC: 0.8660

Epoch 4/30
 - 0s - loss: 1.0159 - val_loss: 0.6291
AUC: 0.8662

Epoch 5/30
 - 0s - loss: 1.0103 - val_loss: 0.6245
AUC: 0.8662

Epoch 6/30
 - 0s - loss: 1.0136 - val_loss: 0.6450
AUC: 0.8668

Epoch 7/30
 - 0s - loss: 1.0125 - val_loss: 0.6326
AUC: 0.8669

Epoch 8/30
 - 0s - loss: 1.0100 - val_loss: 0.6097
AUC: 0.8667

Epoch 9/30
 - 0s - loss: 1.0025 - val_loss: 0.6058
AUC: 0.8667

Epoch 10/30
 - 0s - loss: 1.0058 - val_loss: 0.6068
AUC: 0.8669

Epoch 11/30
 - 0s - loss: 1.0076 - val_loss: 0.6191
AUC: 0.8673

Epoch 12/30
 - 0s - loss: 1.0069 - val_loss: 0.6125
AUC: 0.8673

Epoch 13/30
 - 0s - loss: 1.0014 - val_loss: 0.6078
AUC: 0.8675

Epoch 14/30
 - 0s - loss: 0.9968 - val_loss: 0.6151
AUC: 0.8676

Epoch 15/30
 - 0s - loss: 1.0050 - val_loss: 0.6140
AUC: 0.8676

Epoch 16/30
 - 0s - loss: 0.9978 - val_loss: 0.6036
AUC: 0.8677

Epoch 17/30
 - 0s - loss: 0.9914 - val_loss: 0.6175
AUC: 0.8678

Epoch 18/30
 - 0s - loss: 0.9914 - val_loss: 0.6013
AUC: 0.8679

Epoch 19/30
 - 0s - loss: 0.9908 - val_loss: 0.5997
AUC: 0.8679

Epoch 20/30
 - 0s - loss: 0.9897 - val_loss: 0.6051
AUC: 0.8681

Epoch 21/30
 - 0s - loss: 0.9923 - val_loss: 0.6103
AUC: 0.8685

Epoch 22/30
 - 0s - loss: 0.9842 - val_loss: 0.6106
AUC: 0.8685

Epoch 23/30
 - 0s - loss: 0.9894 - val_loss: 0.6107
AUC: 0.8686

Epoch 24/30
 - 0s - loss: 0.9860 - val_loss: 0.6057
AUC: 0.8687

Epoch 25/30
 - 0s - loss: 0.9795 - val_loss: 0.5829
AUC: 0.8684

Epoch 26/30
 - 0s - loss: 0.9863 - val_loss: 0.6084
AUC: 0.8689

Epoch 27/30
 - 0s - loss: 0.9827 - val_loss: 0.5996
AUC: 0.8686

Epoch 28/30
 - 0s - loss: 0.9760 - val_loss: 0.5952
AUC: 0.8689

Epoch 29/30
 - 0s - loss: 0.9775 - val_loss: 0.6036
AUC: 0.8692

Epoch 30/30
 - 0s - loss: 0.9760 - val_loss: 0.6189
Using TensorFlow backend.
AUC: 0.8694

2019-03-08 05:34:42.733809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:34:42.909766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:34:42.909809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:34:43.213211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:34:43.213252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:34:43.213262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:34:43.213570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2796
Epoch 2/80
 - 2s - loss: 0.3320
Epoch 3/80
 - 2s - loss: 0.3005
Epoch 4/80
 - 2s - loss: 0.2738
Epoch 5/80
 - 2s - loss: 0.2453
Epoch 6/80
 - 2s - loss: 0.2236
Epoch 7/80
 - 2s - loss: 0.2062
Epoch 8/80
 - 2s - loss: 0.1912
Epoch 9/80
 - 2s - loss: 0.1784
Epoch 10/80
 - 2s - loss: 0.1675
Epoch 11/80
 - 2s - loss: 0.1579
Epoch 12/80
 - 2s - loss: 0.1495
Epoch 13/80
 - 2s - loss: 0.1425
Epoch 14/80
 - 2s - loss: 0.1366
Epoch 15/80
 - 2s - loss: 0.1318
Epoch 16/80
 - 2s - loss: 0.1277
Epoch 17/80
 - 2s - loss: 0.1242
Epoch 18/80
 - 2s - loss: 0.1213
Epoch 19/80
 - 2s - loss: 0.1188
Epoch 20/80
 - 2s - loss: 0.1166
Epoch 21/80
 - 2s - loss: 0.1147
Epoch 22/80
 - 2s - loss: 0.1131
Epoch 23/80
 - 2s - loss: 0.1118
Epoch 24/80
 - 2s - loss: 0.1106
Epoch 25/80
 - 2s - loss: 0.1096
Epoch 26/80
 - 2s - loss: 0.1087
Epoch 27/80
 - 2s - loss: 0.1080
Epoch 28/80
 - 2s - loss: 0.1073
Epoch 29/80
 - 2s - loss: 0.1067
Epoch 30/80
 - 2s - loss: 0.1062
Epoch 31/80
 - 2s - loss: 0.1058
Epoch 32/80
 - 2s - loss: 0.1054
Epoch 33/80
 - 2s - loss: 0.1050
Epoch 34/80
 - 2s - loss: 0.1047
Epoch 35/80
 - 2s - loss: 0.1045
Epoch 36/80
 - 2s - loss: 0.1042
Epoch 37/80
 - 2s - loss: 0.1040
Epoch 38/80
 - 2s - loss: 0.1038
Epoch 39/80
 - 2s - loss: 0.1036
Epoch 40/80
 - 2s - loss: 0.1034
Epoch 41/80
 - 2s - loss: 0.1033
Epoch 42/80
 - 2s - loss: 0.1032
Epoch 43/80
 - 2s - loss: 0.1030
Epoch 44/80
 - 2s - loss: 0.1029
Epoch 45/80
 - 2s - loss: 0.1028
Epoch 46/80
 - 2s - loss: 0.1027
Epoch 47/80
 - 2s - loss: 0.1026
Epoch 48/80
 - 2s - loss: 0.1025
Epoch 49/80
 - 2s - loss: 0.1024
Epoch 50/80
 - 2s - loss: 0.1023
Epoch 51/80
 - 2s - loss: 0.1023
Epoch 52/80
 - 2s - loss: 0.1022
Epoch 53/80
 - 2s - loss: 0.1021
Epoch 54/80
 - 2s - loss: 0.1021
Epoch 55/80
 - 2s - loss: 0.1020
Epoch 56/80
 - 2s - loss: 0.1019
Epoch 57/80
 - 2s - loss: 0.1019
Epoch 58/80
 - 2s - loss: 0.1018
Epoch 59/80
 - 2s - loss: 0.1018
Epoch 60/80
 - 2s - loss: 0.1017
Epoch 61/80
 - 2s - loss: 0.1017
Epoch 62/80
 - 2s - loss: 0.1017
Epoch 63/80
 - 2s - loss: 0.1016
Epoch 64/80
 - 2s - loss: 0.1016
Epoch 65/80
 - 2s - loss: 0.1015
Epoch 66/80
 - 2s - loss: 0.1015
Epoch 67/80
 - 2s - loss: 0.1015
Epoch 68/80
 - 2s - loss: 0.1014
Epoch 69/80
 - 2s - loss: 0.1014
Epoch 70/80
 - 2s - loss: 0.1014
Epoch 71/80
 - 2s - loss: 0.0987
Epoch 72/80
 - 2s - loss: 0.0984
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:36:59.613735: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:36:59.778198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:36:59.778244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:37:00.071824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:37:00.071875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:37:00.071884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:37:00.072217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1258
Epoch 2/80
 - 2s - loss: 0.1968
Epoch 3/80
 - 2s - loss: 0.1539
Epoch 4/80
 - 2s - loss: 0.1374
Epoch 5/80
 - 2s - loss: 0.1263
Epoch 6/80
 - 2s - loss: 0.1166
Epoch 7/80
 - 2s - loss: 0.1079
Epoch 8/80
 - 2s - loss: 0.0998
Epoch 9/80
 - 2s - loss: 0.0925
Epoch 10/80
 - 2s - loss: 0.0860
Epoch 11/80
 - 2s - loss: 0.0801
Epoch 12/80
 - 2s - loss: 0.0750
Epoch 13/80
 - 2s - loss: 0.0707
Epoch 14/80
 - 2s - loss: 0.0671
Epoch 15/80
 - 2s - loss: 0.0641
Epoch 16/80
 - 2s - loss: 0.0616
Epoch 17/80
 - 2s - loss: 0.0593
Epoch 18/80
 - 2s - loss: 0.0575
Epoch 19/80
 - 2s - loss: 0.0558
Epoch 20/80
 - 2s - loss: 0.0543
Epoch 21/80
 - 2s - loss: 0.0531
Epoch 22/80
 - 2s - loss: 0.0519
Epoch 23/80
 - 2s - loss: 0.0510
Epoch 24/80
 - 2s - loss: 0.0501
Epoch 25/80
 - 2s - loss: 0.0494
Epoch 26/80
 - 2s - loss: 0.0487
Epoch 27/80
 - 2s - loss: 0.0481
Epoch 28/80
 - 2s - loss: 0.0476
Epoch 29/80
 - 2s - loss: 0.0472
Epoch 30/80
 - 2s - loss: 0.0468
Epoch 31/80
 - 2s - loss: 0.0464
Epoch 32/80
 - 2s - loss: 0.0461
Epoch 33/80
 - 2s - loss: 0.0459
Epoch 34/80
 - 2s - loss: 0.0456
Epoch 35/80
 - 2s - loss: 0.0454
Epoch 36/80
 - 2s - loss: 0.0452
Epoch 37/80
 - 2s - loss: 0.0450
Epoch 38/80
 - 2s - loss: 0.0449
Epoch 39/80
 - 2s - loss: 0.0448
Epoch 40/80
 - 2s - loss: 0.0447
Epoch 41/80
 - 2s - loss: 0.0445
Epoch 42/80
 - 2s - loss: 0.0444
Epoch 43/80
 - 2s - loss: 0.0443
Epoch 44/80
 - 2s - loss: 0.0443
Epoch 45/80
 - 2s - loss: 0.0442
Epoch 46/80
 - 2s - loss: 0.0441
Epoch 47/80
 - 2s - loss: 0.0440
Epoch 48/80
 - 2s - loss: 0.0440
Epoch 49/80
 - 2s - loss: 0.0439
Epoch 50/80
 - 2s - loss: 0.0438
Epoch 51/80
 - 2s - loss: 0.0438
Epoch 52/80
 - 2s - loss: 0.0437
Epoch 53/80
 - 2s - loss: 0.0437
Epoch 54/80
 - 2s - loss: 0.0437
Epoch 55/80
 - 2s - loss: 0.0436
Epoch 56/80
 - 2s - loss: 0.0436
Epoch 57/80
 - 2s - loss: 0.0435
Epoch 58/80
 - 2s - loss: 0.0435
Epoch 59/80
 - 2s - loss: 0.0423
Epoch 60/80
 - 2s - loss: 0.0421
Epoch 61/80
 - 2s - loss: 0.0421
Epoch 62/80
 - 2s - loss: 0.0421
Epoch 63/80
 - 2s - loss: 0.0421
Epoch 64/80
 - 2s - loss: 0.0418
Epoch 65/80
 - 2s - loss: 0.0418
Epoch 66/80
 - 2s - loss: 0.0418
Epoch 67/80
 - 2s - loss: 0.0418
Epoch 68/80
 - 2s - loss: 0.0417
Epoch 69/80
 - 2s - loss: 0.0417
Epoch 70/80
 - 2s - loss: 0.0417
Epoch 71/80
 - 2s - loss: 0.0417
Epoch 72/80
 - 2s - loss: 0.0417
Epoch 73/80
 - 2s - loss: 0.0417
Epoch 74/80
 - 2s - loss: 0.0417
Epoch 75/80
 - 2s - loss: 0.0417
Epoch 76/80
 - 2s - loss: 0.0417
Epoch 77/80
 - 2s - loss: 0.0417
Epoch 78/80
 - 2s - loss: 0.0417
Epoch 79/80
 - 2s - loss: 0.0417
Epoch 80/80
 - 2s - loss: 0.0417
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.9617 - val_loss: 1.4060
AUC: 0.7536

Epoch 2/80
 - 0s - loss: 2.1363 - val_loss: 0.9466
AUC: 0.7793

Epoch 3/80
 - 0s - loss: 1.4802 - val_loss: 0.8142
AUC: 0.8093

Epoch 4/80
 - 0s - loss: 1.2917 - val_loss: 0.6889
AUC: 0.8216

Epoch 5/80
 - 0s - loss: 1.2074 - val_loss: 0.7206
AUC: 0.8330

Epoch 6/80
 - 0s - loss: 1.1874 - val_loss: 0.6811
AUC: 0.8393

Epoch 7/80
 - 0s - loss: 1.1525 - val_loss: 0.7082
AUC: 0.8466

Epoch 8/80
 - 0s - loss: 1.1375 - val_loss: 0.6789
AUC: 0.8482

Epoch 9/80
 - 0s - loss: 1.1211 - val_loss: 0.6868
AUC: 0.8522

Epoch 10/80
 - 0s - loss: 1.0991 - val_loss: 0.6708
AUC: 0.8536

Epoch 11/80
 - 0s - loss: 1.0899 - val_loss: 0.6211
AUC: 0.8542

Epoch 12/80
 - 0s - loss: 1.0811 - val_loss: 0.6912
AUC: 0.8567

Epoch 13/80
 - 0s - loss: 1.0766 - val_loss: 0.6571
AUC: 0.8563

Epoch 14/80
 - 0s - loss: 1.0656 - val_loss: 0.6921
AUC: 0.8575

Epoch 15/80
 - 0s - loss: 1.0658 - val_loss: 0.6345
AUC: 0.8590

Epoch 16/80
 - 0s - loss: 1.0605 - val_loss: 0.6068
AUC: 0.8574

Epoch 17/80
 - 0s - loss: 1.0483 - val_loss: 0.5504
AUC: 0.8578

Epoch 18/80
 - 0s - loss: 1.0500 - val_loss: 0.6290
AUC: 0.8598

Epoch 19/80
 - 0s - loss: 1.0503 - val_loss: 0.5860
AUC: 0.8591

Epoch 20/80
 - 0s - loss: 1.0345 - val_loss: 0.6635
AUC: 0.8606

Epoch 21/80
 - 0s - loss: 1.0319 - val_loss: 0.6096
AUC: 0.8599

Epoch 22/80
 - 0s - loss: 1.0387 - val_loss: 0.6894
AUC: 0.8615

Epoch 23/80
 - 0s - loss: 1.0302 - val_loss: 0.6347
AUC: 0.8611

Epoch 24/80
 - 0s - loss: 1.0243 - val_loss: 0.6034
AUC: 0.8606

Epoch 25/80
 - 0s - loss: 1.0233 - val_loss: 0.6099
AUC: 0.8608

Epoch 26/80
 - 0s - loss: 1.0210 - val_loss: 0.6324
AUC: 0.8615

Epoch 27/80
 - 0s - loss: 1.0217 - val_loss: 0.6140
AUC: 0.8615

Epoch 28/80
 - 0s - loss: 1.0087 - val_loss: 0.6044
AUC: 0.8616

Epoch 29/80
 - 0s - loss: 1.0039 - val_loss: 0.6146
AUC: 0.8617

Epoch 30/80
 - 0s - loss: 1.0110 - val_loss: 0.6140
AUC: 0.8620

Epoch 31/80
 - 0s - loss: 1.0081 - val_loss: 0.6159
AUC: 0.8620

Epoch 32/80
 - 0s - loss: 1.0071 - val_loss: 0.6179
AUC: 0.8624

Epoch 33/80
 - 0s - loss: 1.0092 - val_loss: 0.6290
AUC: 0.8626

Epoch 34/80
 - 0s - loss: 1.0105 - val_loss: 0.6261
AUC: 0.8626

Epoch 35/80
 - 0s - loss: 1.0088 - val_loss: 0.6336
AUC: 0.8625

Epoch 36/80
 - 0s - loss: 1.0132 - val_loss: 0.6370
AUC: 0.8628

Epoch 37/80
 - 0s - loss: 1.0035 - val_loss: 0.6104
AUC: 0.8626

Epoch 38/80
 - 0s - loss: 1.0114 - val_loss: 0.6151
AUC: 0.8626

Epoch 39/80
 - 0s - loss: 1.0075 - val_loss: 0.6148
AUC: 0.8626

Epoch 40/80
 - 0s - loss: 1.0069 - val_loss: 0.6149
AUC: 0.8627

Epoch 41/80
 - 0s - loss: 1.0033 - val_loss: 0.6127
AUC: 0.8627

Epoch 42/80
 - 0s - loss: 1.0030 - val_loss: 0.6182
AUC: 0.8627

Epoch 43/80
 - 0s - loss: 1.0106 - val_loss: 0.6172
AUC: 0.8628

Epoch 44/80
 - 0s - loss: 1.0035 - val_loss: 0.6096
AUC: 0.8627

Epoch 45/80
 - 0s - loss: 1.0081 - val_loss: 0.6118
AUC: 0.8627

Epoch 46/80
 - 0s - loss: 1.0046 - val_loss: 0.6180
AUC: 0.8628

Epoch 47/80
 - 0s - loss: 1.0028 - val_loss: 0.6145
AUC: 0.8627

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0092 - val_loss: 0.6227
AUC: 0.8630

Epoch 2/30
 - 0s - loss: 1.0088 - val_loss: 0.6097
AUC: 0.8629

Epoch 3/30
 - 0s - loss: 1.0046 - val_loss: 0.6197
AUC: 0.8631

Epoch 4/30
 - 0s - loss: 0.9967 - val_loss: 0.6187
AUC: 0.8634

Epoch 5/30
 - 0s - loss: 0.9935 - val_loss: 0.6152
AUC: 0.8633

Epoch 6/30
 - 0s - loss: 0.9975 - val_loss: 0.6122
AUC: 0.8636

Epoch 7/30
 - 0s - loss: 0.9953 - val_loss: 0.6134
AUC: 0.8636

Epoch 8/30
 - 0s - loss: 0.9941 - val_loss: 0.5994
AUC: 0.8635

Epoch 9/30
 - 0s - loss: 0.9957 - val_loss: 0.6093
AUC: 0.8638

Epoch 10/30
 - 0s - loss: 0.9907 - val_loss: 0.6094
AUC: 0.8639

Epoch 11/30
 - 0s - loss: 0.9907 - val_loss: 0.6089
AUC: 0.8641

Epoch 12/30
 - 0s - loss: 0.9948 - val_loss: 0.6165
AUC: 0.8642

Epoch 13/30
 - 0s - loss: 0.9833 - val_loss: 0.6129
AUC: 0.8643

Epoch 14/30
 - 0s - loss: 0.9855 - val_loss: 0.6167
AUC: 0.8643

Epoch 15/30
 - 0s - loss: 0.9867 - val_loss: 0.6112
AUC: 0.8645

Epoch 16/30
 - 0s - loss: 0.9839 - val_loss: 0.6118
AUC: 0.8646

Epoch 17/30
 - 0s - loss: 0.9848 - val_loss: 0.6095
AUC: 0.8646

Epoch 18/30
 - 0s - loss: 0.9838 - val_loss: 0.6107
AUC: 0.8647

Epoch 19/30
 - 0s - loss: 0.9791 - val_loss: 0.6043
AUC: 0.8646

Epoch 20/30
 - 0s - loss: 0.9846 - val_loss: 0.6029
AUC: 0.8647

Epoch 21/30
 - 0s - loss: 0.9775 - val_loss: 0.6048
AUC: 0.8647

Epoch 22/30
 - 0s - loss: 0.9827 - val_loss: 0.6042
AUC: 0.8647

Epoch 23/30
 - 0s - loss: 0.9815 - val_loss: 0.6025
AUC: 0.8647

Epoch 24/30
 - 0s - loss: 0.9835 - val_loss: 0.6022
AUC: 0.8647

Epoch 25/30
 - 0s - loss: 0.9756 - val_loss: 0.6014
AUC: 0.8647

Epoch 26/30
 - 0s - loss: 0.9757 - val_loss: 0.6032
AUC: 0.8648

Epoch 27/30
 - 0s - loss: 0.9813 - val_loss: 0.6011
AUC: 0.8648

Epoch 28/30
 - 0s - loss: 0.9757 - val_loss: 0.6020
AUC: 0.8648

Epoch 29/30
 - 0s - loss: 0.9772 - val_loss: 0.6019
AUC: 0.8648

Epoch 30/30
 - 0s - loss: 0.9826 - val_loss: 0.6029
Using TensorFlow backend.
AUC: 0.8648

2019-03-08 05:40:18.531735: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:40:18.695282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:40:18.695325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:40:18.992547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:40:18.992597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:40:18.992606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:40:18.992859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0795
Epoch 2/80
 - 2s - loss: 0.1948
Epoch 3/80
 - 2s - loss: 0.1622
Epoch 4/80
 - 2s - loss: 0.1453
Epoch 5/80
 - 2s - loss: 0.1304
Epoch 6/80
 - 2s - loss: 0.1194
Epoch 7/80
 - 2s - loss: 0.1104
Epoch 8/80
 - 2s - loss: 0.1022
Epoch 9/80
 - 2s - loss: 0.0945
Epoch 10/80
 - 2s - loss: 0.0876
Epoch 11/80
 - 2s - loss: 0.0815
Epoch 12/80
 - 2s - loss: 0.0763
Epoch 13/80
 - 2s - loss: 0.0719
Epoch 14/80
 - 2s - loss: 0.0680
Epoch 15/80
 - 2s - loss: 0.0648
Epoch 16/80
 - 2s - loss: 0.0620
Epoch 17/80
 - 2s - loss: 0.0596
Epoch 18/80
 - 2s - loss: 0.0575
Epoch 19/80
 - 2s - loss: 0.0558
Epoch 20/80
 - 2s - loss: 0.0542
Epoch 21/80
 - 2s - loss: 0.0529
Epoch 22/80
 - 2s - loss: 0.0517
Epoch 23/80
 - 2s - loss: 0.0507
Epoch 24/80
 - 2s - loss: 0.0499
Epoch 25/80
 - 2s - loss: 0.0491
Epoch 26/80
 - 2s - loss: 0.0485
Epoch 27/80
 - 2s - loss: 0.0480
Epoch 28/80
 - 2s - loss: 0.0475
Epoch 29/80
 - 2s - loss: 0.0471
Epoch 30/80
 - 2s - loss: 0.0467
Epoch 31/80
 - 2s - loss: 0.0464
Epoch 32/80
 - 2s - loss: 0.0461
Epoch 33/80
 - 2s - loss: 0.0459
Epoch 34/80
 - 2s - loss: 0.0456
Epoch 35/80
 - 2s - loss: 0.0454
Epoch 36/80
 - 2s - loss: 0.0453
Epoch 37/80
 - 2s - loss: 0.0451
Epoch 38/80
 - 2s - loss: 0.0450
Epoch 39/80
 - 2s - loss: 0.0448
Epoch 40/80
 - 2s - loss: 0.0447
Epoch 41/80
 - 2s - loss: 0.0446
Epoch 42/80
 - 2s - loss: 0.0445
Epoch 43/80
 - 2s - loss: 0.0444
Epoch 44/80
 - 2s - loss: 0.0444
Epoch 45/80
 - 2s - loss: 0.0443
Epoch 46/80
 - 2s - loss: 0.0442
Epoch 47/80
 - 2s - loss: 0.0442
Epoch 48/80
 - 2s - loss: 0.0441
Epoch 49/80
 - 2s - loss: 0.0441
Epoch 50/80
 - 2s - loss: 0.0440
Epoch 51/80
 - 2s - loss: 0.0439
Epoch 52/80
 - 2s - loss: 0.0439
Epoch 53/80
 - 2s - loss: 0.0439
Epoch 54/80
 - 2s - loss: 0.0438
Epoch 55/80
 - 2s - loss: 0.0438
Epoch 56/80
 - 2s - loss: 0.0437
Epoch 57/80
 - 2s - loss: 0.0437
Epoch 58/80
 - 2s - loss: 0.0437
Epoch 59/80
 - 2s - loss: 0.0436
Epoch 60/80
 - 2s - loss: 0.0436
Epoch 61/80
 - 2s - loss: 0.0424
Epoch 62/80
 - 2s - loss: 0.0422
Epoch 63/80
 - 2s - loss: 0.0422
Epoch 64/80
 - 2s - loss: 0.0422
Epoch 65/80
 - 2s - loss: 0.0422
Epoch 66/80
 - 2s - loss: 0.0419
Epoch 67/80
 - 2s - loss: 0.0419
Epoch 68/80
 - 2s - loss: 0.0419
Epoch 69/80
 - 2s - loss: 0.0419
Epoch 70/80
 - 2s - loss: 0.0418
Epoch 71/80
 - 2s - loss: 0.0418
Epoch 72/80
 - 2s - loss: 0.0418
Epoch 73/80
 - 2s - loss: 0.0418
Epoch 74/80
 - 2s - loss: 0.0418
Epoch 75/80
 - 2s - loss: 0.0418
Epoch 76/80
 - 2s - loss: 0.0418
Epoch 77/80
 - 2s - loss: 0.0418
Epoch 78/80
 - 2s - loss: 0.0418
Epoch 79/80
 - 2s - loss: 0.0418
Epoch 80/80
 - 2s - loss: 0.0418
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 6.9688 - val_loss: 3.0547
AUC: 0.7930

Epoch 2/80
 - 0s - loss: 4.7420 - val_loss: 1.6646
AUC: 0.8276

Epoch 3/80
 - 0s - loss: 2.7538 - val_loss: 0.8373
AUC: 0.8351

Epoch 4/80
 - 0s - loss: 1.6878 - val_loss: 0.7096
AUC: 0.8448

Epoch 5/80
 - 0s - loss: 1.3608 - val_loss: 0.6644
AUC: 0.8462

Epoch 6/80
 - 0s - loss: 1.2673 - val_loss: 0.6969
AUC: 0.8477

Epoch 7/80
 - 0s - loss: 1.2022 - val_loss: 0.6861
AUC: 0.8530

Epoch 8/80
 - 0s - loss: 1.1850 - val_loss: 0.6721
AUC: 0.8549

Epoch 9/80
 - 0s - loss: 1.1592 - val_loss: 0.6298
AUC: 0.8582

Epoch 10/80
 - 0s - loss: 1.1345 - val_loss: 0.6069
AUC: 0.8595

Epoch 11/80
 - 0s - loss: 1.1265 - val_loss: 0.6242
AUC: 0.8620

Epoch 12/80
 - 0s - loss: 1.1046 - val_loss: 0.6527
AUC: 0.8625

Epoch 13/80
 - 0s - loss: 1.1133 - val_loss: 0.6567
AUC: 0.8643

Epoch 14/80
 - 0s - loss: 1.1055 - val_loss: 0.6341
AUC: 0.8644

Epoch 15/80
 - 0s - loss: 1.0816 - val_loss: 0.5979
AUC: 0.8663

Epoch 16/80
 - 0s - loss: 1.0902 - val_loss: 0.6144
AUC: 0.8673

Epoch 17/80
 - 0s - loss: 1.0709 - val_loss: 0.6822
AUC: 0.8682

Epoch 18/80
 - 0s - loss: 1.0651 - val_loss: 0.5417
AUC: 0.8679

Epoch 19/80
 - 0s - loss: 1.0725 - val_loss: 0.5402
AUC: 0.8678

Epoch 20/80
 - 0s - loss: 1.0739 - val_loss: 0.6093
AUC: 0.8694

Epoch 21/80
 - 0s - loss: 1.0530 - val_loss: 0.6837
AUC: 0.8708

Epoch 22/80
 - 0s - loss: 1.0518 - val_loss: 0.6327
AUC: 0.8701

Epoch 23/80
 - 0s - loss: 1.0597 - val_loss: 0.5790
AUC: 0.8699

Epoch 24/80
 - 0s - loss: 1.0448 - val_loss: 0.6382
AUC: 0.8721

Epoch 25/80
 - 0s - loss: 1.0378 - val_loss: 0.6717
AUC: 0.8726

Epoch 26/80
 - 0s - loss: 1.0438 - val_loss: 0.6666
AUC: 0.8723

Epoch 27/80
 - 0s - loss: 1.0359 - val_loss: 0.6302
AUC: 0.8736

Epoch 28/80
 - 0s - loss: 1.0324 - val_loss: 0.6224
AUC: 0.8737

Epoch 29/80
 - 0s - loss: 1.0278 - val_loss: 0.6130
AUC: 0.8737

Epoch 30/80
 - 0s - loss: 1.0273 - val_loss: 0.6041
AUC: 0.8737

Epoch 31/80
 - 0s - loss: 1.0203 - val_loss: 0.6043
AUC: 0.8736

Epoch 32/80
 - 0s - loss: 1.0183 - val_loss: 0.6077
AUC: 0.8738

Epoch 33/80
 - 0s - loss: 1.0228 - val_loss: 0.6221
AUC: 0.8741

Epoch 34/80
 - 0s - loss: 1.0172 - val_loss: 0.6213
AUC: 0.8745

Epoch 35/80
 - 0s - loss: 1.0203 - val_loss: 0.6070
AUC: 0.8745

Epoch 36/80
 - 0s - loss: 1.0148 - val_loss: 0.6050
AUC: 0.8743

Epoch 37/80
 - 0s - loss: 1.0238 - val_loss: 0.6005
AUC: 0.8741

Epoch 38/80
 - 0s - loss: 1.0202 - val_loss: 0.6084
AUC: 0.8746

Epoch 39/80
 - 0s - loss: 1.0126 - val_loss: 0.6028
AUC: 0.8743

Epoch 40/80
 - 0s - loss: 1.0234 - val_loss: 0.6106
AUC: 0.8745

Epoch 41/80
 - 0s - loss: 1.0100 - val_loss: 0.6038
AUC: 0.8744

Epoch 42/80
 - 0s - loss: 1.0180 - val_loss: 0.6030
AUC: 0.8744

Epoch 43/80
 - 0s - loss: 1.0161 - val_loss: 0.6037
AUC: 0.8745

Epoch 44/80
 - 0s - loss: 1.0187 - val_loss: 0.6100
AUC: 0.8746

Epoch 45/80
 - 0s - loss: 1.0078 - val_loss: 0.6104
AUC: 0.8746

Epoch 46/80
 - 0s - loss: 1.0150 - val_loss: 0.6010
AUC: 0.8745

Epoch 47/80
 - 0s - loss: 1.0117 - val_loss: 0.6005
AUC: 0.8745

Epoch 48/80
 - 0s - loss: 1.0162 - val_loss: 0.6101
AUC: 0.8747

Epoch 49/80
 - 0s - loss: 1.0156 - val_loss: 0.6051
AUC: 0.8746

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0168 - val_loss: 0.6251
AUC: 0.8751

Epoch 2/30
 - 0s - loss: 1.0163 - val_loss: 0.6025
AUC: 0.8748

Epoch 3/30
 - 0s - loss: 1.0093 - val_loss: 0.6016
AUC: 0.8749

Epoch 4/30
 - 0s - loss: 1.0130 - val_loss: 0.6173
AUC: 0.8752

Epoch 5/30
 - 0s - loss: 1.0164 - val_loss: 0.6074
AUC: 0.8754

Epoch 6/30
 - 0s - loss: 1.0107 - val_loss: 0.5991
AUC: 0.8754

Epoch 7/30
 - 0s - loss: 1.0114 - val_loss: 0.6032
AUC: 0.8756

Epoch 8/30
 - 0s - loss: 1.0079 - val_loss: 0.6188
AUC: 0.8757

Epoch 9/30
 - 0s - loss: 0.9992 - val_loss: 0.6123
AUC: 0.8758

Epoch 10/30
 - 0s - loss: 1.0043 - val_loss: 0.5959
AUC: 0.8758

Epoch 11/30
 - 0s - loss: 1.0034 - val_loss: 0.6050
AUC: 0.8760

Epoch 12/30
 - 0s - loss: 0.9957 - val_loss: 0.5988
AUC: 0.8759

Epoch 13/30
 - 0s - loss: 0.9991 - val_loss: 0.6025
AUC: 0.8758

Epoch 14/30
 - 0s - loss: 0.9983 - val_loss: 0.5902
AUC: 0.8758

Epoch 15/30
 - 0s - loss: 0.9976 - val_loss: 0.5907
AUC: 0.8759

Epoch 16/30
 - 0s - loss: 0.9896 - val_loss: 0.6059
AUC: 0.8763

Epoch 17/30
 - 0s - loss: 0.9914 - val_loss: 0.6092
AUC: 0.8765

Epoch 18/30
 - 0s - loss: 0.9870 - val_loss: 0.5995
AUC: 0.8764

Epoch 19/30
 - 0s - loss: 0.9919 - val_loss: 0.5847
AUC: 0.8763

Epoch 20/30
 - 0s - loss: 0.9971 - val_loss: 0.6095
AUC: 0.8768

Epoch 21/30
 - 0s - loss: 0.9914 - val_loss: 0.5874
AUC: 0.8767

Epoch 22/30
 - 0s - loss: 0.9870 - val_loss: 0.6056
AUC: 0.8769

Epoch 23/30
 - 0s - loss: 0.9884 - val_loss: 0.6050
AUC: 0.8771

Epoch 24/30
 - 0s - loss: 0.9782 - val_loss: 0.6052
AUC: 0.8771

Epoch 25/30
 - 0s - loss: 0.9790 - val_loss: 0.6068
AUC: 0.8772

Epoch 26/30
 - 0s - loss: 0.9796 - val_loss: 0.5958
AUC: 0.8771

Epoch 27/30
 - 0s - loss: 0.9780 - val_loss: 0.5965
AUC: 0.8773

Epoch 28/30
 - 0s - loss: 0.9842 - val_loss: 0.5862
AUC: 0.8772

Epoch 29/30
 - 0s - loss: 0.9767 - val_loss: 0.6032
AUC: 0.8775

Epoch 30/30
 - 0s - loss: 0.9742 - val_loss: 0.5900
Using TensorFlow backend.
AUC: 0.8773

2019-03-08 05:43:38.676004: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:43:38.841705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:43:38.841749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:43:39.137554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:43:39.137622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:43:39.137632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:43:39.137903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0435
Epoch 2/80
 - 2s - loss: 0.1924
Epoch 3/80
 - 2s - loss: 0.1697
Epoch 4/80
 - 2s - loss: 0.1612
Epoch 5/80
 - 2s - loss: 0.1507
Epoch 6/80
 - 2s - loss: 0.1389
Epoch 7/80
 - 2s - loss: 0.1270
Epoch 8/80
 - 2s - loss: 0.1153
Epoch 9/80
 - 2s - loss: 0.1048
Epoch 10/80
 - 2s - loss: 0.0956
Epoch 11/80
 - 2s - loss: 0.0877
Epoch 12/80
 - 2s - loss: 0.0809
Epoch 13/80
 - 2s - loss: 0.0751
Epoch 14/80
 - 2s - loss: 0.0701
Epoch 15/80
 - 2s - loss: 0.0660
Epoch 16/80
 - 2s - loss: 0.0626
Epoch 17/80
 - 2s - loss: 0.0599
Epoch 18/80
 - 2s - loss: 0.0576
Epoch 19/80
 - 2s - loss: 0.0558
Epoch 20/80
 - 2s - loss: 0.0542
Epoch 21/80
 - 2s - loss: 0.0529
Epoch 22/80
 - 2s - loss: 0.0517
Epoch 23/80
 - 2s - loss: 0.0507
Epoch 24/80
 - 2s - loss: 0.0499
Epoch 25/80
 - 2s - loss: 0.0491
Epoch 26/80
 - 2s - loss: 0.0485
Epoch 27/80
 - 2s - loss: 0.0479
Epoch 28/80
 - 2s - loss: 0.0474
Epoch 29/80
 - 2s - loss: 0.0470
Epoch 30/80
 - 2s - loss: 0.0466
Epoch 31/80
 - 2s - loss: 0.0463
Epoch 32/80
 - 2s - loss: 0.0460
Epoch 33/80
 - 2s - loss: 0.0457
Epoch 34/80
 - 2s - loss: 0.0455
Epoch 35/80
 - 2s - loss: 0.0453
Epoch 36/80
 - 2s - loss: 0.0451
Epoch 37/80
 - 2s - loss: 0.0450
Epoch 38/80
 - 2s - loss: 0.0448
Epoch 39/80
 - 2s - loss: 0.0447
Epoch 40/80
 - 2s - loss: 0.0446
Epoch 41/80
 - 2s - loss: 0.0445
Epoch 42/80
 - 2s - loss: 0.0444
Epoch 43/80
 - 2s - loss: 0.0443
Epoch 44/80
 - 2s - loss: 0.0442
Epoch 45/80
 - 2s - loss: 0.0441
Epoch 46/80
 - 2s - loss: 0.0440
Epoch 47/80
 - 2s - loss: 0.0440
Epoch 48/80
 - 2s - loss: 0.0439
Epoch 49/80
 - 2s - loss: 0.0438
Epoch 50/80
 - 2s - loss: 0.0438
Epoch 51/80
 - 2s - loss: 0.0437
Epoch 52/80
 - 2s - loss: 0.0437
Epoch 53/80
 - 2s - loss: 0.0436
Epoch 54/80
 - 2s - loss: 0.0436
Epoch 55/80
 - 2s - loss: 0.0436
Epoch 56/80
 - 2s - loss: 0.0435
Epoch 57/80
 - 2s - loss: 0.0435
Epoch 58/80
 - 2s - loss: 0.0435
Epoch 59/80
 - 2s - loss: 0.0434
Epoch 60/80
 - 2s - loss: 0.0434
Epoch 61/80
 - 2s - loss: 0.0421
Epoch 62/80
 - 2s - loss: 0.0420
Epoch 63/80
 - 2s - loss: 0.0420
Epoch 64/80
 - 2s - loss: 0.0420
Epoch 65/80
 - 2s - loss: 0.0420
Epoch 66/80
 - 2s - loss: 0.0417
Epoch 67/80
 - 2s - loss: 0.0417
Epoch 68/80
 - 2s - loss: 0.0416
Epoch 69/80
 - 2s - loss: 0.0416
Epoch 70/80
 - 2s - loss: 0.0416
Epoch 71/80
 - 2s - loss: 0.0416
Epoch 72/80
 - 2s - loss: 0.0416
Epoch 73/80
 - 2s - loss: 0.0416
Epoch 74/80
 - 2s - loss: 0.0416
Epoch 75/80
 - 2s - loss: 0.0416
Epoch 76/80
 - 2s - loss: 0.0416
Epoch 77/80
 - 2s - loss: 0.0416
Epoch 78/80
 - 2s - loss: 0.0416
Epoch 79/80
 - 2s - loss: 0.0416
Epoch 80/80
 - 2s - loss: 0.0416
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 11.3776 - val_loss: 4.4681
AUC: 0.6722

Epoch 2/80
 - 0s - loss: 5.1744 - val_loss: 2.0563
AUC: 0.7502

Epoch 3/80
 - 0s - loss: 3.6468 - val_loss: 1.2315
AUC: 0.7858

Epoch 4/80
 - 0s - loss: 2.5765 - val_loss: 1.0708
AUC: 0.8034

Epoch 5/80
 - 0s - loss: 1.9040 - val_loss: 0.7811
AUC: 0.8133

Epoch 6/80
 - 0s - loss: 1.5578 - val_loss: 0.7815
AUC: 0.8256

Epoch 7/80
 - 0s - loss: 1.3343 - val_loss: 0.7042
AUC: 0.8298

Epoch 8/80
 - 0s - loss: 1.2723 - val_loss: 0.7367
AUC: 0.8359

Epoch 9/80
 - 0s - loss: 1.2012 - val_loss: 0.6838
AUC: 0.8408

Epoch 10/80
 - 0s - loss: 1.1622 - val_loss: 0.7151
AUC: 0.8451

Epoch 11/80
 - 0s - loss: 1.1523 - val_loss: 0.6733
AUC: 0.8477

Epoch 12/80
 - 0s - loss: 1.1264 - val_loss: 0.6582
AUC: 0.8505

Epoch 13/80
 - 0s - loss: 1.1103 - val_loss: 0.6884
AUC: 0.8536

Epoch 14/80
 - 0s - loss: 1.1029 - val_loss: 0.6173
AUC: 0.8523

Epoch 15/80
 - 0s - loss: 1.0892 - val_loss: 0.6883
AUC: 0.8559

Epoch 16/80
 - 0s - loss: 1.0866 - val_loss: 0.6241
AUC: 0.8564

Epoch 17/80
 - 0s - loss: 1.0726 - val_loss: 0.6910
AUC: 0.8564

Epoch 18/80
 - 0s - loss: 1.0681 - val_loss: 0.6627
AUC: 0.8586

Epoch 19/80
 - 0s - loss: 1.0696 - val_loss: 0.6084
AUC: 0.8578

Epoch 20/80
 - 0s - loss: 1.0513 - val_loss: 0.6488
AUC: 0.8591

Epoch 21/80
 - 0s - loss: 1.0609 - val_loss: 0.6790
AUC: 0.8593

Epoch 22/80
 - 0s - loss: 1.0489 - val_loss: 0.6428
AUC: 0.8620

Epoch 23/80
 - 0s - loss: 1.0450 - val_loss: 0.6100
AUC: 0.8626

Epoch 24/80
 - 0s - loss: 1.0452 - val_loss: 0.6411
AUC: 0.8631

Epoch 25/80
 - 0s - loss: 1.0376 - val_loss: 0.6345
AUC: 0.8629

Epoch 26/80
 - 0s - loss: 1.0260 - val_loss: 0.6073
AUC: 0.8626

Epoch 27/80
 - 0s - loss: 1.0283 - val_loss: 0.6074
AUC: 0.8632

Epoch 28/80
 - 0s - loss: 1.0221 - val_loss: 0.6429
AUC: 0.8646

Epoch 29/80
 - 0s - loss: 1.0232 - val_loss: 0.6387
AUC: 0.8654

Epoch 30/80
 - 0s - loss: 1.0135 - val_loss: 0.6309
AUC: 0.8661

Epoch 31/80
 - 0s - loss: 1.0179 - val_loss: 0.6254
AUC: 0.8668

Epoch 32/80
 - 0s - loss: 1.0172 - val_loss: 0.6134
AUC: 0.8666

Epoch 33/80
 - 0s - loss: 1.0145 - val_loss: 0.5828
AUC: 0.8659

Epoch 34/80
 - 0s - loss: 1.0119 - val_loss: 0.6377
AUC: 0.8672

Epoch 35/80
 - 0s - loss: 1.0098 - val_loss: 0.5836
AUC: 0.8664

Epoch 36/80
 - 0s - loss: 1.0100 - val_loss: 0.6225
AUC: 0.8681

Epoch 37/80
 - 0s - loss: 1.0025 - val_loss: 0.5894
AUC: 0.8675

Epoch 38/80
 - 0s - loss: 1.0017 - val_loss: 0.6514
AUC: 0.8693

Epoch 39/80
 - 0s - loss: 0.9996 - val_loss: 0.5822
AUC: 0.8685

Epoch 40/80
 - 0s - loss: 0.9944 - val_loss: 0.6185
AUC: 0.8690

Epoch 41/80
 - 0s - loss: 0.9947 - val_loss: 0.6417
AUC: 0.8691

Epoch 42/80
 - 0s - loss: 0.9899 - val_loss: 0.6180
AUC: 0.8685

Epoch 43/80
 - 0s - loss: 0.9923 - val_loss: 0.5908
AUC: 0.8697

Epoch 44/80
 - 0s - loss: 0.9885 - val_loss: 0.6031
AUC: 0.8698

Epoch 45/80
 - 0s - loss: 0.9925 - val_loss: 0.5816
AUC: 0.8704

Epoch 46/80
 - 0s - loss: 0.9850 - val_loss: 0.6457
AUC: 0.8714

Epoch 47/80
 - 0s - loss: 0.9872 - val_loss: 0.5813
AUC: 0.8705

Epoch 48/80
 - 0s - loss: 0.9858 - val_loss: 0.5808
AUC: 0.8710

Epoch 49/80
 - 0s - loss: 0.9831 - val_loss: 0.5768
AUC: 0.8709

Epoch 50/80
 - 0s - loss: 0.9799 - val_loss: 0.5935
AUC: 0.8715

Epoch 51/80
 - 0s - loss: 0.9722 - val_loss: 0.6049
AUC: 0.8717

Epoch 52/80
 - 0s - loss: 0.9714 - val_loss: 0.6494
AUC: 0.8718

Epoch 53/80
 - 0s - loss: 0.9739 - val_loss: 0.5483
AUC: 0.8709

Epoch 54/80
 - 0s - loss: 0.9735 - val_loss: 0.5991
AUC: 0.8720

Epoch 55/80
 - 0s - loss: 0.9783 - val_loss: 0.5736
AUC: 0.8715

Epoch 56/80
 - 0s - loss: 0.9695 - val_loss: 0.5679
AUC: 0.8714

Epoch 57/80
 - 0s - loss: 0.9684 - val_loss: 0.5939
AUC: 0.8717

Epoch 58/80
 - 0s - loss: 0.9693 - val_loss: 0.5513
AUC: 0.8707

Epoch 59/80
 - 0s - loss: 0.9650 - val_loss: 0.5766
AUC: 0.8721

Epoch 60/80
 - 0s - loss: 0.9611 - val_loss: 0.5959
AUC: 0.8729

Epoch 61/80
 - 0s - loss: 0.9647 - val_loss: 0.5396
AUC: 0.8716

Epoch 62/80
 - 0s - loss: 0.9567 - val_loss: 0.5885
AUC: 0.8728

Epoch 63/80
 - 0s - loss: 0.9681 - val_loss: 0.5824
AUC: 0.8726

Epoch 64/80
 - 0s - loss: 0.9542 - val_loss: 0.5713
AUC: 0.8733

Epoch 65/80
 - 0s - loss: 0.9602 - val_loss: 0.6210
AUC: 0.8733

Epoch 66/80
 - 0s - loss: 0.9548 - val_loss: 0.5875
AUC: 0.8741

Epoch 67/80
 - 0s - loss: 0.9520 - val_loss: 0.6051
AUC: 0.8739

Epoch 68/80
 - 0s - loss: 0.9538 - val_loss: 0.5846
AUC: 0.8736

Epoch 69/80
 - 0s - loss: 0.9564 - val_loss: 0.5805
AUC: 0.8731

Epoch 70/80
 - 0s - loss: 0.9532 - val_loss: 0.5328
AUC: 0.8730

Epoch 71/80
 - 0s - loss: 0.9543 - val_loss: 0.5636
AUC: 0.8729

Epoch 72/80
 - 0s - loss: 0.9436 - val_loss: 0.6038
AUC: 0.8741

Epoch 73/80
 - 0s - loss: 0.9479 - val_loss: 0.6131
AUC: 0.8740

Epoch 74/80
 - 0s - loss: 0.9456 - val_loss: 0.5654
AUC: 0.8728

Epoch 75/80
 - 0s - loss: 0.9494 - val_loss: 0.5805
AUC: 0.8738

Epoch 76/80
 - 0s - loss: 0.9479 - val_loss: 0.5708
AUC: 0.8740

Epoch 77/80
 - 0s - loss: 0.9440 - val_loss: 0.5767
AUC: 0.8734

Epoch 78/80
 - 0s - loss: 0.9387 - val_loss: 0.6245
AUC: 0.8744

Epoch 79/80
 - 0s - loss: 0.9413 - val_loss: 0.5914
AUC: 0.8746

Epoch 80/80
 - 0s - loss: 0.9401 - val_loss: 0.5571
AUC: 0.8741

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9336 - val_loss: 0.5774
AUC: 0.8746

Epoch 2/30
 - 0s - loss: 0.9328 - val_loss: 0.5700
AUC: 0.8745

Epoch 3/30
 - 0s - loss: 0.9344 - val_loss: 0.5728
AUC: 0.8746

Epoch 4/30
 - 0s - loss: 0.9223 - val_loss: 0.5772
AUC: 0.8746

Epoch 5/30
 - 0s - loss: 0.9287 - val_loss: 0.5733
AUC: 0.8745

Epoch 6/30
 - 0s - loss: 0.9267 - val_loss: 0.5744
AUC: 0.8747

Epoch 7/30
 - 0s - loss: 0.9223 - val_loss: 0.5770
AUC: 0.8749

Epoch 8/30
 - 0s - loss: 0.9237 - val_loss: 0.5648
AUC: 0.8747

Epoch 9/30
 - 0s - loss: 0.9205 - val_loss: 0.5618
AUC: 0.8748

Epoch 10/30
 - 0s - loss: 0.9194 - val_loss: 0.5791
AUC: 0.8749

Epoch 11/30
 - 0s - loss: 0.9203 - val_loss: 0.5764
AUC: 0.8749

Epoch 12/30
 - 0s - loss: 0.9149 - val_loss: 0.5689
AUC: 0.8749

Epoch 13/30
 - 0s - loss: 0.9151 - val_loss: 0.5741
AUC: 0.8750

Epoch 14/30
 - 0s - loss: 0.9191 - val_loss: 0.5642
AUC: 0.8749

Epoch 15/30
 - 0s - loss: 0.9149 - val_loss: 0.5886
AUC: 0.8751

Epoch 16/30
 - 0s - loss: 0.9160 - val_loss: 0.5726
AUC: 0.8751

Epoch 17/30
 - 0s - loss: 0.9090 - val_loss: 0.5816
AUC: 0.8752

Epoch 18/30
 - 0s - loss: 0.9070 - val_loss: 0.5659
AUC: 0.8752

Epoch 19/30
 - 0s - loss: 0.9116 - val_loss: 0.5636
AUC: 0.8752

Epoch 20/30
 - 0s - loss: 0.9077 - val_loss: 0.5660
AUC: 0.8752

Epoch 21/30
 - 0s - loss: 0.9094 - val_loss: 0.5682
AUC: 0.8753

Epoch 22/30
 - 0s - loss: 0.9026 - val_loss: 0.5663
AUC: 0.8753

Epoch 23/30
 - 0s - loss: 0.9119 - val_loss: 0.5675
AUC: 0.8754

Epoch 24/30
 - 0s - loss: 0.9067 - val_loss: 0.5662
AUC: 0.8753

Epoch 25/30
 - 0s - loss: 0.9025 - val_loss: 0.5659
AUC: 0.8753

Epoch 26/30
 - 0s - loss: 0.9017 - val_loss: 0.5663
AUC: 0.8754

Epoch 27/30
 - 0s - loss: 0.9102 - val_loss: 0.5675
AUC: 0.8753

Epoch 28/30
 - 0s - loss: 0.9073 - val_loss: 0.5652
AUC: 0.8753

Epoch 29/30
 - 0s - loss: 0.9076 - val_loss: 0.5683
AUC: 0.8754

Epoch 30/30
 - 0s - loss: 0.9047 - val_loss: 0.5676
Using TensorFlow backend.
AUC: 0.8754

2019-03-08 05:47:15.710447: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:47:15.875981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:47:15.876026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:47:16.173287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:47:16.173357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:47:16.173379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:47:16.173675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6648
Epoch 2/80
 - 2s - loss: 0.1048
Epoch 3/80
 - 2s - loss: 0.0681
Epoch 4/80
 - 2s - loss: 0.0628
Epoch 5/80
 - 2s - loss: 0.0591
Epoch 6/80
 - 2s - loss: 0.0547
Epoch 7/80
 - 2s - loss: 0.0497
Epoch 8/80
 - 2s - loss: 0.0448
Epoch 9/80
 - 2s - loss: 0.0404
Epoch 10/80
 - 2s - loss: 0.0369
Epoch 11/80
 - 2s - loss: 0.0341
Epoch 12/80
 - 2s - loss: 0.0317
Epoch 13/80
 - 2s - loss: 0.0296
Epoch 14/80
 - 2s - loss: 0.0277
Epoch 15/80
 - 2s - loss: 0.0259
Epoch 16/80
 - 2s - loss: 0.0244
Epoch 17/80
 - 2s - loss: 0.0231
Epoch 18/80
 - 2s - loss: 0.0219
Epoch 19/80
 - 2s - loss: 0.0209
Epoch 20/80
 - 2s - loss: 0.0200
Epoch 21/80
 - 2s - loss: 0.0193
Epoch 22/80
 - 2s - loss: 0.0186
Epoch 23/80
 - 2s - loss: 0.0180
Epoch 24/80
 - 2s - loss: 0.0176
Epoch 25/80
 - 2s - loss: 0.0171
Epoch 26/80
 - 2s - loss: 0.0168
Epoch 27/80
 - 2s - loss: 0.0165
Epoch 28/80
 - 2s - loss: 0.0162
Epoch 29/80
 - 2s - loss: 0.0160
Epoch 30/80
 - 2s - loss: 0.0158
Epoch 31/80
 - 2s - loss: 0.0156
Epoch 32/80
 - 2s - loss: 0.0154
Epoch 33/80
 - 2s - loss: 0.0153
Epoch 34/80
 - 2s - loss: 0.0151
Epoch 35/80
 - 2s - loss: 0.0150
Epoch 36/80
 - 2s - loss: 0.0149
Epoch 37/80
 - 2s - loss: 0.0149
Epoch 38/80
 - 2s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0147
Epoch 40/80
 - 2s - loss: 0.0146
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0145
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0144
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0144
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:48:51.577550: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:48:51.739944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:48:51.739987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:48:52.034161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:48:52.034231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:48:52.034241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:48:52.034525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6640
Epoch 2/80
 - 2s - loss: 0.1062
Epoch 3/80
 - 2s - loss: 0.0696
Epoch 4/80
 - 2s - loss: 0.0640
Epoch 5/80
 - 2s - loss: 0.0607
Epoch 6/80
 - 2s - loss: 0.0567
Epoch 7/80
 - 2s - loss: 0.0519
Epoch 8/80
 - 2s - loss: 0.0470
Epoch 9/80
 - 2s - loss: 0.0426
Epoch 10/80
 - 2s - loss: 0.0387
Epoch 11/80
 - 2s - loss: 0.0353
Epoch 12/80
 - 2s - loss: 0.0324
Epoch 13/80
 - 2s - loss: 0.0299
Epoch 14/80
 - 2s - loss: 0.0277
Epoch 15/80
 - 2s - loss: 0.0259
Epoch 16/80
 - 2s - loss: 0.0243
Epoch 17/80
 - 2s - loss: 0.0230
Epoch 18/80
 - 2s - loss: 0.0218
Epoch 19/80
 - 2s - loss: 0.0208
Epoch 20/80
 - 2s - loss: 0.0199
Epoch 21/80
 - 2s - loss: 0.0192
Epoch 22/80
 - 2s - loss: 0.0186
Epoch 23/80
 - 2s - loss: 0.0180
Epoch 24/80
 - 2s - loss: 0.0175
Epoch 25/80
 - 2s - loss: 0.0171
Epoch 26/80
 - 2s - loss: 0.0167
Epoch 27/80
 - 2s - loss: 0.0164
Epoch 28/80
 - 2s - loss: 0.0162
Epoch 29/80
 - 2s - loss: 0.0159
Epoch 30/80
 - 2s - loss: 0.0157
Epoch 31/80
 - 2s - loss: 0.0155
Epoch 32/80
 - 2s - loss: 0.0154
Epoch 33/80
 - 2s - loss: 0.0152
Epoch 34/80
 - 2s - loss: 0.0151
Epoch 35/80
 - 2s - loss: 0.0150
Epoch 36/80
 - 2s - loss: 0.0149
Epoch 37/80
 - 2s - loss: 0.0148
Epoch 38/80
 - 2s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0147
Epoch 40/80
 - 2s - loss: 0.0146
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0145
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0144
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 2s - loss: 0.0143
Epoch 48/80
 - 2s - loss: 0.0143
Epoch 49/80
 - 2s - loss: 0.0143
Epoch 50/80
 - 2s - loss: 0.0138
Epoch 51/80
 - 2s - loss: 0.0138
Epoch 52/80
 - 2s - loss: 0.0137
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 2s - loss: 0.0136
Epoch 55/80
 - 2s - loss: 0.0136
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 2s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0136
Epoch 62/80
 - 2s - loss: 0.0136
Epoch 63/80
 - 2s - loss: 0.0136
Epoch 64/80
 - 2s - loss: 0.0136
Epoch 65/80
 - 2s - loss: 0.0136
Epoch 66/80
 - 2s - loss: 0.0136
Epoch 67/80
 - 2s - loss: 0.0136
Epoch 68/80
 - 2s - loss: 0.0136
Epoch 69/80
 - 2s - loss: 0.0136
Epoch 70/80
 - 2s - loss: 0.0136
Epoch 71/80
 - 2s - loss: 0.0136
Epoch 72/80
 - 2s - loss: 0.0136
Epoch 73/80
 - 2s - loss: 0.0136
Epoch 74/80
 - 2s - loss: 0.0136
Epoch 75/80
 - 2s - loss: 0.0136
Epoch 76/80
 - 2s - loss: 0.0136
Epoch 77/80
 - 2s - loss: 0.0136
Epoch 78/80
 - 2s - loss: 0.0136
Epoch 79/80
 - 2s - loss: 0.0136
Epoch 80/80
 - 2s - loss: 0.0136
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 6.2697 - val_loss: 1.7635
AUC: 0.7289

Epoch 2/80
 - 0s - loss: 3.8633 - val_loss: 1.4338
AUC: 0.7801

Epoch 3/80
 - 0s - loss: 2.5961 - val_loss: 1.1058
AUC: 0.8135

Epoch 4/80
 - 0s - loss: 1.7223 - val_loss: 0.7488
AUC: 0.8213

Epoch 5/80
 - 0s - loss: 1.4243 - val_loss: 0.7659
AUC: 0.8304

Epoch 6/80
 - 0s - loss: 1.3023 - val_loss: 0.6707
AUC: 0.8337

Epoch 7/80
 - 0s - loss: 1.2307 - val_loss: 0.6327
AUC: 0.8394

Epoch 8/80
 - 0s - loss: 1.2055 - val_loss: 0.6860
AUC: 0.8440

Epoch 9/80
 - 0s - loss: 1.1606 - val_loss: 0.6910
AUC: 0.8456

Epoch 10/80
 - 0s - loss: 1.1448 - val_loss: 0.6776
AUC: 0.8486

Epoch 11/80
 - 0s - loss: 1.1339 - val_loss: 0.6497
AUC: 0.8499

Epoch 12/80
 - 0s - loss: 1.1151 - val_loss: 0.6816
AUC: 0.8509

Epoch 13/80
 - 0s - loss: 1.1133 - val_loss: 0.6187
AUC: 0.8516

Epoch 14/80
 - 0s - loss: 1.1099 - val_loss: 0.6688
AUC: 0.8534

Epoch 15/80
 - 0s - loss: 1.0896 - val_loss: 0.6888
AUC: 0.8554

Epoch 16/80
 - 0s - loss: 1.0916 - val_loss: 0.6255
AUC: 0.8550

Epoch 17/80
 - 0s - loss: 1.0720 - val_loss: 0.6509
AUC: 0.8556

Epoch 18/80
 - 0s - loss: 1.0754 - val_loss: 0.6481
AUC: 0.8572

Epoch 19/80
 - 0s - loss: 1.0703 - val_loss: 0.6580
AUC: 0.8588

Epoch 20/80
 - 0s - loss: 1.0652 - val_loss: 0.6485
AUC: 0.8590

Epoch 21/80
 - 0s - loss: 1.0629 - val_loss: 0.6889
AUC: 0.8601

Epoch 22/80
 - 0s - loss: 1.0679 - val_loss: 0.6652
AUC: 0.8601

Epoch 23/80
 - 0s - loss: 1.0623 - val_loss: 0.6424
AUC: 0.8609

Epoch 24/80
 - 0s - loss: 1.0531 - val_loss: 0.6411
AUC: 0.8611

Epoch 25/80
 - 0s - loss: 1.0471 - val_loss: 0.6201
AUC: 0.8604

Epoch 26/80
 - 0s - loss: 1.0487 - val_loss: 0.6713
AUC: 0.8612

Epoch 27/80
 - 0s - loss: 1.0501 - val_loss: 0.6470
AUC: 0.8611

Epoch 28/80
 - 0s - loss: 1.0485 - val_loss: 0.6192
AUC: 0.8605

Epoch 29/80
 - 0s - loss: 1.0410 - val_loss: 0.6308
AUC: 0.8608

Epoch 30/80
 - 0s - loss: 1.0409 - val_loss: 0.6166
AUC: 0.8607

Epoch 31/80
 - 0s - loss: 1.0442 - val_loss: 0.6543
AUC: 0.8616

Epoch 32/80
 - 0s - loss: 1.0404 - val_loss: 0.6510
AUC: 0.8615

Epoch 33/80
 - 0s - loss: 1.0449 - val_loss: 0.6197
AUC: 0.8612

Epoch 34/80
 - 0s - loss: 1.0373 - val_loss: 0.6345
AUC: 0.8615

Epoch 35/80
 - 0s - loss: 1.0420 - val_loss: 0.6409
AUC: 0.8618

Epoch 36/80
 - 0s - loss: 1.0405 - val_loss: 0.6334
AUC: 0.8616

Epoch 37/80
 - 0s - loss: 1.0394 - val_loss: 0.6536
AUC: 0.8620

Epoch 38/80
 - 0s - loss: 1.0428 - val_loss: 0.6167
AUC: 0.8617

Epoch 39/80
 - 0s - loss: 1.0368 - val_loss: 0.6308
AUC: 0.8621

Epoch 40/80
 - 0s - loss: 1.0414 - val_loss: 0.6316
AUC: 0.8621

Epoch 41/80
 - 0s - loss: 1.0374 - val_loss: 0.6295
AUC: 0.8620

Epoch 42/80
 - 0s - loss: 1.0419 - val_loss: 0.6348
AUC: 0.8622

Epoch 43/80
 - 0s - loss: 1.0322 - val_loss: 0.6322
AUC: 0.8621

Epoch 44/80
 - 0s - loss: 1.0260 - val_loss: 0.6334
AUC: 0.8621

Epoch 45/80
 - 0s - loss: 1.0351 - val_loss: 0.6255
AUC: 0.8620

Epoch 46/80
 - 0s - loss: 1.0305 - val_loss: 0.6228
AUC: 0.8620

Epoch 47/80
 - 0s - loss: 1.0331 - val_loss: 0.6285
AUC: 0.8621

Epoch 48/80
 - 0s - loss: 1.0329 - val_loss: 0.6269
AUC: 0.8621

Epoch 49/80
 - 0s - loss: 1.0360 - val_loss: 0.6296
AUC: 0.8622

Epoch 50/80
 - 0s - loss: 1.0391 - val_loss: 0.6309
AUC: 0.8622

Epoch 51/80
 - 0s - loss: 1.0357 - val_loss: 0.6305
AUC: 0.8622

Epoch 52/80
 - 0s - loss: 1.0356 - val_loss: 0.6303
AUC: 0.8622

Epoch 53/80
 - 0s - loss: 1.0374 - val_loss: 0.6304
AUC: 0.8622

Epoch 54/80
 - 0s - loss: 1.0269 - val_loss: 0.6283
AUC: 0.8622

Epoch 55/80
 - 0s - loss: 1.0339 - val_loss: 0.6288
AUC: 0.8622

Epoch 56/80
 - 0s - loss: 1.0247 - val_loss: 0.6293
AUC: 0.8622

Epoch 57/80
 - 0s - loss: 1.0273 - val_loss: 0.6290
AUC: 0.8622

Epoch 58/80
 - 0s - loss: 1.0347 - val_loss: 0.6304
AUC: 0.8622

Epoch 59/80
 - 0s - loss: 1.0320 - val_loss: 0.6303
AUC: 0.8622

Epoch 60/80
 - 0s - loss: 1.0349 - val_loss: 0.6302
AUC: 0.8622

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0238 - val_loss: 0.6198
AUC: 0.8622

Epoch 2/30
 - 0s - loss: 1.0286 - val_loss: 0.6456
AUC: 0.8627

Epoch 3/30
 - 0s - loss: 1.0310 - val_loss: 0.6160
AUC: 0.8624

Epoch 4/30
 - 0s - loss: 1.0282 - val_loss: 0.6216
AUC: 0.8627

Epoch 5/30
 - 0s - loss: 1.0270 - val_loss: 0.6203
AUC: 0.8630

Epoch 6/30
 - 0s - loss: 1.0295 - val_loss: 0.6356
AUC: 0.8635

Epoch 7/30
 - 0s - loss: 1.0165 - val_loss: 0.6201
AUC: 0.8633

Epoch 8/30
 - 0s - loss: 1.0227 - val_loss: 0.6156
AUC: 0.8636

Epoch 9/30
 - 0s - loss: 1.0236 - val_loss: 0.6182
AUC: 0.8637

Epoch 10/30
 - 0s - loss: 1.0203 - val_loss: 0.6326
AUC: 0.8640

Epoch 11/30
 - 0s - loss: 1.0133 - val_loss: 0.6215
AUC: 0.8641

Epoch 12/30
 - 0s - loss: 1.0182 - val_loss: 0.6070
AUC: 0.8641

Epoch 13/30
 - 0s - loss: 1.0191 - val_loss: 0.6151
AUC: 0.8645

Epoch 14/30
 - 0s - loss: 1.0098 - val_loss: 0.6334
AUC: 0.8649

Epoch 15/30
 - 0s - loss: 1.0103 - val_loss: 0.6082
AUC: 0.8647

Epoch 16/30
 - 0s - loss: 1.0081 - val_loss: 0.6189
AUC: 0.8651

Epoch 17/30
 - 0s - loss: 1.0039 - val_loss: 0.6338
AUC: 0.8654

Epoch 18/30
 - 0s - loss: 1.0051 - val_loss: 0.6143
AUC: 0.8653

Epoch 19/30
 - 0s - loss: 1.0027 - val_loss: 0.6156
AUC: 0.8656

Epoch 20/30
 - 0s - loss: 1.0045 - val_loss: 0.6128
AUC: 0.8657

Epoch 21/30
 - 0s - loss: 0.9994 - val_loss: 0.6133
AUC: 0.8658

Epoch 22/30
 - 0s - loss: 0.9980 - val_loss: 0.6120
AUC: 0.8661

Epoch 23/30
 - 0s - loss: 1.0026 - val_loss: 0.6137
AUC: 0.8662

Epoch 24/30
 - 0s - loss: 1.0027 - val_loss: 0.6133
AUC: 0.8662

Epoch 25/30
 - 0s - loss: 0.9978 - val_loss: 0.6123
AUC: 0.8662

Epoch 26/30
 - 0s - loss: 0.9946 - val_loss: 0.6116
AUC: 0.8661

Epoch 27/30
 - 0s - loss: 0.9981 - val_loss: 0.6133
AUC: 0.8662

Epoch 28/30
 - 0s - loss: 0.9985 - val_loss: 0.6110
AUC: 0.8662

Epoch 29/30
 - 0s - loss: 1.0004 - val_loss: 0.6116
AUC: 0.8662

Epoch 30/30
 - 0s - loss: 1.0012 - val_loss: 0.6156
Using TensorFlow backend.
AUC: 0.8662

2019-03-08 05:52:16.556116: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:52:16.722180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:52:16.722225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:52:17.017459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:52:17.017522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:52:17.017531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:52:17.017783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6483
Epoch 2/80
 - 2s - loss: 0.0988
Epoch 3/80
 - 2s - loss: 0.0684
Epoch 4/80
 - 2s - loss: 0.0639
Epoch 5/80
 - 2s - loss: 0.0610
Epoch 6/80
 - 2s - loss: 0.0576
Epoch 7/80
 - 2s - loss: 0.0534
Epoch 8/80
 - 2s - loss: 0.0489
Epoch 9/80
 - 2s - loss: 0.0446
Epoch 10/80
 - 2s - loss: 0.0408
Epoch 11/80
 - 2s - loss: 0.0374
Epoch 12/80
 - 2s - loss: 0.0342
Epoch 13/80
 - 2s - loss: 0.0313
Epoch 14/80
 - 2s - loss: 0.0287
Epoch 15/80
 - 2s - loss: 0.0265
Epoch 16/80
 - 2s - loss: 0.0247
Epoch 17/80
 - 2s - loss: 0.0232
Epoch 18/80
 - 2s - loss: 0.0219
Epoch 19/80
 - 2s - loss: 0.0209
Epoch 20/80
 - 2s - loss: 0.0200
Epoch 21/80
 - 2s - loss: 0.0193
Epoch 22/80
 - 2s - loss: 0.0187
Epoch 23/80
 - 2s - loss: 0.0181
Epoch 24/80
 - 2s - loss: 0.0176
Epoch 25/80
 - 2s - loss: 0.0172
Epoch 26/80
 - 2s - loss: 0.0169
Epoch 27/80
 - 2s - loss: 0.0165
Epoch 28/80
 - 2s - loss: 0.0163
Epoch 29/80
 - 2s - loss: 0.0160
Epoch 30/80
 - 2s - loss: 0.0158
Epoch 31/80
 - 2s - loss: 0.0156
Epoch 32/80
 - 2s - loss: 0.0155
Epoch 33/80
 - 2s - loss: 0.0153
Epoch 34/80
 - 2s - loss: 0.0152
Epoch 35/80
 - 2s - loss: 0.0151
Epoch 36/80
 - 2s - loss: 0.0150
Epoch 37/80
 - 2s - loss: 0.0149
Epoch 38/80
 - 2s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0148
Epoch 40/80
 - 2s - loss: 0.0147
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0146
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0145
Epoch 45/80
 - 2s - loss: 0.0145
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 2s - loss: 0.0144
Epoch 48/80
 - 2s - loss: 0.0144
Epoch 49/80
 - 2s - loss: 0.0143
Epoch 50/80
 - 2s - loss: 0.0143
Epoch 51/80
 - 2s - loss: 0.0143
Epoch 52/80
 - 2s - loss: 0.0138
Epoch 53/80
 - 2s - loss: 0.0138
Epoch 54/80
 - 2s - loss: 0.0138
Epoch 55/80
 - 2s - loss: 0.0138
Epoch 56/80
 - 2s - loss: 0.0137
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 2s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0136
Epoch 62/80
 - 2s - loss: 0.0136
Epoch 63/80
 - 2s - loss: 0.0136
Epoch 64/80
 - 2s - loss: 0.0136
Epoch 65/80
 - 2s - loss: 0.0136
Epoch 66/80
 - 2s - loss: 0.0136
Epoch 67/80
 - 2s - loss: 0.0136
Epoch 68/80
 - 2s - loss: 0.0136
Epoch 69/80
 - 2s - loss: 0.0136
Epoch 70/80
 - 2s - loss: 0.0136
Epoch 71/80
 - 2s - loss: 0.0136
Epoch 72/80
 - 2s - loss: 0.0136
Epoch 73/80
 - 2s - loss: 0.0136
Epoch 74/80
 - 2s - loss: 0.0136
Epoch 75/80
 - 2s - loss: 0.0136
Epoch 76/80
 - 2s - loss: 0.0136
Epoch 77/80
 - 2s - loss: 0.0136
Epoch 78/80
 - 2s - loss: 0.0136
Epoch 79/80
 - 2s - loss: 0.0136
Epoch 80/80
 - 2s - loss: 0.0136
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.8751 - val_loss: 1.4682
AUC: 0.7853

Epoch 2/80
 - 0s - loss: 2.7533 - val_loss: 0.8999
AUC: 0.8092

Epoch 3/80
 - 0s - loss: 1.7244 - val_loss: 0.7563
AUC: 0.8200

Epoch 4/80
 - 0s - loss: 1.3743 - val_loss: 0.7656
AUC: 0.8282

Epoch 5/80
 - 0s - loss: 1.2656 - val_loss: 0.7033
AUC: 0.8342

Epoch 6/80
 - 0s - loss: 1.2129 - val_loss: 0.6815
AUC: 0.8391

Epoch 7/80
 - 0s - loss: 1.1853 - val_loss: 0.6727
AUC: 0.8421

Epoch 8/80
 - 0s - loss: 1.1510 - val_loss: 0.6698
AUC: 0.8475

Epoch 9/80
 - 0s - loss: 1.1351 - val_loss: 0.6947
AUC: 0.8510

Epoch 10/80
 - 0s - loss: 1.1223 - val_loss: 0.6473
AUC: 0.8507

Epoch 11/80
 - 0s - loss: 1.1143 - val_loss: 0.6331
AUC: 0.8521

Epoch 12/80
 - 0s - loss: 1.1044 - val_loss: 0.6544
AUC: 0.8545

Epoch 13/80
 - 0s - loss: 1.0864 - val_loss: 0.5911
AUC: 0.8549

Epoch 14/80
 - 0s - loss: 1.0779 - val_loss: 0.6463
AUC: 0.8569

Epoch 15/80
 - 0s - loss: 1.0744 - val_loss: 0.6240
AUC: 0.8570

Epoch 16/80
 - 0s - loss: 1.0742 - val_loss: 0.6675
AUC: 0.8576

Epoch 17/80
 - 0s - loss: 1.0664 - val_loss: 0.6603
AUC: 0.8585

Epoch 18/80
 - 0s - loss: 1.0555 - val_loss: 0.6292
AUC: 0.8583

Epoch 19/80
 - 0s - loss: 1.0558 - val_loss: 0.6406
AUC: 0.8583

Epoch 20/80
 - 0s - loss: 1.0468 - val_loss: 0.5901
AUC: 0.8583

Epoch 21/80
 - 0s - loss: 1.0455 - val_loss: 0.6798
AUC: 0.8603

Epoch 22/80
 - 0s - loss: 1.0435 - val_loss: 0.6695
AUC: 0.8600

Epoch 23/80
 - 0s - loss: 1.0463 - val_loss: 0.5967
AUC: 0.8591

Epoch 24/80
 - 0s - loss: 1.0402 - val_loss: 0.6357
AUC: 0.8594

Epoch 25/80
 - 0s - loss: 1.0337 - val_loss: 0.6585
AUC: 0.8614

Epoch 26/80
 - 0s - loss: 1.0340 - val_loss: 0.6091
AUC: 0.8612

Epoch 27/80
 - 0s - loss: 1.0299 - val_loss: 0.6062
AUC: 0.8614

Epoch 28/80
 - 0s - loss: 1.0300 - val_loss: 0.6004
AUC: 0.8615

Epoch 29/80
 - 0s - loss: 1.0276 - val_loss: 0.6006
AUC: 0.8616

Epoch 30/80
 - 0s - loss: 1.0241 - val_loss: 0.6323
AUC: 0.8626

Epoch 31/80
 - 0s - loss: 1.0194 - val_loss: 0.6138
AUC: 0.8627

Epoch 32/80
 - 0s - loss: 1.0164 - val_loss: 0.6217
AUC: 0.8629

Epoch 33/80
 - 0s - loss: 1.0188 - val_loss: 0.6228
AUC: 0.8628

Epoch 34/80
 - 0s - loss: 1.0083 - val_loss: 0.6075
AUC: 0.8627

Epoch 35/80
 - 0s - loss: 1.0092 - val_loss: 0.6109
AUC: 0.8629

Epoch 36/80
 - 0s - loss: 1.0128 - val_loss: 0.5982
AUC: 0.8629

Epoch 37/80
 - 0s - loss: 1.0128 - val_loss: 0.6145
AUC: 0.8630

Epoch 38/80
 - 0s - loss: 1.0111 - val_loss: 0.6267
AUC: 0.8635

Epoch 39/80
 - 0s - loss: 1.0105 - val_loss: 0.6137
AUC: 0.8632

Epoch 40/80
 - 0s - loss: 1.0114 - val_loss: 0.6352
AUC: 0.8638

Epoch 41/80
 - 0s - loss: 1.0069 - val_loss: 0.6193
AUC: 0.8636

Epoch 42/80
 - 0s - loss: 1.0135 - val_loss: 0.6198
AUC: 0.8637

Epoch 43/80
 - 0s - loss: 0.9981 - val_loss: 0.6195
AUC: 0.8636

Epoch 44/80
 - 0s - loss: 1.0137 - val_loss: 0.6192
AUC: 0.8636

Epoch 45/80
 - 0s - loss: 1.0082 - val_loss: 0.6200
AUC: 0.8636

Epoch 46/80
 - 0s - loss: 1.0063 - val_loss: 0.6145
AUC: 0.8635

Epoch 47/80
 - 0s - loss: 1.0034 - val_loss: 0.6233
AUC: 0.8637

Epoch 48/80
 - 0s - loss: 1.0100 - val_loss: 0.6161
AUC: 0.8636

Epoch 49/80
 - 0s - loss: 1.0101 - val_loss: 0.6186
AUC: 0.8635

Epoch 50/80
 - 0s - loss: 1.0095 - val_loss: 0.6209
AUC: 0.8636

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0144 - val_loss: 0.6013
AUC: 0.8635

Epoch 2/30
 - 0s - loss: 1.0064 - val_loss: 0.6280
AUC: 0.8640

Epoch 3/30
 - 0s - loss: 1.0071 - val_loss: 0.6154
AUC: 0.8639

Epoch 4/30
 - 0s - loss: 1.0035 - val_loss: 0.6218
AUC: 0.8641

Epoch 5/30
 - 0s - loss: 1.0017 - val_loss: 0.6294
AUC: 0.8643

Epoch 6/30
 - 0s - loss: 1.0116 - val_loss: 0.6091
AUC: 0.8644

Epoch 7/30
 - 0s - loss: 1.0037 - val_loss: 0.6151
AUC: 0.8645

Epoch 8/30
 - 0s - loss: 1.0040 - val_loss: 0.6087
AUC: 0.8646

Epoch 9/30
 - 0s - loss: 0.9948 - val_loss: 0.6021
AUC: 0.8646

Epoch 10/30
 - 0s - loss: 0.9944 - val_loss: 0.6209
AUC: 0.8649

Epoch 11/30
 - 0s - loss: 0.9965 - val_loss: 0.6170
AUC: 0.8651

Epoch 12/30
 - 0s - loss: 0.9967 - val_loss: 0.6150
AUC: 0.8651

Epoch 13/30
 - 0s - loss: 0.9876 - val_loss: 0.6128
AUC: 0.8651

Epoch 14/30
 - 0s - loss: 0.9938 - val_loss: 0.6150
AUC: 0.8651

Epoch 15/30
 - 0s - loss: 0.9954 - val_loss: 0.6112
AUC: 0.8651

Epoch 16/30
 - 0s - loss: 0.9899 - val_loss: 0.6104
AUC: 0.8651

Epoch 17/30
 - 0s - loss: 0.9960 - val_loss: 0.6138
AUC: 0.8651

Epoch 18/30
 - 0s - loss: 0.9900 - val_loss: 0.6101
AUC: 0.8651

Epoch 19/30
 - 0s - loss: 0.9890 - val_loss: 0.6111
AUC: 0.8652

Epoch 20/30
 - 0s - loss: 0.9969 - val_loss: 0.6102
AUC: 0.8651

Epoch 21/30
 - 0s - loss: 0.9928 - val_loss: 0.6147
AUC: 0.8652

Epoch 22/30
 - 0s - loss: 0.9956 - val_loss: 0.6133
AUC: 0.8652

Epoch 23/30
 - 0s - loss: 0.9885 - val_loss: 0.6125
AUC: 0.8652

Epoch 24/30
 - 0s - loss: 0.9994 - val_loss: 0.6124
AUC: 0.8652

Epoch 25/30
 - 0s - loss: 0.9921 - val_loss: 0.6121
AUC: 0.8652

Epoch 26/30
 - 0s - loss: 0.9978 - val_loss: 0.6118
AUC: 0.8652

Epoch 27/30
 - 0s - loss: 0.9894 - val_loss: 0.6126
AUC: 0.8652

Epoch 28/30
 - 0s - loss: 0.9927 - val_loss: 0.6108
AUC: 0.8652

Epoch 29/30
 - 0s - loss: 0.9932 - val_loss: 0.6116
AUC: 0.8652

Epoch 30/30
 - 0s - loss: 0.9896 - val_loss: 0.6101
Using TensorFlow backend.
AUC: 0.8652

2019-03-08 05:55:34.864259: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:55:35.030094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:55:35.030137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:55:35.332329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:55:35.332378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:55:35.332388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:55:35.332701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3179
Epoch 2/80
 - 2s - loss: 0.3319
Epoch 3/80
 - 2s - loss: 0.2969
Epoch 4/80
 - 2s - loss: 0.2712
Epoch 5/80
 - 2s - loss: 0.2451
Epoch 6/80
 - 2s - loss: 0.2236
Epoch 7/80
 - 2s - loss: 0.2056
Epoch 8/80
 - 2s - loss: 0.1898
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 05:56:05.889371: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:56:06.052517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:56:06.052559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:56:06.351463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:56:06.351530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:56:06.351538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:56:06.351796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2972
Epoch 2/80
 - 2s - loss: 0.3290
Epoch 3/80
 - 2s - loss: 0.2833
Epoch 4/80
 - 2s - loss: 0.2515
Epoch 5/80
 - 2s - loss: 0.2280
Epoch 6/80
 - 2s - loss: 0.2123
Epoch 7/80
 - 2s - loss: 0.1988
Epoch 8/80
 - 2s - loss: 0.1857
Epoch 9/80
 - 2s - loss: 0.1738
Epoch 10/80
 - 2s - loss: 0.1637
Epoch 11/80
 - 2s - loss: 0.1551
Epoch 12/80
 - 2s - loss: 0.1479
Epoch 13/80
 - 2s - loss: 0.1415
Epoch 14/80
 - 2s - loss: 0.1361
Epoch 15/80
 - 2s - loss: 0.1312
Epoch 16/80
 - 2s - loss: 0.1271
Epoch 17/80
 - 2s - loss: 0.1236
Epoch 18/80
 - 2s - loss: 0.1206
Epoch 19/80
 - 2s - loss: 0.1182
Epoch 20/80
 - 2s - loss: 0.1161
Epoch 21/80
 - 2s - loss: 0.1143
Epoch 22/80
 - 2s - loss: 0.1127
Epoch 23/80
 - 2s - loss: 0.1113
Epoch 24/80
 - 2s - loss: 0.1101
Epoch 25/80
 - 2s - loss: 0.1091
Epoch 26/80
 - 2s - loss: 0.1082
Epoch 27/80
 - 2s - loss: 0.1074
Epoch 28/80
 - 2s - loss: 0.1068
Epoch 29/80
 - 2s - loss: 0.1062
Epoch 30/80
 - 2s - loss: 0.1057
Epoch 31/80
 - 2s - loss: 0.1053
Epoch 32/80
 - 2s - loss: 0.1049
Epoch 33/80
 - 2s - loss: 0.1046
Epoch 34/80
 - 2s - loss: 0.1043
Epoch 35/80
 - 2s - loss: 0.1040
Epoch 36/80
 - 2s - loss: 0.1038
Epoch 37/80
 - 2s - loss: 0.1035
Epoch 38/80
 - 2s - loss: 0.1033
Epoch 39/80
 - 2s - loss: 0.1031
Epoch 40/80
 - 2s - loss: 0.1029
Epoch 41/80
 - 2s - loss: 0.1028
Epoch 42/80
 - 2s - loss: 0.1027
Epoch 43/80
 - 2s - loss: 0.1025
Epoch 44/80
 - 2s - loss: 0.1024
Epoch 45/80
 - 2s - loss: 0.1023
Epoch 46/80
 - 2s - loss: 0.1022
Epoch 47/80
 - 2s - loss: 0.1021
Epoch 48/80
 - 2s - loss: 0.1020
Epoch 49/80
 - 2s - loss: 0.1019
Epoch 50/80
 - 2s - loss: 0.1018
Epoch 51/80
 - 2s - loss: 0.1018
Epoch 52/80
 - 2s - loss: 0.1017
Epoch 53/80
 - 2s - loss: 0.1016
Epoch 54/80
 - 2s - loss: 0.1015
Epoch 55/80
 - 2s - loss: 0.1015
Epoch 56/80
 - 2s - loss: 0.1015
Epoch 57/80
 - 2s - loss: 0.1014
Epoch 58/80
 - 2s - loss: 0.1013
Epoch 59/80
 - 2s - loss: 0.1013
Epoch 60/80
 - 2s - loss: 0.1012
Epoch 61/80
 - 2s - loss: 0.1012
Epoch 62/80
 - 2s - loss: 0.1012
Epoch 63/80
 - 2s - loss: 0.1011
Epoch 64/80
 - 2s - loss: 0.1011
Epoch 65/80
 - 2s - loss: 0.1010
Epoch 66/80
 - 2s - loss: 0.1010
Epoch 67/80
 - 2s - loss: 0.1010
Epoch 68/80
 - 2s - loss: 0.1009
Epoch 69/80
 - 2s - loss: 0.1009
Epoch 70/80
 - 2s - loss: 0.0983
Epoch 71/80
 - 2s - loss: 0.0980
Epoch 72/80
 - 2s - loss: 0.0980
Epoch 73/80
 - 2s - loss: 0.0980
Epoch 74/80
 - 2s - loss: 0.0980
Epoch 75/80
 - 2s - loss: 0.0973
Epoch 76/80
 - 2s - loss: 0.0973
Epoch 77/80
 - 2s - loss: 0.0973
Epoch 78/80
 - 2s - loss: 0.0973
Epoch 79/80
 - 2s - loss: 0.0971
Epoch 80/80
 - 2s - loss: 0.0971
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.2682 - val_loss: 1.2529
AUC: 0.7768

Epoch 2/80
 - 0s - loss: 2.0518 - val_loss: 0.8229
AUC: 0.8003

Epoch 3/80
 - 0s - loss: 1.3799 - val_loss: 0.7171
AUC: 0.8283

Epoch 4/80
 - 0s - loss: 1.2473 - val_loss: 0.6996
AUC: 0.8417

Epoch 5/80
 - 0s - loss: 1.1869 - val_loss: 0.6729
AUC: 0.8469

Epoch 6/80
 - 0s - loss: 1.1482 - val_loss: 0.6922
AUC: 0.8516

Epoch 7/80
 - 0s - loss: 1.1265 - val_loss: 0.6309
AUC: 0.8535

Epoch 8/80
 - 0s - loss: 1.1163 - val_loss: 0.6849
AUC: 0.8592

Epoch 9/80
 - 0s - loss: 1.1003 - val_loss: 0.6438
AUC: 0.8591

Epoch 10/80
 - 0s - loss: 1.0885 - val_loss: 0.6509
AUC: 0.8593

Epoch 11/80
 - 0s - loss: 1.0839 - val_loss: 0.6986
AUC: 0.8615

Epoch 12/80
 - 0s - loss: 1.0713 - val_loss: 0.6511
AUC: 0.8614

Epoch 13/80
 - 0s - loss: 1.0712 - val_loss: 0.6415
AUC: 0.8628

Epoch 14/80
 - 0s - loss: 1.0643 - val_loss: 0.6728
AUC: 0.8644

Epoch 15/80
 - 0s - loss: 1.0522 - val_loss: 0.6401
AUC: 0.8644

Epoch 16/80
 - 0s - loss: 1.0492 - val_loss: 0.6196
AUC: 0.8648

Epoch 17/80
 - 0s - loss: 1.0437 - val_loss: 0.6179
AUC: 0.8660

Epoch 18/80
 - 0s - loss: 1.0401 - val_loss: 0.6579
AUC: 0.8674

Epoch 19/80
 - 0s - loss: 1.0305 - val_loss: 0.6341
AUC: 0.8668

Epoch 20/80
 - 0s - loss: 1.0362 - val_loss: 0.6144
AUC: 0.8669

Epoch 21/80
 - 0s - loss: 1.0294 - val_loss: 0.5588
AUC: 0.8659

Epoch 22/80
 - 0s - loss: 1.0256 - val_loss: 0.6163
AUC: 0.8667

Epoch 23/80
 - 0s - loss: 1.0234 - val_loss: 0.6113
AUC: 0.8676

Epoch 24/80
 - 0s - loss: 1.0252 - val_loss: 0.6160
AUC: 0.8675

Epoch 25/80
 - 0s - loss: 1.0168 - val_loss: 0.6700
AUC: 0.8685

Epoch 26/80
 - 0s - loss: 1.0135 - val_loss: 0.6087
AUC: 0.8681

Epoch 27/80
 - 0s - loss: 1.0166 - val_loss: 0.5725
AUC: 0.8680

Epoch 28/80
 - 0s - loss: 1.0156 - val_loss: 0.5946
AUC: 0.8690

Epoch 29/80
 - 0s - loss: 1.0109 - val_loss: 0.5902
AUC: 0.8687

Epoch 30/80
 - 0s - loss: 1.0081 - val_loss: 0.5425
AUC: 0.8684

Epoch 31/80
 - 0s - loss: 1.0078 - val_loss: 0.5676
AUC: 0.8685

Epoch 32/80
 - 0s - loss: 1.0034 - val_loss: 0.5928
AUC: 0.8691

Epoch 33/80
 - 0s - loss: 0.9983 - val_loss: 0.6355
AUC: 0.8696

Epoch 34/80
 - 0s - loss: 0.9979 - val_loss: 0.6425
AUC: 0.8696

Epoch 35/80
 - 0s - loss: 0.9904 - val_loss: 0.6431
AUC: 0.8702

Epoch 36/80
 - 0s - loss: 0.9928 - val_loss: 0.5936
AUC: 0.8692

Epoch 37/80
 - 0s - loss: 0.9870 - val_loss: 0.5976
AUC: 0.8701

Epoch 38/80
 - 0s - loss: 0.9917 - val_loss: 0.6203
AUC: 0.8705

Epoch 39/80
 - 0s - loss: 0.9845 - val_loss: 0.6066
AUC: 0.8688

Epoch 40/80
 - 0s - loss: 0.9883 - val_loss: 0.5861
AUC: 0.8697

Epoch 41/80
 - 0s - loss: 0.9746 - val_loss: 0.5987
AUC: 0.8702

Epoch 42/80
 - 0s - loss: 0.9767 - val_loss: 0.6038
AUC: 0.8700

Epoch 43/80
 - 0s - loss: 0.9694 - val_loss: 0.5866
AUC: 0.8700

Epoch 44/80
 - 0s - loss: 0.9727 - val_loss: 0.5719
AUC: 0.8700

Epoch 45/80
 - 0s - loss: 0.9747 - val_loss: 0.5997
AUC: 0.8703

Epoch 46/80
 - 0s - loss: 0.9718 - val_loss: 0.5730
AUC: 0.8698

Epoch 47/80
 - 0s - loss: 0.9738 - val_loss: 0.5793
AUC: 0.8702

Epoch 48/80
 - 0s - loss: 0.9728 - val_loss: 0.5900
AUC: 0.8703

Epoch 49/80
 - 0s - loss: 0.9699 - val_loss: 0.5908
AUC: 0.8705

Epoch 50/80
 - 0s - loss: 0.9736 - val_loss: 0.5820
AUC: 0.8702

Epoch 51/80
 - 0s - loss: 0.9650 - val_loss: 0.5850
AUC: 0.8703

Epoch 52/80
 - 0s - loss: 0.9676 - val_loss: 0.5898
AUC: 0.8703

Epoch 53/80
 - 0s - loss: 0.9713 - val_loss: 0.5880
AUC: 0.8703

Epoch 54/80
 - 0s - loss: 0.9697 - val_loss: 0.5834
AUC: 0.8702

Epoch 55/80
 - 0s - loss: 0.9662 - val_loss: 0.5837
AUC: 0.8701

Epoch 56/80
 - 0s - loss: 0.9710 - val_loss: 0.5926
AUC: 0.8701

Epoch 57/80
 - 0s - loss: 0.9625 - val_loss: 0.5878
AUC: 0.8702

Epoch 58/80
 - 0s - loss: 0.9620 - val_loss: 0.5942
AUC: 0.8702

Epoch 59/80
 - 0s - loss: 0.9691 - val_loss: 0.5855
AUC: 0.8702

Epoch 60/80
 - 0s - loss: 0.9728 - val_loss: 0.5912
AUC: 0.8703

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9676 - val_loss: 0.5952
AUC: 0.8704

Epoch 2/30
 - 0s - loss: 0.9649 - val_loss: 0.5914
AUC: 0.8704

Epoch 3/30
 - 0s - loss: 0.9701 - val_loss: 0.5846
AUC: 0.8704

Epoch 4/30
 - 0s - loss: 0.9663 - val_loss: 0.5951
AUC: 0.8705

Epoch 5/30
 - 0s - loss: 0.9631 - val_loss: 0.5848
AUC: 0.8704

Epoch 6/30
 - 0s - loss: 0.9629 - val_loss: 0.5894
AUC: 0.8708

Epoch 7/30
 - 0s - loss: 0.9657 - val_loss: 0.5765
AUC: 0.8707

Epoch 8/30
 - 0s - loss: 0.9601 - val_loss: 0.5907
AUC: 0.8708

Epoch 9/30
 - 0s - loss: 0.9654 - val_loss: 0.5930
AUC: 0.8711

Epoch 10/30
 - 0s - loss: 0.9551 - val_loss: 0.5894
AUC: 0.8712

Epoch 11/30
 - 0s - loss: 0.9562 - val_loss: 0.6090
AUC: 0.8713

Epoch 12/30
 - 0s - loss: 0.9563 - val_loss: 0.5831
AUC: 0.8711

Epoch 13/30
 - 0s - loss: 0.9543 - val_loss: 0.5671
AUC: 0.8712

Epoch 14/30
 - 0s - loss: 0.9507 - val_loss: 0.5845
AUC: 0.8711

Epoch 15/30
 - 0s - loss: 0.9514 - val_loss: 0.5911
AUC: 0.8715

Epoch 16/30
 - 0s - loss: 0.9526 - val_loss: 0.5988
AUC: 0.8716

Epoch 17/30
 - 0s - loss: 0.9481 - val_loss: 0.5869
AUC: 0.8715

Epoch 18/30
 - 0s - loss: 0.9487 - val_loss: 0.5766
AUC: 0.8714

Epoch 19/30
 - 0s - loss: 0.9465 - val_loss: 0.5921
AUC: 0.8717

Epoch 20/30
 - 0s - loss: 0.9482 - val_loss: 0.5996
AUC: 0.8717

Epoch 21/30
 - 0s - loss: 0.9483 - val_loss: 0.5775
AUC: 0.8717

Epoch 22/30
 - 0s - loss: 0.9445 - val_loss: 0.5798
AUC: 0.8716

Epoch 23/30
 - 0s - loss: 0.9424 - val_loss: 0.5729
AUC: 0.8717

Epoch 24/30
 - 0s - loss: 0.9395 - val_loss: 0.5801
AUC: 0.8718

Epoch 25/30
 - 0s - loss: 0.9444 - val_loss: 0.5773
AUC: 0.8718

Epoch 26/30
 - 0s - loss: 0.9428 - val_loss: 0.5776
AUC: 0.8718

Epoch 27/30
 - 0s - loss: 0.9403 - val_loss: 0.5768
AUC: 0.8717

Epoch 28/30
 - 0s - loss: 0.9445 - val_loss: 0.5793
AUC: 0.8718

Epoch 29/30
 - 0s - loss: 0.9425 - val_loss: 0.5831
AUC: 0.8718

Epoch 30/30
 - 0s - loss: 0.9393 - val_loss: 0.5785
Using TensorFlow backend.
AUC: 0.8718

2019-03-08 05:59:30.282598: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 05:59:30.447022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 05:59:30.447067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 05:59:30.744936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 05:59:30.744988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 05:59:30.744997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 05:59:30.745257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2838
Epoch 2/80
 - 2s - loss: 0.3312
Epoch 3/80
 - 2s - loss: 0.2967
Epoch 4/80
 - 2s - loss: 0.2683
Epoch 5/80
 - 2s - loss: 0.2418
Epoch 6/80
 - 2s - loss: 0.2232
Epoch 7/80
 - 2s - loss: 0.2070
Epoch 8/80
 - 2s - loss: 0.1909
Epoch 9/80
 - 2s - loss: 0.1764
Epoch 10/80
 - 2s - loss: 0.1647
Epoch 11/80
 - 2s - loss: 0.1556
Epoch 12/80
 - 2s - loss: 0.1482
Epoch 13/80
 - 2s - loss: 0.1418
Epoch 14/80
 - 2s - loss: 0.1363
Epoch 15/80
 - 2s - loss: 0.1315
Epoch 16/80
 - 2s - loss: 0.1275
Epoch 17/80
 - 2s - loss: 0.1240
Epoch 18/80
 - 2s - loss: 0.1210
Epoch 19/80
 - 2s - loss: 0.1185
Epoch 20/80
 - 2s - loss: 0.1163
Epoch 21/80
 - 2s - loss: 0.1144
Epoch 22/80
 - 2s - loss: 0.1127
Epoch 23/80
 - 2s - loss: 0.1113
Epoch 24/80
 - 2s - loss: 0.1101
Epoch 25/80
 - 2s - loss: 0.1091
Epoch 26/80
 - 2s - loss: 0.1082
Epoch 27/80
 - 2s - loss: 0.1074
Epoch 28/80
 - 2s - loss: 0.1068
Epoch 29/80
 - 2s - loss: 0.1062
Epoch 30/80
 - 2s - loss: 0.1057
Epoch 31/80
 - 2s - loss: 0.1052
Epoch 32/80
 - 2s - loss: 0.1048
Epoch 33/80
 - 2s - loss: 0.1045
Epoch 34/80
 - 2s - loss: 0.1042
Epoch 35/80
 - 2s - loss: 0.1039
Epoch 36/80
 - 2s - loss: 0.1036
Epoch 37/80
 - 2s - loss: 0.1034
Epoch 38/80
 - 2s - loss: 0.1032
Epoch 39/80
 - 2s - loss: 0.1030
Epoch 40/80
 - 2s - loss: 0.1029
Epoch 41/80
 - 2s - loss: 0.1027
Epoch 42/80
 - 2s - loss: 0.1025
Epoch 43/80
 - 2s - loss: 0.1024
Epoch 44/80
 - 2s - loss: 0.1023
Epoch 45/80
 - 2s - loss: 0.1022
Epoch 46/80
 - 2s - loss: 0.1021
Epoch 47/80
 - 2s - loss: 0.1020
Epoch 48/80
 - 2s - loss: 0.1019
Epoch 49/80
 - 2s - loss: 0.1018
Epoch 50/80
 - 2s - loss: 0.1017
Epoch 51/80
 - 2s - loss: 0.1017
Epoch 52/80
 - 2s - loss: 0.1016
Epoch 53/80
 - 2s - loss: 0.1015
Epoch 54/80
 - 2s - loss: 0.1015
Epoch 55/80
 - 2s - loss: 0.1014
Epoch 56/80
 - 2s - loss: 0.1014
Epoch 57/80
 - 2s - loss: 0.1013
Epoch 58/80
 - 2s - loss: 0.1013
Epoch 59/80
 - 2s - loss: 0.1012
Epoch 60/80
 - 2s - loss: 0.1012
Epoch 61/80
 - 2s - loss: 0.1012
Epoch 62/80
 - 2s - loss: 0.0985
Epoch 63/80
 - 2s - loss: 0.0982
Epoch 64/80
 - 2s - loss: 0.0982
Epoch 65/80
 - 2s - loss: 0.0982
Epoch 66/80
 - 2s - loss: 0.0982
Epoch 67/80
 - 2s - loss: 0.0975
Epoch 68/80
 - 2s - loss: 0.0975
Epoch 69/80
 - 2s - loss: 0.0975
Epoch 70/80
 - 2s - loss: 0.0975
Epoch 71/80
 - 2s - loss: 0.0973
Epoch 72/80
 - 2s - loss: 0.0973
Epoch 73/80
 - 2s - loss: 0.0973
Epoch 74/80
 - 2s - loss: 0.0973
Epoch 75/80
 - 2s - loss: 0.0973
Epoch 76/80
 - 2s - loss: 0.0973
Epoch 77/80
 - 2s - loss: 0.0973
Epoch 78/80
 - 2s - loss: 0.0973
Epoch 79/80
 - 2s - loss: 0.0973
Epoch 80/80
 - 2s - loss: 0.0973
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.1201 - val_loss: 1.8996
AUC: 0.7871

Epoch 2/80
 - 0s - loss: 2.5075 - val_loss: 0.9808
AUC: 0.8010

Epoch 3/80
 - 0s - loss: 1.4866 - val_loss: 0.7619
AUC: 0.8109

Epoch 4/80
 - 0s - loss: 1.2633 - val_loss: 0.7082
AUC: 0.8268

Epoch 5/80
 - 0s - loss: 1.2055 - val_loss: 0.6527
AUC: 0.8344

Epoch 6/80
 - 0s - loss: 1.1756 - val_loss: 0.7151
AUC: 0.8431

Epoch 7/80
 - 0s - loss: 1.1479 - val_loss: 0.6790
AUC: 0.8458

Epoch 8/80
 - 0s - loss: 1.1197 - val_loss: 0.6216
AUC: 0.8494

Epoch 9/80
 - 0s - loss: 1.1050 - val_loss: 0.7166
AUC: 0.8541

Epoch 10/80
 - 0s - loss: 1.1000 - val_loss: 0.6940
AUC: 0.8560

Epoch 11/80
 - 0s - loss: 1.0812 - val_loss: 0.6256
AUC: 0.8568

Epoch 12/80
 - 0s - loss: 1.0719 - val_loss: 0.7035
AUC: 0.8589

Epoch 13/80
 - 0s - loss: 1.0671 - val_loss: 0.6700
AUC: 0.8600

Epoch 14/80
 - 0s - loss: 1.0539 - val_loss: 0.6859
AUC: 0.8608

Epoch 15/80
 - 0s - loss: 1.0514 - val_loss: 0.7109
AUC: 0.8618

Epoch 16/80
 - 0s - loss: 1.0403 - val_loss: 0.6281
AUC: 0.8619

Epoch 17/80
 - 0s - loss: 1.0354 - val_loss: 0.5726
AUC: 0.8613

Epoch 18/80
 - 0s - loss: 1.0526 - val_loss: 0.6494
AUC: 0.8630

Epoch 19/80
 - 0s - loss: 1.0328 - val_loss: 0.6221
AUC: 0.8634

Epoch 20/80
 - 0s - loss: 1.0311 - val_loss: 0.6223
AUC: 0.8627

Epoch 21/80
 - 0s - loss: 1.0322 - val_loss: 0.6429
AUC: 0.8636

Epoch 22/80
 - 0s - loss: 1.0157 - val_loss: 0.6082
AUC: 0.8634

Epoch 23/80
 - 0s - loss: 1.0237 - val_loss: 0.6096
AUC: 0.8634

Epoch 24/80
 - 0s - loss: 1.0253 - val_loss: 0.6175
AUC: 0.8647

Epoch 25/80
 - 0s - loss: 1.0162 - val_loss: 0.5873
AUC: 0.8636

Epoch 26/80
 - 0s - loss: 1.0157 - val_loss: 0.6006
AUC: 0.8653

Epoch 27/80
 - 0s - loss: 1.0222 - val_loss: 0.6265
AUC: 0.8652

Epoch 28/80
 - 0s - loss: 1.0038 - val_loss: 0.6307
AUC: 0.8655

Epoch 29/80
 - 0s - loss: 0.9982 - val_loss: 0.6049
AUC: 0.8653

Epoch 30/80
 - 0s - loss: 1.0001 - val_loss: 0.6272
AUC: 0.8657

Epoch 31/80
 - 0s - loss: 1.0005 - val_loss: 0.5968
AUC: 0.8651

Epoch 32/80
 - 0s - loss: 0.9997 - val_loss: 0.6226
AUC: 0.8657

Epoch 33/80
 - 0s - loss: 0.9966 - val_loss: 0.6191
AUC: 0.8657

Epoch 34/80
 - 0s - loss: 0.9986 - val_loss: 0.5986
AUC: 0.8655

Epoch 35/80
 - 0s - loss: 0.9941 - val_loss: 0.6215
AUC: 0.8659

Epoch 36/80
 - 0s - loss: 0.9977 - val_loss: 0.6221
AUC: 0.8660

Epoch 37/80
 - 0s - loss: 0.9949 - val_loss: 0.6218
AUC: 0.8661

Epoch 38/80
 - 0s - loss: 0.9941 - val_loss: 0.6165
AUC: 0.8659

Epoch 39/80
 - 0s - loss: 0.9962 - val_loss: 0.6077
AUC: 0.8657

Epoch 40/80
 - 0s - loss: 0.9893 - val_loss: 0.6172
AUC: 0.8657

Epoch 41/80
 - 0s - loss: 0.9979 - val_loss: 0.6059
AUC: 0.8656

Epoch 42/80
 - 0s - loss: 0.9906 - val_loss: 0.6092
AUC: 0.8656

Epoch 43/80
 - 0s - loss: 0.9928 - val_loss: 0.6086
AUC: 0.8656

Epoch 44/80
 - 0s - loss: 0.9901 - val_loss: 0.6055
AUC: 0.8656

Epoch 45/80
 - 0s - loss: 0.9902 - val_loss: 0.6081
AUC: 0.8656

Epoch 46/80
 - 0s - loss: 0.9889 - val_loss: 0.6142
AUC: 0.8657

Epoch 47/80
 - 0s - loss: 0.9869 - val_loss: 0.6098
AUC: 0.8657

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9955 - val_loss: 0.6039
AUC: 0.8657

Epoch 2/30
 - 0s - loss: 0.9908 - val_loss: 0.6221
AUC: 0.8661

Epoch 3/30
 - 0s - loss: 0.9894 - val_loss: 0.6161
AUC: 0.8663

Epoch 4/30
 - 0s - loss: 0.9869 - val_loss: 0.6150
AUC: 0.8664

Epoch 5/30
 - 0s - loss: 0.9898 - val_loss: 0.6144
AUC: 0.8664

Epoch 6/30
 - 0s - loss: 0.9833 - val_loss: 0.6110
AUC: 0.8665

Epoch 7/30
 - 0s - loss: 0.9867 - val_loss: 0.6043
AUC: 0.8666

Epoch 8/30
 - 0s - loss: 0.9874 - val_loss: 0.6037
AUC: 0.8668

Epoch 9/30
 - 0s - loss: 0.9780 - val_loss: 0.5971
AUC: 0.8667

Epoch 10/30
 - 0s - loss: 0.9843 - val_loss: 0.6200
AUC: 0.8672

Epoch 11/30
 - 0s - loss: 0.9847 - val_loss: 0.6011
AUC: 0.8670

Epoch 12/30
 - 0s - loss: 0.9800 - val_loss: 0.5867
AUC: 0.8670

Epoch 13/30
 - 0s - loss: 0.9806 - val_loss: 0.5909
AUC: 0.8671

Epoch 14/30
 - 0s - loss: 0.9744 - val_loss: 0.5904
AUC: 0.8673

Epoch 15/30
 - 0s - loss: 0.9742 - val_loss: 0.5888
AUC: 0.8674

Epoch 16/30
 - 0s - loss: 0.9769 - val_loss: 0.6122
AUC: 0.8677

Epoch 17/30
 - 0s - loss: 0.9672 - val_loss: 0.5889
AUC: 0.8673

Epoch 18/30
 - 0s - loss: 0.9747 - val_loss: 0.6134
AUC: 0.8679

Epoch 19/30
 - 0s - loss: 0.9706 - val_loss: 0.6019
AUC: 0.8678

Epoch 20/30
 - 0s - loss: 0.9698 - val_loss: 0.6164
AUC: 0.8682

Epoch 21/30
 - 0s - loss: 0.9708 - val_loss: 0.5919
AUC: 0.8681

Epoch 22/30
 - 0s - loss: 0.9748 - val_loss: 0.5811
AUC: 0.8680

Epoch 23/30
 - 0s - loss: 0.9654 - val_loss: 0.5972
AUC: 0.8681

Epoch 24/30
 - 0s - loss: 0.9642 - val_loss: 0.5863
AUC: 0.8681

Epoch 25/30
 - 0s - loss: 0.9637 - val_loss: 0.6000
AUC: 0.8684

Epoch 26/30
 - 0s - loss: 0.9619 - val_loss: 0.5942
AUC: 0.8684

Epoch 27/30
 - 0s - loss: 0.9652 - val_loss: 0.5987
AUC: 0.8686

Epoch 28/30
 - 0s - loss: 0.9579 - val_loss: 0.5987
AUC: 0.8684

Epoch 29/30
 - 0s - loss: 0.9592 - val_loss: 0.6012
AUC: 0.8686

Epoch 30/30
 - 0s - loss: 0.9570 - val_loss: 0.6022
Using TensorFlow backend.
AUC: 0.8687

2019-03-08 06:02:50.344653: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:02:50.508607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:02:50.508651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:02:50.805300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:02:50.805353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:02:50.805365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:02:50.805668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2902
Epoch 2/80
 - 2s - loss: 0.3339
Epoch 3/80
 - 2s - loss: 0.3057
Epoch 4/80
 - 2s - loss: 0.2866
Epoch 5/80
 - 2s - loss: 0.2598
Epoch 6/80
 - 2s - loss: 0.2316
Epoch 7/80
 - 2s - loss: 0.2099
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b9272483198>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 06:03:19.822933: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:03:19.985162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:03:19.985243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:03:20.285296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:03:20.285349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:03:20.285359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:03:20.285632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0958
Epoch 2/80
 - 2s - loss: 0.1973
Epoch 3/80
 - 2s - loss: 0.1615
Epoch 4/80
 - 2s - loss: 0.1427
Epoch 5/80
 - 2s - loss: 0.1277
Epoch 6/80
 - 2s - loss: 0.1167
Epoch 7/80
 - 2s - loss: 0.1077
Epoch 8/80
 - 2s - loss: 0.0996
Epoch 9/80
 - 2s - loss: 0.0927
Epoch 10/80
 - 2s - loss: 0.0867
Epoch 11/80
 - 2s - loss: 0.0814
Epoch 12/80
 - 2s - loss: 0.0766
Epoch 13/80
 - 2s - loss: 0.0723
Epoch 14/80
 - 2s - loss: 0.0685
Epoch 15/80
 - 2s - loss: 0.0651
Epoch 16/80
 - 2s - loss: 0.0623
Epoch 17/80
 - 2s - loss: 0.0599
Epoch 18/80
 - 2s - loss: 0.0578
Epoch 19/80
 - 2s - loss: 0.0561
Epoch 20/80
 - 2s - loss: 0.0545
Epoch 21/80
 - 2s - loss: 0.0532
Epoch 22/80
 - 2s - loss: 0.0520
Epoch 23/80
 - 2s - loss: 0.0510
Epoch 24/80
 - 2s - loss: 0.0501
Epoch 25/80
 - 2s - loss: 0.0493
Epoch 26/80
 - 2s - loss: 0.0487
Epoch 27/80
 - 2s - loss: 0.0481
Epoch 28/80
 - 2s - loss: 0.0476
Epoch 29/80
 - 2s - loss: 0.0472
Epoch 30/80
 - 2s - loss: 0.0468
Epoch 31/80
 - 2s - loss: 0.0465
Epoch 32/80
 - 2s - loss: 0.0462
Epoch 33/80
 - 2s - loss: 0.0459
Epoch 34/80
 - 2s - loss: 0.0457
Epoch 35/80
 - 2s - loss: 0.0455
Epoch 36/80
 - 2s - loss: 0.0453
Epoch 37/80
 - 2s - loss: 0.0451
Epoch 38/80
 - 2s - loss: 0.0450
Epoch 39/80
 - 2s - loss: 0.0449
Epoch 40/80
 - 2s - loss: 0.0447
Epoch 41/80
 - 2s - loss: 0.0446
Epoch 42/80
 - 2s - loss: 0.0445
Epoch 43/80
 - 2s - loss: 0.0444
Epoch 44/80
 - 2s - loss: 0.0443
Epoch 45/80
 - 2s - loss: 0.0443
Epoch 46/80
 - 2s - loss: 0.0442
Epoch 47/80
 - 2s - loss: 0.0441
Epoch 48/80
 - 2s - loss: 0.0441
Epoch 49/80
 - 2s - loss: 0.0440
Epoch 50/80
 - 2s - loss: 0.0440
Epoch 51/80
 - 2s - loss: 0.0439
Epoch 52/80
 - 2s - loss: 0.0439
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2ae8d60e79e8>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 06:05:05.608294: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:05:05.773084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:05:05.773136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:05:06.070013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:05:06.070063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:05:06.070072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:05:06.070331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0771
Epoch 2/80
 - 2s - loss: 0.1945
Epoch 3/80
 - 2s - loss: 0.1684
Epoch 4/80
 - 2s - loss: 0.1571
Epoch 5/80
 - 2s - loss: 0.1422
Epoch 6/80
 - 2s - loss: 0.1275
Epoch 7/80
 - 2s - loss: 0.1158
Epoch 8/80
 - 2s - loss: 0.1066
Epoch 9/80
 - 2s - loss: 0.0985
Epoch 10/80
 - 2s - loss: 0.0912
Epoch 11/80
 - 2s - loss: 0.0845
Epoch 12/80
 - 2s - loss: 0.0783
Epoch 13/80
 - 2s - loss: 0.0729
Epoch 14/80
 - 2s - loss: 0.0685
Epoch 15/80
 - 2s - loss: 0.0649
Epoch 16/80
 - 2s - loss: 0.0620
Epoch 17/80
 - 2s - loss: 0.0595
Epoch 18/80
 - 2s - loss: 0.0575
Epoch 19/80
 - 2s - loss: 0.0557
Epoch 20/80
 - 2s - loss: 0.0542
Epoch 21/80
 - 2s - loss: 0.0529
Epoch 22/80
 - 2s - loss: 0.0518
Epoch 23/80
 - 2s - loss: 0.0508
Epoch 24/80
 - 2s - loss: 0.0499
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2abbbf8016a0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 06:06:06.469022: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:06:06.632183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:06:06.632228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:06:06.925671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:06:06.925719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:06:06.925728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:06:06.925980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0755
Epoch 2/80
 - 2s - loss: 0.1935
Epoch 3/80
 - 2s - loss: 0.1668
Epoch 4/80
 - 2s - loss: 0.1531
Epoch 5/80
 - 2s - loss: 0.1404
Epoch 6/80
 - 2s - loss: 0.1298
Epoch 7/80
 - 2s - loss: 0.1201
Epoch 8/80
 - 2s - loss: 0.1104
Epoch 9/80
 - 2s - loss: 0.1009
Epoch 10/80
 - 2s - loss: 0.0922
Epoch 11/80
 - 2s - loss: 0.0846
Epoch 12/80
 - 2s - loss: 0.0784
Epoch 13/80
 - 2s - loss: 0.0731
Epoch 14/80
 - 2s - loss: 0.0688
Epoch 15/80
 - 2s - loss: 0.0651
Epoch 16/80
 - 2s - loss: 0.0621
Epoch 17/80
 - 2s - loss: 0.0596
Epoch 18/80
 - 2s - loss: 0.0574
Epoch 19/80
 - 2s - loss: 0.0556
Epoch 20/80
 - 2s - loss: 0.0540
Epoch 21/80
 - 2s - loss: 0.0526
Epoch 22/80
 - 2s - loss: 0.0515
Epoch 23/80
 - 2s - loss: 0.0505
Epoch 24/80
 - 2s - loss: 0.0496
Epoch 25/80
 - 2s - loss: 0.0489
Epoch 26/80
 - 2s - loss: 0.0483
Epoch 27/80
 - 2s - loss: 0.0477
Epoch 28/80
 - 2s - loss: 0.0472
Epoch 29/80
 - 2s - loss: 0.0468
Epoch 30/80
 - 2s - loss: 0.0465
Epoch 31/80
 - 2s - loss: 0.0462
Epoch 32/80
 - 2s - loss: 0.0459
Epoch 33/80
 - 2s - loss: 0.0457
Epoch 34/80
 - 2s - loss: 0.0455
Epoch 35/80
 - 2s - loss: 0.0453
Epoch 36/80
 - 2s - loss: 0.0451
Epoch 37/80
 - 2s - loss: 0.0449
Epoch 38/80
 - 2s - loss: 0.0448
Epoch 39/80
 - 2s - loss: 0.0447
Epoch 40/80
 - 2s - loss: 0.0445
Epoch 41/80
 - 2s - loss: 0.0444
Epoch 42/80
 - 2s - loss: 0.0443
Epoch 43/80
 - 2s - loss: 0.0442
Epoch 44/80
 - 2s - loss: 0.0442
Epoch 45/80
 - 2s - loss: 0.0441
Epoch 46/80
 - 2s - loss: 0.0440
Epoch 47/80
 - 2s - loss: 0.0440
Epoch 48/80
 - 2s - loss: 0.0439
Epoch 49/80
 - 2s - loss: 0.0438
Epoch 50/80
 - 2s - loss: 0.0438
Epoch 51/80
 - 2s - loss: 0.0437
Epoch 52/80
 - 2s - loss: 0.0437
Epoch 53/80
 - 2s - loss: 0.0437
Epoch 54/80
 - 2s - loss: 0.0436
Epoch 55/80
 - 2s - loss: 0.0436
Epoch 56/80
 - 2s - loss: 0.0435
Epoch 57/80
 - 2s - loss: 0.0435
Epoch 58/80
 - 2s - loss: 0.0435
Epoch 59/80
 - 2s - loss: 0.0434
Epoch 60/80
 - 2s - loss: 0.0434
Epoch 61/80
 - 2s - loss: 0.0434
Epoch 62/80
 - 2s - loss: 0.0433
Epoch 63/80
 - 2s - loss: 0.0433
Epoch 64/80
 - 2s - loss: 0.0421
Epoch 65/80
 - 2s - loss: 0.0419
Epoch 66/80
 - 2s - loss: 0.0419
Epoch 67/80
 - 2s - loss: 0.0419
Epoch 68/80
 - 2s - loss: 0.0419
Epoch 69/80
 - 2s - loss: 0.0416
Epoch 70/80
 - 2s - loss: 0.0416
Epoch 71/80
 - 2s - loss: 0.0416
Epoch 72/80
 - 2s - loss: 0.0416
Epoch 73/80
 - 2s - loss: 0.0415
Epoch 74/80
 - 2s - loss: 0.0415
Epoch 75/80
 - 2s - loss: 0.0415
Epoch 76/80
 - 2s - loss: 0.0415
Epoch 77/80
 - 2s - loss: 0.0415
Epoch 78/80
 - 2s - loss: 0.0415
Epoch 79/80
 - 2s - loss: 0.0415
Epoch 80/80
 - 2s - loss: 0.0415
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.3473 - val_loss: 1.2847
AUC: 0.8089

Epoch 2/80
 - 0s - loss: 2.1208 - val_loss: 0.8020
AUC: 0.8170

Epoch 3/80
 - 0s - loss: 1.3753 - val_loss: 0.7958
AUC: 0.8265

Epoch 4/80
 - 0s - loss: 1.2334 - val_loss: 0.6829
AUC: 0.8371

Epoch 5/80
 - 0s - loss: 1.1848 - val_loss: 0.7035
AUC: 0.8455

Epoch 6/80
 - 0s - loss: 1.1399 - val_loss: 0.6385
AUC: 0.8501

Epoch 7/80
 - 0s - loss: 1.1106 - val_loss: 0.6796
AUC: 0.8541

Epoch 8/80
 - 0s - loss: 1.0981 - val_loss: 0.6702
AUC: 0.8591

Epoch 9/80
 - 0s - loss: 1.0828 - val_loss: 0.5720
AUC: 0.8582

Epoch 10/80
 - 0s - loss: 1.0620 - val_loss: 0.5560
AUC: 0.8592

Epoch 11/80
 - 0s - loss: 1.0544 - val_loss: 0.6531
AUC: 0.8645

Epoch 12/80
 - 0s - loss: 1.0474 - val_loss: 0.6055
AUC: 0.8633

Epoch 13/80
 - 0s - loss: 1.0421 - val_loss: 0.5813
AUC: 0.8639

Epoch 14/80
 - 0s - loss: 1.0372 - val_loss: 0.6055
AUC: 0.8660

Epoch 15/80
 - 0s - loss: 1.0331 - val_loss: 0.6339
AUC: 0.8673

Epoch 16/80
 - 0s - loss: 1.0231 - val_loss: 0.5787
AUC: 0.8661

Epoch 17/80
 - 0s - loss: 1.0221 - val_loss: 0.6020
AUC: 0.8673

Epoch 18/80
 - 0s - loss: 1.0110 - val_loss: 0.6209
AUC: 0.8696

Epoch 19/80
 - 0s - loss: 1.0127 - val_loss: 0.5983
AUC: 0.8680

Epoch 20/80
 - 0s - loss: 1.0119 - val_loss: 0.6554
AUC: 0.8712

Epoch 21/80
 - 0s - loss: 1.0054 - val_loss: 0.5862
AUC: 0.8697

Epoch 22/80
 - 0s - loss: 0.9955 - val_loss: 0.5949
AUC: 0.8701

Epoch 23/80
 - 0s - loss: 1.0005 - val_loss: 0.6057
AUC: 0.8702

Epoch 24/80
 - 0s - loss: 0.9915 - val_loss: 0.6231
AUC: 0.8706

Epoch 25/80
 - 0s - loss: 0.9936 - val_loss: 0.5867
AUC: 0.8704

Epoch 26/80
 - 0s - loss: 0.9966 - val_loss: 0.6079
AUC: 0.8711

Epoch 27/80
 - 0s - loss: 0.9910 - val_loss: 0.5939
AUC: 0.8706

Epoch 28/80
 - 0s - loss: 0.9937 - val_loss: 0.5993
AUC: 0.8706

Epoch 29/80
 - 0s - loss: 0.9899 - val_loss: 0.6262
AUC: 0.8712

Epoch 30/80
 - 0s - loss: 0.9890 - val_loss: 0.6200
AUC: 0.8714

Epoch 31/80
 - 0s - loss: 0.9836 - val_loss: 0.5908
AUC: 0.8711

Epoch 32/80
 - 0s - loss: 0.9888 - val_loss: 0.5999
AUC: 0.8712

Epoch 33/80
 - 0s - loss: 0.9810 - val_loss: 0.5966
AUC: 0.8711

Epoch 34/80
 - 0s - loss: 0.9828 - val_loss: 0.6003
AUC: 0.8711

Epoch 35/80
 - 0s - loss: 0.9849 - val_loss: 0.5947
AUC: 0.8711

Epoch 36/80
 - 0s - loss: 0.9833 - val_loss: 0.6014
AUC: 0.8712

Epoch 37/80
 - 0s - loss: 0.9863 - val_loss: 0.5972
AUC: 0.8712

Epoch 38/80
 - 0s - loss: 0.9854 - val_loss: 0.6037
AUC: 0.8713

Epoch 39/80
 - 0s - loss: 0.9846 - val_loss: 0.5941
AUC: 0.8712

Epoch 40/80
 - 0s - loss: 0.9850 - val_loss: 0.5939
AUC: 0.8710

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9873 - val_loss: 0.6107
AUC: 0.8714

Epoch 2/30
 - 0s - loss: 0.9866 - val_loss: 0.5903
AUC: 0.8713

Epoch 3/30
 - 0s - loss: 0.9853 - val_loss: 0.6031
AUC: 0.8719

Epoch 4/30
 - 0s - loss: 0.9829 - val_loss: 0.5975
AUC: 0.8718

Epoch 5/30
 - 0s - loss: 0.9810 - val_loss: 0.6185
AUC: 0.8719

Epoch 6/30
 - 0s - loss: 0.9814 - val_loss: 0.6112
AUC: 0.8718

Epoch 7/30
 - 0s - loss: 0.9766 - val_loss: 0.6192
AUC: 0.8721

Epoch 8/30
 - 0s - loss: 0.9735 - val_loss: 0.6038
AUC: 0.8721

Epoch 9/30
 - 0s - loss: 0.9791 - val_loss: 0.5967
AUC: 0.8722

Epoch 10/30
 - 0s - loss: 0.9759 - val_loss: 0.5704
AUC: 0.8718

Epoch 11/30
 - 0s - loss: 0.9709 - val_loss: 0.5881
AUC: 0.8724

Epoch 12/30
 - 0s - loss: 0.9694 - val_loss: 0.5976
AUC: 0.8727

Epoch 13/30
 - 0s - loss: 0.9674 - val_loss: 0.5898
AUC: 0.8728

Epoch 14/30
 - 0s - loss: 0.9729 - val_loss: 0.6052
AUC: 0.8731

Epoch 15/30
 - 0s - loss: 0.9702 - val_loss: 0.5919
AUC: 0.8730

Epoch 16/30
 - 0s - loss: 0.9648 - val_loss: 0.5992
AUC: 0.8732

Epoch 17/30
 - 0s - loss: 0.9624 - val_loss: 0.5909
AUC: 0.8731

Epoch 18/30
 - 0s - loss: 0.9616 - val_loss: 0.5849
AUC: 0.8732

Epoch 19/30
 - 0s - loss: 0.9633 - val_loss: 0.5734
AUC: 0.8730

Epoch 20/30
 - 0s - loss: 0.9573 - val_loss: 0.5932
AUC: 0.8737

Epoch 21/30
 - 0s - loss: 0.9524 - val_loss: 0.5899
AUC: 0.8736

Epoch 22/30
 - 0s - loss: 0.9587 - val_loss: 0.5888
AUC: 0.8735

Epoch 23/30
 - 0s - loss: 0.9588 - val_loss: 0.5881
AUC: 0.8735

Epoch 24/30
 - 0s - loss: 0.9566 - val_loss: 0.5851
AUC: 0.8735

Epoch 25/30
 - 0s - loss: 0.9596 - val_loss: 0.5916
AUC: 0.8736

Epoch 26/30
 - 0s - loss: 0.9546 - val_loss: 0.5849
AUC: 0.8736

Epoch 27/30
 - 0s - loss: 0.9569 - val_loss: 0.5818
AUC: 0.8735

Epoch 28/30
 - 0s - loss: 0.9586 - val_loss: 0.5866
AUC: 0.8736

Epoch 29/30
 - 0s - loss: 0.9594 - val_loss: 0.5875
AUC: 0.8736

Epoch 30/30
 - 0s - loss: 0.9588 - val_loss: 0.5907
Using TensorFlow backend.
AUC: 0.8736

2019-03-08 06:09:21.912620: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:09:22.076881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:09:22.076925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:09:22.373841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:09:22.373892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:09:22.373900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:09:22.374152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6667
Epoch 2/80
 - 2s - loss: 0.1059
Epoch 3/80
 - 2s - loss: 0.0689
Epoch 4/80
 - 2s - loss: 0.0638
Epoch 5/80
 - 2s - loss: 0.0603
Epoch 6/80
 - 2s - loss: 0.0557
Epoch 7/80
 - 2s - loss: 0.0504
Epoch 8/80
 - 2s - loss: 0.0458
Epoch 9/80
 - 2s - loss: 0.0421
Epoch 10/80
 - 2s - loss: 0.0387
Epoch 11/80
 - 2s - loss: 0.0355
Epoch 12/80
 - 2s - loss: 0.0325
Epoch 13/80
 - 2s - loss: 0.0299
Epoch 14/80
 - 2s - loss: 0.0277
Epoch 15/80
 - 2s - loss: 0.0258
Epoch 16/80
 - 2s - loss: 0.0242
Epoch 17/80
 - 2s - loss: 0.0229
Epoch 18/80
 - 2s - loss: 0.0217
Epoch 19/80
 - 2s - loss: 0.0207
Epoch 20/80
 - 2s - loss: 0.0198
Epoch 21/80
 - 2s - loss: 0.0191
Epoch 22/80
 - 2s - loss: 0.0185
Epoch 23/80
 - 2s - loss: 0.0180
Epoch 24/80
 - 2s - loss: 0.0175
Epoch 25/80
 - 2s - loss: 0.0171
Epoch 26/80
 - 2s - loss: 0.0168
Epoch 27/80
 - 2s - loss: 0.0165
Epoch 28/80
 - 2s - loss: 0.0162
Epoch 29/80
 - 2s - loss: 0.0160
Epoch 30/80
 - 2s - loss: 0.0157
Epoch 31/80
 - 2s - loss: 0.0156
Epoch 32/80
 - 2s - loss: 0.0154
Epoch 33/80
 - 2s - loss: 0.0152
Epoch 34/80
 - 2s - loss: 0.0151
Epoch 35/80
 - 2s - loss: 0.0150
Epoch 36/80
 - 2s - loss: 0.0149
Epoch 37/80
 - 2s - loss: 0.0148
Epoch 38/80
 - 2s - loss: 0.0147
Epoch 39/80
 - 2s - loss: 0.0147
Epoch 40/80
 - 2s - loss: 0.0146
Epoch 41/80
 - 2s - loss: 0.0145
Epoch 42/80
 - 2s - loss: 0.0145
Epoch 43/80
 - 2s - loss: 0.0144
Epoch 44/80
 - 2s - loss: 0.0144
Epoch 45/80
 - 2s - loss: 0.0143
Epoch 46/80
 - 2s - loss: 0.0143
Epoch 47/80
 - 2s - loss: 0.0143
Epoch 48/80
 - 2s - loss: 0.0142
Epoch 49/80
 - 2s - loss: 0.0142
Epoch 50/80
 - 2s - loss: 0.0138
Epoch 51/80
 - 2s - loss: 0.0137
Epoch 52/80
 - 2s - loss: 0.0137
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 2s - loss: 0.0136
Epoch 55/80
 - 2s - loss: 0.0136
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 2s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0135
Epoch 62/80
 - 2s - loss: 0.0135
Epoch 63/80
 - 2s - loss: 0.0135
Epoch 64/80
 - 2s - loss: 0.0135
Epoch 65/80
 - 2s - loss: 0.0135
Epoch 66/80
 - 2s - loss: 0.0135
Epoch 67/80
 - 2s - loss: 0.0135
Epoch 68/80
 - 2s - loss: 0.0135
Epoch 69/80
 - 2s - loss: 0.0135
Epoch 70/80
 - 2s - loss: 0.0135
Epoch 71/80
 - 2s - loss: 0.0135
Epoch 72/80
 - 2s - loss: 0.0135
Epoch 73/80
 - 2s - loss: 0.0135
Epoch 74/80
 - 2s - loss: 0.0135
Epoch 75/80
 - 1s - loss: 0.0135
Epoch 76/80
 - 2s - loss: 0.0135
Epoch 77/80
 - 2s - loss: 0.0135
Epoch 78/80
 - 2s - loss: 0.0135
Epoch 79/80
 - 2s - loss: 0.0135
Epoch 80/80
 - 2s - loss: 0.0135
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.9291 - val_loss: 1.6109
AUC: 0.7294

Epoch 2/80
 - 0s - loss: 2.3478 - val_loss: 1.0323
AUC: 0.7795

Epoch 3/80
 - 0s - loss: 1.4893 - val_loss: 0.7253
AUC: 0.8095

Epoch 4/80
 - 0s - loss: 1.2779 - val_loss: 0.7846
AUC: 0.8257

Epoch 5/80
 - 0s - loss: 1.1983 - val_loss: 0.7194
AUC: 0.8338

Epoch 6/80
 - 0s - loss: 1.1570 - val_loss: 0.6734
AUC: 0.8375

Epoch 7/80
 - 0s - loss: 1.1338 - val_loss: 0.6681
AUC: 0.8414

Epoch 8/80
 - 0s - loss: 1.1193 - val_loss: 0.6436
AUC: 0.8436

Epoch 9/80
 - 0s - loss: 1.0990 - val_loss: 0.6821
AUC: 0.8477

Epoch 10/80
 - 0s - loss: 1.0840 - val_loss: 0.5981
AUC: 0.8476

Epoch 11/80
 - 0s - loss: 1.0754 - val_loss: 0.6423
AUC: 0.8489

Epoch 12/80
 - 0s - loss: 1.0673 - val_loss: 0.6799
AUC: 0.8519

Epoch 13/80
 - 0s - loss: 1.0626 - val_loss: 0.6395
AUC: 0.8516

Epoch 14/80
 - 0s - loss: 1.0629 - val_loss: 0.6697
AUC: 0.8539

Epoch 15/80
 - 0s - loss: 1.0597 - val_loss: 0.7206
AUC: 0.8554

Epoch 16/80
 - 0s - loss: 1.0502 - val_loss: 0.6690
AUC: 0.8541

Epoch 17/80
 - 0s - loss: 1.0453 - val_loss: 0.7010
AUC: 0.8568

Epoch 18/80
 - 0s - loss: 1.0439 - val_loss: 0.6295
AUC: 0.8557

Epoch 19/80
 - 0s - loss: 1.0282 - val_loss: 0.6673
AUC: 0.8572

Epoch 20/80
 - 0s - loss: 1.0314 - val_loss: 0.6408
AUC: 0.8569

Epoch 21/80
 - 0s - loss: 1.0254 - val_loss: 0.6227
AUC: 0.8571

Epoch 22/80
 - 0s - loss: 1.0151 - val_loss: 0.6431
AUC: 0.8577

Epoch 23/80
 - 0s - loss: 1.0190 - val_loss: 0.6154
AUC: 0.8575

Epoch 24/80
 - 0s - loss: 1.0188 - val_loss: 0.6416
AUC: 0.8584

Epoch 25/80
 - 0s - loss: 1.0096 - val_loss: 0.6168
AUC: 0.8582

Epoch 26/80
 - 0s - loss: 1.0220 - val_loss: 0.6207
AUC: 0.8582

Epoch 27/80
 - 0s - loss: 1.0114 - val_loss: 0.6195
AUC: 0.8584

Epoch 28/80
 - 0s - loss: 1.0156 - val_loss: 0.6234
AUC: 0.8583

Epoch 29/80
 - 0s - loss: 1.0132 - val_loss: 0.6245
AUC: 0.8586

Epoch 30/80
 - 0s - loss: 1.0157 - val_loss: 0.6235
AUC: 0.8588

Epoch 31/80
 - 0s - loss: 1.0111 - val_loss: 0.6310
AUC: 0.8589

Epoch 32/80
 - 0s - loss: 1.0120 - val_loss: 0.6234
AUC: 0.8587

Epoch 33/80
 - 0s - loss: 1.0136 - val_loss: 0.6261
AUC: 0.8588

Epoch 34/80
 - 0s - loss: 1.0077 - val_loss: 0.6247
AUC: 0.8588

Epoch 35/80
 - 0s - loss: 1.0163 - val_loss: 0.6221
AUC: 0.8588

Epoch 36/80
 - 0s - loss: 1.0124 - val_loss: 0.6253
AUC: 0.8588

Epoch 37/80
 - 0s - loss: 1.0093 - val_loss: 0.6284
AUC: 0.8589

Epoch 38/80
 - 0s - loss: 1.0088 - val_loss: 0.6146
AUC: 0.8587

Epoch 39/80
 - 0s - loss: 1.0093 - val_loss: 0.6172
AUC: 0.8587

Epoch 40/80
 - 0s - loss: 1.0159 - val_loss: 0.6240
AUC: 0.8590

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0145 - val_loss: 0.6156
AUC: 0.8590

Epoch 2/30
 - 0s - loss: 1.0139 - val_loss: 0.6264
AUC: 0.8593

Epoch 3/30
 - 0s - loss: 1.0082 - val_loss: 0.6101
AUC: 0.8592

Epoch 4/30
 - 0s - loss: 1.0079 - val_loss: 0.6272
AUC: 0.8596

Epoch 5/30
 - 0s - loss: 1.0055 - val_loss: 0.6237
AUC: 0.8598

Epoch 6/30
 - 0s - loss: 1.0013 - val_loss: 0.6260
AUC: 0.8600

Epoch 7/30
 - 0s - loss: 1.0016 - val_loss: 0.6120
AUC: 0.8602

Epoch 8/30
 - 0s - loss: 0.9976 - val_loss: 0.6140
AUC: 0.8603

Epoch 9/30
 - 0s - loss: 0.9942 - val_loss: 0.6228
AUC: 0.8605

Epoch 10/30
 - 0s - loss: 0.9994 - val_loss: 0.6206
AUC: 0.8607

Epoch 11/30
 - 0s - loss: 0.9999 - val_loss: 0.6134
AUC: 0.8607

Epoch 12/30
 - 0s - loss: 0.9917 - val_loss: 0.6013
AUC: 0.8606

Epoch 13/30
 - 0s - loss: 0.9934 - val_loss: 0.5990
AUC: 0.8608

Epoch 14/30
 - 0s - loss: 0.9934 - val_loss: 0.6114
AUC: 0.8611

Epoch 15/30
 - 0s - loss: 0.9927 - val_loss: 0.6018
AUC: 0.8610

Epoch 16/30
 - 0s - loss: 0.9887 - val_loss: 0.6360
AUC: 0.8616

Epoch 17/30
 - 0s - loss: 0.9879 - val_loss: 0.6066
AUC: 0.8614

Epoch 18/30
 - 0s - loss: 0.9825 - val_loss: 0.6154
AUC: 0.8617

Epoch 19/30
 - 0s - loss: 0.9811 - val_loss: 0.6099
AUC: 0.8617

Epoch 20/30
 - 0s - loss: 0.9854 - val_loss: 0.6036
AUC: 0.8618

Epoch 21/30
 - 0s - loss: 0.9824 - val_loss: 0.6023
AUC: 0.8617

Epoch 22/30
 - 0s - loss: 0.9851 - val_loss: 0.5887
AUC: 0.8617

Epoch 23/30
 - 0s - loss: 0.9804 - val_loss: 0.6220
AUC: 0.8623

Epoch 24/30
 - 0s - loss: 0.9774 - val_loss: 0.5943
AUC: 0.8620

Epoch 25/30
 - 0s - loss: 0.9738 - val_loss: 0.6081
AUC: 0.8624

Epoch 26/30
 - 0s - loss: 0.9725 - val_loss: 0.6073
AUC: 0.8624

Epoch 27/30
 - 0s - loss: 0.9694 - val_loss: 0.6157
AUC: 0.8627

Epoch 28/30
 - 0s - loss: 0.9687 - val_loss: 0.5921
AUC: 0.8625

Epoch 29/30
 - 0s - loss: 0.9718 - val_loss: 0.6181
AUC: 0.8628

Epoch 30/30
 - 0s - loss: 0.9712 - val_loss: 0.6070
Using TensorFlow backend.
AUC: 0.8629

2019-03-08 06:12:34.487410: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:12:34.655100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:12:34.655144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:12:34.949858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:12:34.949909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:12:34.949918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:12:34.950178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6608
Epoch 2/80
 - 2s - loss: 0.1053
Epoch 3/80
 - 2s - loss: 0.0694
Epoch 4/80
 - 2s - loss: 0.0641
Epoch 5/80
 - 2s - loss: 0.0611
Epoch 6/80
 - 2s - loss: 0.0574
Epoch 7/80
 - 2s - loss: 0.0527
Epoch 8/80
 - 2s - loss: 0.0473
Epoch 9/80
 - 2s - loss: 0.0420
Epoch 10/80
 - 2s - loss: 0.0377
Epoch 11/80
 - 2s - loss: 0.0343
Epoch 12/80
 - 2s - loss: 0.0317
Epoch 13/80
 - 2s - loss: 0.0295
Epoch 14/80
 - 2s - loss: 0.0276
Epoch 15/80
 - 2s - loss: 0.0259
Epoch 16/80
 - 2s - loss: 0.0244
Epoch 17/80
 - 2s - loss: 0.0231
Epoch 18/80
 - 2s - loss: 0.0220
Epoch 19/80
 - 2s - loss: 0.0210
Epoch 20/80
 - 2s - loss: 0.0201
Epoch 21/80
 - 2s - loss: 0.0193
Epoch 22/80
 - 2s - loss: 0.0187
Epoch 23/80
 - 2s - loss: 0.0181
Epoch 24/80
 - 2s - loss: 0.0176
Epoch 25/80
 - 2s - loss: 0.0172
Epoch 26/80
 - 2s - loss: 0.0168
Epoch 27/80
 - 2s - loss: 0.0165
Epoch 28/80
 - 2s - loss: 0.0162
Epoch 29/80
 - 2s - loss: 0.0160
Epoch 30/80
 - 2s - loss: 0.0158
Epoch 31/80
 - 2s - loss: 0.0156
Epoch 32/80
 - 2s - loss: 0.0154
Epoch 33/80
 - 2s - loss: 0.0153
Epoch 34/80
 - 2s - loss: 0.0152
Epoch 35/80
 - 2s - loss: 0.0151
Epoch 36/80
 - 2s - loss: 0.0150
Epoch 37/80
 - 2s - loss: 0.0149
Epoch 38/80
 - 2s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0147
Epoch 40/80
 - 2s - loss: 0.0146
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0145
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0144
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 2s - loss: 0.0143
Epoch 48/80
 - 2s - loss: 0.0143
Epoch 49/80
 - 2s - loss: 0.0143
Epoch 50/80
 - 2s - loss: 0.0142
Epoch 51/80
 - 2s - loss: 0.0142
Epoch 52/80
 - 2s - loss: 0.0138
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 2s - loss: 0.0137
Epoch 55/80
 - 2s - loss: 0.0137
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 2s - loss: 0.0135
Epoch 61/80
 - 2s - loss: 0.0135
Epoch 62/80
 - 2s - loss: 0.0135
Epoch 63/80
 - 2s - loss: 0.0135
Epoch 64/80
 - 2s - loss: 0.0135
Epoch 65/80
 - 2s - loss: 0.0135
Epoch 66/80
 - 2s - loss: 0.0135
Epoch 67/80
 - 2s - loss: 0.0135
Epoch 68/80
 - 2s - loss: 0.0135
Epoch 69/80
 - 2s - loss: 0.0135
Epoch 70/80
 - 2s - loss: 0.0135
Epoch 71/80
 - 2s - loss: 0.0135
Epoch 72/80
 - 2s - loss: 0.0135
Epoch 73/80
 - 2s - loss: 0.0135
Epoch 74/80
 - 2s - loss: 0.0135
Epoch 75/80
 - 2s - loss: 0.0135
Epoch 76/80
 - 2s - loss: 0.0135
Epoch 77/80
 - 2s - loss: 0.0135
Epoch 78/80
 - 2s - loss: 0.0135
Epoch 79/80
 - 2s - loss: 0.0135
Epoch 80/80
 - 2s - loss: 0.0135
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.5155 - val_loss: 1.8708
AUC: 0.7761

Epoch 2/80
 - 0s - loss: 2.6088 - val_loss: 1.0418
AUC: 0.8145

Epoch 3/80
 - 0s - loss: 1.5172 - val_loss: 0.7148
AUC: 0.8277

Epoch 4/80
 - 0s - loss: 1.2793 - val_loss: 0.7528
AUC: 0.8382

Epoch 5/80
 - 0s - loss: 1.2010 - val_loss: 0.7423
AUC: 0.8459

Epoch 6/80
 - 0s - loss: 1.1608 - val_loss: 0.7284
AUC: 0.8490

Epoch 7/80
 - 0s - loss: 1.1386 - val_loss: 0.6723
AUC: 0.8516

Epoch 8/80
 - 0s - loss: 1.1119 - val_loss: 0.6939
AUC: 0.8557

Epoch 9/80
 - 0s - loss: 1.0968 - val_loss: 0.6029
AUC: 0.8550

Epoch 10/80
 - 0s - loss: 1.0929 - val_loss: 0.6281
AUC: 0.8584

Epoch 11/80
 - 0s - loss: 1.0763 - val_loss: 0.6166
AUC: 0.8585

Epoch 12/80
 - 0s - loss: 1.0679 - val_loss: 0.6201
AUC: 0.8595

Epoch 13/80
 - 0s - loss: 1.0582 - val_loss: 0.6021
AUC: 0.8597

Epoch 14/80
 - 0s - loss: 1.0647 - val_loss: 0.6014
AUC: 0.8597

Epoch 15/80
 - 0s - loss: 1.0587 - val_loss: 0.6981
AUC: 0.8625

Epoch 16/80
 - 0s - loss: 1.0524 - val_loss: 0.6477
AUC: 0.8612

Epoch 17/80
 - 0s - loss: 1.0462 - val_loss: 0.7379
AUC: 0.8637

Epoch 18/80
 - 0s - loss: 1.0420 - val_loss: 0.6424
AUC: 0.8639

Epoch 19/80
 - 0s - loss: 1.0379 - val_loss: 0.6273
AUC: 0.8628

Epoch 20/80
 - 0s - loss: 1.0316 - val_loss: 0.6176
AUC: 0.8633

Epoch 21/80
 - 0s - loss: 1.0278 - val_loss: 0.6154
AUC: 0.8637

Epoch 22/80
 - 0s - loss: 1.0239 - val_loss: 0.5907
AUC: 0.8633

Epoch 23/80
 - 0s - loss: 1.0257 - val_loss: 0.6198
AUC: 0.8643

Epoch 24/80
 - 0s - loss: 1.0223 - val_loss: 0.5918
AUC: 0.8644

Epoch 25/80
 - 0s - loss: 1.0209 - val_loss: 0.5867
AUC: 0.8642

Epoch 26/80
 - 0s - loss: 1.0170 - val_loss: 0.6576
AUC: 0.8646

Epoch 27/80
 - 0s - loss: 1.0187 - val_loss: 0.6165
AUC: 0.8649

Epoch 28/80
 - 0s - loss: 1.0126 - val_loss: 0.6074
AUC: 0.8660

Epoch 29/80
 - 0s - loss: 1.0166 - val_loss: 0.6194
AUC: 0.8654

Epoch 30/80
 - 0s - loss: 1.0074 - val_loss: 0.6156
AUC: 0.8651

Epoch 31/80
 - 0s - loss: 1.0072 - val_loss: 0.6136
AUC: 0.8656

Epoch 32/80
 - 0s - loss: 1.0083 - val_loss: 0.6754
AUC: 0.8675

Epoch 33/80
 - 0s - loss: 1.0016 - val_loss: 0.6082
AUC: 0.8673

Epoch 34/80
 - 0s - loss: 1.0060 - val_loss: 0.6545
AUC: 0.8683

Epoch 35/80
 - 0s - loss: 1.0043 - val_loss: 0.6791
AUC: 0.8678

Epoch 36/80
 - 0s - loss: 0.9972 - val_loss: 0.5897
AUC: 0.8672

Epoch 37/80
 - 0s - loss: 0.9962 - val_loss: 0.6037
AUC: 0.8675

Epoch 38/80
 - 0s - loss: 0.9879 - val_loss: 0.6341
AUC: 0.8676

Epoch 39/80
 - 0s - loss: 0.9922 - val_loss: 0.6182
AUC: 0.8677

Epoch 40/80
 - 0s - loss: 0.9926 - val_loss: 0.6199
AUC: 0.8674

Epoch 41/80
 - 0s - loss: 0.9880 - val_loss: 0.6057
AUC: 0.8675

Epoch 42/80
 - 0s - loss: 0.9889 - val_loss: 0.6419
AUC: 0.8681

Epoch 43/80
 - 0s - loss: 0.9884 - val_loss: 0.6163
AUC: 0.8678

Epoch 44/80
 - 0s - loss: 0.9805 - val_loss: 0.6112
AUC: 0.8679

Epoch 45/80
 - 0s - loss: 0.9868 - val_loss: 0.6054
AUC: 0.8677

Epoch 46/80
 - 0s - loss: 0.9819 - val_loss: 0.6087
AUC: 0.8678

Epoch 47/80
 - 0s - loss: 0.9896 - val_loss: 0.6144
AUC: 0.8679

Epoch 48/80
 - 0s - loss: 0.9829 - val_loss: 0.6004
AUC: 0.8678

Epoch 49/80
 - 0s - loss: 0.9843 - val_loss: 0.6078
AUC: 0.8678

Epoch 50/80
 - 0s - loss: 0.9849 - val_loss: 0.6011
AUC: 0.8677

Epoch 51/80
 - 0s - loss: 0.9848 - val_loss: 0.6060
AUC: 0.8678

Epoch 52/80
 - 0s - loss: 0.9827 - val_loss: 0.5994
AUC: 0.8677

Epoch 53/80
 - 0s - loss: 0.9775 - val_loss: 0.5977
AUC: 0.8677

Epoch 54/80
 - 0s - loss: 0.9860 - val_loss: 0.6102
AUC: 0.8679

Epoch 55/80
 - 0s - loss: 0.9843 - val_loss: 0.6064
AUC: 0.8679

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9953 - val_loss: 0.6166
AUC: 0.8678

Epoch 2/30
 - 0s - loss: 0.9833 - val_loss: 0.6115
AUC: 0.8678

Epoch 3/30
 - 0s - loss: 0.9923 - val_loss: 0.6039
AUC: 0.8677

Epoch 4/30
 - 0s - loss: 0.9894 - val_loss: 0.6314
AUC: 0.8682

Epoch 5/30
 - 0s - loss: 0.9819 - val_loss: 0.6052
AUC: 0.8680

Epoch 6/30
 - 0s - loss: 0.9863 - val_loss: 0.5891
AUC: 0.8678

Epoch 7/30
 - 0s - loss: 0.9849 - val_loss: 0.5991
AUC: 0.8681

Epoch 8/30
 - 0s - loss: 0.9821 - val_loss: 0.6108
AUC: 0.8684

Epoch 9/30
 - 0s - loss: 0.9834 - val_loss: 0.6036
AUC: 0.8685

Epoch 10/30
 - 0s - loss: 0.9782 - val_loss: 0.5921
AUC: 0.8685

Epoch 11/30
 - 0s - loss: 0.9810 - val_loss: 0.6090
AUC: 0.8688

Epoch 12/30
 - 0s - loss: 0.9797 - val_loss: 0.6179
AUC: 0.8689

Epoch 13/30
 - 0s - loss: 0.9738 - val_loss: 0.6099
AUC: 0.8690

Epoch 14/30
 - 0s - loss: 0.9717 - val_loss: 0.6075
AUC: 0.8690

Epoch 15/30
 - 0s - loss: 0.9746 - val_loss: 0.5986
AUC: 0.8689

Epoch 16/30
 - 0s - loss: 0.9713 - val_loss: 0.6085
AUC: 0.8691

Epoch 17/30
 - 0s - loss: 0.9691 - val_loss: 0.6044
AUC: 0.8691

Epoch 18/30
 - 0s - loss: 0.9734 - val_loss: 0.6041
AUC: 0.8691

Epoch 19/30
 - 0s - loss: 0.9679 - val_loss: 0.6010
AUC: 0.8691

Epoch 20/30
 - 0s - loss: 0.9699 - val_loss: 0.6011
AUC: 0.8692

Epoch 21/30
 - 0s - loss: 0.9708 - val_loss: 0.6043
AUC: 0.8692

Epoch 22/30
 - 0s - loss: 0.9681 - val_loss: 0.6029
AUC: 0.8692

Epoch 23/30
 - 0s - loss: 0.9621 - val_loss: 0.5995
AUC: 0.8692

Epoch 24/30
 - 0s - loss: 0.9671 - val_loss: 0.5983
AUC: 0.8692

Epoch 25/30
 - 0s - loss: 0.9645 - val_loss: 0.5976
AUC: 0.8693

Epoch 26/30
 - 0s - loss: 0.9664 - val_loss: 0.6006
AUC: 0.8693

Epoch 27/30
 - 0s - loss: 0.9680 - val_loss: 0.5994
AUC: 0.8693

Epoch 28/30
 - 0s - loss: 0.9675 - val_loss: 0.6002
AUC: 0.8693

Epoch 29/30
 - 0s - loss: 0.9650 - val_loss: 0.5998
AUC: 0.8693

Epoch 30/30
 - 0s - loss: 0.9746 - val_loss: 0.6003
Using TensorFlow backend.
AUC: 0.8693

2019-03-08 06:15:56.735595: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:15:56.900920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:15:56.900963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:15:57.193032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:15:57.193082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:15:57.193091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:15:57.193361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6485
Epoch 2/80
 - 2s - loss: 0.0987
Epoch 3/80
 - 2s - loss: 0.0687
Epoch 4/80
 - 2s - loss: 0.0647
Epoch 5/80
 - 2s - loss: 0.0625
Epoch 6/80
 - 2s - loss: 0.0600
Epoch 7/80
 - 2s - loss: 0.0565
Epoch 8/80
 - 2s - loss: 0.0518
Epoch 9/80
 - 2s - loss: 0.0463
Epoch 10/80
 - 2s - loss: 0.0409
Epoch 11/80
 - 2s - loss: 0.0365
Epoch 12/80
 - 2s - loss: 0.0330
Epoch 13/80
 - 2s - loss: 0.0304
Epoch 14/80
 - 2s - loss: 0.0282
Epoch 15/80
 - 2s - loss: 0.0263
Epoch 16/80
 - 2s - loss: 0.0246
Epoch 17/80
 - 2s - loss: 0.0232
Epoch 18/80
 - 2s - loss: 0.0220
Epoch 19/80
 - 2s - loss: 0.0209
Epoch 20/80
 - 2s - loss: 0.0201
Epoch 21/80
 - 2s - loss: 0.0193
Epoch 22/80
 - 2s - loss: 0.0187
Epoch 23/80
 - 2s - loss: 0.0181
Epoch 24/80
 - 2s - loss: 0.0177
Epoch 25/80
 - 2s - loss: 0.0172
Epoch 26/80
 - 2s - loss: 0.0169
Epoch 27/80
 - 2s - loss: 0.0166
Epoch 28/80
 - 2s - loss: 0.0163
Epoch 29/80
 - 2s - loss: 0.0160
Epoch 30/80
 - 2s - loss: 0.0158
Epoch 31/80
 - 2s - loss: 0.0156
Epoch 32/80
 - 2s - loss: 0.0155
Epoch 33/80
 - 2s - loss: 0.0153
Epoch 34/80
 - 2s - loss: 0.0152
Epoch 35/80
 - 2s - loss: 0.0151
Epoch 36/80
 - 2s - loss: 0.0150
Epoch 37/80
 - 2s - loss: 0.0149
Epoch 38/80
 - 2s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0148
Epoch 40/80
 - 2s - loss: 0.0147
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0146
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0145
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 2s - loss: 0.0144
Epoch 48/80
 - 2s - loss: 0.0143
Epoch 49/80
 - 2s - loss: 0.0143
Epoch 50/80
 - 2s - loss: 0.0143
Epoch 51/80
 - 2s - loss: 0.0138
Epoch 52/80
 - 2s - loss: 0.0138
Epoch 53/80
 - 2s - loss: 0.0138
Epoch 54/80
 - 2s - loss: 0.0138
Epoch 55/80
 - 2s - loss: 0.0137
Epoch 56/80
 - 2s - loss: 0.0137
Epoch 57/80
 - 2s - loss: 0.0137
Epoch 58/80
 - 2s - loss: 0.0137
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 2s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0136
Epoch 62/80
 - 2s - loss: 0.0136
Epoch 63/80
 - 2s - loss: 0.0136
Epoch 64/80
 - 2s - loss: 0.0136
Epoch 65/80
 - 2s - loss: 0.0136
Epoch 66/80
 - 2s - loss: 0.0136
Epoch 67/80
 - 2s - loss: 0.0136
Epoch 68/80
 - 2s - loss: 0.0136
Epoch 69/80
 - 2s - loss: 0.0136
Epoch 70/80
 - 2s - loss: 0.0136
Epoch 71/80
 - 2s - loss: 0.0136
Epoch 72/80
 - 2s - loss: 0.0136
Epoch 73/80
 - 2s - loss: 0.0136
Epoch 74/80
 - 2s - loss: 0.0136
Epoch 75/80
 - 2s - loss: 0.0136
Epoch 76/80
 - 2s - loss: 0.0136
Epoch 77/80
 - 2s - loss: 0.0136
Epoch 78/80
 - 2s - loss: 0.0136
Epoch 79/80
 - 2s - loss: 0.0136
Epoch 80/80
 - 2s - loss: 0.0136
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4425 - val_loss: 1.0353
AUC: 0.8046

Epoch 2/80
 - 0s - loss: 1.7279 - val_loss: 0.8250
AUC: 0.8266

Epoch 3/80
 - 0s - loss: 1.3087 - val_loss: 0.7641
AUC: 0.8358

Epoch 4/80
 - 0s - loss: 1.1924 - val_loss: 0.7247
AUC: 0.8430

Epoch 5/80
 - 0s - loss: 1.1552 - val_loss: 0.6582
AUC: 0.8454

Epoch 6/80
 - 0s - loss: 1.1209 - val_loss: 0.6959
AUC: 0.8499

Epoch 7/80
 - 0s - loss: 1.1082 - val_loss: 0.6827
AUC: 0.8506

Epoch 8/80
 - 0s - loss: 1.0849 - val_loss: 0.6861
AUC: 0.8545

Epoch 9/80
 - 0s - loss: 1.0735 - val_loss: 0.6419
AUC: 0.8540

Epoch 10/80
 - 0s - loss: 1.0676 - val_loss: 0.6422
AUC: 0.8550

Epoch 11/80
 - 0s - loss: 1.0499 - val_loss: 0.6669
AUC: 0.8552

Epoch 12/80
 - 0s - loss: 1.0570 - val_loss: 0.6022
AUC: 0.8567

Epoch 13/80
 - 0s - loss: 1.0411 - val_loss: 0.6317
AUC: 0.8568

Epoch 14/80
 - 0s - loss: 1.0363 - val_loss: 0.6600
AUC: 0.8589

Epoch 15/80
 - 0s - loss: 1.0310 - val_loss: 0.6311
AUC: 0.8594

Epoch 16/80
 - 0s - loss: 1.0304 - val_loss: 0.5945
AUC: 0.8564

Epoch 17/80
 - 0s - loss: 1.0303 - val_loss: 0.5925
AUC: 0.8589

Epoch 18/80
 - 0s - loss: 1.0303 - val_loss: 0.5856
AUC: 0.8587

Epoch 19/80
 - 0s - loss: 1.0224 - val_loss: 0.5957
AUC: 0.8603

Epoch 20/80
 - 0s - loss: 1.0169 - val_loss: 0.6250
AUC: 0.8601

Epoch 21/80
 - 0s - loss: 1.0130 - val_loss: 0.6351
AUC: 0.8617

Epoch 22/80
 - 0s - loss: 1.0132 - val_loss: 0.6532
AUC: 0.8611

Epoch 23/80
 - 0s - loss: 1.0085 - val_loss: 0.5652
AUC: 0.8600

Epoch 24/80
 - 0s - loss: 1.0118 - val_loss: 0.5766
AUC: 0.8616

Epoch 25/80
 - 0s - loss: 1.0047 - val_loss: 0.6486
AUC: 0.8630

Epoch 26/80
 - 0s - loss: 1.0051 - val_loss: 0.5973
AUC: 0.8627

Epoch 27/80
 - 0s - loss: 0.9977 - val_loss: 0.6753
AUC: 0.8637

Epoch 28/80
 - 0s - loss: 1.0028 - val_loss: 0.6708
AUC: 0.8642

Epoch 29/80
 - 0s - loss: 0.9911 - val_loss: 0.7073
AUC: 0.8651

Epoch 30/80
 - 0s - loss: 0.9959 - val_loss: 0.6628
AUC: 0.8651

Epoch 31/80
 - 0s - loss: 0.9871 - val_loss: 0.6329
AUC: 0.8643

Epoch 32/80
 - 0s - loss: 0.9921 - val_loss: 0.6200
AUC: 0.8637

Epoch 33/80
 - 0s - loss: 0.9890 - val_loss: 0.6301
AUC: 0.8654

Epoch 34/80
 - 0s - loss: 0.9737 - val_loss: 0.6068
AUC: 0.8653

Epoch 35/80
 - 0s - loss: 0.9808 - val_loss: 0.6230
AUC: 0.8658

Epoch 36/80
 - 0s - loss: 0.9785 - val_loss: 0.5899
AUC: 0.8656

Epoch 37/80
 - 0s - loss: 0.9804 - val_loss: 0.6024
AUC: 0.8658

Epoch 38/80
 - 0s - loss: 0.9747 - val_loss: 0.5991
AUC: 0.8659

Epoch 39/80
 - 0s - loss: 0.9751 - val_loss: 0.5937
AUC: 0.8655

Epoch 40/80
 - 0s - loss: 0.9782 - val_loss: 0.5788
AUC: 0.8658

Epoch 41/80
 - 0s - loss: 0.9743 - val_loss: 0.6224
AUC: 0.8659

Epoch 42/80
 - 0s - loss: 0.9696 - val_loss: 0.6027
AUC: 0.8661

Epoch 43/80
 - 0s - loss: 0.9770 - val_loss: 0.6241
AUC: 0.8661

Epoch 44/80
 - 0s - loss: 0.9700 - val_loss: 0.6010
AUC: 0.8660

Epoch 45/80
 - 0s - loss: 0.9713 - val_loss: 0.6016
AUC: 0.8660

Epoch 46/80
 - 0s - loss: 0.9662 - val_loss: 0.6022
AUC: 0.8661

Epoch 47/80
 - 0s - loss: 0.9654 - val_loss: 0.5944
AUC: 0.8659

Epoch 48/80
 - 0s - loss: 0.9659 - val_loss: 0.5960
AUC: 0.8660

Epoch 49/80
 - 0s - loss: 0.9694 - val_loss: 0.5985
AUC: 0.8661

Epoch 50/80
 - 0s - loss: 0.9728 - val_loss: 0.6050
AUC: 0.8662

Epoch 51/80
 - 0s - loss: 0.9710 - val_loss: 0.6016
AUC: 0.8663

Epoch 52/80
 - 0s - loss: 0.9677 - val_loss: 0.5998
AUC: 0.8662

Epoch 53/80
 - 0s - loss: 0.9680 - val_loss: 0.6064
AUC: 0.8662

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9759 - val_loss: 0.5946
AUC: 0.8664

Epoch 2/30
 - 0s - loss: 0.9672 - val_loss: 0.6058
AUC: 0.8665

Epoch 3/30
 - 0s - loss: 0.9704 - val_loss: 0.6196
AUC: 0.8667

Epoch 4/30
 - 0s - loss: 0.9666 - val_loss: 0.5913
AUC: 0.8665

Epoch 5/30
 - 0s - loss: 0.9672 - val_loss: 0.5946
AUC: 0.8665

Epoch 6/30
 - 0s - loss: 0.9661 - val_loss: 0.5973
AUC: 0.8668

Epoch 7/30
 - 0s - loss: 0.9633 - val_loss: 0.5836
AUC: 0.8667

Epoch 8/30
 - 0s - loss: 0.9613 - val_loss: 0.6156
AUC: 0.8672

Epoch 9/30
 - 0s - loss: 0.9591 - val_loss: 0.6019
AUC: 0.8671

Epoch 10/30
 - 0s - loss: 0.9553 - val_loss: 0.6013
AUC: 0.8673

Epoch 11/30
 - 0s - loss: 0.9588 - val_loss: 0.6018
AUC: 0.8674

Epoch 12/30
 - 0s - loss: 0.9525 - val_loss: 0.5972
AUC: 0.8674

Epoch 13/30
 - 0s - loss: 0.9525 - val_loss: 0.5987
AUC: 0.8675

Epoch 14/30
 - 0s - loss: 0.9552 - val_loss: 0.6085
AUC: 0.8677

Epoch 15/30
 - 0s - loss: 0.9547 - val_loss: 0.6122
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.9505 - val_loss: 0.5935
AUC: 0.8677

Epoch 17/30
 - 0s - loss: 0.9488 - val_loss: 0.5948
AUC: 0.8678

Epoch 18/30
 - 0s - loss: 0.9499 - val_loss: 0.5891
AUC: 0.8677

Epoch 19/30
 - 0s - loss: 0.9491 - val_loss: 0.5925
AUC: 0.8678

Epoch 20/30
 - 0s - loss: 0.9521 - val_loss: 0.5955
AUC: 0.8678

Epoch 21/30
 - 0s - loss: 0.9445 - val_loss: 0.5899
AUC: 0.8678

Epoch 22/30
 - 0s - loss: 0.9486 - val_loss: 0.5910
AUC: 0.8679

Epoch 23/30
 - 0s - loss: 0.9448 - val_loss: 0.5930
AUC: 0.8679

Epoch 24/30
 - 0s - loss: 0.9475 - val_loss: 0.5918
AUC: 0.8679

Epoch 25/30
 - 0s - loss: 0.9442 - val_loss: 0.5913
AUC: 0.8679

Epoch 26/30
 - 0s - loss: 0.9458 - val_loss: 0.5937
AUC: 0.8679

Epoch 27/30
 - 0s - loss: 0.9419 - val_loss: 0.5921
AUC: 0.8679

Epoch 28/30
 - 0s - loss: 0.9465 - val_loss: 0.5926
AUC: 0.8679

Epoch 29/30
 - 0s - loss: 0.9447 - val_loss: 0.5915
AUC: 0.8679

Epoch 30/30
 - 0s - loss: 0.9422 - val_loss: 0.5905
Using TensorFlow backend.
AUC: 0.8679

2019-03-08 06:19:17.761582: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:19:17.925006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:19:17.925049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:19:18.221143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:19:18.221215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:19:18.221224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:19:18.221525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3128
Epoch 2/80
 - 2s - loss: 0.3332
Epoch 3/80
 - 2s - loss: 0.2900
Epoch 4/80
 - 2s - loss: 0.2562
Epoch 5/80
 - 2s - loss: 0.2297
Epoch 6/80
 - 2s - loss: 0.2105
Epoch 7/80
 - 2s - loss: 0.1950
Epoch 8/80
 - 2s - loss: 0.1821
Epoch 9/80
 - 2s - loss: 0.1711
Epoch 10/80
 - 2s - loss: 0.1617
Epoch 11/80
 - 2s - loss: 0.1533
Epoch 12/80
 - 2s - loss: 0.1459
Epoch 13/80
 - 2s - loss: 0.1395
Epoch 14/80
 - 2s - loss: 0.1341
Epoch 15/80
 - 2s - loss: 0.1297
Epoch 16/80
 - 2s - loss: 0.1259
Epoch 17/80
 - 2s - loss: 0.1227
Epoch 18/80
 - 2s - loss: 0.1199
Epoch 19/80
 - 2s - loss: 0.1175
Epoch 20/80
 - 2s - loss: 0.1155
Epoch 21/80
 - 2s - loss: 0.1137
Epoch 22/80
 - 2s - loss: 0.1121
Epoch 23/80
 - 2s - loss: 0.1108
Epoch 24/80
 - 2s - loss: 0.1096
Epoch 25/80
 - 2s - loss: 0.1086
Epoch 26/80
 - 2s - loss: 0.1078
Epoch 27/80
 - 2s - loss: 0.1070
Epoch 28/80
 - 2s - loss: 0.1064
Epoch 29/80
 - 2s - loss: 0.1059
Epoch 30/80
 - 2s - loss: 0.1053
Epoch 31/80
 - 2s - loss: 0.1050
Epoch 32/80
 - 2s - loss: 0.1046
Epoch 33/80
 - 2s - loss: 0.1043
Epoch 34/80
 - 2s - loss: 0.1040
Epoch 35/80
 - 2s - loss: 0.1037
Epoch 36/80
 - 2s - loss: 0.1035
Epoch 37/80
 - 2s - loss: 0.1032
Epoch 38/80
 - 2s - loss: 0.1031
Epoch 39/80
 - 2s - loss: 0.1029
Epoch 40/80
 - 2s - loss: 0.1027
Epoch 41/80
 - 2s - loss: 0.1026
Epoch 42/80
 - 2s - loss: 0.1024
Epoch 43/80
 - 2s - loss: 0.1023
Epoch 44/80
 - 2s - loss: 0.1022
Epoch 45/80
 - 2s - loss: 0.1021
Epoch 46/80
 - 2s - loss: 0.1020
Epoch 47/80
 - 2s - loss: 0.1019
Epoch 48/80
 - 2s - loss: 0.1018
Epoch 49/80
 - 2s - loss: 0.1017
Epoch 50/80
 - 2s - loss: 0.1016
Epoch 51/80
 - 2s - loss: 0.1016
Epoch 52/80
 - 2s - loss: 0.1015
Epoch 53/80
 - 2s - loss: 0.1014
Epoch 54/80
 - 2s - loss: 0.1014
Epoch 55/80
 - 2s - loss: 0.1013
Epoch 56/80
 - 2s - loss: 0.1013
Epoch 57/80
 - 2s - loss: 0.1012
Epoch 58/80
 - 2s - loss: 0.1011
Epoch 59/80
 - 2s - loss: 0.1011
Epoch 60/80
 - 2s - loss: 0.1011
Epoch 61/80
 - 2s - loss: 0.1011
Epoch 62/80
 - 2s - loss: 0.1010
Epoch 63/80
 - 2s - loss: 0.1009
Epoch 64/80
 - 2s - loss: 0.1009
Epoch 65/80
 - 2s - loss: 0.1009
Epoch 66/80
 - 2s - loss: 0.1008
Epoch 67/80
 - 2s - loss: 0.1008
Epoch 68/80
 - 2s - loss: 0.1008
Epoch 69/80
 - 2s - loss: 0.1008
Epoch 70/80
 - 2s - loss: 0.0981
Epoch 71/80
 - 2s - loss: 0.0978
Epoch 72/80
 - 2s - loss: 0.0978
Epoch 73/80
 - 2s - loss: 0.0978
Epoch 74/80
 - 2s - loss: 0.0978
Epoch 75/80
 - 2s - loss: 0.0971
Epoch 76/80
 - 2s - loss: 0.0971
Epoch 77/80
 - 2s - loss: 0.0971
Epoch 78/80
 - 2s - loss: 0.0971
Epoch 79/80
 - 2s - loss: 0.0970
Epoch 80/80
 - 2s - loss: 0.0970
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.1299 - val_loss: 1.0263
AUC: 0.7878

Epoch 2/80
 - 0s - loss: 2.0041 - val_loss: 0.7494
AUC: 0.8298

Epoch 3/80
 - 0s - loss: 1.3759 - val_loss: 0.7001
AUC: 0.8407

Epoch 4/80
 - 0s - loss: 1.2255 - val_loss: 0.7098
AUC: 0.8479

Epoch 5/80
 - 0s - loss: 1.1572 - val_loss: 0.6756
AUC: 0.8544

Epoch 6/80
 - 0s - loss: 1.1401 - val_loss: 0.6930
AUC: 0.8575

Epoch 7/80
 - 0s - loss: 1.1183 - val_loss: 0.6961
AUC: 0.8599

Epoch 8/80
 - 0s - loss: 1.1050 - val_loss: 0.6258
AUC: 0.8611

Epoch 9/80
 - 0s - loss: 1.0892 - val_loss: 0.6519
AUC: 0.8628

Epoch 10/80
 - 0s - loss: 1.0787 - val_loss: 0.6576
AUC: 0.8643

Epoch 11/80
 - 0s - loss: 1.0758 - val_loss: 0.6696
AUC: 0.8650

Epoch 12/80
 - 0s - loss: 1.0691 - val_loss: 0.6213
AUC: 0.8647

Epoch 13/80
 - 0s - loss: 1.0680 - val_loss: 0.7040
AUC: 0.8671

Epoch 14/80
 - 0s - loss: 1.0584 - val_loss: 0.6047
AUC: 0.8658

Epoch 15/80
 - 0s - loss: 1.0526 - val_loss: 0.6227
AUC: 0.8674

Epoch 16/80
 - 0s - loss: 1.0451 - val_loss: 0.7130
AUC: 0.8682

Epoch 17/80
 - 0s - loss: 1.0431 - val_loss: 0.6255
AUC: 0.8675

Epoch 18/80
 - 0s - loss: 1.0388 - val_loss: 0.6504
AUC: 0.8692

Epoch 19/80
 - 0s - loss: 1.0393 - val_loss: 0.6281
AUC: 0.8684

Epoch 20/80
 - 0s - loss: 1.0302 - val_loss: 0.6122
AUC: 0.8691

Epoch 21/80
 - 0s - loss: 1.0364 - val_loss: 0.6120
AUC: 0.8698

Epoch 22/80
 - 0s - loss: 1.0260 - val_loss: 0.6387
AUC: 0.8702

Epoch 23/80
 - 0s - loss: 1.0290 - val_loss: 0.6437
AUC: 0.8705

Epoch 24/80
 - 0s - loss: 1.0247 - val_loss: 0.7186
AUC: 0.8714

Epoch 25/80
 - 0s - loss: 1.0132 - val_loss: 0.6022
AUC: 0.8707

Epoch 26/80
 - 0s - loss: 1.0060 - val_loss: 0.5912
AUC: 0.8703

Epoch 27/80
 - 0s - loss: 1.0108 - val_loss: 0.6043
AUC: 0.8705

Epoch 28/80
 - 0s - loss: 1.0098 - val_loss: 0.6227
AUC: 0.8712

Epoch 29/80
 - 0s - loss: 1.0060 - val_loss: 0.6147
AUC: 0.8708

Epoch 30/80
 - 0s - loss: 1.0094 - val_loss: 0.5978
AUC: 0.8703

Epoch 31/80
 - 0s - loss: 1.0062 - val_loss: 0.6014
AUC: 0.8708

Epoch 32/80
 - 0s - loss: 1.0094 - val_loss: 0.6419
AUC: 0.8717

Epoch 33/80
 - 0s - loss: 1.0037 - val_loss: 0.6045
AUC: 0.8710

Epoch 34/80
 - 0s - loss: 1.0023 - val_loss: 0.6412
AUC: 0.8715

Epoch 35/80
 - 0s - loss: 1.0010 - val_loss: 0.6273
AUC: 0.8712

Epoch 36/80
 - 0s - loss: 0.9965 - val_loss: 0.6261
AUC: 0.8713

Epoch 37/80
 - 0s - loss: 1.0034 - val_loss: 0.6142
AUC: 0.8712

Epoch 38/80
 - 0s - loss: 1.0004 - val_loss: 0.6092
AUC: 0.8712

Epoch 39/80
 - 0s - loss: 1.0032 - val_loss: 0.6079
AUC: 0.8712

Epoch 40/80
 - 0s - loss: 1.0051 - val_loss: 0.6018
AUC: 0.8711

Epoch 41/80
 - 0s - loss: 1.0002 - val_loss: 0.6082
AUC: 0.8712

Epoch 42/80
 - 0s - loss: 1.0022 - val_loss: 0.6066
AUC: 0.8712

Epoch 43/80
 - 0s - loss: 0.9976 - val_loss: 0.6001
AUC: 0.8711

Epoch 44/80
 - 0s - loss: 1.0040 - val_loss: 0.6052
AUC: 0.8713

Epoch 45/80
 - 0s - loss: 0.9987 - val_loss: 0.6147
AUC: 0.8714

Epoch 46/80
 - 0s - loss: 1.0050 - val_loss: 0.6093
AUC: 0.8713

Epoch 47/80
 - 0s - loss: 0.9997 - val_loss: 0.6118
AUC: 0.8713

Epoch 48/80
 - 0s - loss: 1.0024 - val_loss: 0.6114
AUC: 0.8713

Epoch 49/80
 - 0s - loss: 0.9961 - val_loss: 0.6119
AUC: 0.8713

Epoch 50/80
 - 0s - loss: 0.9961 - val_loss: 0.6101
AUC: 0.8713

Epoch 51/80
 - 0s - loss: 0.9985 - val_loss: 0.6090
AUC: 0.8713

Epoch 52/80
 - 0s - loss: 0.9937 - val_loss: 0.6090
AUC: 0.8713

Epoch 53/80
 - 0s - loss: 0.9932 - val_loss: 0.6080
AUC: 0.8713

Epoch 54/80
 - 0s - loss: 0.9965 - val_loss: 0.6057
AUC: 0.8712

Epoch 55/80
 - 0s - loss: 1.0016 - val_loss: 0.6073
AUC: 0.8713

Epoch 56/80
 - 0s - loss: 1.0007 - val_loss: 0.6104
AUC: 0.8713

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0067 - val_loss: 0.5989
AUC: 0.8708

Epoch 2/30
 - 0s - loss: 1.0096 - val_loss: 0.6002
AUC: 0.8710

Epoch 3/30
 - 0s - loss: 0.9996 - val_loss: 0.6281
AUC: 0.8715

Epoch 4/30
 - 0s - loss: 1.0010 - val_loss: 0.5893
AUC: 0.8707

Epoch 5/30
 - 0s - loss: 0.9969 - val_loss: 0.6067
AUC: 0.8713

Epoch 6/30
 - 0s - loss: 0.9978 - val_loss: 0.6106
AUC: 0.8717

Epoch 7/30
 - 0s - loss: 0.9957 - val_loss: 0.5949
AUC: 0.8714

Epoch 8/30
 - 0s - loss: 0.9945 - val_loss: 0.6200
AUC: 0.8717

Epoch 9/30
 - 0s - loss: 0.9930 - val_loss: 0.6248
AUC: 0.8720

Epoch 10/30
 - 0s - loss: 0.9940 - val_loss: 0.6003
AUC: 0.8717

Epoch 11/30
 - 0s - loss: 0.9948 - val_loss: 0.6349
AUC: 0.8725

Epoch 12/30
 - 0s - loss: 0.9927 - val_loss: 0.6045
AUC: 0.8719

Epoch 13/30
 - 0s - loss: 0.9933 - val_loss: 0.6245
AUC: 0.8727

Epoch 14/30
 - 0s - loss: 0.9854 - val_loss: 0.6049
AUC: 0.8722

Epoch 15/30
 - 0s - loss: 0.9853 - val_loss: 0.6037
AUC: 0.8721

Epoch 16/30
 - 0s - loss: 0.9895 - val_loss: 0.6033
AUC: 0.8722

Epoch 17/30
 - 0s - loss: 0.9866 - val_loss: 0.6054
AUC: 0.8723

Epoch 18/30
 - 0s - loss: 0.9847 - val_loss: 0.6021
AUC: 0.8722

Epoch 19/30
 - 0s - loss: 0.9855 - val_loss: 0.6079
AUC: 0.8723

Epoch 20/30
 - 0s - loss: 0.9837 - val_loss: 0.6002
AUC: 0.8721

Epoch 21/30
 - 0s - loss: 0.9909 - val_loss: 0.6053
AUC: 0.8723

Epoch 22/30
 - 0s - loss: 0.9832 - val_loss: 0.6059
AUC: 0.8723

Epoch 23/30
 - 0s - loss: 0.9830 - val_loss: 0.5996
AUC: 0.8721

Epoch 24/30
 - 0s - loss: 0.9813 - val_loss: 0.6055
AUC: 0.8723

Epoch 25/30
 - 0s - loss: 0.9795 - val_loss: 0.6045
AUC: 0.8723

Epoch 26/30
 - 0s - loss: 0.9828 - val_loss: 0.6038
AUC: 0.8722

Epoch 27/30
 - 0s - loss: 0.9887 - val_loss: 0.6032
AUC: 0.8722

Epoch 28/30
 - 0s - loss: 0.9795 - val_loss: 0.6038
AUC: 0.8723

Epoch 29/30
 - 0s - loss: 0.9815 - val_loss: 0.6031
AUC: 0.8723

Epoch 30/30
 - 0s - loss: 0.9826 - val_loss: 0.6020
Using TensorFlow backend.
AUC: 0.8722

2019-03-08 06:22:44.575803: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:22:44.740323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:22:44.740366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:22:45.036193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:22:45.036243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:22:45.036252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:22:45.036507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2585
Epoch 2/80
 - 2s - loss: 0.3315
Epoch 3/80
 - 2s - loss: 0.3047
Epoch 4/80
 - 2s - loss: 0.2851
Epoch 5/80
 - 2s - loss: 0.2577
Epoch 6/80
 - 2s - loss: 0.2331
Epoch 7/80
 - 2s - loss: 0.2135
Epoch 8/80
 - 2s - loss: 0.1965
Epoch 9/80
 - 2s - loss: 0.1816
Epoch 10/80
 - 2s - loss: 0.1692
Epoch 11/80
 - 2s - loss: 0.1591
Epoch 12/80
 - 2s - loss: 0.1506
Epoch 13/80
 - 2s - loss: 0.1433
Epoch 14/80
 - 2s - loss: 0.1371
Epoch 15/80
 - 2s - loss: 0.1320
Epoch 16/80
 - 2s - loss: 0.1278
Epoch 17/80
 - 2s - loss: 0.1242
Epoch 18/80
 - 2s - loss: 0.1213
Epoch 19/80
 - 2s - loss: 0.1188
Epoch 20/80
 - 2s - loss: 0.1166
Epoch 21/80
 - 2s - loss: 0.1148
Epoch 22/80
 - 2s - loss: 0.1132
Epoch 23/80
 - 2s - loss: 0.1117
Epoch 24/80
 - 2s - loss: 0.1105
Epoch 25/80
 - 2s - loss: 0.1095
Epoch 26/80
 - 2s - loss: 0.1086
Epoch 27/80
 - 2s - loss: 0.1078
Epoch 28/80
 - 2s - loss: 0.1071
Epoch 29/80
 - 2s - loss: 0.1066
Epoch 30/80
 - 2s - loss: 0.1060
Epoch 31/80
 - 2s - loss: 0.1056
Epoch 32/80
 - 2s - loss: 0.1052
Epoch 33/80
 - 2s - loss: 0.1048
Epoch 34/80
 - 2s - loss: 0.1045
Epoch 35/80
 - 2s - loss: 0.1043
Epoch 36/80
 - 2s - loss: 0.1040
Epoch 37/80
 - 2s - loss: 0.1038
Epoch 38/80
 - 2s - loss: 0.1036
Epoch 39/80
 - 2s - loss: 0.1034
Epoch 40/80
 - 2s - loss: 0.1032
Epoch 41/80
 - 2s - loss: 0.1030
Epoch 42/80
 - 2s - loss: 0.1029
Epoch 43/80
 - 2s - loss: 0.1028
Epoch 44/80
 - 2s - loss: 0.1027
Epoch 45/80
 - 2s - loss: 0.1025
Epoch 46/80
 - 2s - loss: 0.1024
Epoch 47/80
 - 2s - loss: 0.1023
Epoch 48/80
 - 2s - loss: 0.1022
Epoch 49/80
 - 2s - loss: 0.1021
Epoch 50/80
 - 2s - loss: 0.1021
Epoch 51/80
 - 2s - loss: 0.1020
Epoch 52/80
 - 2s - loss: 0.1019
Epoch 53/80
 - 2s - loss: 0.1018
Epoch 54/80
 - 2s - loss: 0.1018
Epoch 55/80
 - 2s - loss: 0.1017
Epoch 56/80
 - 2s - loss: 0.1016
Epoch 57/80
 - 2s - loss: 0.1016
Epoch 58/80
 - 2s - loss: 0.1016
Epoch 59/80
 - 2s - loss: 0.1015
Epoch 60/80
 - 2s - loss: 0.1015
Epoch 61/80
 - 2s - loss: 0.1014
Epoch 62/80
 - 2s - loss: 0.1014
Epoch 63/80
 - 2s - loss: 0.1013
Epoch 64/80
 - 2s - loss: 0.1013
Epoch 65/80
 - 2s - loss: 0.1013
Epoch 66/80
 - 2s - loss: 0.1012
Epoch 67/80
 - 2s - loss: 0.1012
Epoch 68/80
 - 2s - loss: 0.1011
Epoch 69/80
 - 2s - loss: 0.1011
Epoch 70/80
 - 2s - loss: 0.1011
Epoch 71/80
 - 2s - loss: 0.1011
Epoch 72/80
 - 2s - loss: 0.0984
Epoch 73/80
 - 2s - loss: 0.0981
Epoch 74/80
 - 2s - loss: 0.0981
Epoch 75/80
 - 2s - loss: 0.0981
Epoch 76/80
 - 2s - loss: 0.0981
Epoch 77/80
 - 2s - loss: 0.0974
Epoch 78/80
 - 2s - loss: 0.0974
Epoch 79/80
 - 2s - loss: 0.0974
Epoch 80/80
 - 2s - loss: 0.0974
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.6092 - val_loss: 1.4957
AUC: 0.7690

Epoch 2/80
 - 0s - loss: 2.1691 - val_loss: 0.8235
AUC: 0.8191

Epoch 3/80
 - 0s - loss: 1.4379 - val_loss: 0.7303
AUC: 0.8320

Epoch 4/80
 - 0s - loss: 1.2593 - val_loss: 0.6604
AUC: 0.8370

Epoch 5/80
 - 0s - loss: 1.1879 - val_loss: 0.6931
AUC: 0.8460

Epoch 6/80
 - 0s - loss: 1.1525 - val_loss: 0.6654
AUC: 0.8523

Epoch 7/80
 - 0s - loss: 1.1279 - val_loss: 0.6366
AUC: 0.8550

Epoch 8/80
 - 0s - loss: 1.1002 - val_loss: 0.6158
AUC: 0.8550

Epoch 9/80
 - 0s - loss: 1.0941 - val_loss: 0.6325
AUC: 0.8589

Epoch 10/80
 - 0s - loss: 1.0903 - val_loss: 0.6508
AUC: 0.8610

Epoch 11/80
 - 0s - loss: 1.0809 - val_loss: 0.6932
AUC: 0.8638

Epoch 12/80
 - 0s - loss: 1.0594 - val_loss: 0.6092
AUC: 0.8635

Epoch 13/80
 - 0s - loss: 1.0622 - val_loss: 0.5758
AUC: 0.8634

Epoch 14/80
 - 0s - loss: 1.0488 - val_loss: 0.6250
AUC: 0.8650

Epoch 15/80
 - 0s - loss: 1.0521 - val_loss: 0.6149
AUC: 0.8653

Epoch 16/80
 - 0s - loss: 1.0453 - val_loss: 0.6362
AUC: 0.8643

Epoch 17/80
 - 0s - loss: 1.0389 - val_loss: 0.6606
AUC: 0.8672

Epoch 18/80
 - 0s - loss: 1.0351 - val_loss: 0.5911
AUC: 0.8664

Epoch 19/80
 - 0s - loss: 1.0259 - val_loss: 0.6219
AUC: 0.8683

Epoch 20/80
 - 0s - loss: 1.0298 - val_loss: 0.5811
AUC: 0.8658

Epoch 21/80
 - 0s - loss: 1.0242 - val_loss: 0.6526
AUC: 0.8696

Epoch 22/80
 - 0s - loss: 1.0273 - val_loss: 0.6301
AUC: 0.8679

Epoch 23/80
 - 0s - loss: 1.0206 - val_loss: 0.6591
AUC: 0.8701

Epoch 24/80
 - 0s - loss: 1.0139 - val_loss: 0.5775
AUC: 0.8691

Epoch 25/80
 - 0s - loss: 1.0068 - val_loss: 0.6208
AUC: 0.8701

Epoch 26/80
 - 0s - loss: 1.0010 - val_loss: 0.6028
AUC: 0.8699

Epoch 27/80
 - 0s - loss: 1.0060 - val_loss: 0.6014
AUC: 0.8699

Epoch 28/80
 - 0s - loss: 1.0000 - val_loss: 0.6014
AUC: 0.8699

Epoch 29/80
 - 0s - loss: 1.0023 - val_loss: 0.6257
AUC: 0.8706

Epoch 30/80
 - 0s - loss: 1.0000 - val_loss: 0.6130
AUC: 0.8699

Epoch 31/80
 - 0s - loss: 1.0041 - val_loss: 0.5798
AUC: 0.8695

Epoch 32/80
 - 0s - loss: 0.9998 - val_loss: 0.6079
AUC: 0.8702

Epoch 33/80
 - 0s - loss: 0.9984 - val_loss: 0.5945
AUC: 0.8697

Epoch 34/80
 - 0s - loss: 0.9972 - val_loss: 0.6012
AUC: 0.8700

Epoch 35/80
 - 0s - loss: 0.9993 - val_loss: 0.5958
AUC: 0.8701

Epoch 36/80
 - 0s - loss: 0.9941 - val_loss: 0.6013
AUC: 0.8702

Epoch 37/80
 - 0s - loss: 0.9915 - val_loss: 0.5943
AUC: 0.8701

Epoch 38/80
 - 0s - loss: 1.0009 - val_loss: 0.5969
AUC: 0.8700

Epoch 39/80
 - 0s - loss: 1.0000 - val_loss: 0.5955
AUC: 0.8701

Epoch 40/80
 - 0s - loss: 0.9979 - val_loss: 0.5979
AUC: 0.8702

Epoch 41/80
 - 0s - loss: 0.9960 - val_loss: 0.5921
AUC: 0.8700

Epoch 42/80
 - 0s - loss: 0.9945 - val_loss: 0.6011
AUC: 0.8703

Epoch 43/80
 - 0s - loss: 1.0052 - val_loss: 0.6001
AUC: 0.8702

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9992 - val_loss: 0.6097
AUC: 0.8701

Epoch 2/30
 - 0s - loss: 1.0002 - val_loss: 0.6116
AUC: 0.8703

Epoch 3/30
 - 0s - loss: 0.9994 - val_loss: 0.6125
AUC: 0.8702

Epoch 4/30
 - 0s - loss: 0.9935 - val_loss: 0.6005
AUC: 0.8702

Epoch 5/30
 - 0s - loss: 0.9972 - val_loss: 0.6091
AUC: 0.8706

Epoch 6/30
 - 0s - loss: 0.9894 - val_loss: 0.5973
AUC: 0.8703

Epoch 7/30
 - 0s - loss: 0.9917 - val_loss: 0.6053
AUC: 0.8706

Epoch 8/30
 - 0s - loss: 0.9920 - val_loss: 0.5805
AUC: 0.8704

Epoch 9/30
 - 0s - loss: 0.9899 - val_loss: 0.5953
AUC: 0.8707

Epoch 10/30
 - 0s - loss: 0.9917 - val_loss: 0.5986
AUC: 0.8709

Epoch 11/30
 - 0s - loss: 0.9869 - val_loss: 0.5987
AUC: 0.8710

Epoch 12/30
 - 0s - loss: 0.9856 - val_loss: 0.6088
AUC: 0.8713

Epoch 13/30
 - 0s - loss: 0.9788 - val_loss: 0.5873
AUC: 0.8709

Epoch 14/30
 - 0s - loss: 0.9815 - val_loss: 0.6027
AUC: 0.8712

Epoch 15/30
 - 0s - loss: 0.9855 - val_loss: 0.5876
AUC: 0.8708

Epoch 16/30
 - 0s - loss: 0.9857 - val_loss: 0.5923
AUC: 0.8709

Epoch 17/30
 - 0s - loss: 0.9832 - val_loss: 0.5943
AUC: 0.8710

Epoch 18/30
 - 0s - loss: 0.9781 - val_loss: 0.5936
AUC: 0.8711

Epoch 19/30
 - 0s - loss: 0.9785 - val_loss: 0.5872
AUC: 0.8710

Epoch 20/30
 - 0s - loss: 0.9724 - val_loss: 0.5866
AUC: 0.8710

Epoch 21/30
 - 0s - loss: 0.9737 - val_loss: 0.5857
AUC: 0.8711

Epoch 22/30
 - 0s - loss: 0.9715 - val_loss: 0.5844
AUC: 0.8711

Epoch 23/30
 - 0s - loss: 0.9736 - val_loss: 0.5856
AUC: 0.8711

Epoch 24/30
 - 0s - loss: 0.9757 - val_loss: 0.5867
AUC: 0.8712

Epoch 25/30
 - 0s - loss: 0.9789 - val_loss: 0.5882
AUC: 0.8712

Epoch 26/30
 - 0s - loss: 0.9707 - val_loss: 0.5887
AUC: 0.8712

Epoch 27/30
 - 0s - loss: 0.9775 - val_loss: 0.5878
AUC: 0.8712

Epoch 28/30
 - 0s - loss: 0.9674 - val_loss: 0.5867
AUC: 0.8712

Epoch 29/30
 - 0s - loss: 0.9730 - val_loss: 0.5890
AUC: 0.8712

Epoch 30/30
 - 0s - loss: 0.9698 - val_loss: 0.5883
Using TensorFlow backend.
AUC: 0.8712

2019-03-08 06:26:05.097896: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:26:05.266223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:26:05.266268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:26:05.567133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:26:05.567199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:26:05.567209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:26:05.567507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2799
Epoch 2/80
 - 2s - loss: 0.3297
Epoch 3/80
 - 2s - loss: 0.2872
Epoch 4/80
 - 2s - loss: 0.2579
Epoch 5/80
 - 2s - loss: 0.2354
Epoch 6/80
 - 2s - loss: 0.2197
Epoch 7/80
 - 2s - loss: 0.2056
Epoch 8/80
 - 2s - loss: 0.1909
Epoch 9/80
 - 2s - loss: 0.1768
Epoch 10/80
 - 2s - loss: 0.1654
Epoch 11/80
 - 2s - loss: 0.1561
Epoch 12/80
 - 2s - loss: 0.1481
Epoch 13/80
 - 2s - loss: 0.1413
Epoch 14/80
 - 2s - loss: 0.1354
Epoch 15/80
 - 2s - loss: 0.1307
Epoch 16/80
 - 2s - loss: 0.1266
Epoch 17/80
 - 2s - loss: 0.1232
Epoch 18/80
 - 2s - loss: 0.1202
Epoch 19/80
 - 2s - loss: 0.1177
Epoch 20/80
 - 2s - loss: 0.1155
Epoch 21/80
 - 2s - loss: 0.1137
Epoch 22/80
 - 2s - loss: 0.1121
Epoch 23/80
 - 2s - loss: 0.1108
Epoch 24/80
 - 2s - loss: 0.1097
Epoch 25/80
 - 2s - loss: 0.1087
Epoch 26/80
 - 2s - loss: 0.1078
Epoch 27/80
 - 2s - loss: 0.1071
Epoch 28/80
 - 2s - loss: 0.1064
Epoch 29/80
 - 2s - loss: 0.1059
Epoch 30/80
 - 2s - loss: 0.1054
Epoch 31/80
 - 2s - loss: 0.1050
Epoch 32/80
 - 2s - loss: 0.1047
Epoch 33/80
 - 2s - loss: 0.1043
Epoch 34/80
 - 2s - loss: 0.1041
Epoch 35/80
 - 2s - loss: 0.1038
Epoch 36/80
 - 2s - loss: 0.1036
Epoch 37/80
 - 2s - loss: 0.1033
Epoch 38/80
 - 2s - loss: 0.1031
Epoch 39/80
 - 2s - loss: 0.1030
Epoch 40/80
 - 2s - loss: 0.1028
Epoch 41/80
 - 2s - loss: 0.1026
Epoch 42/80
 - 2s - loss: 0.1025
Epoch 43/80
 - 2s - loss: 0.1024
Epoch 44/80
 - 2s - loss: 0.1023
Epoch 45/80
 - 2s - loss: 0.1022
Epoch 46/80
 - 2s - loss: 0.1021
Epoch 47/80
 - 2s - loss: 0.1019
Epoch 48/80
 - 2s - loss: 0.1019
Epoch 49/80
 - 2s - loss: 0.1018
Epoch 50/80
 - 2s - loss: 0.1017
Epoch 51/80
 - 2s - loss: 0.1016
Epoch 52/80
 - 2s - loss: 0.1016
Epoch 53/80
 - 2s - loss: 0.1015
Epoch 54/80
 - 2s - loss: 0.1014
Epoch 55/80
 - 2s - loss: 0.1014
Epoch 56/80
 - 2s - loss: 0.1014
Epoch 57/80
 - 2s - loss: 0.1013
Epoch 58/80
 - 2s - loss: 0.1013
Epoch 59/80
 - 2s - loss: 0.1012
Epoch 60/80
 - 2s - loss: 0.1012
Epoch 61/80
 - 2s - loss: 0.1011
Epoch 62/80
 - 2s - loss: 0.1011
Epoch 63/80
 - 2s - loss: 0.1010
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 06:28:07.976633: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:28:08.143151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:28:08.143218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:28:08.444008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:28:08.444069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:28:08.444078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:28:08.444395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2962
Epoch 2/80
 - 2s - loss: 0.3292
Epoch 3/80
 - 2s - loss: 0.2864
Epoch 4/80
 - 2s - loss: 0.2564
Epoch 5/80
 - 2s - loss: 0.2330
Epoch 6/80
 - 2s - loss: 0.2151
Epoch 7/80
 - 2s - loss: 0.1991
Epoch 8/80
 - 2s - loss: 0.1849
Epoch 9/80
 - 2s - loss: 0.1733
Epoch 10/80
 - 2s - loss: 0.1634
Epoch 11/80
 - 2s - loss: 0.1545
Epoch 12/80
 - 2s - loss: 0.1465
Epoch 13/80
 - 2s - loss: 0.1396
Epoch 14/80
 - 2s - loss: 0.1340
Epoch 15/80
 - 2s - loss: 0.1295
Epoch 16/80
 - 2s - loss: 0.1257
Epoch 17/80
 - 2s - loss: 0.1227
Epoch 18/80
 - 2s - loss: 0.1201
Epoch 19/80
 - 2s - loss: 0.1178
Epoch 20/80
 - 2s - loss: 0.1157
Epoch 21/80
 - 2s - loss: 0.1139
Epoch 22/80
 - 2s - loss: 0.1123
Epoch 23/80
 - 2s - loss: 0.1110
Epoch 24/80
 - 2s - loss: 0.1098
Epoch 25/80
 - 2s - loss: 0.1088
Epoch 26/80
 - 2s - loss: 0.1080
Epoch 27/80
 - 2s - loss: 0.1072
Epoch 28/80
 - 2s - loss: 0.1066
Epoch 29/80
 - 2s - loss: 0.1060
Epoch 30/80
 - 2s - loss: 0.1056
Epoch 31/80
 - 2s - loss: 0.1051
Epoch 32/80
 - 2s - loss: 0.1048
Epoch 33/80
 - 2s - loss: 0.1045
Epoch 34/80
 - 2s - loss: 0.1042
Epoch 35/80
 - 2s - loss: 0.1039
Epoch 36/80
 - 2s - loss: 0.1037
Epoch 37/80
 - 2s - loss: 0.1035
Epoch 38/80
 - 2s - loss: 0.1033
Epoch 39/80
 - 2s - loss: 0.1032
Epoch 40/80
 - 2s - loss: 0.1030
Epoch 41/80
 - 2s - loss: 0.1028
Epoch 42/80
 - 2s - loss: 0.1027
Epoch 43/80
 - 2s - loss: 0.1026
Epoch 44/80
 - 2s - loss: 0.1024
Epoch 45/80
 - 2s - loss: 0.1024
Epoch 46/80
 - 2s - loss: 0.1023
Epoch 47/80
 - 2s - loss: 0.1022
Epoch 48/80
 - 2s - loss: 0.1021
Epoch 49/80
 - 2s - loss: 0.1020
Epoch 50/80
 - 2s - loss: 0.1020
Epoch 51/80
 - 2s - loss: 0.1019
Epoch 52/80
 - 2s - loss: 0.1018
Epoch 53/80
 - 2s - loss: 0.1018
Epoch 54/80
 - 2s - loss: 0.1017
Epoch 55/80
 - 2s - loss: 0.1017
Epoch 56/80
 - 2s - loss: 0.1016
Epoch 57/80
 - 2s - loss: 0.1016
Epoch 58/80
 - 2s - loss: 0.1015
Epoch 59/80
 - 2s - loss: 0.1015
Epoch 60/80
 - 2s - loss: 0.1014
Epoch 61/80
 - 2s - loss: 0.1014
Epoch 62/80
 - 2s - loss: 0.1013
Epoch 63/80
 - 2s - loss: 0.1013
Epoch 64/80
 - 2s - loss: 0.1013
Epoch 65/80
 - 2s - loss: 0.1013
Epoch 66/80
 - 2s - loss: 0.0986
Epoch 67/80
 - 2s - loss: 0.0983
Epoch 68/80
 - 2s - loss: 0.0983
Epoch 69/80
 - 2s - loss: 0.0983
Epoch 70/80
 - 2s - loss: 0.0983
Epoch 71/80
 - 2s - loss: 0.0976
Epoch 72/80
 - 2s - loss: 0.0976
Epoch 73/80
 - 2s - loss: 0.0976
Epoch 74/80
 - 2s - loss: 0.0976
Epoch 75/80
 - 2s - loss: 0.0975
Epoch 76/80
 - 2s - loss: 0.0975
Epoch 77/80
 - 2s - loss: 0.0975
Epoch 78/80
 - 2s - loss: 0.0975
Epoch 79/80
 - 2s - loss: 0.0974
Epoch 80/80
 - 2s - loss: 0.0974
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.6094 - val_loss: 0.9771
AUC: 0.8172

Epoch 2/80
 - 0s - loss: 1.3042 - val_loss: 0.7482
AUC: 0.8349

Epoch 3/80
 - 0s - loss: 1.1699 - val_loss: 0.6667
AUC: 0.8433

Epoch 4/80
 - 0s - loss: 1.1150 - val_loss: 0.6935
AUC: 0.8498

Epoch 5/80
 - 0s - loss: 1.0981 - val_loss: 0.6996
AUC: 0.8537

Epoch 6/80
 - 0s - loss: 1.0807 - val_loss: 0.7169
AUC: 0.8568

Epoch 7/80
 - 0s - loss: 1.0544 - val_loss: 0.6051
AUC: 0.8563

Epoch 8/80
 - 0s - loss: 1.0609 - val_loss: 0.6753
AUC: 0.8589

Epoch 9/80
 - 0s - loss: 1.0550 - val_loss: 0.5599
AUC: 0.8601

Epoch 10/80
 - 0s - loss: 1.0395 - val_loss: 0.6213
AUC: 0.8606

Epoch 11/80
 - 0s - loss: 1.0318 - val_loss: 0.6701
AUC: 0.8627

Epoch 12/80
 - 0s - loss: 1.0280 - val_loss: 0.5835
AUC: 0.8635

Epoch 13/80
 - 0s - loss: 1.0294 - val_loss: 0.6817
AUC: 0.8646

Epoch 14/80
 - 0s - loss: 1.0240 - val_loss: 0.6905
AUC: 0.8658

Epoch 15/80
 - 0s - loss: 1.0195 - val_loss: 0.6195
AUC: 0.8653

Epoch 16/80
 - 0s - loss: 1.0151 - val_loss: 0.6508
AUC: 0.8658

Epoch 17/80
 - 0s - loss: 1.0028 - val_loss: 0.6604
AUC: 0.8654

Epoch 18/80
 - 0s - loss: 1.0068 - val_loss: 0.5515
AUC: 0.8654

Epoch 19/80
 - 0s - loss: 1.0013 - val_loss: 0.6820
AUC: 0.8670

Epoch 20/80
 - 0s - loss: 1.0045 - val_loss: 0.6779
AUC: 0.8679

Epoch 21/80
 - 0s - loss: 0.9980 - val_loss: 0.6036
AUC: 0.8676

Epoch 22/80
 - 0s - loss: 0.9930 - val_loss: 0.6415
AUC: 0.8675

Epoch 23/80
 - 0s - loss: 0.9844 - val_loss: 0.6210
AUC: 0.8675

Epoch 24/80
 - 0s - loss: 0.9848 - val_loss: 0.5968
AUC: 0.8667

Epoch 25/80
 - 0s - loss: 0.9840 - val_loss: 0.6223
AUC: 0.8676

Epoch 26/80
 - 0s - loss: 0.9854 - val_loss: 0.6071
AUC: 0.8685

Epoch 27/80
 - 0s - loss: 0.9781 - val_loss: 0.6340
AUC: 0.8682

Epoch 28/80
 - 0s - loss: 0.9740 - val_loss: 0.5850
AUC: 0.8689

Epoch 29/80
 - 0s - loss: 0.9632 - val_loss: 0.6006
AUC: 0.8683

Epoch 30/80
 - 0s - loss: 0.9640 - val_loss: 0.6334
AUC: 0.8686

Epoch 31/80
 - 0s - loss: 0.9653 - val_loss: 0.5823
AUC: 0.8685

Epoch 32/80
 - 0s - loss: 0.9607 - val_loss: 0.5796
AUC: 0.8686

Epoch 33/80
 - 0s - loss: 0.9568 - val_loss: 0.6269
AUC: 0.8687

Epoch 34/80
 - 0s - loss: 0.9641 - val_loss: 0.5925
AUC: 0.8691

Epoch 35/80
 - 0s - loss: 0.9565 - val_loss: 0.6279
AUC: 0.8690

Epoch 36/80
 - 0s - loss: 0.9573 - val_loss: 0.6124
AUC: 0.8688

Epoch 37/80
 - 0s - loss: 0.9575 - val_loss: 0.6053
AUC: 0.8688

Epoch 38/80
 - 0s - loss: 0.9580 - val_loss: 0.5993
AUC: 0.8687

Epoch 39/80
 - 0s - loss: 0.9566 - val_loss: 0.5955
AUC: 0.8686

Epoch 40/80
 - 0s - loss: 0.9584 - val_loss: 0.6076
AUC: 0.8688

Epoch 41/80
 - 0s - loss: 0.9530 - val_loss: 0.6043
AUC: 0.8688

Epoch 42/80
 - 0s - loss: 0.9533 - val_loss: 0.6003
AUC: 0.8688

Epoch 43/80
 - 0s - loss: 0.9570 - val_loss: 0.6052
AUC: 0.8688

Epoch 44/80
 - 0s - loss: 0.9529 - val_loss: 0.5871
AUC: 0.8687

Epoch 45/80
 - 0s - loss: 0.9584 - val_loss: 0.5990
AUC: 0.8687

Epoch 46/80
 - 0s - loss: 0.9517 - val_loss: 0.5977
AUC: 0.8687

Epoch 47/80
 - 0s - loss: 0.9522 - val_loss: 0.6046
AUC: 0.8688

Epoch 48/80
 - 0s - loss: 0.9581 - val_loss: 0.6042
AUC: 0.8689

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9585 - val_loss: 0.5887
AUC: 0.8687

Epoch 2/30
 - 0s - loss: 0.9543 - val_loss: 0.6109
AUC: 0.8692

Epoch 3/30
 - 0s - loss: 0.9570 - val_loss: 0.5932
AUC: 0.8688

Epoch 4/30
 - 0s - loss: 0.9512 - val_loss: 0.5765
AUC: 0.8690

Epoch 5/30
 - 0s - loss: 0.9534 - val_loss: 0.6007
AUC: 0.8692

Epoch 6/30
 - 0s - loss: 0.9493 - val_loss: 0.5942
AUC: 0.8692

Epoch 7/30
 - 0s - loss: 0.9513 - val_loss: 0.5999
AUC: 0.8693

Epoch 8/30
 - 0s - loss: 0.9500 - val_loss: 0.5832
AUC: 0.8694

Epoch 9/30
 - 0s - loss: 0.9431 - val_loss: 0.6184
AUC: 0.8694

Epoch 10/30
 - 0s - loss: 0.9443 - val_loss: 0.5946
AUC: 0.8691

Epoch 11/30
 - 0s - loss: 0.9456 - val_loss: 0.6124
AUC: 0.8693

Epoch 12/30
 - 0s - loss: 0.9460 - val_loss: 0.5892
AUC: 0.8693

Epoch 13/30
 - 0s - loss: 0.9402 - val_loss: 0.5952
AUC: 0.8692

Epoch 14/30
 - 0s - loss: 0.9373 - val_loss: 0.5845
AUC: 0.8692

Epoch 15/30
 - 0s - loss: 0.9334 - val_loss: 0.5883
AUC: 0.8692

Epoch 16/30
 - 0s - loss: 0.9339 - val_loss: 0.5939
AUC: 0.8692

Epoch 17/30
 - 0s - loss: 0.9361 - val_loss: 0.5887
AUC: 0.8692

Epoch 18/30
 - 0s - loss: 0.9378 - val_loss: 0.5935
AUC: 0.8693

Epoch 19/30
 - 0s - loss: 0.9316 - val_loss: 0.5924
AUC: 0.8693

Epoch 20/30
 - 0s - loss: 0.9385 - val_loss: 0.5943
AUC: 0.8693

Epoch 21/30
 - 0s - loss: 0.9383 - val_loss: 0.5888
AUC: 0.8693

Epoch 22/30
 - 0s - loss: 0.9351 - val_loss: 0.5882
AUC: 0.8693

Epoch 23/30
 - 0s - loss: 0.9376 - val_loss: 0.5941
AUC: 0.8694

Epoch 24/30
 - 0s - loss: 0.9337 - val_loss: 0.5968
AUC: 0.8694

Epoch 25/30
 - 0s - loss: 0.9330 - val_loss: 0.5945
AUC: 0.8694

Epoch 26/30
 - 0s - loss: 0.9343 - val_loss: 0.5935
AUC: 0.8693

Epoch 27/30
 - 0s - loss: 0.9367 - val_loss: 0.5933
AUC: 0.8693

Epoch 28/30
 - 0s - loss: 0.9355 - val_loss: 0.5923
AUC: 0.8693

Epoch 29/30
 - 0s - loss: 0.9319 - val_loss: 0.5918
AUC: 0.8693

Epoch 30/30
 - 0s - loss: 0.9350 - val_loss: 0.5911
Using TensorFlow backend.
AUC: 0.8693

2019-03-08 06:31:32.079316: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:31:32.245976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:31:32.246019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:31:32.545990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:31:32.546041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:31:32.546049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:31:32.546331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0617
Epoch 2/80
 - 2s - loss: 0.1939
Epoch 3/80
 - 2s - loss: 0.1665
Epoch 4/80
 - 2s - loss: 0.1560
Epoch 5/80
 - 2s - loss: 0.1457
Epoch 6/80
 - 2s - loss: 0.1352
Epoch 7/80
 - 2s - loss: 0.1237
Epoch 8/80
 - 2s - loss: 0.1119
Epoch 9/80
 - 2s - loss: 0.1018
Epoch 10/80
 - 2s - loss: 0.0932
Epoch 11/80
 - 2s - loss: 0.0856
Epoch 12/80
 - 2s - loss: 0.0790
Epoch 13/80
 - 2s - loss: 0.0733
Epoch 14/80
 - 2s - loss: 0.0686
Epoch 15/80
 - 2s - loss: 0.0648
Epoch 16/80
 - 2s - loss: 0.0618
Epoch 17/80
 - 2s - loss: 0.0593
Epoch 18/80
 - 2s - loss: 0.0573
Epoch 19/80
 - 2s - loss: 0.0556
Epoch 20/80
 - 2s - loss: 0.0542
Epoch 21/80
 - 2s - loss: 0.0529
Epoch 22/80
 - 2s - loss: 0.0518
Epoch 23/80
 - 2s - loss: 0.0509
Epoch 24/80
 - 2s - loss: 0.0501
Epoch 25/80
 - 2s - loss: 0.0493
Epoch 26/80
 - 2s - loss: 0.0487
Epoch 27/80
 - 2s - loss: 0.0481
Epoch 28/80
 - 2s - loss: 0.0477
Epoch 29/80
 - 2s - loss: 0.0472
Epoch 30/80
 - 2s - loss: 0.0469
Epoch 31/80
 - 2s - loss: 0.0465
Epoch 32/80
 - 2s - loss: 0.0462
Epoch 33/80
 - 2s - loss: 0.0460
Epoch 34/80
 - 2s - loss: 0.0457
Epoch 35/80
 - 2s - loss: 0.0455
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 06:32:49.656812: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:32:49.818134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:32:49.818198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:32:50.112447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:32:50.112496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:32:50.112506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:32:50.112762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0682
Epoch 2/80
 - 2s - loss: 0.1949
Epoch 3/80
 - 2s - loss: 0.1705
Epoch 4/80
 - 2s - loss: 0.1628
Epoch 5/80
 - 2s - loss: 0.1527
Epoch 6/80
 - 2s - loss: 0.1389
Epoch 7/80
 - 2s - loss: 0.1234
Epoch 8/80
 - 2s - loss: 0.1092
Epoch 9/80
 - 2s - loss: 0.0984
Epoch 10/80
 - 2s - loss: 0.0902
Epoch 11/80
 - 2s - loss: 0.0836
Epoch 12/80
 - 2s - loss: 0.0780
Epoch 13/80
 - 2s - loss: 0.0731
Epoch 14/80
 - 2s - loss: 0.0688
Epoch 15/80
 - 2s - loss: 0.0652
Epoch 16/80
 - 2s - loss: 0.0621
Epoch 17/80
 - 2s - loss: 0.0597
Epoch 18/80
 - 2s - loss: 0.0576
Epoch 19/80
 - 2s - loss: 0.0558
Epoch 20/80
 - 2s - loss: 0.0543
Epoch 21/80
 - 2s - loss: 0.0529
Epoch 22/80
 - 2s - loss: 0.0518
Epoch 23/80
 - 2s - loss: 0.0508
Epoch 24/80
 - 2s - loss: 0.0499
Epoch 25/80
 - 2s - loss: 0.0492
Epoch 26/80
 - 2s - loss: 0.0486
Epoch 27/80
 - 2s - loss: 0.0480
Epoch 28/80
 - 2s - loss: 0.0475
Epoch 29/80
 - 2s - loss: 0.0471
Epoch 30/80
 - 2s - loss: 0.0467
Epoch 31/80
 - 2s - loss: 0.0464
Epoch 32/80
 - 2s - loss: 0.0461
Epoch 33/80
 - 2s - loss: 0.0459
Epoch 34/80
 - 2s - loss: 0.0457
Epoch 35/80
 - 2s - loss: 0.0455
Epoch 36/80
 - 2s - loss: 0.0453
Epoch 37/80
 - 2s - loss: 0.0452
Epoch 38/80
 - 2s - loss: 0.0450
Epoch 39/80
 - 2s - loss: 0.0449
Epoch 40/80
 - 2s - loss: 0.0447
Epoch 41/80
 - 2s - loss: 0.0447
Epoch 42/80
 - 2s - loss: 0.0446
Epoch 43/80
 - 2s - loss: 0.0445
Epoch 44/80
 - 2s - loss: 0.0444
Epoch 45/80
 - 2s - loss: 0.0443
Epoch 46/80
 - 2s - loss: 0.0442
Epoch 47/80
 - 2s - loss: 0.0442
Epoch 48/80
 - 2s - loss: 0.0441
Epoch 49/80
 - 2s - loss: 0.0441
Epoch 50/80
 - 2s - loss: 0.0440
Epoch 51/80
 - 2s - loss: 0.0440
Epoch 52/80
 - 2s - loss: 0.0439
Epoch 53/80
 - 2s - loss: 0.0439
Epoch 54/80
 - 2s - loss: 0.0438
Epoch 55/80
 - 2s - loss: 0.0438
Epoch 56/80
 - 2s - loss: 0.0438
Epoch 57/80
 - 2s - loss: 0.0437
Epoch 58/80
 - 2s - loss: 0.0437
Epoch 59/80
 - 2s - loss: 0.0437
Epoch 60/80
 - 2s - loss: 0.0424
Epoch 61/80
 - 2s - loss: 0.0423
Epoch 62/80
 - 2s - loss: 0.0423
Epoch 63/80
 - 2s - loss: 0.0423
Epoch 64/80
 - 2s - loss: 0.0422
Epoch 65/80
 - 2s - loss: 0.0419
Epoch 66/80
 - 2s - loss: 0.0419
Epoch 67/80
 - 2s - loss: 0.0419
Epoch 68/80
 - 2s - loss: 0.0419
Epoch 69/80
 - 2s - loss: 0.0418
Epoch 70/80
 - 2s - loss: 0.0418
Epoch 71/80
 - 2s - loss: 0.0418
Epoch 72/80
 - 2s - loss: 0.0418
Epoch 73/80
 - 2s - loss: 0.0418
Epoch 74/80
 - 2s - loss: 0.0418
Epoch 75/80
 - 2s - loss: 0.0418
Epoch 76/80
 - 2s - loss: 0.0418
Epoch 77/80
 - 2s - loss: 0.0418
Epoch 78/80
 - 2s - loss: 0.0418
Epoch 79/80
 - 2s - loss: 0.0418
Epoch 80/80
 - 2s - loss: 0.0418
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 108, in train_glove
    model.load_weights(cache_path+'glove_temp.h5')
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1152, in load_weights
    with h5py.File(filepath, mode='r') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 142, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 78, in h5py.h5f.open
OSError: Unable to open file (file signature not found)
2019-03-08 06:35:19.013300: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:35:19.178627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:35:19.178672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:35:19.474624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:35:19.474674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:35:19.474683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:35:19.474933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0905
Epoch 2/80
 - 2s - loss: 0.1984
Epoch 3/80
 - 2s - loss: 0.1681
Epoch 4/80
 - 2s - loss: 0.1541
Epoch 5/80
 - 2s - loss: 0.1374
Epoch 6/80
 - 2s - loss: 0.1232
Epoch 7/80
 - 2s - loss: 0.1126
Epoch 8/80
 - 2s - loss: 0.1034
Epoch 9/80
 - 2s - loss: 0.0951
Epoch 10/80
 - 2s - loss: 0.0879
Epoch 11/80
 - 2s - loss: 0.0817
Epoch 12/80
 - 2s - loss: 0.0763
Epoch 13/80
 - 2s - loss: 0.0716
Epoch 14/80
 - 2s - loss: 0.0675
Epoch 15/80
 - 2s - loss: 0.0641
Epoch 16/80
 - 2s - loss: 0.0612
Epoch 17/80
 - 2s - loss: 0.0589
Epoch 18/80
 - 2s - loss: 0.0569
Epoch 19/80
 - 2s - loss: 0.0552
Epoch 20/80
 - 2s - loss: 0.0538
Epoch 21/80
 - 2s - loss: 0.0526
Epoch 22/80
 - 2s - loss: 0.0515
Epoch 23/80
 - 2s - loss: 0.0506
Epoch 24/80
 - 2s - loss: 0.0498
Epoch 25/80
 - 2s - loss: 0.0490
Epoch 26/80
 - 2s - loss: 0.0484
Epoch 27/80
 - 2s - loss: 0.0479
Epoch 28/80
 - 2s - loss: 0.0474
Epoch 29/80
 - 2s - loss: 0.0469
Epoch 30/80
 - 2s - loss: 0.0466
Epoch 31/80
 - 2s - loss: 0.0463
Epoch 32/80
 - 2s - loss: 0.0460
Epoch 33/80
 - 2s - loss: 0.0457
Epoch 34/80
 - 2s - loss: 0.0455
Epoch 35/80
 - 2s - loss: 0.0453
Epoch 36/80
 - 2s - loss: 0.0451
Epoch 37/80
 - 2s - loss: 0.0450
Epoch 38/80
 - 2s - loss: 0.0448
Epoch 39/80
 - 2s - loss: 0.0447
Epoch 40/80
 - 2s - loss: 0.0446
Epoch 41/80
 - 2s - loss: 0.0445
Epoch 42/80
 - 2s - loss: 0.0444
Epoch 43/80
 - 2s - loss: 0.0443
Epoch 44/80
 - 2s - loss: 0.0442
Epoch 45/80
 - 2s - loss: 0.0441
Epoch 46/80
 - 2s - loss: 0.0441
Epoch 47/80
 - 2s - loss: 0.0440
Epoch 48/80
 - 2s - loss: 0.0440
Epoch 49/80
 - 2s - loss: 0.0439
Epoch 50/80
 - 2s - loss: 0.0438
Epoch 51/80
 - 2s - loss: 0.0438
Epoch 52/80
 - 2s - loss: 0.0437
Epoch 53/80
 - 2s - loss: 0.0437
Epoch 54/80
 - 2s - loss: 0.0436
Epoch 55/80
 - 2s - loss: 0.0436
Epoch 56/80
 - 2s - loss: 0.0436
Epoch 57/80
 - 2s - loss: 0.0435
Epoch 58/80
 - 2s - loss: 0.0435
Epoch 59/80
 - 2s - loss: 0.0435
Epoch 60/80
 - 2s - loss: 0.0435
Epoch 61/80
 - 2s - loss: 0.0434
Epoch 62/80
 - 2s - loss: 0.0422
Epoch 63/80
 - 2s - loss: 0.0420
Epoch 64/80
 - 2s - loss: 0.0420
Epoch 65/80
 - 2s - loss: 0.0420
Epoch 66/80
 - 2s - loss: 0.0420
Epoch 67/80
 - 2s - loss: 0.0417
Epoch 68/80
 - 2s - loss: 0.0417
Epoch 69/80
 - 2s - loss: 0.0417
Epoch 70/80
 - 2s - loss: 0.0417
Epoch 71/80
 - 2s - loss: 0.0416
Epoch 72/80
 - 2s - loss: 0.0416
Epoch 73/80
 - 2s - loss: 0.0416
Epoch 74/80
 - 2s - loss: 0.0416
Epoch 75/80
 - 2s - loss: 0.0416
Epoch 76/80
 - 2s - loss: 0.0416
Epoch 77/80
 - 2s - loss: 0.0416
Epoch 78/80
 - 2s - loss: 0.0416
Epoch 79/80
 - 2s - loss: 0.0416
Epoch 80/80
 - 2s - loss: 0.0416
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.4784 - val_loss: 0.7751
AUC: 0.8228

Epoch 2/80
 - 0s - loss: 1.2995 - val_loss: 0.7550
AUC: 0.8414

Epoch 3/80
 - 0s - loss: 1.1726 - val_loss: 0.7422
AUC: 0.8500

Epoch 4/80
 - 0s - loss: 1.1230 - val_loss: 0.6841
AUC: 0.8549

Epoch 5/80
 - 0s - loss: 1.0965 - val_loss: 0.7023
AUC: 0.8609

Epoch 6/80
 - 0s - loss: 1.0703 - val_loss: 0.6035
AUC: 0.8608

Epoch 7/80
 - 0s - loss: 1.0603 - val_loss: 0.6482
AUC: 0.8642

Epoch 8/80
 - 0s - loss: 1.0494 - val_loss: 0.5994
AUC: 0.8637

Epoch 9/80
 - 0s - loss: 1.0405 - val_loss: 0.6429
AUC: 0.8658

Epoch 10/80
 - 0s - loss: 1.0295 - val_loss: 0.5997
AUC: 0.8654

Epoch 11/80
 - 0s - loss: 1.0254 - val_loss: 0.6498
AUC: 0.8680

Epoch 12/80
 - 0s - loss: 1.0258 - val_loss: 0.6315
AUC: 0.8687

Epoch 13/80
 - 0s - loss: 1.0181 - val_loss: 0.6260
AUC: 0.8682

Epoch 14/80
 - 0s - loss: 1.0116 - val_loss: 0.6520
AUC: 0.8690

Epoch 15/80
 - 0s - loss: 1.0019 - val_loss: 0.6255
AUC: 0.8702

Epoch 16/80
 - 0s - loss: 0.9990 - val_loss: 0.6375
AUC: 0.8704

Epoch 17/80
 - 0s - loss: 1.0007 - val_loss: 0.6257
AUC: 0.8697

Epoch 18/80
 - 0s - loss: 0.9960 - val_loss: 0.5957
AUC: 0.8710

Epoch 19/80
 - 0s - loss: 0.9900 - val_loss: 0.6200
AUC: 0.8712

Epoch 20/80
 - 0s - loss: 0.9847 - val_loss: 0.5811
AUC: 0.8697

Epoch 21/80
 - 0s - loss: 0.9865 - val_loss: 0.6050
AUC: 0.8713

Epoch 22/80
 - 0s - loss: 0.9838 - val_loss: 0.6346
AUC: 0.8723

Epoch 23/80
 - 0s - loss: 0.9823 - val_loss: 0.5868
AUC: 0.8712

Epoch 24/80
 - 0s - loss: 0.9815 - val_loss: 0.5625
AUC: 0.8713

Epoch 25/80
 - 0s - loss: 0.9691 - val_loss: 0.5420
AUC: 0.8712

Epoch 26/80
 - 0s - loss: 0.9649 - val_loss: 0.5491
AUC: 0.8718

Epoch 27/80
 - 0s - loss: 0.9715 - val_loss: 0.6016
AUC: 0.8723

Epoch 28/80
 - 0s - loss: 0.9623 - val_loss: 0.5994
AUC: 0.8728

Epoch 29/80
 - 0s - loss: 0.9616 - val_loss: 0.6237
AUC: 0.8737

Epoch 30/80
 - 0s - loss: 0.9633 - val_loss: 0.5355
AUC: 0.8716

Epoch 31/80
 - 0s - loss: 0.9565 - val_loss: 0.6064
AUC: 0.8742

Epoch 32/80
 - 0s - loss: 0.9587 - val_loss: 0.5856
AUC: 0.8737

Epoch 33/80
 - 0s - loss: 0.9523 - val_loss: 0.5877
AUC: 0.8726

Epoch 34/80
 - 0s - loss: 0.9551 - val_loss: 0.5429
AUC: 0.8732

Epoch 35/80
 - 0s - loss: 0.9462 - val_loss: 0.5775
AUC: 0.8733

Epoch 36/80
 - 0s - loss: 0.9487 - val_loss: 0.5769
AUC: 0.8736

Epoch 37/80
 - 0s - loss: 0.9442 - val_loss: 0.6019
AUC: 0.8738

Epoch 38/80
 - 0s - loss: 0.9476 - val_loss: 0.6798
AUC: 0.8750

Epoch 39/80
 - 0s - loss: 0.9420 - val_loss: 0.5426
AUC: 0.8727

Epoch 40/80
 - 0s - loss: 0.9367 - val_loss: 0.5900
AUC: 0.8742

Epoch 41/80
 - 0s - loss: 0.9274 - val_loss: 0.5725
AUC: 0.8750

Epoch 42/80
 - 0s - loss: 0.9276 - val_loss: 0.5771
AUC: 0.8748

Epoch 43/80
 - 0s - loss: 0.9238 - val_loss: 0.5652
AUC: 0.8747

Epoch 44/80
 - 0s - loss: 0.9160 - val_loss: 0.5771
AUC: 0.8749

Epoch 45/80
 - 0s - loss: 0.9237 - val_loss: 0.5696
AUC: 0.8749

Epoch 46/80
 - 0s - loss: 0.9220 - val_loss: 0.5929
AUC: 0.8752

Epoch 47/80
 - 0s - loss: 0.9259 - val_loss: 0.5806
AUC: 0.8748

Epoch 48/80
 - 0s - loss: 0.9150 - val_loss: 0.5708
AUC: 0.8748

Epoch 49/80
 - 0s - loss: 0.9222 - val_loss: 0.5752
AUC: 0.8747

Epoch 50/80
 - 0s - loss: 0.9222 - val_loss: 0.5688
AUC: 0.8747

Epoch 51/80
 - 0s - loss: 0.9169 - val_loss: 0.5769
AUC: 0.8748

Epoch 52/80
 - 0s - loss: 0.9206 - val_loss: 0.5658
AUC: 0.8747

Epoch 53/80
 - 0s - loss: 0.9170 - val_loss: 0.5718
AUC: 0.8748

Epoch 54/80
 - 0s - loss: 0.9132 - val_loss: 0.5662
AUC: 0.8747

Epoch 55/80
 - 0s - loss: 0.9128 - val_loss: 0.5799
AUC: 0.8749

Epoch 56/80
 - 0s - loss: 0.9165 - val_loss: 0.5702
AUC: 0.8748

Epoch 57/80
 - 0s - loss: 0.9197 - val_loss: 0.5738
AUC: 0.8749

Epoch 58/80
 - 0s - loss: 0.9130 - val_loss: 0.5636
AUC: 0.8747

Epoch 59/80
 - 0s - loss: 0.9167 - val_loss: 0.5724
AUC: 0.8748

Epoch 60/80
 - 0s - loss: 0.9190 - val_loss: 0.5727
AUC: 0.8748

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9246 - val_loss: 0.5740
AUC: 0.8750

Epoch 2/30
 - 0s - loss: 0.9203 - val_loss: 0.5722
AUC: 0.8753

Epoch 3/30
 - 0s - loss: 0.9207 - val_loss: 0.5757
AUC: 0.8752

Epoch 4/30
 - 0s - loss: 0.9179 - val_loss: 0.5780
AUC: 0.8752

Epoch 5/30
 - 0s - loss: 0.9128 - val_loss: 0.5816
AUC: 0.8755

Epoch 6/30
 - 0s - loss: 0.9152 - val_loss: 0.5680
AUC: 0.8751

Epoch 7/30
 - 0s - loss: 0.9122 - val_loss: 0.5713
AUC: 0.8751

Epoch 8/30
 - 0s - loss: 0.9083 - val_loss: 0.5637
AUC: 0.8750

Epoch 9/30
 - 0s - loss: 0.9119 - val_loss: 0.5557
AUC: 0.8751

Epoch 10/30
 - 0s - loss: 0.9114 - val_loss: 0.5548
AUC: 0.8752

Epoch 11/30
 - 0s - loss: 0.9088 - val_loss: 0.5606
AUC: 0.8755

Epoch 12/30
 - 0s - loss: 0.9084 - val_loss: 0.5760
AUC: 0.8757

Epoch 13/30
 - 0s - loss: 0.9039 - val_loss: 0.5630
AUC: 0.8752

Epoch 14/30
 - 0s - loss: 0.9092 - val_loss: 0.5932
AUC: 0.8756

Epoch 15/30
 - 0s - loss: 0.9001 - val_loss: 0.5725
AUC: 0.8755

Epoch 16/30
 - 0s - loss: 0.9014 - val_loss: 0.5800
AUC: 0.8755

Epoch 17/30
 - 0s - loss: 0.9026 - val_loss: 0.5525
AUC: 0.8754

Epoch 18/30
 - 0s - loss: 0.8977 - val_loss: 0.5666
AUC: 0.8758

Epoch 19/30
 - 0s - loss: 0.8983 - val_loss: 0.5571
AUC: 0.8757

Epoch 20/30
 - 0s - loss: 0.8990 - val_loss: 0.5613
AUC: 0.8757

Epoch 21/30
 - 0s - loss: 0.8956 - val_loss: 0.5708
AUC: 0.8760

Epoch 22/30
 - 0s - loss: 0.8943 - val_loss: 0.5680
AUC: 0.8758

Epoch 23/30
 - 0s - loss: 0.8926 - val_loss: 0.5601
AUC: 0.8759

Epoch 24/30
 - 0s - loss: 0.8958 - val_loss: 0.5731
AUC: 0.8760

Epoch 25/30
 - 0s - loss: 0.8942 - val_loss: 0.5765
AUC: 0.8761

Epoch 26/30
 - 0s - loss: 0.8918 - val_loss: 0.5631
AUC: 0.8760

Epoch 27/30
 - 0s - loss: 0.8899 - val_loss: 0.5628
AUC: 0.8758

Epoch 28/30
 - 0s - loss: 0.8912 - val_loss: 0.5653
AUC: 0.8759

Epoch 29/30
 - 0s - loss: 0.8867 - val_loss: 0.5615
AUC: 0.8759

Epoch 30/30
 - 0s - loss: 0.8822 - val_loss: 0.5589
Using TensorFlow backend.
AUC: 0.8759

2019-03-08 06:38:48.158650: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:38:48.322694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:38:48.322738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:38:48.618454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:38:48.618517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:38:48.618525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:38:48.618777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6563
Epoch 2/80
 - 2s - loss: 0.1030
Epoch 3/80
 - 2s - loss: 0.0683
Epoch 4/80
 - 2s - loss: 0.0632
Epoch 5/80
 - 2s - loss: 0.0593
Epoch 6/80
 - 2s - loss: 0.0546
Epoch 7/80
 - 2s - loss: 0.0497
Epoch 8/80
 - 2s - loss: 0.0450
Epoch 9/80
 - 2s - loss: 0.0409
Epoch 10/80
 - 2s - loss: 0.0373
Epoch 11/80
 - 2s - loss: 0.0342
Epoch 12/80
 - 2s - loss: 0.0314
Epoch 13/80
 - 2s - loss: 0.0290
Epoch 14/80
 - 2s - loss: 0.0270
Epoch 15/80
 - 2s - loss: 0.0253
Epoch 16/80
 - 2s - loss: 0.0238
Epoch 17/80
 - 2s - loss: 0.0226
Epoch 18/80
 - 2s - loss: 0.0215
Epoch 19/80
 - 2s - loss: 0.0206
Epoch 20/80
 - 2s - loss: 0.0198
Epoch 21/80
 - 2s - loss: 0.0191
Epoch 22/80
 - 2s - loss: 0.0184
Epoch 23/80
 - 2s - loss: 0.0179
Epoch 24/80
 - 2s - loss: 0.0174
Epoch 25/80
 - 2s - loss: 0.0171
Epoch 26/80
 - 2s - loss: 0.0167
Epoch 27/80
 - 2s - loss: 0.0164
Epoch 28/80
 - 2s - loss: 0.0161
Epoch 29/80
 - 2s - loss: 0.0159
Epoch 30/80
 - 2s - loss: 0.0157
Epoch 31/80
 - 2s - loss: 0.0155
Epoch 32/80
 - 2s - loss: 0.0154
Epoch 33/80
 - 2s - loss: 0.0152
Epoch 34/80
 - 2s - loss: 0.0151
Epoch 35/80
 - 2s - loss: 0.0150
Epoch 36/80
 - 2s - loss: 0.0149
Epoch 37/80
 - 2s - loss: 0.0148
Epoch 38/80
 - 2s - loss: 0.0147
Epoch 39/80
 - 2s - loss: 0.0147
Epoch 40/80
 - 2s - loss: 0.0146
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0145
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0144
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0143
Epoch 47/80
 - 2s - loss: 0.0143
Epoch 48/80
 - 2s - loss: 0.0143
Epoch 49/80
 - 2s - loss: 0.0142
Epoch 50/80
 - 2s - loss: 0.0138
Epoch 51/80
 - 2s - loss: 0.0137
Epoch 52/80
 - 2s - loss: 0.0137
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 2s - loss: 0.0136
Epoch 55/80
 - 2s - loss: 0.0136
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 2s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0136
Epoch 62/80
 - 2s - loss: 0.0136
Epoch 63/80
 - 2s - loss: 0.0136
Epoch 64/80
 - 2s - loss: 0.0136
Epoch 65/80
 - 2s - loss: 0.0136
Epoch 66/80
 - 2s - loss: 0.0136
Epoch 67/80
 - 2s - loss: 0.0136
Epoch 68/80
 - 2s - loss: 0.0136
Epoch 69/80
 - 2s - loss: 0.0136
Epoch 70/80
 - 2s - loss: 0.0136
Epoch 71/80
 - 2s - loss: 0.0136
Epoch 72/80
 - 2s - loss: 0.0136
Epoch 73/80
 - 2s - loss: 0.0136
Epoch 74/80
 - 2s - loss: 0.0136
Epoch 75/80
 - 2s - loss: 0.0136
Epoch 76/80
 - 2s - loss: 0.0136
Epoch 77/80
 - 2s - loss: 0.0136
Epoch 78/80
 - 2s - loss: 0.0136
Epoch 79/80
 - 2s - loss: 0.0136
Epoch 80/80
 - 2s - loss: 0.0136
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.3649 - val_loss: 1.1586
AUC: 0.7663

Epoch 2/80
 - 0s - loss: 1.9246 - val_loss: 0.7793
AUC: 0.8116

Epoch 3/80
 - 0s - loss: 1.3795 - val_loss: 0.6810
AUC: 0.8265

Epoch 4/80
 - 0s - loss: 1.2425 - val_loss: 0.6742
AUC: 0.8336

Epoch 5/80
 - 0s - loss: 1.1774 - val_loss: 0.7309
AUC: 0.8399

Epoch 6/80
 - 0s - loss: 1.1493 - val_loss: 0.6808
AUC: 0.8419

Epoch 7/80
 - 0s - loss: 1.1258 - val_loss: 0.6704
AUC: 0.8460

Epoch 8/80
 - 0s - loss: 1.1157 - val_loss: 0.6286
AUC: 0.8482

Epoch 9/80
 - 0s - loss: 1.0948 - val_loss: 0.6911
AUC: 0.8514

Epoch 10/80
 - 0s - loss: 1.0856 - val_loss: 0.6778
AUC: 0.8507

Epoch 11/80
 - 0s - loss: 1.0710 - val_loss: 0.6649
AUC: 0.8517

Epoch 12/80
 - 0s - loss: 1.0661 - val_loss: 0.6385
AUC: 0.8537

Epoch 13/80
 - 0s - loss: 1.0591 - val_loss: 0.6329
AUC: 0.8539

Epoch 14/80
 - 0s - loss: 1.0510 - val_loss: 0.5793
AUC: 0.8527

Epoch 15/80
 - 0s - loss: 1.0430 - val_loss: 0.6365
AUC: 0.8559

Epoch 16/80
 - 0s - loss: 1.0398 - val_loss: 0.6285
AUC: 0.8559

Epoch 17/80
 - 0s - loss: 1.0497 - val_loss: 0.6758
AUC: 0.8587

Epoch 18/80
 - 0s - loss: 1.0313 - val_loss: 0.6192
AUC: 0.8571

Epoch 19/80
 - 0s - loss: 1.0316 - val_loss: 0.5748
AUC: 0.8581

Epoch 20/80
 - 0s - loss: 1.0281 - val_loss: 0.6247
AUC: 0.8596

Epoch 21/80
 - 0s - loss: 1.0157 - val_loss: 0.5998
AUC: 0.8589

Epoch 22/80
 - 0s - loss: 1.0138 - val_loss: 0.6048
AUC: 0.8588

Epoch 23/80
 - 0s - loss: 1.0170 - val_loss: 0.6590
AUC: 0.8615

Epoch 24/80
 - 0s - loss: 1.0078 - val_loss: 0.5877
AUC: 0.8599

Epoch 25/80
 - 0s - loss: 1.0101 - val_loss: 0.6961
AUC: 0.8605

Epoch 26/80
 - 0s - loss: 1.0072 - val_loss: 0.6321
AUC: 0.8611

Epoch 27/80
 - 0s - loss: 1.0008 - val_loss: 0.6315
AUC: 0.8610

Epoch 28/80
 - 0s - loss: 0.9939 - val_loss: 0.6268
AUC: 0.8621

Epoch 29/80
 - 0s - loss: 0.9992 - val_loss: 0.5859
AUC: 0.8613

Epoch 30/80
 - 0s - loss: 0.9870 - val_loss: 0.6147
AUC: 0.8624

Epoch 31/80
 - 0s - loss: 0.9913 - val_loss: 0.5822
AUC: 0.8621

Epoch 32/80
 - 0s - loss: 0.9887 - val_loss: 0.6119
AUC: 0.8626

Epoch 33/80
 - 0s - loss: 0.9898 - val_loss: 0.5854
AUC: 0.8619

Epoch 34/80
 - 0s - loss: 0.9838 - val_loss: 0.6238
AUC: 0.8631

Epoch 35/80
 - 0s - loss: 0.9847 - val_loss: 0.5938
AUC: 0.8628

Epoch 36/80
 - 0s - loss: 0.9791 - val_loss: 0.5966
AUC: 0.8629

Epoch 37/80
 - 0s - loss: 0.9820 - val_loss: 0.5996
AUC: 0.8628

Epoch 38/80
 - 0s - loss: 0.9824 - val_loss: 0.6182
AUC: 0.8632

Epoch 39/80
 - 0s - loss: 0.9857 - val_loss: 0.6339
AUC: 0.8634

Epoch 40/80
 - 0s - loss: 0.9780 - val_loss: 0.6061
AUC: 0.8630

Epoch 41/80
 - 0s - loss: 0.9747 - val_loss: 0.6012
AUC: 0.8630

Epoch 42/80
 - 0s - loss: 0.9800 - val_loss: 0.6088
AUC: 0.8632

Epoch 43/80
 - 0s - loss: 0.9746 - val_loss: 0.6082
AUC: 0.8632

Epoch 44/80
 - 0s - loss: 0.9787 - val_loss: 0.6013
AUC: 0.8631

Epoch 45/80
 - 0s - loss: 0.9775 - val_loss: 0.6010
AUC: 0.8632

Epoch 46/80
 - 0s - loss: 0.9793 - val_loss: 0.6116
AUC: 0.8634

Epoch 47/80
 - 0s - loss: 0.9761 - val_loss: 0.6083
AUC: 0.8633

Epoch 48/80
 - 0s - loss: 0.9731 - val_loss: 0.6099
AUC: 0.8633

Epoch 49/80
 - 0s - loss: 0.9795 - val_loss: 0.6166
AUC: 0.8635

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9821 - val_loss: 0.5968
AUC: 0.8632

Epoch 2/30
 - 0s - loss: 0.9751 - val_loss: 0.6081
AUC: 0.8634

Epoch 3/30
 - 0s - loss: 0.9674 - val_loss: 0.5946
AUC: 0.8633

Epoch 4/30
 - 0s - loss: 0.9707 - val_loss: 0.6008
AUC: 0.8638

Epoch 5/30
 - 0s - loss: 0.9713 - val_loss: 0.6224
AUC: 0.8639

Epoch 6/30
 - 0s - loss: 0.9734 - val_loss: 0.6026
AUC: 0.8639

Epoch 7/30
 - 0s - loss: 0.9717 - val_loss: 0.5862
AUC: 0.8636

Epoch 8/30
 - 0s - loss: 0.9634 - val_loss: 0.5753
AUC: 0.8635

Epoch 9/30
 - 0s - loss: 0.9606 - val_loss: 0.5983
AUC: 0.8639

Epoch 10/30
 - 0s - loss: 0.9705 - val_loss: 0.5854
AUC: 0.8636

Epoch 11/30
 - 0s - loss: 0.9548 - val_loss: 0.6044
AUC: 0.8644

Epoch 12/30
 - 0s - loss: 0.9648 - val_loss: 0.5997
AUC: 0.8641

Epoch 13/30
 - 0s - loss: 0.9627 - val_loss: 0.5987
AUC: 0.8642

Epoch 14/30
 - 0s - loss: 0.9564 - val_loss: 0.5930
AUC: 0.8642

Epoch 15/30
 - 0s - loss: 0.9540 - val_loss: 0.5877
AUC: 0.8640

Epoch 16/30
 - 0s - loss: 0.9600 - val_loss: 0.6036
AUC: 0.8642

Epoch 17/30
 - 0s - loss: 0.9534 - val_loss: 0.6033
AUC: 0.8644

Epoch 18/30
 - 0s - loss: 0.9558 - val_loss: 0.5845
AUC: 0.8642

Epoch 19/30
 - 0s - loss: 0.9465 - val_loss: 0.5963
AUC: 0.8644

Epoch 20/30
 - 0s - loss: 0.9560 - val_loss: 0.5986
AUC: 0.8645

Epoch 21/30
 - 0s - loss: 0.9479 - val_loss: 0.5963
AUC: 0.8645

Epoch 22/30
 - 0s - loss: 0.9474 - val_loss: 0.6002
AUC: 0.8645

Epoch 23/30
 - 0s - loss: 0.9475 - val_loss: 0.5988
AUC: 0.8645

Epoch 24/30
 - 0s - loss: 0.9437 - val_loss: 0.5937
AUC: 0.8644

Epoch 25/30
 - 0s - loss: 0.9485 - val_loss: 0.5967
AUC: 0.8645

Epoch 26/30
 - 0s - loss: 0.9476 - val_loss: 0.5950
AUC: 0.8645

Epoch 27/30
 - 0s - loss: 0.9473 - val_loss: 0.5923
AUC: 0.8644

Epoch 28/30
 - 0s - loss: 0.9438 - val_loss: 0.5886
AUC: 0.8644

Epoch 29/30
 - 0s - loss: 0.9499 - val_loss: 0.5913
AUC: 0.8644

Epoch 30/30
 - 0s - loss: 0.9432 - val_loss: 0.5914
Using TensorFlow backend.
AUC: 0.8644

2019-03-08 06:42:13.108404: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:42:13.275384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:42:13.275417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:42:13.577817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:42:13.577896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:42:13.577905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:42:13.578156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6446
Epoch 2/80
 - 2s - loss: 0.1012
Epoch 3/80
 - 2s - loss: 0.0681
Epoch 4/80
 - 2s - loss: 0.0620
Epoch 5/80
 - 2s - loss: 0.0580
Epoch 6/80
 - 2s - loss: 0.0543
Epoch 7/80
 - 2s - loss: 0.0507
Epoch 8/80
 - 2s - loss: 0.0472
Epoch 9/80
 - 2s - loss: 0.0433
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 06:42:45.818870: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:42:45.983310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:42:45.983354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:42:46.286601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:42:46.286651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:42:46.286659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:42:46.286912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6639
Epoch 2/80
 - 2s - loss: 0.1038
Epoch 3/80
 - 2s - loss: 0.0682
Epoch 4/80
 - 2s - loss: 0.0626
Epoch 5/80
 - 2s - loss: 0.0578
Epoch 6/80
 - 2s - loss: 0.0522
Epoch 7/80
 - 2s - loss: 0.0472
Epoch 8/80
 - 2s - loss: 0.0434
Epoch 9/80
 - 2s - loss: 0.0403
Epoch 10/80
 - 2s - loss: 0.0376
Epoch 11/80
 - 2s - loss: 0.0350
Epoch 12/80
 - 2s - loss: 0.0325
Epoch 13/80
 - 2s - loss: 0.0301
Epoch 14/80
 - 2s - loss: 0.0279
Epoch 15/80
 - 2s - loss: 0.0260
Epoch 16/80
 - 2s - loss: 0.0244
Epoch 17/80
 - 2s - loss: 0.0230
Epoch 18/80
 - 2s - loss: 0.0218
Epoch 19/80
 - 2s - loss: 0.0208
Epoch 20/80
 - 2s - loss: 0.0200
Epoch 21/80
 - 2s - loss: 0.0193
Epoch 22/80
 - 2s - loss: 0.0187
Epoch 23/80
 - 2s - loss: 0.0182
Epoch 24/80
 - 2s - loss: 0.0177
Epoch 25/80
 - 2s - loss: 0.0173
Epoch 26/80
 - 2s - loss: 0.0169
Epoch 27/80
 - 2s - loss: 0.0166
Epoch 28/80
 - 2s - loss: 0.0163
Epoch 29/80
 - 2s - loss: 0.0161
Epoch 30/80
 - 2s - loss: 0.0159
Epoch 31/80
 - 2s - loss: 0.0157
Epoch 32/80
 - 2s - loss: 0.0155
Epoch 33/80
 - 2s - loss: 0.0154
Epoch 34/80
 - 2s - loss: 0.0152
Epoch 35/80
 - 2s - loss: 0.0151
Epoch 36/80
 - 2s - loss: 0.0150
Epoch 37/80
 - 2s - loss: 0.0149
Epoch 38/80
 - 2s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0148
Epoch 40/80
 - 2s - loss: 0.0147
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0146
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0145
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 2s - loss: 0.0144
Epoch 48/80
 - 2s - loss: 0.0143
Epoch 49/80
 - 2s - loss: 0.0143
Epoch 50/80
 - 2s - loss: 0.0139
Epoch 51/80
 - 2s - loss: 0.0138
Epoch 52/80
 - 2s - loss: 0.0138
Epoch 53/80
 - 2s - loss: 0.0138
Epoch 54/80
 - 2s - loss: 0.0137
Epoch 55/80
 - 2s - loss: 0.0137
Epoch 56/80
 - 2s - loss: 0.0137
Epoch 57/80
 - 2s - loss: 0.0137
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 2s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0136
Epoch 62/80
 - 2s - loss: 0.0136
Epoch 63/80
 - 2s - loss: 0.0136
Epoch 64/80
 - 2s - loss: 0.0136
Epoch 65/80
 - 2s - loss: 0.0136
Epoch 66/80
 - 2s - loss: 0.0136
Epoch 67/80
 - 2s - loss: 0.0136
Epoch 68/80
 - 2s - loss: 0.0136
Epoch 69/80
 - 2s - loss: 0.0136
Epoch 70/80
 - 2s - loss: 0.0136
Epoch 71/80
 - 2s - loss: 0.0136
Epoch 72/80
 - 2s - loss: 0.0136
Epoch 73/80
 - 2s - loss: 0.0136
Epoch 74/80
 - 2s - loss: 0.0136
Epoch 75/80
 - 2s - loss: 0.0136
Epoch 76/80
 - 2s - loss: 0.0136
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 06:45:06.879873: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:45:07.042596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:45:07.042638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:45:07.340564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:45:07.340613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:45:07.340622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:45:07.340873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2885
Epoch 2/80
 - 2s - loss: 0.3322
Epoch 3/80
 - 2s - loss: 0.3006
Epoch 4/80
 - 2s - loss: 0.2786
Epoch 5/80
 - 2s - loss: 0.2502
Epoch 6/80
 - 2s - loss: 0.2253
Epoch 7/80
 - 2s - loss: 0.2064
Epoch 8/80
 - 2s - loss: 0.1910
Epoch 9/80
 - 2s - loss: 0.1780
Epoch 10/80
 - 2s - loss: 0.1671
Epoch 11/80
 - 2s - loss: 0.1580
Epoch 12/80
 - 2s - loss: 0.1501
Epoch 13/80
 - 2s - loss: 0.1432
Epoch 14/80
 - 2s - loss: 0.1371
Epoch 15/80
 - 2s - loss: 0.1318
Epoch 16/80
 - 2s - loss: 0.1274
Epoch 17/80
 - 2s - loss: 0.1237
Epoch 18/80
 - 2s - loss: 0.1207
Epoch 19/80
 - 2s - loss: 0.1181
Epoch 20/80
 - 2s - loss: 0.1159
Epoch 21/80
 - 2s - loss: 0.1141
Epoch 22/80
 - 2s - loss: 0.1125
Epoch 23/80
 - 2s - loss: 0.1112
Epoch 24/80
 - 2s - loss: 0.1100
Epoch 25/80
 - 2s - loss: 0.1091
Epoch 26/80
 - 2s - loss: 0.1082
Epoch 27/80
 - 2s - loss: 0.1074
Epoch 28/80
 - 2s - loss: 0.1068
Epoch 29/80
 - 2s - loss: 0.1062
Epoch 30/80
 - 2s - loss: 0.1057
Epoch 31/80
 - 2s - loss: 0.1052
Epoch 32/80
 - 2s - loss: 0.1049
Epoch 33/80
 - 2s - loss: 0.1045
Epoch 34/80
 - 2s - loss: 0.1041
Epoch 35/80
 - 2s - loss: 0.1039
Epoch 36/80
 - 2s - loss: 0.1037
Epoch 37/80
 - 2s - loss: 0.1034
Epoch 38/80
 - 2s - loss: 0.1032
Epoch 39/80
 - 2s - loss: 0.1030
Epoch 40/80
 - 2s - loss: 0.1029
Epoch 41/80
 - 2s - loss: 0.1027
Epoch 42/80
 - 2s - loss: 0.1026
Epoch 43/80
 - 2s - loss: 0.1024
Epoch 44/80
 - 2s - loss: 0.1023
Epoch 45/80
 - 2s - loss: 0.1022
Epoch 46/80
 - 2s - loss: 0.1020
Epoch 47/80
 - 2s - loss: 0.1020
Epoch 48/80
 - 2s - loss: 0.1018
Epoch 49/80
 - 2s - loss: 0.1018
Epoch 50/80
 - 2s - loss: 0.1017
Epoch 51/80
 - 2s - loss: 0.1016
Epoch 52/80
 - 2s - loss: 0.1015
Epoch 53/80
 - 2s - loss: 0.1015
Epoch 54/80
 - 2s - loss: 0.1014
Epoch 55/80
 - 2s - loss: 0.1013
Epoch 56/80
 - 2s - loss: 0.1013
Epoch 57/80
 - 2s - loss: 0.1012
Epoch 58/80
 - 2s - loss: 0.1012
Epoch 59/80
 - 2s - loss: 0.1011
Epoch 60/80
 - 2s - loss: 0.1011
Epoch 61/80
 - 2s - loss: 0.1010
Epoch 62/80
 - 2s - loss: 0.1010
Epoch 63/80
 - 2s - loss: 0.1009
Epoch 64/80
 - 2s - loss: 0.1009
Epoch 65/80
 - 2s - loss: 0.1009
Epoch 66/80
 - 2s - loss: 0.1008
Epoch 67/80
 - 2s - loss: 0.1008
Epoch 68/80
 - 2s - loss: 0.1007
Epoch 69/80
 - 2s - loss: 0.1007
Epoch 70/80
 - 2s - loss: 0.1007
Epoch 71/80
 - 2s - loss: 0.1007
Epoch 72/80
 - 2s - loss: 0.0980
Epoch 73/80
 - 2s - loss: 0.0977
Epoch 74/80
 - 2s - loss: 0.0977
Epoch 75/80
 - 2s - loss: 0.0977
Epoch 76/80
 - 2s - loss: 0.0977
Epoch 77/80
 - 2s - loss: 0.0970
Epoch 78/80
 - 2s - loss: 0.0970
Epoch 79/80
 - 2s - loss: 0.0970
Epoch 80/80
 - 2s - loss: 0.0970
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.6238 - val_loss: 2.2555
AUC: 0.7874

Epoch 2/80
 - 0s - loss: 3.7254 - val_loss: 1.3279
AUC: 0.8186

Epoch 3/80
 - 0s - loss: 2.5356 - val_loss: 0.9601
AUC: 0.8351

Epoch 4/80
 - 0s - loss: 1.7229 - val_loss: 0.7759
AUC: 0.8396

Epoch 5/80
 - 0s - loss: 1.3456 - val_loss: 0.6666
AUC: 0.8422

Epoch 6/80
 - 0s - loss: 1.2436 - val_loss: 0.6897
AUC: 0.8467

Epoch 7/80
 - 0s - loss: 1.2094 - val_loss: 0.6876
AUC: 0.8488

Epoch 8/80
 - 0s - loss: 1.1610 - val_loss: 0.7136
AUC: 0.8503

Epoch 9/80
 - 0s - loss: 1.1398 - val_loss: 0.6179
AUC: 0.8536

Epoch 10/80
 - 0s - loss: 1.1199 - val_loss: 0.6633
AUC: 0.8563

Epoch 11/80
 - 0s - loss: 1.0993 - val_loss: 0.5842
AUC: 0.8571

Epoch 12/80
 - 0s - loss: 1.0946 - val_loss: 0.6238
AUC: 0.8607

Epoch 13/80
 - 0s - loss: 1.0796 - val_loss: 0.6501
AUC: 0.8620

Epoch 14/80
 - 0s - loss: 1.0774 - val_loss: 0.6514
AUC: 0.8632

Epoch 15/80
 - 0s - loss: 1.0679 - val_loss: 0.6683
AUC: 0.8649

Epoch 16/80
 - 0s - loss: 1.0609 - val_loss: 0.6755
AUC: 0.8652

Epoch 17/80
 - 0s - loss: 1.0563 - val_loss: 0.6362
AUC: 0.8676

Epoch 18/80
 - 0s - loss: 1.0505 - val_loss: 0.6241
AUC: 0.8669

Epoch 19/80
 - 0s - loss: 1.0468 - val_loss: 0.6225
AUC: 0.8680

Epoch 20/80
 - 0s - loss: 1.0365 - val_loss: 0.6672
AUC: 0.8685

Epoch 21/80
 - 0s - loss: 1.0372 - val_loss: 0.6857
AUC: 0.8698

Epoch 22/80
 - 0s - loss: 1.0234 - val_loss: 0.6172
AUC: 0.8696

Epoch 23/80
 - 0s - loss: 1.0222 - val_loss: 0.6130
AUC: 0.8696

Epoch 24/80
 - 0s - loss: 1.0225 - val_loss: 0.6226
AUC: 0.8696

Epoch 25/80
 - 0s - loss: 1.0193 - val_loss: 0.6175
AUC: 0.8697

Epoch 26/80
 - 0s - loss: 1.0197 - val_loss: 0.6194
AUC: 0.8700

Epoch 27/80
 - 0s - loss: 1.0191 - val_loss: 0.6017
AUC: 0.8699

Epoch 28/80
 - 0s - loss: 1.0263 - val_loss: 0.6215
AUC: 0.8700

Epoch 29/80
 - 0s - loss: 1.0161 - val_loss: 0.6568
AUC: 0.8702

Epoch 30/80
 - 0s - loss: 1.0173 - val_loss: 0.6640
AUC: 0.8699

Epoch 31/80
 - 0s - loss: 1.0204 - val_loss: 0.6107
AUC: 0.8700

Epoch 32/80
 - 0s - loss: 1.0141 - val_loss: 0.6135
AUC: 0.8700

Epoch 33/80
 - 0s - loss: 1.0126 - val_loss: 0.6226
AUC: 0.8700

Epoch 34/80
 - 0s - loss: 1.0141 - val_loss: 0.6205
AUC: 0.8700

Epoch 35/80
 - 0s - loss: 1.0138 - val_loss: 0.6120
AUC: 0.8702

Epoch 36/80
 - 0s - loss: 1.0117 - val_loss: 0.6218
AUC: 0.8703

Epoch 37/80
 - 0s - loss: 1.0166 - val_loss: 0.6204
AUC: 0.8703

Epoch 38/80
 - 0s - loss: 1.0131 - val_loss: 0.6210
AUC: 0.8703

Epoch 39/80
 - 0s - loss: 1.0131 - val_loss: 0.6192
AUC: 0.8703

Epoch 40/80
 - 0s - loss: 1.0146 - val_loss: 0.6172
AUC: 0.8703

Epoch 41/80
 - 0s - loss: 1.0055 - val_loss: 0.6220
AUC: 0.8704

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0189 - val_loss: 0.6242
AUC: 0.8705

Epoch 2/30
 - 0s - loss: 1.0105 - val_loss: 0.6415
AUC: 0.8706

Epoch 3/30
 - 0s - loss: 1.0136 - val_loss: 0.6256
AUC: 0.8708

Epoch 4/30
 - 0s - loss: 1.0132 - val_loss: 0.6149
AUC: 0.8709

Epoch 5/30
 - 0s - loss: 0.9994 - val_loss: 0.6392
AUC: 0.8712

Epoch 6/30
 - 0s - loss: 1.0093 - val_loss: 0.6057
AUC: 0.8713

Epoch 7/30
 - 0s - loss: 0.9994 - val_loss: 0.5985
AUC: 0.8715

Epoch 8/30
 - 0s - loss: 1.0015 - val_loss: 0.6285
AUC: 0.8715

Epoch 9/30
 - 0s - loss: 0.9987 - val_loss: 0.6149
AUC: 0.8717

Epoch 10/30
 - 0s - loss: 1.0009 - val_loss: 0.6023
AUC: 0.8718

Epoch 11/30
 - 0s - loss: 0.9973 - val_loss: 0.6146
AUC: 0.8720

Epoch 12/30
 - 0s - loss: 0.9971 - val_loss: 0.6124
AUC: 0.8718

Epoch 13/30
 - 0s - loss: 0.9895 - val_loss: 0.6039
AUC: 0.8724

Epoch 14/30
 - 0s - loss: 0.9933 - val_loss: 0.6173
AUC: 0.8723

Epoch 15/30
 - 0s - loss: 0.9962 - val_loss: 0.6230
AUC: 0.8727

Epoch 16/30
 - 0s - loss: 0.9918 - val_loss: 0.6103
AUC: 0.8724

Epoch 17/30
 - 0s - loss: 0.9911 - val_loss: 0.5886
AUC: 0.8726

Epoch 18/30
 - 0s - loss: 0.9820 - val_loss: 0.5858
AUC: 0.8726

Epoch 19/30
 - 0s - loss: 0.9807 - val_loss: 0.5983
AUC: 0.8730

Epoch 20/30
 - 0s - loss: 0.9877 - val_loss: 0.6119
AUC: 0.8728

Epoch 21/30
 - 0s - loss: 0.9806 - val_loss: 0.6040
AUC: 0.8730

Epoch 22/30
 - 0s - loss: 0.9813 - val_loss: 0.6070
AUC: 0.8730

Epoch 23/30
 - 0s - loss: 0.9813 - val_loss: 0.6088
AUC: 0.8734

Epoch 24/30
 - 0s - loss: 0.9802 - val_loss: 0.6184
AUC: 0.8736

Epoch 25/30
 - 0s - loss: 0.9789 - val_loss: 0.6218
AUC: 0.8736

Epoch 26/30
 - 0s - loss: 0.9786 - val_loss: 0.5897
AUC: 0.8736

Epoch 27/30
 - 0s - loss: 0.9810 - val_loss: 0.6034
AUC: 0.8738

Epoch 28/30
 - 0s - loss: 0.9740 - val_loss: 0.5892
AUC: 0.8740

Epoch 29/30
 - 0s - loss: 0.9701 - val_loss: 0.6036
AUC: 0.8740

Epoch 30/30
 - 0s - loss: 0.9699 - val_loss: 0.5969
Using TensorFlow backend.
AUC: 0.8740

2019-03-08 06:48:19.256103: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:48:19.421119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:48:19.421162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:48:19.714521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:48:19.714572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:48:19.714581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:48:19.714834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2941
Epoch 2/80
 - 2s - loss: 0.3318
Epoch 3/80
 - 2s - loss: 0.2884
Epoch 4/80
 - 2s - loss: 0.2605
Epoch 5/80
 - 2s - loss: 0.2372
Epoch 6/80
 - 2s - loss: 0.2156
Epoch 7/80
 - 2s - loss: 0.1973
Epoch 8/80
 - 2s - loss: 0.1835
Epoch 9/80
 - 2s - loss: 0.1725
Epoch 10/80
 - 2s - loss: 0.1632
Epoch 11/80
 - 2s - loss: 0.1553
Epoch 12/80
 - 2s - loss: 0.1483
Epoch 13/80
 - 2s - loss: 0.1420
Epoch 14/80
 - 2s - loss: 0.1362
Epoch 15/80
 - 2s - loss: 0.1312
Epoch 16/80
 - 2s - loss: 0.1270
Epoch 17/80
 - 2s - loss: 0.1234
Epoch 18/80
 - 2s - loss: 0.1204
Epoch 19/80
 - 2s - loss: 0.1179
Epoch 20/80
 - 2s - loss: 0.1158
Epoch 21/80
 - 2s - loss: 0.1139
Epoch 22/80
 - 2s - loss: 0.1124
Epoch 23/80
 - 2s - loss: 0.1110
Epoch 24/80
 - 2s - loss: 0.1099
Epoch 25/80
 - 2s - loss: 0.1088
Epoch 26/80
 - 2s - loss: 0.1080
Epoch 27/80
 - 2s - loss: 0.1072
Epoch 28/80
 - 2s - loss: 0.1066
Epoch 29/80
 - 2s - loss: 0.1061
Epoch 30/80
 - 2s - loss: 0.1056
Epoch 31/80
 - 2s - loss: 0.1052
Epoch 32/80
 - 2s - loss: 0.1048
Epoch 33/80
 - 2s - loss: 0.1045
Epoch 34/80
 - 2s - loss: 0.1042
Epoch 35/80
 - 2s - loss: 0.1039
Epoch 36/80
 - 2s - loss: 0.1037
Epoch 37/80
 - 2s - loss: 0.1034
Epoch 38/80
 - 2s - loss: 0.1033
Epoch 39/80
 - 2s - loss: 0.1031
Epoch 40/80
 - 2s - loss: 0.1029
Epoch 41/80
 - 2s - loss: 0.1028
Epoch 42/80
 - 2s - loss: 0.1027
Epoch 43/80
 - 2s - loss: 0.1025
Epoch 44/80
 - 2s - loss: 0.1024
Epoch 45/80
 - 2s - loss: 0.1023
Epoch 46/80
 - 2s - loss: 0.1022
Epoch 47/80
 - 2s - loss: 0.1021
Epoch 48/80
 - 2s - loss: 0.1020
Epoch 49/80
 - 2s - loss: 0.1019
Epoch 50/80
 - 2s - loss: 0.1018
Epoch 51/80
 - 2s - loss: 0.1018
Epoch 52/80
 - 2s - loss: 0.1017
Epoch 53/80
 - 2s - loss: 0.1017
Epoch 54/80
 - 2s - loss: 0.1016
Epoch 55/80
 - 2s - loss: 0.1015
Epoch 56/80
 - 2s - loss: 0.1015
Epoch 57/80
 - 2s - loss: 0.1014
Epoch 58/80
 - 2s - loss: 0.1014
Epoch 59/80
 - 2s - loss: 0.1013
Epoch 60/80
 - 2s - loss: 0.1013
Epoch 61/80
 - 2s - loss: 0.1013
Epoch 62/80
 - 2s - loss: 0.1012
Epoch 63/80
 - 2s - loss: 0.1012
Epoch 64/80
 - 2s - loss: 0.1012
Epoch 65/80
 - 2s - loss: 0.1011
Epoch 66/80
 - 2s - loss: 0.1011
Epoch 67/80
 - 2s - loss: 0.1010
Epoch 68/80
 - 2s - loss: 0.1010
Epoch 69/80
 - 2s - loss: 0.0983
Epoch 70/80
 - 2s - loss: 0.0981
Epoch 71/80
 - 2s - loss: 0.0981
Epoch 72/80
 - 2s - loss: 0.0981
Epoch 73/80
 - 2s - loss: 0.0981
Epoch 74/80
 - 2s - loss: 0.0974
Epoch 75/80
 - 2s - loss: 0.0974
Epoch 76/80
 - 2s - loss: 0.0974
Epoch 77/80
 - 2s - loss: 0.0974
Epoch 78/80
 - 2s - loss: 0.0972
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 06:50:43.947837: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:50:44.110316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:50:44.110360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:50:44.404512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:50:44.404563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:50:44.404572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:50:44.404826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2982
Epoch 2/80
 - 2s - loss: 0.3292
Epoch 3/80
 - 2s - loss: 0.2833
Epoch 4/80
 - 2s - loss: 0.2570
Epoch 5/80
 - 2s - loss: 0.2387
Epoch 6/80
 - 2s - loss: 0.2233
Epoch 7/80
 - 2s - loss: 0.2085
Epoch 8/80
 - 2s - loss: 0.1927
Epoch 9/80
 - 2s - loss: 0.1779
Epoch 10/80
 - 2s - loss: 0.1655
Epoch 11/80
 - 2s - loss: 0.1556
Epoch 12/80
 - 2s - loss: 0.1477
Epoch 13/80
 - 2s - loss: 0.1411
Epoch 14/80
 - 2s - loss: 0.1356
Epoch 15/80
 - 2s - loss: 0.1309
Epoch 16/80
 - 2s - loss: 0.1269
Epoch 17/80
 - 2s - loss: 0.1235
Epoch 18/80
 - 2s - loss: 0.1205
Epoch 19/80
 - 2s - loss: 0.1180
Epoch 20/80
 - 2s - loss: 0.1159
Epoch 21/80
 - 2s - loss: 0.1140
Epoch 22/80
 - 2s - loss: 0.1124
Epoch 23/80
 - 2s - loss: 0.1111
Epoch 24/80
 - 2s - loss: 0.1100
Epoch 25/80
 - 2s - loss: 0.1090
Epoch 26/80
 - 2s - loss: 0.1082
Epoch 27/80
 - 2s - loss: 0.1075
Epoch 28/80
 - 2s - loss: 0.1068
Epoch 29/80
 - 2s - loss: 0.1063
Epoch 30/80
 - 2s - loss: 0.1058
Epoch 31/80
 - 2s - loss: 0.1054
Epoch 32/80
 - 2s - loss: 0.1050
Epoch 33/80
 - 2s - loss: 0.1047
Epoch 34/80
 - 2s - loss: 0.1044
Epoch 35/80
 - 2s - loss: 0.1041
Epoch 36/80
 - 2s - loss: 0.1039
Epoch 37/80
 - 2s - loss: 0.1037
Epoch 38/80
 - 2s - loss: 0.1035
Epoch 39/80
 - 2s - loss: 0.1033
Epoch 40/80
 - 2s - loss: 0.1032
Epoch 41/80
 - 2s - loss: 0.1030
Epoch 42/80
 - 2s - loss: 0.1029
Epoch 43/80
 - 2s - loss: 0.1027
Epoch 44/80
 - 2s - loss: 0.1026
Epoch 45/80
 - 2s - loss: 0.1025
Epoch 46/80
 - 2s - loss: 0.1024
Epoch 47/80
 - 2s - loss: 0.1023
Epoch 48/80
 - 2s - loss: 0.1022
Epoch 49/80
 - 2s - loss: 0.1022
Epoch 50/80
 - 2s - loss: 0.1020
Epoch 51/80
 - 2s - loss: 0.1020
Epoch 52/80
 - 2s - loss: 0.1019
Epoch 53/80
 - 2s - loss: 0.1019
Epoch 54/80
 - 2s - loss: 0.1018
Epoch 55/80
 - 2s - loss: 0.1017
Epoch 56/80
 - 2s - loss: 0.1017
Epoch 57/80
 - 2s - loss: 0.1016
Epoch 58/80
 - 2s - loss: 0.1016
Epoch 59/80
 - 2s - loss: 0.1015
Epoch 60/80
 - 2s - loss: 0.1015
Epoch 61/80
 - 2s - loss: 0.1014
Epoch 62/80
 - 2s - loss: 0.1014
Epoch 63/80
 - 2s - loss: 0.0987
Epoch 64/80
 - 2s - loss: 0.0984
Epoch 65/80
 - 2s - loss: 0.0984
Epoch 66/80
 - 2s - loss: 0.0984
Epoch 67/80
 - 2s - loss: 0.0984
Epoch 68/80
 - 2s - loss: 0.0977
Epoch 69/80
 - 2s - loss: 0.0977
Epoch 70/80
 - 2s - loss: 0.0977
Epoch 71/80
 - 2s - loss: 0.0977
Epoch 72/80
 - 2s - loss: 0.0975
Epoch 73/80
 - 2s - loss: 0.0975
Epoch 74/80
 - 2s - loss: 0.0975
Epoch 75/80
 - 2s - loss: 0.0975
Epoch 76/80
 - 2s - loss: 0.0975
Epoch 77/80
 - 2s - loss: 0.0975
Epoch 78/80
 - 2s - loss: 0.0975
Epoch 79/80
 - 2s - loss: 0.0975
Epoch 80/80
 - 2s - loss: 0.0975
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.5734 - val_loss: 1.6858
AUC: 0.7321

Epoch 2/80
 - 0s - loss: 3.1459 - val_loss: 1.2984
AUC: 0.7963

Epoch 3/80
 - 0s - loss: 2.4651 - val_loss: 0.9777
AUC: 0.8072

Epoch 4/80
 - 0s - loss: 1.9032 - val_loss: 0.9281
AUC: 0.8194

Epoch 5/80
 - 0s - loss: 1.5910 - val_loss: 0.8330
AUC: 0.8293

Epoch 6/80
 - 0s - loss: 1.3414 - val_loss: 0.6762
AUC: 0.8361

Epoch 7/80
 - 0s - loss: 1.2502 - val_loss: 0.6974
AUC: 0.8425

Epoch 8/80
 - 0s - loss: 1.1948 - val_loss: 0.7470
AUC: 0.8474

Epoch 9/80
 - 0s - loss: 1.1510 - val_loss: 0.6335
AUC: 0.8491

Epoch 10/80
 - 0s - loss: 1.1263 - val_loss: 0.6422
AUC: 0.8517

Epoch 11/80
 - 0s - loss: 1.1082 - val_loss: 0.6697
AUC: 0.8536

Epoch 12/80
 - 0s - loss: 1.1047 - val_loss: 0.7279
AUC: 0.8554

Epoch 13/80
 - 0s - loss: 1.0773 - val_loss: 0.7069
AUC: 0.8572

Epoch 14/80
 - 0s - loss: 1.0652 - val_loss: 0.5969
AUC: 0.8556

Epoch 15/80
 - 0s - loss: 1.0673 - val_loss: 0.6341
AUC: 0.8567

Epoch 16/80
 - 0s - loss: 1.0630 - val_loss: 0.6495
AUC: 0.8596

Epoch 17/80
 - 0s - loss: 1.0583 - val_loss: 0.7100
AUC: 0.8617

Epoch 18/80
 - 0s - loss: 1.0474 - val_loss: 0.6539
AUC: 0.8608

Epoch 19/80
 - 0s - loss: 1.0483 - val_loss: 0.6007
AUC: 0.8601

Epoch 20/80
 - 0s - loss: 1.0445 - val_loss: 0.6890
AUC: 0.8612

Epoch 21/80
 - 0s - loss: 1.0383 - val_loss: 0.6633
AUC: 0.8624

Epoch 22/80
 - 0s - loss: 1.0327 - val_loss: 0.6259
AUC: 0.8618

Epoch 23/80
 - 0s - loss: 1.0321 - val_loss: 0.6222
AUC: 0.8616

Epoch 24/80
 - 0s - loss: 1.0256 - val_loss: 0.5813
AUC: 0.8623

Epoch 25/80
 - 0s - loss: 1.0210 - val_loss: 0.6391
AUC: 0.8633

Epoch 26/80
 - 0s - loss: 1.0142 - val_loss: 0.5824
AUC: 0.8627

Epoch 27/80
 - 0s - loss: 1.0152 - val_loss: 0.6494
AUC: 0.8640

Epoch 28/80
 - 0s - loss: 1.0127 - val_loss: 0.6769
AUC: 0.8656

Epoch 29/80
 - 0s - loss: 1.0098 - val_loss: 0.5894
AUC: 0.8629

Epoch 30/80
 - 0s - loss: 1.0061 - val_loss: 0.6522
AUC: 0.8650

Epoch 31/80
 - 0s - loss: 1.0144 - val_loss: 0.6310
AUC: 0.8652

Epoch 32/80
 - 0s - loss: 1.0047 - val_loss: 0.5821
AUC: 0.8649

Epoch 33/80
 - 0s - loss: 1.0033 - val_loss: 0.6197
AUC: 0.8657

Epoch 34/80
 - 0s - loss: 1.0017 - val_loss: 0.5802
AUC: 0.8657

Epoch 35/80
 - 0s - loss: 0.9962 - val_loss: 0.5855
AUC: 0.8658

Epoch 36/80
 - 0s - loss: 0.9967 - val_loss: 0.6492
AUC: 0.8672

Epoch 37/80
 - 0s - loss: 0.9895 - val_loss: 0.6298
AUC: 0.8670

Epoch 38/80
 - 0s - loss: 0.9934 - val_loss: 0.6467
AUC: 0.8670

Epoch 39/80
 - 0s - loss: 0.9860 - val_loss: 0.5514
AUC: 0.8658

Epoch 40/80
 - 0s - loss: 0.9909 - val_loss: 0.6360
AUC: 0.8667

Epoch 41/80
 - 0s - loss: 0.9849 - val_loss: 0.6104
AUC: 0.8664

Epoch 42/80
 - 0s - loss: 0.9819 - val_loss: 0.5800
AUC: 0.8670

Epoch 43/80
 - 0s - loss: 0.9789 - val_loss: 0.6131
AUC: 0.8669

Epoch 44/80
 - 0s - loss: 0.9831 - val_loss: 0.5553
AUC: 0.8647

Epoch 45/80
 - 0s - loss: 0.9776 - val_loss: 0.6293
AUC: 0.8670

Epoch 46/80
 - 0s - loss: 0.9801 - val_loss: 0.6082
AUC: 0.8678

Epoch 47/80
 - 0s - loss: 0.9766 - val_loss: 0.6194
AUC: 0.8678

Epoch 48/80
 - 0s - loss: 0.9830 - val_loss: 0.6277
AUC: 0.8676

Epoch 49/80
 - 0s - loss: 0.9759 - val_loss: 0.6532
AUC: 0.8684

Epoch 50/80
 - 0s - loss: 0.9672 - val_loss: 0.5936
AUC: 0.8678

Epoch 51/80
 - 0s - loss: 0.9639 - val_loss: 0.6230
AUC: 0.8686

Epoch 52/80
 - 0s - loss: 0.9667 - val_loss: 0.5808
AUC: 0.8679

Epoch 53/80
 - 0s - loss: 0.9694 - val_loss: 0.6010
AUC: 0.8681

Epoch 54/80
 - 0s - loss: 0.9605 - val_loss: 0.5977
AUC: 0.8682

Epoch 55/80
 - 0s - loss: 0.9690 - val_loss: 0.6104
AUC: 0.8687

Epoch 56/80
 - 0s - loss: 0.9612 - val_loss: 0.5965
AUC: 0.8681

Epoch 57/80
 - 0s - loss: 0.9662 - val_loss: 0.5934
AUC: 0.8680

Epoch 58/80
 - 0s - loss: 0.9575 - val_loss: 0.5931
AUC: 0.8681

Epoch 59/80
 - 0s - loss: 0.9598 - val_loss: 0.6091
AUC: 0.8683

Epoch 60/80
 - 0s - loss: 0.9552 - val_loss: 0.5919
AUC: 0.8682

Epoch 61/80
 - 0s - loss: 0.9622 - val_loss: 0.6024
AUC: 0.8684

Epoch 62/80
 - 0s - loss: 0.9555 - val_loss: 0.5953
AUC: 0.8682

Epoch 63/80
 - 0s - loss: 0.9565 - val_loss: 0.5902
AUC: 0.8682

Epoch 64/80
 - 0s - loss: 0.9574 - val_loss: 0.6038
AUC: 0.8684

Epoch 65/80
 - 0s - loss: 0.9540 - val_loss: 0.5976
AUC: 0.8684

Epoch 66/80
 - 0s - loss: 0.9597 - val_loss: 0.5995
AUC: 0.8684

Epoch 67/80
 - 0s - loss: 0.9601 - val_loss: 0.6023
AUC: 0.8684

Epoch 68/80
 - 0s - loss: 0.9532 - val_loss: 0.5913
AUC: 0.8683

Epoch 69/80
 - 0s - loss: 0.9571 - val_loss: 0.6012
AUC: 0.8684

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9588 - val_loss: 0.5750
AUC: 0.8682

Epoch 2/30
 - 0s - loss: 0.9568 - val_loss: 0.5893
AUC: 0.8686

Epoch 3/30
 - 0s - loss: 0.9570 - val_loss: 0.6035
AUC: 0.8688

Epoch 4/30
 - 0s - loss: 0.9548 - val_loss: 0.6065
AUC: 0.8689

Epoch 5/30
 - 0s - loss: 0.9606 - val_loss: 0.5906
AUC: 0.8688

Epoch 6/30
 - 0s - loss: 0.9541 - val_loss: 0.6104
AUC: 0.8689

Epoch 7/30
 - 0s - loss: 0.9517 - val_loss: 0.6067
AUC: 0.8691

Epoch 8/30
 - 0s - loss: 0.9497 - val_loss: 0.6112
AUC: 0.8692

Epoch 9/30
 - 0s - loss: 0.9483 - val_loss: 0.5818
AUC: 0.8691

Epoch 10/30
 - 0s - loss: 0.9475 - val_loss: 0.5870
AUC: 0.8693

Epoch 11/30
 - 0s - loss: 0.9436 - val_loss: 0.6112
AUC: 0.8696

Epoch 12/30
 - 0s - loss: 0.9439 - val_loss: 0.5960
AUC: 0.8694

Epoch 13/30
 - 0s - loss: 0.9427 - val_loss: 0.5958
AUC: 0.8694

Epoch 14/30
 - 0s - loss: 0.9429 - val_loss: 0.5953
AUC: 0.8694

Epoch 15/30
 - 0s - loss: 0.9464 - val_loss: 0.5940
AUC: 0.8694

Epoch 16/30
 - 0s - loss: 0.9458 - val_loss: 0.5922
AUC: 0.8694

Epoch 17/30
 - 0s - loss: 0.9410 - val_loss: 0.5915
AUC: 0.8694

Epoch 18/30
 - 0s - loss: 0.9439 - val_loss: 0.5902
AUC: 0.8694

Epoch 19/30
 - 0s - loss: 0.9387 - val_loss: 0.5931
AUC: 0.8695

Epoch 20/30
 - 0s - loss: 0.9425 - val_loss: 0.5927
AUC: 0.8695

Epoch 21/30
 - 0s - loss: 0.9409 - val_loss: 0.5922
AUC: 0.8695

Epoch 22/30
 - 0s - loss: 0.9420 - val_loss: 0.5926
AUC: 0.8695

Epoch 23/30
 - 0s - loss: 0.9411 - val_loss: 0.5932
AUC: 0.8695

Epoch 24/30
 - 0s - loss: 0.9389 - val_loss: 0.5930
AUC: 0.8695

Epoch 25/30
 - 0s - loss: 0.9459 - val_loss: 0.5933
AUC: 0.8695

Epoch 26/30
 - 0s - loss: 0.9393 - val_loss: 0.5933
AUC: 0.8695

Epoch 27/30
 - 0s - loss: 0.9415 - val_loss: 0.5945
AUC: 0.8695

Epoch 28/30
 - 0s - loss: 0.9428 - val_loss: 0.5936
AUC: 0.8695

Epoch 29/30
 - 0s - loss: 0.9375 - val_loss: 0.5935
AUC: 0.8695

Epoch 30/30
 - 0s - loss: 0.9371 - val_loss: 0.5934
Using TensorFlow backend.
AUC: 0.8695

2019-03-08 06:54:12.461812: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:54:12.644821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:54:12.644869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:54:12.941848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:54:12.941899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:54:12.941908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:54:12.942161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2993
Epoch 2/80
 - 2s - loss: 0.3335
Epoch 3/80
 - 2s - loss: 0.2991
Epoch 4/80
 - 2s - loss: 0.2697
Epoch 5/80
 - 2s - loss: 0.2407
Epoch 6/80
 - 2s - loss: 0.2192
Epoch 7/80
 - 2s - loss: 0.2021
Epoch 8/80
 - 2s - loss: 0.1873
Epoch 9/80
 - 2s - loss: 0.1745
Epoch 10/80
 - 2s - loss: 0.1635
Epoch 11/80
 - 2s - loss: 0.1541
Epoch 12/80
 - 2s - loss: 0.1462
Epoch 13/80
 - 2s - loss: 0.1397
Epoch 14/80
 - 2s - loss: 0.1343
Epoch 15/80
 - 2s - loss: 0.1297
Epoch 16/80
 - 2s - loss: 0.1260
Epoch 17/80
 - 2s - loss: 0.1228
Epoch 18/80
 - 2s - loss: 0.1201
Epoch 19/80
 - 2s - loss: 0.1177
Epoch 20/80
 - 2s - loss: 0.1156
Epoch 21/80
 - 2s - loss: 0.1139
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 06:55:03.959971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:55:04.123830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:55:04.123873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:55:04.421341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:55:04.421388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:55:04.421397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:55:04.421649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0670
Epoch 2/80
 - 2s - loss: 0.1934
Epoch 3/80
 - 2s - loss: 0.1607
Epoch 4/80
 - 2s - loss: 0.1445
Epoch 5/80
 - 2s - loss: 0.1326
Epoch 6/80
 - 2s - loss: 0.1227
Epoch 7/80
 - 2s - loss: 0.1138
Epoch 8/80
 - 2s - loss: 0.1052
Epoch 9/80
 - 2s - loss: 0.0971
Epoch 10/80
 - 2s - loss: 0.0897
Epoch 11/80
 - 2s - loss: 0.0833
Epoch 12/80
 - 2s - loss: 0.0777
Epoch 13/80
 - 2s - loss: 0.0730
Epoch 14/80
 - 2s - loss: 0.0688
Epoch 15/80
 - 2s - loss: 0.0653
Epoch 16/80
 - 2s - loss: 0.0623
Epoch 17/80
 - 2s - loss: 0.0597
Epoch 18/80
 - 2s - loss: 0.0576
Epoch 19/80
 - 2s - loss: 0.0558
Epoch 20/80
 - 2s - loss: 0.0543
Epoch 21/80
 - 2s - loss: 0.0529
Epoch 22/80
 - 2s - loss: 0.0518
Epoch 23/80
 - 2s - loss: 0.0508
Epoch 24/80
 - 2s - loss: 0.0499
Epoch 25/80
 - 2s - loss: 0.0492
Epoch 26/80
 - 2s - loss: 0.0485
Epoch 27/80
 - 2s - loss: 0.0480
Epoch 28/80
 - 2s - loss: 0.0475
Epoch 29/80
 - 2s - loss: 0.0470
Epoch 30/80
 - 2s - loss: 0.0466
Epoch 31/80
 - 2s - loss: 0.0463
Epoch 32/80
 - 2s - loss: 0.0460
Epoch 33/80
 - 2s - loss: 0.0458
Epoch 34/80
 - 2s - loss: 0.0455
Epoch 35/80
 - 2s - loss: 0.0453
Epoch 36/80
 - 2s - loss: 0.0451
Epoch 37/80
 - 2s - loss: 0.0450
Epoch 38/80
 - 2s - loss: 0.0448
Epoch 39/80
 - 2s - loss: 0.0447
Epoch 40/80
 - 2s - loss: 0.0446
Epoch 41/80
 - 2s - loss: 0.0445
Epoch 42/80
 - 2s - loss: 0.0444
Epoch 43/80
 - 2s - loss: 0.0443
Epoch 44/80
 - 2s - loss: 0.0442
Epoch 45/80
 - 2s - loss: 0.0441
Epoch 46/80
 - 2s - loss: 0.0440
Epoch 47/80
 - 2s - loss: 0.0440
Epoch 48/80
 - 2s - loss: 0.0439
Epoch 49/80
 - 2s - loss: 0.0438
Epoch 50/80
 - 2s - loss: 0.0438
Epoch 51/80
 - 2s - loss: 0.0438
Epoch 52/80
 - 2s - loss: 0.0437
Epoch 53/80
 - 2s - loss: 0.0437
Epoch 54/80
 - 2s - loss: 0.0436
Epoch 55/80
 - 2s - loss: 0.0436
Epoch 56/80
 - 2s - loss: 0.0435
Epoch 57/80
 - 2s - loss: 0.0435
Epoch 58/80
 - 2s - loss: 0.0435
Epoch 59/80
 - 2s - loss: 0.0434
Epoch 60/80
 - 2s - loss: 0.0434
Epoch 61/80
 - 2s - loss: 0.0434
Epoch 62/80
 - 2s - loss: 0.0434
Epoch 63/80
 - 2s - loss: 0.0421
Epoch 64/80
 - 2s - loss: 0.0420
Epoch 65/80
 - 2s - loss: 0.0420
Epoch 66/80
 - 2s - loss: 0.0420
Epoch 67/80
 - 2s - loss: 0.0419
Epoch 68/80
 - 2s - loss: 0.0416
Epoch 69/80
 - 2s - loss: 0.0416
Epoch 70/80
 - 2s - loss: 0.0416
Epoch 71/80
 - 2s - loss: 0.0416
Epoch 72/80
 - 2s - loss: 0.0416
Epoch 73/80
 - 2s - loss: 0.0416
Epoch 74/80
 - 2s - loss: 0.0416
Epoch 75/80
 - 2s - loss: 0.0415
Epoch 76/80
 - 2s - loss: 0.0415
Epoch 77/80
 - 2s - loss: 0.0415
Epoch 78/80
 - 2s - loss: 0.0415
Epoch 79/80
 - 2s - loss: 0.0415
Epoch 80/80
 - 2s - loss: 0.0415
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 108, in train_glove
    model.load_weights(cache_path+'glove_temp.h5')
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1152, in load_weights
    with h5py.File(filepath, mode='r') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 142, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 78, in h5py.h5f.open
OSError: Unable to open file (file signature not found)
2019-03-08 06:57:31.376826: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:57:31.541293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:57:31.541340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:57:31.839682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:57:31.839734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:57:31.839753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:57:31.840008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0644
Epoch 2/80
 - 2s - loss: 0.1938
Epoch 3/80
 - 2s - loss: 0.1690
Epoch 4/80
 - 2s - loss: 0.1568
Epoch 5/80
 - 2s - loss: 0.1403
Epoch 6/80
 - 2s - loss: 0.1265
Epoch 7/80
 - 2s - loss: 0.1163
Epoch 8/80
 - 2s - loss: 0.1077
Epoch 9/80
 - 2s - loss: 0.0996
Epoch 10/80
 - 2s - loss: 0.0918
Epoch 11/80
 - 2s - loss: 0.0846
Epoch 12/80
 - 2s - loss: 0.0783
Epoch 13/80
 - 2s - loss: 0.0729
Epoch 14/80
 - 2s - loss: 0.0684
Epoch 15/80
 - 2s - loss: 0.0648
Epoch 16/80
 - 2s - loss: 0.0619
Epoch 17/80
 - 2s - loss: 0.0595
Epoch 18/80
 - 2s - loss: 0.0575
Epoch 19/80
 - 2s - loss: 0.0558
Epoch 20/80
 - 2s - loss: 0.0543
Epoch 21/80
 - 2s - loss: 0.0530
Epoch 22/80
 - 2s - loss: 0.0518
Epoch 23/80
 - 2s - loss: 0.0508
Epoch 24/80
 - 2s - loss: 0.0499
Epoch 25/80
 - 2s - loss: 0.0492
Epoch 26/80
 - 2s - loss: 0.0485
Epoch 27/80
 - 2s - loss: 0.0480
Epoch 28/80
 - 2s - loss: 0.0475
Epoch 29/80
 - 2s - loss: 0.0471
Epoch 30/80
 - 2s - loss: 0.0467
Epoch 31/80
 - 2s - loss: 0.0464
Epoch 32/80
 - 2s - loss: 0.0462
Epoch 33/80
 - 2s - loss: 0.0459
Epoch 34/80
 - 2s - loss: 0.0457
Epoch 35/80
 - 2s - loss: 0.0455
Epoch 36/80
 - 2s - loss: 0.0453
Epoch 37/80
 - 2s - loss: 0.0452
Epoch 38/80
 - 2s - loss: 0.0450
Epoch 39/80
 - 2s - loss: 0.0449
Epoch 40/80
 - 2s - loss: 0.0448
Epoch 41/80
 - 2s - loss: 0.0447
Epoch 42/80
 - 2s - loss: 0.0446
Epoch 43/80
 - 2s - loss: 0.0445
Epoch 44/80
 - 2s - loss: 0.0444
Epoch 45/80
 - 2s - loss: 0.0444
Epoch 46/80
 - 2s - loss: 0.0443
Epoch 47/80
 - 1s - loss: 0.0442
Epoch 48/80
 - 1s - loss: 0.0442
Epoch 49/80
 - 1s - loss: 0.0441
Epoch 50/80
 - 1s - loss: 0.0441
Epoch 51/80
 - 2s - loss: 0.0440
Epoch 52/80
 - 2s - loss: 0.0440
Epoch 53/80
 - 2s - loss: 0.0439
Epoch 54/80
 - 2s - loss: 0.0439
Epoch 55/80
 - 2s - loss: 0.0438
Epoch 56/80
 - 2s - loss: 0.0438
Epoch 57/80
 - 2s - loss: 0.0438
Epoch 58/80
 - 2s - loss: 0.0437
Epoch 59/80
 - 2s - loss: 0.0425
Epoch 60/80
 - 2s - loss: 0.0423
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 06:59:30.471679: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 06:59:30.633772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 06:59:30.633816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 06:59:30.923259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 06:59:30.923309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 06:59:30.923318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 06:59:30.923572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0617
Epoch 2/80
 - 2s - loss: 0.1938
Epoch 3/80
 - 1s - loss: 0.1653
Epoch 4/80
 - 1s - loss: 0.1503
Epoch 5/80
 - 1s - loss: 0.1376
Epoch 6/80
 - 1s - loss: 0.1263
Epoch 7/80
 - 1s - loss: 0.1159
Epoch 8/80
 - 1s - loss: 0.1067
Epoch 9/80
 - 1s - loss: 0.0979
Epoch 10/80
 - 1s - loss: 0.0900
Epoch 11/80
 - 1s - loss: 0.0832
Epoch 12/80
 - 1s - loss: 0.0777
Epoch 13/80
 - 1s - loss: 0.0731
Epoch 14/80
 - 1s - loss: 0.0691
Epoch 15/80
 - 1s - loss: 0.0657
Epoch 16/80
 - 1s - loss: 0.0627
Epoch 17/80
 - 1s - loss: 0.0601
Epoch 18/80
 - 1s - loss: 0.0579
Epoch 19/80
 - 1s - loss: 0.0560
Epoch 20/80
 - 2s - loss: 0.0544
Epoch 21/80
 - 2s - loss: 0.0530
Epoch 22/80
 - 2s - loss: 0.0518
Epoch 23/80
 - 2s - loss: 0.0508
Epoch 24/80
 - 1s - loss: 0.0499
Epoch 25/80
 - 1s - loss: 0.0492
Epoch 26/80
 - 1s - loss: 0.0486
Epoch 27/80
 - 1s - loss: 0.0480
Epoch 28/80
 - 2s - loss: 0.0475
Epoch 29/80
 - 2s - loss: 0.0471
Epoch 30/80
 - 1s - loss: 0.0467
Epoch 31/80
 - 1s - loss: 0.0464
Epoch 32/80
 - 1s - loss: 0.0461
Epoch 33/80
 - 2s - loss: 0.0459
Epoch 34/80
 - 1s - loss: 0.0457
Epoch 35/80
 - 1s - loss: 0.0455
Epoch 36/80
 - 2s - loss: 0.0453
Epoch 37/80
 - 2s - loss: 0.0451
Epoch 38/80
 - 2s - loss: 0.0450
Epoch 39/80
 - 1s - loss: 0.0448
Epoch 40/80
 - 1s - loss: 0.0447
Epoch 41/80
 - 1s - loss: 0.0446
Epoch 42/80
 - 2s - loss: 0.0445
Epoch 43/80
 - 1s - loss: 0.0444
Epoch 44/80
 - 1s - loss: 0.0443
Epoch 45/80
 - 1s - loss: 0.0442
Epoch 46/80
 - 1s - loss: 0.0442
Epoch 47/80
 - 1s - loss: 0.0441
Epoch 48/80
 - 1s - loss: 0.0440
Epoch 49/80
 - 1s - loss: 0.0440
Epoch 50/80
 - 1s - loss: 0.0439
Epoch 51/80
 - 1s - loss: 0.0439
Epoch 52/80
 - 1s - loss: 0.0438
Epoch 53/80
 - 1s - loss: 0.0438
Epoch 54/80
 - 1s - loss: 0.0438
Epoch 55/80
 - 1s - loss: 0.0437
Epoch 56/80
 - 1s - loss: 0.0437
Epoch 57/80
 - 1s - loss: 0.0436
Epoch 58/80
 - 1s - loss: 0.0436
Epoch 59/80
 - 1s - loss: 0.0436
Epoch 60/80
 - 1s - loss: 0.0423
Epoch 61/80
 - 1s - loss: 0.0422
Epoch 62/80
 - 2s - loss: 0.0422
Epoch 63/80
 - 1s - loss: 0.0421
Epoch 64/80
 - 1s - loss: 0.0421
Epoch 65/80
 - 1s - loss: 0.0418
Epoch 66/80
 - 1s - loss: 0.0418
Epoch 67/80
 - 1s - loss: 0.0418
Epoch 68/80
 - 1s - loss: 0.0418
Epoch 69/80
 - 1s - loss: 0.0417
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:01:40.941012: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:01:41.103835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:01:41.103877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:01:41.394889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:01:41.394955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:01:41.394965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:01:41.395321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6594
Epoch 2/80
 - 2s - loss: 0.1024
Epoch 3/80
 - 1s - loss: 0.0687
Epoch 4/80
 - 1s - loss: 0.0642
Epoch 5/80
 - 1s - loss: 0.0615
Epoch 6/80
 - 1s - loss: 0.0582
Epoch 7/80
 - 1s - loss: 0.0541
Epoch 8/80
 - 1s - loss: 0.0494
Epoch 9/80
 - 2s - loss: 0.0446
Epoch 10/80
 - 1s - loss: 0.0399
Epoch 11/80
 - 1s - loss: 0.0359
Epoch 12/80
 - 1s - loss: 0.0327
Epoch 13/80
 - 1s - loss: 0.0300
Epoch 14/80
 - 1s - loss: 0.0277
Epoch 15/80
 - 1s - loss: 0.0258
Epoch 16/80
 - 1s - loss: 0.0241
Epoch 17/80
 - 1s - loss: 0.0227
Epoch 18/80
 - 1s - loss: 0.0216
Epoch 19/80
 - 1s - loss: 0.0206
Epoch 20/80
 - 1s - loss: 0.0197
Epoch 21/80
 - 1s - loss: 0.0190
Epoch 22/80
 - 1s - loss: 0.0184
Epoch 23/80
 - 1s - loss: 0.0178
Epoch 24/80
 - 1s - loss: 0.0174
Epoch 25/80
 - 1s - loss: 0.0170
Epoch 26/80
 - 1s - loss: 0.0166
Epoch 27/80
 - 1s - loss: 0.0163
Epoch 28/80
 - 1s - loss: 0.0160
Epoch 29/80
 - 1s - loss: 0.0158
Epoch 30/80
 - 1s - loss: 0.0156
Epoch 31/80
 - 1s - loss: 0.0154
Epoch 32/80
 - 1s - loss: 0.0153
Epoch 33/80
 - 1s - loss: 0.0151
Epoch 34/80
 - 1s - loss: 0.0150
Epoch 35/80
 - 1s - loss: 0.0149
Epoch 36/80
 - 1s - loss: 0.0148
Epoch 37/80
 - 1s - loss: 0.0147
Epoch 38/80
 - 1s - loss: 0.0147
Epoch 39/80
 - 1s - loss: 0.0146
Epoch 40/80
 - 1s - loss: 0.0145
Epoch 41/80
 - 1s - loss: 0.0145
Epoch 42/80
 - 1s - loss: 0.0144
Epoch 43/80
 - 1s - loss: 0.0144
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:03:11.424798: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:03:11.586174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:03:11.586218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:03:11.877242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:03:11.877293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:03:11.877302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:03:11.877555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6588
Epoch 2/80
 - 1s - loss: 0.1031
Epoch 3/80
 - 1s - loss: 0.0686
Epoch 4/80
 - 1s - loss: 0.0639
Epoch 5/80
 - 1s - loss: 0.0604
Epoch 6/80
 - 1s - loss: 0.0559
Epoch 7/80
 - 1s - loss: 0.0510
Epoch 8/80
 - 1s - loss: 0.0464
Epoch 9/80
 - 1s - loss: 0.0421
Epoch 10/80
 - 1s - loss: 0.0383
Epoch 11/80
 - 1s - loss: 0.0349
Epoch 12/80
 - 1s - loss: 0.0320
Epoch 13/80
 - 1s - loss: 0.0296
Epoch 14/80
 - 1s - loss: 0.0275
Epoch 15/80
 - 1s - loss: 0.0257
Epoch 16/80
 - 1s - loss: 0.0242
Epoch 17/80
 - 1s - loss: 0.0229
Epoch 18/80
 - 1s - loss: 0.0218
Epoch 19/80
 - 1s - loss: 0.0208
Epoch 20/80
 - 1s - loss: 0.0200
Epoch 21/80
 - 1s - loss: 0.0192
Epoch 22/80
 - 1s - loss: 0.0186
Epoch 23/80
 - 1s - loss: 0.0181
Epoch 24/80
 - 1s - loss: 0.0176
Epoch 25/80
 - 1s - loss: 0.0172
Epoch 26/80
 - 1s - loss: 0.0168
Epoch 27/80
 - 1s - loss: 0.0165
Epoch 28/80
 - 1s - loss: 0.0162
Epoch 29/80
 - 2s - loss: 0.0160
Epoch 30/80
 - 1s - loss: 0.0158
Epoch 31/80
 - 1s - loss: 0.0156
Epoch 32/80
 - 1s - loss: 0.0154
Epoch 33/80
 - 2s - loss: 0.0152
Epoch 34/80
 - 1s - loss: 0.0151
Epoch 35/80
 - 2s - loss: 0.0150
Epoch 36/80
 - 1s - loss: 0.0149
Epoch 37/80
 - 1s - loss: 0.0148
Epoch 38/80
 - 1s - loss: 0.0147
Epoch 39/80
 - 1s - loss: 0.0147
Epoch 40/80
 - 1s - loss: 0.0146
Epoch 41/80
 - 1s - loss: 0.0145
Epoch 42/80
 - 1s - loss: 0.0145
Epoch 43/80
 - 1s - loss: 0.0144
Epoch 44/80
 - 1s - loss: 0.0144
Epoch 45/80
 - 1s - loss: 0.0144
Epoch 46/80
 - 1s - loss: 0.0143
Epoch 47/80
 - 1s - loss: 0.0143
Epoch 48/80
 - 1s - loss: 0.0142
Epoch 49/80
 - 1s - loss: 0.0142
Epoch 50/80
 - 1s - loss: 0.0142
Epoch 51/80
 - 1s - loss: 0.0142
Epoch 52/80
 - 1s - loss: 0.0137
Epoch 53/80
 - 1s - loss: 0.0137
Epoch 54/80
 - 1s - loss: 0.0137
Epoch 55/80
 - 2s - loss: 0.0137
Epoch 56/80
 - 1s - loss: 0.0135
Epoch 57/80
 - 1s - loss: 0.0135
Epoch 58/80
 - 1s - loss: 0.0135
Epoch 59/80
 - 1s - loss: 0.0135
Epoch 60/80
 - 1s - loss: 0.0135
Epoch 61/80
 - 1s - loss: 0.0135
Epoch 62/80
 - 1s - loss: 0.0135
Epoch 63/80
 - 1s - loss: 0.0135
Epoch 64/80
 - 1s - loss: 0.0135
Epoch 65/80
 - 1s - loss: 0.0135
Epoch 66/80
 - 1s - loss: 0.0135
Epoch 67/80
 - 1s - loss: 0.0135
Epoch 68/80
 - 1s - loss: 0.0135
Epoch 69/80
 - 1s - loss: 0.0135
Epoch 70/80
 - 1s - loss: 0.0135
Epoch 71/80
 - 1s - loss: 0.0135
Epoch 72/80
 - 1s - loss: 0.0135
Epoch 73/80
 - 2s - loss: 0.0135
Epoch 74/80
 - 1s - loss: 0.0135
Epoch 75/80
 - 2s - loss: 0.0135
Epoch 76/80
 - 1s - loss: 0.0135
Epoch 77/80
 - 1s - loss: 0.0135
Epoch 78/80
 - 1s - loss: 0.0135
Epoch 79/80
 - 1s - loss: 0.0135
Epoch 80/80
 - 1s - loss: 0.0135
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4710 - val_loss: 0.9548
AUC: 0.7833

Epoch 2/80
 - 0s - loss: 1.9440 - val_loss: 0.7961
AUC: 0.8148

Epoch 3/80
 - 0s - loss: 1.4085 - val_loss: 0.7134
AUC: 0.8315

Epoch 4/80
 - 0s - loss: 1.2562 - val_loss: 0.6632
AUC: 0.8369

Epoch 5/80
 - 0s - loss: 1.1785 - val_loss: 0.6957
AUC: 0.8448

Epoch 6/80
 - 0s - loss: 1.1274 - val_loss: 0.6728
AUC: 0.8491

Epoch 7/80
 - 0s - loss: 1.1205 - val_loss: 0.6913
AUC: 0.8524

Epoch 8/80
 - 0s - loss: 1.0880 - val_loss: 0.6127
AUC: 0.8516

Epoch 9/80
 - 0s - loss: 1.0894 - val_loss: 0.6682
AUC: 0.8568

Epoch 10/80
 - 0s - loss: 1.0721 - val_loss: 0.7217
AUC: 0.8587

Epoch 11/80
 - 0s - loss: 1.0616 - val_loss: 0.6287
AUC: 0.8592

Epoch 12/80
 - 0s - loss: 1.0654 - val_loss: 0.6417
AUC: 0.8605

Epoch 13/80
 - 0s - loss: 1.0491 - val_loss: 0.6750
AUC: 0.8615

Epoch 14/80
 - 0s - loss: 1.0456 - val_loss: 0.5972
AUC: 0.8605

Epoch 15/80
 - 0s - loss: 1.0363 - val_loss: 0.5981
AUC: 0.8621

Epoch 16/80
 - 0s - loss: 1.0324 - val_loss: 0.5955
AUC: 0.8629

Epoch 17/80
 - 0s - loss: 1.0298 - val_loss: 0.6151
AUC: 0.8637

Epoch 18/80
 - 0s - loss: 1.0242 - val_loss: 0.6661
AUC: 0.8643

Epoch 19/80
 - 0s - loss: 1.0269 - val_loss: 0.6645
AUC: 0.8642

Epoch 20/80
 - 0s - loss: 1.0205 - val_loss: 0.6771
AUC: 0.8659

Epoch 21/80
 - 0s - loss: 1.0199 - val_loss: 0.5983
AUC: 0.8653

Epoch 22/80
 - 0s - loss: 1.0131 - val_loss: 0.5884
AUC: 0.8654

Epoch 23/80
 - 0s - loss: 1.0072 - val_loss: 0.6317
AUC: 0.8663

Epoch 24/80
 - 0s - loss: 1.0079 - val_loss: 0.5934
AUC: 0.8657

Epoch 25/80
 - 0s - loss: 1.0095 - val_loss: 0.6529
AUC: 0.8673

Epoch 26/80
 - 0s - loss: 1.0055 - val_loss: 0.6328
AUC: 0.8660

Epoch 27/80
 - 0s - loss: 1.0006 - val_loss: 0.6159
AUC: 0.8667

Epoch 28/80
 - 0s - loss: 0.9994 - val_loss: 0.6531
AUC: 0.8670

Epoch 29/80
 - 0s - loss: 0.9970 - val_loss: 0.5948
AUC: 0.8675

Epoch 30/80
 - 0s - loss: 0.9954 - val_loss: 0.5869
AUC: 0.8675

Epoch 31/80
 - 0s - loss: 0.9938 - val_loss: 0.5656
AUC: 0.8678

Epoch 32/80
 - 0s - loss: 0.9896 - val_loss: 0.6046
AUC: 0.8687

Epoch 33/80
 - 0s - loss: 0.9888 - val_loss: 0.6054
AUC: 0.8684

Epoch 34/80
 - 0s - loss: 0.9868 - val_loss: 0.6311
AUC: 0.8687

Epoch 35/80
 - 0s - loss: 0.9867 - val_loss: 0.5769
AUC: 0.8685

Epoch 36/80
 - 0s - loss: 0.9861 - val_loss: 0.6251
AUC: 0.8685

Epoch 37/80
 - 0s - loss: 0.9765 - val_loss: 0.6447
AUC: 0.8691

Epoch 38/80
 - 0s - loss: 0.9823 - val_loss: 0.6301
AUC: 0.8684

Epoch 39/80
 - 0s - loss: 0.9816 - val_loss: 0.6319
AUC: 0.8694

Epoch 40/80
 - 0s - loss: 0.9714 - val_loss: 0.5794
AUC: 0.8693

Epoch 41/80
 - 0s - loss: 0.9707 - val_loss: 0.5579
AUC: 0.8682

Epoch 42/80
 - 0s - loss: 0.9730 - val_loss: 0.5964
AUC: 0.8689

Epoch 43/80
 - 0s - loss: 0.9744 - val_loss: 0.5638
AUC: 0.8697

Epoch 44/80
 - 0s - loss: 0.9642 - val_loss: 0.5675
AUC: 0.8691

Epoch 45/80
 - 0s - loss: 0.9699 - val_loss: 0.6385
AUC: 0.8697

Epoch 46/80
 - 0s - loss: 0.9627 - val_loss: 0.5921
AUC: 0.8704

Epoch 47/80
 - 0s - loss: 0.9674 - val_loss: 0.5473
AUC: 0.8703

Epoch 48/80
 - 0s - loss: 0.9642 - val_loss: 0.5647
AUC: 0.8689

Epoch 49/80
 - 0s - loss: 0.9670 - val_loss: 0.6762
AUC: 0.8702

Epoch 50/80
 - 0s - loss: 0.9547 - val_loss: 0.5828
AUC: 0.8697

Epoch 51/80
 - 0s - loss: 0.9586 - val_loss: 0.5860
AUC: 0.8702

Epoch 52/80
 - 0s - loss: 0.9637 - val_loss: 0.5866
AUC: 0.8704

Epoch 53/80
 - 0s - loss: 0.9575 - val_loss: 0.6026
AUC: 0.8711

Epoch 54/80
 - 0s - loss: 0.9525 - val_loss: 0.5421
AUC: 0.8703

Epoch 55/80
 - 0s - loss: 0.9527 - val_loss: 0.6179
AUC: 0.8708

Epoch 56/80
 - 0s - loss: 0.9615 - val_loss: 0.6328
AUC: 0.8713

Epoch 57/80
 - 0s - loss: 0.9547 - val_loss: 0.5758
AUC: 0.8714

Epoch 58/80
 - 0s - loss: 0.9570 - val_loss: 0.5229
AUC: 0.8704

Epoch 59/80
 - 0s - loss: 0.9523 - val_loss: 0.6084
AUC: 0.8718

Epoch 60/80
 - 0s - loss: 0.9467 - val_loss: 0.5813
AUC: 0.8711

Epoch 61/80
 - 0s - loss: 0.9482 - val_loss: 0.5662
AUC: 0.8717

Epoch 62/80
 - 0s - loss: 0.9428 - val_loss: 0.5944
AUC: 0.8724

Epoch 63/80
 - 0s - loss: 0.9461 - val_loss: 0.5811
AUC: 0.8710

Epoch 64/80
 - 0s - loss: 0.9410 - val_loss: 0.6276
AUC: 0.8718

Epoch 65/80
 - 0s - loss: 0.9376 - val_loss: 0.6529
AUC: 0.8723

Epoch 66/80
 - 0s - loss: 0.9402 - val_loss: 0.5676
AUC: 0.8706

Epoch 67/80
 - 0s - loss: 0.9407 - val_loss: 0.6104
AUC: 0.8724

Epoch 68/80
 - 0s - loss: 0.9403 - val_loss: 0.5945
AUC: 0.8710

Epoch 69/80
 - 0s - loss: 0.9238 - val_loss: 0.6040
AUC: 0.8720

Epoch 70/80
 - 0s - loss: 0.9307 - val_loss: 0.5998
AUC: 0.8722

Epoch 71/80
 - 0s - loss: 0.9258 - val_loss: 0.5933
AUC: 0.8721

Epoch 72/80
 - 0s - loss: 0.9233 - val_loss: 0.5939
AUC: 0.8721

Epoch 73/80
 - 0s - loss: 0.9212 - val_loss: 0.5858
AUC: 0.8720

Epoch 74/80
 - 0s - loss: 0.9208 - val_loss: 0.5989
AUC: 0.8720

Epoch 75/80
 - 0s - loss: 0.9274 - val_loss: 0.5777
AUC: 0.8718

Epoch 76/80
 - 0s - loss: 0.9244 - val_loss: 0.5717
AUC: 0.8718

Epoch 77/80
 - 0s - loss: 0.9228 - val_loss: 0.5782
AUC: 0.8718

Epoch 78/80
 - 0s - loss: 0.9203 - val_loss: 0.5968
AUC: 0.8718

Epoch 79/80
 - 0s - loss: 0.9198 - val_loss: 0.5775
AUC: 0.8718

Epoch 80/80
 - 0s - loss: 0.9208 - val_loss: 0.5694
AUC: 0.8718

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9348 - val_loss: 0.5896
AUC: 0.8724

Epoch 2/30
 - 0s - loss: 0.9259 - val_loss: 0.5764
AUC: 0.8724

Epoch 3/30
 - 0s - loss: 0.9284 - val_loss: 0.5786
AUC: 0.8725

Epoch 4/30
 - 0s - loss: 0.9262 - val_loss: 0.5754
AUC: 0.8724

Epoch 5/30
 - 0s - loss: 0.9205 - val_loss: 0.5797
AUC: 0.8726

Epoch 6/30
 - 0s - loss: 0.9220 - val_loss: 0.5637
AUC: 0.8726

Epoch 7/30
 - 0s - loss: 0.9153 - val_loss: 0.5865
AUC: 0.8727

Epoch 8/30
 - 0s - loss: 0.9186 - val_loss: 0.5752
AUC: 0.8728

Epoch 9/30
 - 0s - loss: 0.9144 - val_loss: 0.5713
AUC: 0.8727

Epoch 10/30
 - 0s - loss: 0.9146 - val_loss: 0.5818
AUC: 0.8728

Epoch 11/30
 - 0s - loss: 0.9108 - val_loss: 0.5831
AUC: 0.8728

Epoch 12/30
 - 0s - loss: 0.9155 - val_loss: 0.5784
AUC: 0.8729

Epoch 13/30
 - 0s - loss: 0.9138 - val_loss: 0.5725
AUC: 0.8729

Epoch 14/30
 - 0s - loss: 0.9097 - val_loss: 0.5640
AUC: 0.8727

Epoch 15/30
 - 0s - loss: 0.9083 - val_loss: 0.5660
AUC: 0.8728

Epoch 16/30
 - 0s - loss: 0.9069 - val_loss: 0.5764
AUC: 0.8729

Epoch 17/30
 - 0s - loss: 0.9018 - val_loss: 0.5690
AUC: 0.8729

Epoch 18/30
 - 0s - loss: 0.9045 - val_loss: 0.5729
AUC: 0.8729

Epoch 19/30
 - 0s - loss: 0.9046 - val_loss: 0.5778
AUC: 0.8730

Epoch 20/30
 - 0s - loss: 0.9039 - val_loss: 0.5719
AUC: 0.8730

Epoch 21/30
 - 0s - loss: 0.9027 - val_loss: 0.5725
AUC: 0.8730

Epoch 22/30
 - 0s - loss: 0.9083 - val_loss: 0.5729
AUC: 0.8730

Epoch 23/30
 - 0s - loss: 0.8980 - val_loss: 0.5698
AUC: 0.8730

Epoch 24/30
 - 0s - loss: 0.9049 - val_loss: 0.5712
AUC: 0.8730

Epoch 25/30
 - 0s - loss: 0.9045 - val_loss: 0.5723
AUC: 0.8730

Epoch 26/30
 - 0s - loss: 0.9067 - val_loss: 0.5713
AUC: 0.8731

Epoch 27/30
 - 0s - loss: 0.9031 - val_loss: 0.5716
AUC: 0.8731

Epoch 28/30
 - 0s - loss: 0.9037 - val_loss: 0.5713
AUC: 0.8731

Epoch 29/30
 - 0s - loss: 0.9040 - val_loss: 0.5706
AUC: 0.8730

Epoch 30/30
 - 0s - loss: 0.9052 - val_loss: 0.5712
Using TensorFlow backend.
AUC: 0.8731

2019-03-08 07:06:42.933537: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:06:43.094131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:06:43.094194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:06:43.390735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:06:43.390787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:06:43.390796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:06:43.391048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6529
Epoch 2/80
 - 1s - loss: 0.1032
Epoch 3/80
 - 1s - loss: 0.0678
Epoch 4/80
 - 1s - loss: 0.0602
Epoch 5/80
 - 1s - loss: 0.0548
Epoch 6/80
 - 1s - loss: 0.0507
Epoch 7/80
 - 1s - loss: 0.0474
Epoch 8/80
 - 2s - loss: 0.0446
Epoch 9/80
 - 1s - loss: 0.0418
Epoch 10/80
 - 1s - loss: 0.0389
Epoch 11/80
 - 1s - loss: 0.0360
Epoch 12/80
 - 2s - loss: 0.0331
Epoch 13/80
 - 1s - loss: 0.0305
Epoch 14/80
 - 2s - loss: 0.0282
Epoch 15/80
 - 1s - loss: 0.0263
Epoch 16/80
 - 2s - loss: 0.0246
Epoch 17/80
 - 1s - loss: 0.0232
Epoch 18/80
 - 1s - loss: 0.0221
Epoch 19/80
 - 1s - loss: 0.0211
Epoch 20/80
 - 2s - loss: 0.0202
Epoch 21/80
 - 1s - loss: 0.0195
Epoch 22/80
 - 1s - loss: 0.0188
Epoch 23/80
 - 1s - loss: 0.0183
Epoch 24/80
 - 1s - loss: 0.0178
Epoch 25/80
 - 1s - loss: 0.0174
Epoch 26/80
 - 1s - loss: 0.0170
Epoch 27/80
 - 1s - loss: 0.0166
Epoch 28/80
 - 1s - loss: 0.0164
Epoch 29/80
 - 1s - loss: 0.0161
Epoch 30/80
 - 2s - loss: 0.0159
Epoch 31/80
 - 1s - loss: 0.0157
Epoch 32/80
 - 1s - loss: 0.0155
Epoch 33/80
 - 1s - loss: 0.0154
Epoch 34/80
 - 2s - loss: 0.0152
Epoch 35/80
 - 1s - loss: 0.0151
Epoch 36/80
 - 1s - loss: 0.0150
Epoch 37/80
 - 1s - loss: 0.0149
Epoch 38/80
 - 1s - loss: 0.0148
Epoch 39/80
 - 1s - loss: 0.0148
Epoch 40/80
 - 2s - loss: 0.0147
Epoch 41/80
 - 1s - loss: 0.0146
Epoch 42/80
 - 1s - loss: 0.0146
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:08:11.805013: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:08:11.967398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:08:11.967442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:08:12.260532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:08:12.260585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:08:12.260593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:08:12.260847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3025
Epoch 2/80
 - 1s - loss: 0.3303
Epoch 3/80
 - 1s - loss: 0.2869
Epoch 4/80
 - 1s - loss: 0.2567
Epoch 5/80
 - 1s - loss: 0.2378
Epoch 6/80
 - 1s - loss: 0.2235
Epoch 7/80
 - 1s - loss: 0.2090
Epoch 8/80
 - 1s - loss: 0.1937
Epoch 9/80
 - 1s - loss: 0.1794
Epoch 10/80
 - 1s - loss: 0.1672
Epoch 11/80
 - 1s - loss: 0.1572
Epoch 12/80
 - 1s - loss: 0.1488
Epoch 13/80
 - 1s - loss: 0.1416
Epoch 14/80
 - 1s - loss: 0.1356
Epoch 15/80
 - 1s - loss: 0.1307
Epoch 16/80
 - 1s - loss: 0.1266
Epoch 17/80
 - 1s - loss: 0.1231
Epoch 18/80
 - 1s - loss: 0.1202
Epoch 19/80
 - 1s - loss: 0.1177
Epoch 20/80
 - 1s - loss: 0.1156
Epoch 21/80
 - 1s - loss: 0.1137
Epoch 22/80
 - 1s - loss: 0.1121
Epoch 23/80
 - 1s - loss: 0.1107
Epoch 24/80
 - 1s - loss: 0.1096
Epoch 25/80
 - 1s - loss: 0.1086
Epoch 26/80
 - 1s - loss: 0.1077
Epoch 27/80
 - 1s - loss: 0.1070
Epoch 28/80
 - 1s - loss: 0.1063
Epoch 29/80
 - 1s - loss: 0.1058
Epoch 30/80
 - 1s - loss: 0.1053
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:09:21.526983: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:09:21.688586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:09:21.688630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:09:21.978284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:09:21.978334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:09:21.978343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:09:21.978596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2921
Epoch 2/80
 - 2s - loss: 0.3328
Epoch 3/80
 - 1s - loss: 0.3028
Epoch 4/80
 - 1s - loss: 0.2814
Epoch 5/80
 - 1s - loss: 0.2550
Epoch 6/80
 - 1s - loss: 0.2301
Epoch 7/80
 - 1s - loss: 0.2092
Epoch 8/80
 - 1s - loss: 0.1909
Epoch 9/80
 - 1s - loss: 0.1764
Epoch 10/80
 - 1s - loss: 0.1652
Epoch 11/80
 - 1s - loss: 0.1560
Epoch 12/80
 - 1s - loss: 0.1480
Epoch 13/80
 - 1s - loss: 0.1412
Epoch 14/80
 - 1s - loss: 0.1354
Epoch 15/80
 - 1s - loss: 0.1306
Epoch 16/80
 - 1s - loss: 0.1268
Epoch 17/80
 - 1s - loss: 0.1235
Epoch 18/80
 - 1s - loss: 0.1208
Epoch 19/80
 - 1s - loss: 0.1185
Epoch 20/80
 - 1s - loss: 0.1164
Epoch 21/80
 - 1s - loss: 0.1147
Epoch 22/80
 - 1s - loss: 0.1131
Epoch 23/80
 - 1s - loss: 0.1117
Epoch 24/80
 - 1s - loss: 0.1105
Epoch 25/80
 - 1s - loss: 0.1095
Epoch 26/80
 - 1s - loss: 0.1085
Epoch 27/80
 - 2s - loss: 0.1078
Epoch 28/80
 - 1s - loss: 0.1071
Epoch 29/80
 - 1s - loss: 0.1066
Epoch 30/80
 - 1s - loss: 0.1060
Epoch 31/80
 - 1s - loss: 0.1056
Epoch 32/80
 - 1s - loss: 0.1052
Epoch 33/80
 - 1s - loss: 0.1049
Epoch 34/80
 - 1s - loss: 0.1045
Epoch 35/80
 - 1s - loss: 0.1042
Epoch 36/80
 - 1s - loss: 0.1040
Epoch 37/80
 - 1s - loss: 0.1037
Epoch 38/80
 - 1s - loss: 0.1035
Epoch 39/80
 - 1s - loss: 0.1033
Epoch 40/80
 - 1s - loss: 0.1031
Epoch 41/80
 - 1s - loss: 0.1030
Epoch 42/80
 - 1s - loss: 0.1028
Epoch 43/80
 - 1s - loss: 0.1027
Epoch 44/80
 - 1s - loss: 0.1026
Epoch 45/80
 - 1s - loss: 0.1025
Epoch 46/80
 - 1s - loss: 0.1023
Epoch 47/80
 - 1s - loss: 0.1022
Epoch 48/80
 - 1s - loss: 0.1021
Epoch 49/80
 - 1s - loss: 0.1021
Epoch 50/80
 - 1s - loss: 0.1020
Epoch 51/80
 - 1s - loss: 0.1019
Epoch 52/80
 - 1s - loss: 0.1018
Epoch 53/80
 - 1s - loss: 0.1017
Epoch 54/80
 - 1s - loss: 0.1017
Epoch 55/80
 - 1s - loss: 0.1016
Epoch 56/80
 - 1s - loss: 0.1016
Epoch 57/80
 - 1s - loss: 0.1015
Epoch 58/80
 - 1s - loss: 0.1014
Epoch 59/80
 - 1s - loss: 0.1014
Epoch 60/80
 - 1s - loss: 0.1014
Epoch 61/80
 - 1s - loss: 0.1013
Epoch 62/80
 - 1s - loss: 0.1013
Epoch 63/80
 - 1s - loss: 0.1012
Epoch 64/80
 - 1s - loss: 0.1012
Epoch 65/80
 - 1s - loss: 0.1011
Epoch 66/80
 - 1s - loss: 0.1011
Epoch 67/80
 - 1s - loss: 0.1011
Epoch 68/80
 - 2s - loss: 0.1010
Epoch 69/80
 - 1s - loss: 0.1010
Epoch 70/80
 - 1s - loss: 0.0984
Epoch 71/80
 - 1s - loss: 0.0981
Epoch 72/80
 - 1s - loss: 0.0981
Epoch 73/80
 - 1s - loss: 0.0980
Epoch 74/80
 - 1s - loss: 0.0980
Epoch 75/80
 - 1s - loss: 0.0974
Epoch 76/80
 - 1s - loss: 0.0974
Epoch 77/80
 - 1s - loss: 0.0974
Epoch 78/80
 - 1s - loss: 0.0974
Epoch 79/80
 - 1s - loss: 0.0972
Epoch 80/80
 - 1s - loss: 0.0972
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4329 - val_loss: 1.1649
AUC: 0.8075

Epoch 2/80
 - 0s - loss: 2.0529 - val_loss: 0.7412
AUC: 0.8369

Epoch 3/80
 - 0s - loss: 1.4650 - val_loss: 0.8315
AUC: 0.8495

Epoch 4/80
 - 0s - loss: 1.2208 - val_loss: 0.6899
AUC: 0.8510

Epoch 5/80
 - 0s - loss: 1.1538 - val_loss: 0.6504
AUC: 0.8535

Epoch 6/80
 - 0s - loss: 1.1101 - val_loss: 0.7087
AUC: 0.8545

Epoch 7/80
 - 0s - loss: 1.0961 - val_loss: 0.6653
AUC: 0.8575

Epoch 8/80
 - 0s - loss: 1.0836 - val_loss: 0.7082
AUC: 0.8588

Epoch 9/80
 - 0s - loss: 1.0670 - val_loss: 0.6315
AUC: 0.8606

Epoch 10/80
 - 0s - loss: 1.0604 - val_loss: 0.6665
AUC: 0.8619

Epoch 11/80
 - 0s - loss: 1.0514 - val_loss: 0.5923
AUC: 0.8609

Epoch 12/80
 - 0s - loss: 1.0491 - val_loss: 0.6158
AUC: 0.8624

Epoch 13/80
 - 0s - loss: 1.0372 - val_loss: 0.5842
AUC: 0.8627

Epoch 14/80
 - 0s - loss: 1.0327 - val_loss: 0.5986
AUC: 0.8637

Epoch 15/80
 - 0s - loss: 1.0351 - val_loss: 0.5591
AUC: 0.8636

Epoch 16/80
 - 0s - loss: 1.0305 - val_loss: 0.6407
AUC: 0.8654

Epoch 17/80
 - 0s - loss: 1.0237 - val_loss: 0.5774
AUC: 0.8647

Epoch 18/80
 - 0s - loss: 1.0112 - val_loss: 0.6278
AUC: 0.8663

Epoch 19/80
 - 0s - loss: 1.0152 - val_loss: 0.5932
AUC: 0.8663

Epoch 20/80
 - 0s - loss: 1.0070 - val_loss: 0.5995
AUC: 0.8665

Epoch 21/80
 - 0s - loss: 1.0118 - val_loss: 0.5870
AUC: 0.8671

Epoch 22/80
 - 0s - loss: 1.0019 - val_loss: 0.5656
AUC: 0.8671

Epoch 23/80
 - 0s - loss: 1.0056 - val_loss: 0.6127
AUC: 0.8670

Epoch 24/80
 - 0s - loss: 0.9951 - val_loss: 0.5769
AUC: 0.8676

Epoch 25/80
 - 0s - loss: 0.9956 - val_loss: 0.6084
AUC: 0.8692

Epoch 26/80
 - 0s - loss: 0.9835 - val_loss: 0.6144
AUC: 0.8695

Epoch 27/80
 - 0s - loss: 0.9829 - val_loss: 0.5906
AUC: 0.8690

Epoch 28/80
 - 0s - loss: 0.9829 - val_loss: 0.6028
AUC: 0.8690

Epoch 29/80
 - 0s - loss: 0.9744 - val_loss: 0.6046
AUC: 0.8690

Epoch 30/80
 - 0s - loss: 0.9814 - val_loss: 0.5999
AUC: 0.8690

Epoch 31/80
 - 0s - loss: 0.9812 - val_loss: 0.5944
AUC: 0.8690

Epoch 32/80
 - 0s - loss: 0.9772 - val_loss: 0.5983
AUC: 0.8693

Epoch 33/80
 - 0s - loss: 0.9730 - val_loss: 0.6143
AUC: 0.8696

Epoch 34/80
 - 0s - loss: 0.9768 - val_loss: 0.6040
AUC: 0.8695

Epoch 35/80
 - 0s - loss: 0.9739 - val_loss: 0.5980
AUC: 0.8691

Epoch 36/80
 - 0s - loss: 0.9766 - val_loss: 0.5971
AUC: 0.8693

Epoch 37/80
 - 0s - loss: 0.9724 - val_loss: 0.5944
AUC: 0.8693

Epoch 38/80
 - 0s - loss: 0.9702 - val_loss: 0.5923
AUC: 0.8693

Epoch 39/80
 - 0s - loss: 0.9715 - val_loss: 0.5892
AUC: 0.8693

Epoch 40/80
 - 0s - loss: 0.9753 - val_loss: 0.6079
AUC: 0.8695

Epoch 41/80
 - 0s - loss: 0.9636 - val_loss: 0.5920
AUC: 0.8694

Epoch 42/80
 - 0s - loss: 0.9692 - val_loss: 0.6010
AUC: 0.8695

Epoch 43/80
 - 0s - loss: 0.9695 - val_loss: 0.5930
AUC: 0.8694

Epoch 44/80
 - 0s - loss: 0.9708 - val_loss: 0.5934
AUC: 0.8695

Epoch 45/80
 - 0s - loss: 0.9713 - val_loss: 0.5862
AUC: 0.8695

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9748 - val_loss: 0.5715
AUC: 0.8692

Epoch 2/30
 - 0s - loss: 0.9683 - val_loss: 0.5983
AUC: 0.8698

Epoch 3/30
 - 0s - loss: 0.9683 - val_loss: 0.6012
AUC: 0.8698

Epoch 4/30
 - 0s - loss: 0.9694 - val_loss: 0.5859
AUC: 0.8699

Epoch 5/30
 - 0s - loss: 0.9648 - val_loss: 0.5954
AUC: 0.8700

Epoch 6/30
 - 0s - loss: 0.9672 - val_loss: 0.5895
AUC: 0.8699

Epoch 7/30
 - 0s - loss: 0.9628 - val_loss: 0.5802
AUC: 0.8699

Epoch 8/30
 - 0s - loss: 0.9613 - val_loss: 0.6188
AUC: 0.8704

Epoch 9/30
 - 0s - loss: 0.9602 - val_loss: 0.5852
AUC: 0.8701

Epoch 10/30
 - 0s - loss: 0.9587 - val_loss: 0.5822
AUC: 0.8702

Epoch 11/30
 - 0s - loss: 0.9587 - val_loss: 0.5799
AUC: 0.8703

Epoch 12/30
 - 0s - loss: 0.9532 - val_loss: 0.5852
AUC: 0.8704

Epoch 13/30
 - 0s - loss: 0.9525 - val_loss: 0.5857
AUC: 0.8704

Epoch 14/30
 - 0s - loss: 0.9590 - val_loss: 0.5867
AUC: 0.8704

Epoch 15/30
 - 0s - loss: 0.9568 - val_loss: 0.5858
AUC: 0.8705

Epoch 16/30
 - 0s - loss: 0.9560 - val_loss: 0.5800
AUC: 0.8704

Epoch 17/30
 - 0s - loss: 0.9546 - val_loss: 0.5867
AUC: 0.8705

Epoch 18/30
 - 0s - loss: 0.9538 - val_loss: 0.5872
AUC: 0.8706

Epoch 19/30
 - 0s - loss: 0.9537 - val_loss: 0.5903
AUC: 0.8706

Epoch 20/30
 - 0s - loss: 0.9530 - val_loss: 0.5875
AUC: 0.8706

Epoch 21/30
 - 0s - loss: 0.9579 - val_loss: 0.5896
AUC: 0.8707

Epoch 22/30
 - 0s - loss: 0.9495 - val_loss: 0.5894
AUC: 0.8707

Epoch 23/30
 - 0s - loss: 0.9500 - val_loss: 0.5865
AUC: 0.8706

Epoch 24/30
 - 0s - loss: 0.9463 - val_loss: 0.5871
AUC: 0.8707

Epoch 25/30
 - 0s - loss: 0.9556 - val_loss: 0.5875
AUC: 0.8707

Epoch 26/30
 - 0s - loss: 0.9549 - val_loss: 0.5860
AUC: 0.8707

Epoch 27/30
 - 0s - loss: 0.9525 - val_loss: 0.5860
AUC: 0.8707

Epoch 28/30
 - 0s - loss: 0.9538 - val_loss: 0.5861
AUC: 0.8707

Epoch 29/30
 - 0s - loss: 0.9519 - val_loss: 0.5854
AUC: 0.8707

Epoch 30/30
 - 0s - loss: 0.9497 - val_loss: 0.5850
Using TensorFlow backend.
AUC: 0.8707

2019-03-08 07:12:35.455609: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:12:35.619873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:12:35.619916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:12:35.911475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:12:35.911527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:12:35.911536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:12:35.911792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2745
Epoch 2/80
 - 1s - loss: 0.3341
Epoch 3/80
 - 1s - loss: 0.3034
Epoch 4/80
 - 1s - loss: 0.2832
Epoch 5/80
 - 2s - loss: 0.2569
Epoch 6/80
 - 1s - loss: 0.2294
Epoch 7/80
 - 1s - loss: 0.2082
Epoch 8/80
 - 1s - loss: 0.1927
Epoch 9/80
 - 1s - loss: 0.1801
Epoch 10/80
 - 1s - loss: 0.1692
Epoch 11/80
 - 1s - loss: 0.1597
Epoch 12/80
 - 1s - loss: 0.1513
Epoch 13/80
 - 1s - loss: 0.1439
Epoch 14/80
 - 1s - loss: 0.1377
Epoch 15/80
 - 1s - loss: 0.1325
Epoch 16/80
 - 1s - loss: 0.1282
Epoch 17/80
 - 2s - loss: 0.1246
Epoch 18/80
 - 1s - loss: 0.1215
Epoch 19/80
 - 2s - loss: 0.1188
Epoch 20/80
 - 1s - loss: 0.1165
Epoch 21/80
 - 1s - loss: 0.1145
Epoch 22/80
 - 1s - loss: 0.1128
Epoch 23/80
 - 1s - loss: 0.1114
Epoch 24/80
 - 1s - loss: 0.1102
Epoch 25/80
 - 1s - loss: 0.1091
Epoch 26/80
 - 1s - loss: 0.1082
Epoch 27/80
 - 1s - loss: 0.1075
Epoch 28/80
 - 1s - loss: 0.1068
Epoch 29/80
 - 1s - loss: 0.1062
Epoch 30/80
 - 1s - loss: 0.1057
Epoch 31/80
 - 1s - loss: 0.1053
Epoch 32/80
 - 2s - loss: 0.1049
Epoch 33/80
 - 1s - loss: 0.1046
Epoch 34/80
 - 1s - loss: 0.1043
Epoch 35/80
 - 2s - loss: 0.1040
Epoch 36/80
 - 1s - loss: 0.1037
Epoch 37/80
 - 2s - loss: 0.1035
Epoch 38/80
 - 1s - loss: 0.1033
Epoch 39/80
 - 2s - loss: 0.1031
Epoch 40/80
 - 1s - loss: 0.1030
Epoch 41/80
 - 1s - loss: 0.1028
Epoch 42/80
 - 1s - loss: 0.1027
Epoch 43/80
 - 1s - loss: 0.1026
Epoch 44/80
 - 1s - loss: 0.1024
Epoch 45/80
 - 1s - loss: 0.1023
Epoch 46/80
 - 1s - loss: 0.1022
Epoch 47/80
 - 1s - loss: 0.1021
Epoch 48/80
 - 1s - loss: 0.1020
Epoch 49/80
 - 1s - loss: 0.1019
Epoch 50/80
 - 1s - loss: 0.1018
Epoch 51/80
 - 1s - loss: 0.1018
Epoch 52/80
 - 1s - loss: 0.1017
Epoch 53/80
 - 1s - loss: 0.1016
Epoch 54/80
 - 1s - loss: 0.1016
Epoch 55/80
 - 1s - loss: 0.1015
Epoch 56/80
 - 2s - loss: 0.1015
Epoch 57/80
 - 1s - loss: 0.1013
Epoch 58/80
 - 1s - loss: 0.1014
Epoch 59/80
 - 2s - loss: 0.1013
Epoch 60/80
 - 1s - loss: 0.1012
Epoch 61/80
 - 1s - loss: 0.1012
Epoch 62/80
 - 1s - loss: 0.1012
Epoch 63/80
 - 1s - loss: 0.1011
Epoch 64/80
 - 1s - loss: 0.1011
Epoch 65/80
 - 1s - loss: 0.1010
Epoch 66/80
 - 1s - loss: 0.1010
Epoch 67/80
 - 1s - loss: 0.0984
Epoch 68/80
 - 1s - loss: 0.0981
Epoch 69/80
 - 1s - loss: 0.0981
Epoch 70/80
 - 1s - loss: 0.0980
Epoch 71/80
 - 1s - loss: 0.0980
Epoch 72/80
 - 1s - loss: 0.0974
Epoch 73/80
 - 1s - loss: 0.0974
Epoch 74/80
 - 1s - loss: 0.0974
Epoch 75/80
 - 2s - loss: 0.0974
Epoch 76/80
 - 1s - loss: 0.0972
Epoch 77/80
 - 1s - loss: 0.0972
Epoch 78/80
 - 2s - loss: 0.0972
Epoch 79/80
 - 1s - loss: 0.0972
Epoch 80/80
 - 1s - loss: 0.0972
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.8800 - val_loss: 1.2603
AUC: 0.8034

Epoch 2/80
 - 0s - loss: 1.9615 - val_loss: 0.8645
AUC: 0.8323

Epoch 3/80
 - 0s - loss: 1.3729 - val_loss: 0.7369
AUC: 0.8415

Epoch 4/80
 - 0s - loss: 1.2070 - val_loss: 0.6816
AUC: 0.8449

Epoch 5/80
 - 0s - loss: 1.1624 - val_loss: 0.7444
AUC: 0.8513

Epoch 6/80
 - 0s - loss: 1.1128 - val_loss: 0.6783
AUC: 0.8546

Epoch 7/80
 - 0s - loss: 1.0920 - val_loss: 0.6309
AUC: 0.8547

Epoch 8/80
 - 0s - loss: 1.0831 - val_loss: 0.6039
AUC: 0.8564

Epoch 9/80
 - 0s - loss: 1.0670 - val_loss: 0.6672
AUC: 0.8575

Epoch 10/80
 - 0s - loss: 1.0636 - val_loss: 0.7559
AUC: 0.8616

Epoch 11/80
 - 0s - loss: 1.0538 - val_loss: 0.6015
AUC: 0.8577

Epoch 12/80
 - 0s - loss: 1.0477 - val_loss: 0.6333
AUC: 0.8607

Epoch 13/80
 - 0s - loss: 1.0392 - val_loss: 0.6481
AUC: 0.8615

Epoch 14/80
 - 0s - loss: 1.0338 - val_loss: 0.6903
AUC: 0.8623

Epoch 15/80
 - 0s - loss: 1.0298 - val_loss: 0.5756
AUC: 0.8622

Epoch 16/80
 - 0s - loss: 1.0187 - val_loss: 0.6222
AUC: 0.8635

Epoch 17/80
 - 0s - loss: 1.0200 - val_loss: 0.6428
AUC: 0.8643

Epoch 18/80
 - 0s - loss: 1.0155 - val_loss: 0.5592
AUC: 0.8629

Epoch 19/80
 - 0s - loss: 1.0166 - val_loss: 0.6804
AUC: 0.8656

Epoch 20/80
 - 0s - loss: 1.0094 - val_loss: 0.5668
AUC: 0.8637

Epoch 21/80
 - 0s - loss: 1.0102 - val_loss: 0.6610
AUC: 0.8659

Epoch 22/80
 - 0s - loss: 1.0008 - val_loss: 0.5946
AUC: 0.8641

Epoch 23/80
 - 0s - loss: 1.0015 - val_loss: 0.6238
AUC: 0.8658

Epoch 24/80
 - 0s - loss: 0.9918 - val_loss: 0.5566
AUC: 0.8642

Epoch 25/80
 - 0s - loss: 0.9899 - val_loss: 0.6649
AUC: 0.8671

Epoch 26/80
 - 0s - loss: 0.9881 - val_loss: 0.6396
AUC: 0.8669

Epoch 27/80
 - 0s - loss: 0.9850 - val_loss: 0.6403
AUC: 0.8665

Epoch 28/80
 - 0s - loss: 0.9803 - val_loss: 0.6976
AUC: 0.8668

Epoch 29/80
 - 0s - loss: 0.9821 - val_loss: 0.6196
AUC: 0.8672

Epoch 30/80
 - 0s - loss: 0.9818 - val_loss: 0.5996
AUC: 0.8660

Epoch 31/80
 - 0s - loss: 0.9762 - val_loss: 0.5949
AUC: 0.8663

Epoch 32/80
 - 0s - loss: 0.9775 - val_loss: 0.6472
AUC: 0.8670

Epoch 33/80
 - 0s - loss: 0.9710 - val_loss: 0.6441
AUC: 0.8669

Epoch 34/80
 - 0s - loss: 0.9715 - val_loss: 0.6117
AUC: 0.8658

Epoch 35/80
 - 0s - loss: 0.9603 - val_loss: 0.5989
AUC: 0.8667

Epoch 36/80
 - 0s - loss: 0.9575 - val_loss: 0.5914
AUC: 0.8669

Epoch 37/80
 - 0s - loss: 0.9609 - val_loss: 0.6314
AUC: 0.8676

Epoch 38/80
 - 0s - loss: 0.9573 - val_loss: 0.5801
AUC: 0.8666

Epoch 39/80
 - 0s - loss: 0.9493 - val_loss: 0.5992
AUC: 0.8670

Epoch 40/80
 - 0s - loss: 0.9539 - val_loss: 0.5979
AUC: 0.8675

Epoch 41/80
 - 0s - loss: 0.9488 - val_loss: 0.5902
AUC: 0.8671

Epoch 42/80
 - 0s - loss: 0.9524 - val_loss: 0.5893
AUC: 0.8670

Epoch 43/80
 - 0s - loss: 0.9547 - val_loss: 0.5995
AUC: 0.8673

Epoch 44/80
 - 0s - loss: 0.9574 - val_loss: 0.5877
AUC: 0.8671

Epoch 45/80
 - 0s - loss: 0.9499 - val_loss: 0.5926
AUC: 0.8673

Epoch 46/80
 - 0s - loss: 0.9482 - val_loss: 0.5880
AUC: 0.8672

Epoch 47/80
 - 0s - loss: 0.9498 - val_loss: 0.5934
AUC: 0.8672

Epoch 48/80
 - 0s - loss: 0.9500 - val_loss: 0.5923
AUC: 0.8672

Epoch 49/80
 - 0s - loss: 0.9525 - val_loss: 0.5939
AUC: 0.8673

Epoch 50/80
 - 0s - loss: 0.9540 - val_loss: 0.5952
AUC: 0.8675

Epoch 51/80
 - 0s - loss: 0.9483 - val_loss: 0.5950
AUC: 0.8674

Epoch 52/80
 - 0s - loss: 0.9520 - val_loss: 0.5890
AUC: 0.8673

Epoch 53/80
 - 0s - loss: 0.9503 - val_loss: 0.5975
AUC: 0.8673

Epoch 54/80
 - 0s - loss: 0.9455 - val_loss: 0.5990
AUC: 0.8673

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9510 - val_loss: 0.6106
AUC: 0.8673

Epoch 2/30
 - 0s - loss: 0.9550 - val_loss: 0.5843
AUC: 0.8671

Epoch 3/30
 - 0s - loss: 0.9557 - val_loss: 0.5916
AUC: 0.8672

Epoch 4/30
 - 0s - loss: 0.9481 - val_loss: 0.6122
AUC: 0.8676

Epoch 5/30
 - 0s - loss: 0.9501 - val_loss: 0.5937
AUC: 0.8674

Epoch 6/30
 - 0s - loss: 0.9459 - val_loss: 0.5958
AUC: 0.8675

Epoch 7/30
 - 0s - loss: 0.9477 - val_loss: 0.5913
AUC: 0.8676

Epoch 8/30
 - 0s - loss: 0.9438 - val_loss: 0.5823
AUC: 0.8677

Epoch 9/30
 - 0s - loss: 0.9453 - val_loss: 0.5837
AUC: 0.8674

Epoch 10/30
 - 0s - loss: 0.9388 - val_loss: 0.6008
AUC: 0.8678

Epoch 11/30
 - 0s - loss: 0.9370 - val_loss: 0.5905
AUC: 0.8678

Epoch 12/30
 - 0s - loss: 0.9374 - val_loss: 0.5776
AUC: 0.8677

Epoch 13/30
 - 0s - loss: 0.9419 - val_loss: 0.5746
AUC: 0.8677

Epoch 14/30
 - 0s - loss: 0.9350 - val_loss: 0.5808
AUC: 0.8678

Epoch 15/30
 - 0s - loss: 0.9375 - val_loss: 0.5793
AUC: 0.8681

Epoch 16/30
 - 0s - loss: 0.9315 - val_loss: 0.5704
AUC: 0.8681

Epoch 17/30
 - 0s - loss: 0.9315 - val_loss: 0.6242
AUC: 0.8685

Epoch 18/30
 - 0s - loss: 0.9353 - val_loss: 0.5873
AUC: 0.8682

Epoch 19/30
 - 0s - loss: 0.9310 - val_loss: 0.5837
AUC: 0.8684

Epoch 20/30
 - 0s - loss: 0.9277 - val_loss: 0.6023
AUC: 0.8685

Epoch 21/30
 - 0s - loss: 0.9279 - val_loss: 0.6137
AUC: 0.8688

Epoch 22/30
 - 0s - loss: 0.9282 - val_loss: 0.5849
AUC: 0.8687

Epoch 23/30
 - 0s - loss: 0.9267 - val_loss: 0.5816
AUC: 0.8686

Epoch 24/30
 - 0s - loss: 0.9256 - val_loss: 0.5989
AUC: 0.8689

Epoch 25/30
 - 0s - loss: 0.9272 - val_loss: 0.5682
AUC: 0.8688

Epoch 26/30
 - 0s - loss: 0.9208 - val_loss: 0.5900
AUC: 0.8689

Epoch 27/30
 - 0s - loss: 0.9235 - val_loss: 0.5907
AUC: 0.8691

Epoch 28/30
 - 0s - loss: 0.9233 - val_loss: 0.5846
AUC: 0.8689

Epoch 29/30
 - 0s - loss: 0.9265 - val_loss: 0.5754
AUC: 0.8689

Epoch 30/30
 - 0s - loss: 0.9220 - val_loss: 0.5914
Using TensorFlow backend.
AUC: 0.8691

2019-03-08 07:15:54.378855: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:15:54.544676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:15:54.544719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:15:54.841764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:15:54.841804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:15:54.841813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:15:54.842065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2914
Epoch 2/80
 - 2s - loss: 0.3332
Epoch 3/80
 - 2s - loss: 0.3066
Epoch 4/80
 - 2s - loss: 0.2917
Epoch 5/80
 - 2s - loss: 0.2708
Epoch 6/80
 - 2s - loss: 0.2440
Epoch 7/80
 - 2s - loss: 0.2177
Epoch 8/80
 - 2s - loss: 0.1979
Epoch 9/80
 - 2s - loss: 0.1826
Epoch 10/80
 - 2s - loss: 0.1697
Epoch 11/80
 - 2s - loss: 0.1588
Epoch 12/80
 - 2s - loss: 0.1498
Epoch 13/80
 - 1s - loss: 0.1423
Epoch 14/80
 - 1s - loss: 0.1363
Epoch 15/80
 - 2s - loss: 0.1313
Epoch 16/80
 - 1s - loss: 0.1273
Epoch 17/80
 - 2s - loss: 0.1240
Epoch 18/80
 - 1s - loss: 0.1212
Epoch 19/80
 - 2s - loss: 0.1189
Epoch 20/80
 - 1s - loss: 0.1167
Epoch 21/80
 - 2s - loss: 0.1150
Epoch 22/80
 - 2s - loss: 0.1134
Epoch 23/80
 - 1s - loss: 0.1120
Epoch 24/80
 - 1s - loss: 0.1108
Epoch 25/80
 - 2s - loss: 0.1098
Epoch 26/80
 - 2s - loss: 0.1089
Epoch 27/80
 - 1s - loss: 0.1081
Epoch 28/80
 - 2s - loss: 0.1074
Epoch 29/80
 - 1s - loss: 0.1068
Epoch 30/80
 - 1s - loss: 0.1063
Epoch 31/80
 - 1s - loss: 0.1059
Epoch 32/80
 - 1s - loss: 0.1055
Epoch 33/80
 - 2s - loss: 0.1051
Epoch 34/80
 - 1s - loss: 0.1048
Epoch 35/80
 - 1s - loss: 0.1045
Epoch 36/80
 - 2s - loss: 0.1043
Epoch 37/80
 - 1s - loss: 0.1040
Epoch 38/80
 - 2s - loss: 0.1039
Epoch 39/80
 - 1s - loss: 0.1037
Epoch 40/80
 - 2s - loss: 0.1035
Epoch 41/80
 - 2s - loss: 0.1033
Epoch 42/80
 - 2s - loss: 0.1032
Epoch 43/80
 - 1s - loss: 0.1031
Epoch 44/80
 - 2s - loss: 0.1029
Epoch 45/80
 - 2s - loss: 0.1028
Epoch 46/80
 - 2s - loss: 0.1027
Epoch 47/80
 - 1s - loss: 0.1026
Epoch 48/80
 - 1s - loss: 0.1025
Epoch 49/80
 - 2s - loss: 0.1024
Epoch 50/80
 - 1s - loss: 0.1024
Epoch 51/80
 - 1s - loss: 0.1023
Epoch 52/80
 - 2s - loss: 0.1022
Epoch 53/80
 - 1s - loss: 0.1022
Epoch 54/80
 - 2s - loss: 0.1021
Epoch 55/80
 - 1s - loss: 0.1020
Epoch 56/80
 - 1s - loss: 0.1020
Epoch 57/80
 - 1s - loss: 0.1020
Epoch 58/80
 - 1s - loss: 0.1019
Epoch 59/80
 - 2s - loss: 0.1018
Epoch 60/80
 - 2s - loss: 0.1018
Epoch 61/80
 - 2s - loss: 0.1017
Epoch 62/80
 - 2s - loss: 0.1017
Epoch 63/80
 - 1s - loss: 0.1017
Epoch 64/80
 - 1s - loss: 0.1017
Epoch 65/80
 - 2s - loss: 0.0990
Epoch 66/80
 - 2s - loss: 0.0987
Epoch 67/80
 - 2s - loss: 0.0987
Epoch 68/80
 - 1s - loss: 0.0987
Epoch 69/80
 - 1s - loss: 0.0986
Epoch 70/80
 - 1s - loss: 0.0980
Epoch 71/80
 - 2s - loss: 0.0980
Epoch 72/80
 - 2s - loss: 0.0980
Epoch 73/80
 - 2s - loss: 0.0980
Epoch 74/80
 - 2s - loss: 0.0978
Epoch 75/80
 - 2s - loss: 0.0978
Epoch 76/80
 - 1s - loss: 0.0978
Epoch 77/80
 - 2s - loss: 0.0978
Epoch 78/80
 - 1s - loss: 0.0978
Epoch 79/80
 - 2s - loss: 0.0978
Epoch 80/80
 - 2s - loss: 0.0978
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0511 - val_loss: 1.0632
AUC: 0.8127

Epoch 2/80
 - 0s - loss: 1.5743 - val_loss: 0.8154
AUC: 0.8312

Epoch 3/80
 - 0s - loss: 1.2348 - val_loss: 0.6811
AUC: 0.8358

Epoch 4/80
 - 0s - loss: 1.1597 - val_loss: 0.7191
AUC: 0.8464

Epoch 5/80
 - 0s - loss: 1.1318 - val_loss: 0.7309
AUC: 0.8469

Epoch 6/80
 - 0s - loss: 1.1049 - val_loss: 0.6837
AUC: 0.8539

Epoch 7/80
 - 0s - loss: 1.0899 - val_loss: 0.6545
AUC: 0.8557

Epoch 8/80
 - 0s - loss: 1.0662 - val_loss: 0.6462
AUC: 0.8556

Epoch 9/80
 - 0s - loss: 1.0648 - val_loss: 0.7001
AUC: 0.8582

Epoch 10/80
 - 0s - loss: 1.0502 - val_loss: 0.6017
AUC: 0.8571

Epoch 11/80
 - 0s - loss: 1.0393 - val_loss: 0.6195
AUC: 0.8614

Epoch 12/80
 - 0s - loss: 1.0371 - val_loss: 0.6388
AUC: 0.8615

Epoch 13/80
 - 0s - loss: 1.0280 - val_loss: 0.6499
AUC: 0.8615

Epoch 14/80
 - 0s - loss: 1.0211 - val_loss: 0.6042
AUC: 0.8624

Epoch 15/80
 - 0s - loss: 1.0208 - val_loss: 0.6235
AUC: 0.8632

Epoch 16/80
 - 0s - loss: 1.0132 - val_loss: 0.6393
AUC: 0.8636

Epoch 17/80
 - 0s - loss: 1.0132 - val_loss: 0.5791
AUC: 0.8645

Epoch 18/80
 - 0s - loss: 1.0106 - val_loss: 0.5971
AUC: 0.8648

Epoch 19/80
 - 0s - loss: 1.0070 - val_loss: 0.6248
AUC: 0.8660

Epoch 20/80
 - 0s - loss: 0.9924 - val_loss: 0.6769
AUC: 0.8662

Epoch 21/80
 - 0s - loss: 0.9905 - val_loss: 0.6626
AUC: 0.8652

Epoch 22/80
 - 0s - loss: 0.9914 - val_loss: 0.6379
AUC: 0.8649

Epoch 23/80
 - 0s - loss: 0.9925 - val_loss: 0.5854
AUC: 0.8676

Epoch 24/80
 - 0s - loss: 0.9888 - val_loss: 0.6367
AUC: 0.8659

Epoch 25/80
 - 0s - loss: 0.9835 - val_loss: 0.5803
AUC: 0.8675

Epoch 26/80
 - 0s - loss: 0.9845 - val_loss: 0.7159
AUC: 0.8679

Epoch 27/80
 - 0s - loss: 0.9816 - val_loss: 0.6428
AUC: 0.8666

Epoch 28/80
 - 0s - loss: 0.9688 - val_loss: 0.5987
AUC: 0.8676

Epoch 29/80
 - 0s - loss: 0.9659 - val_loss: 0.5750
AUC: 0.8677

Epoch 30/80
 - 0s - loss: 0.9634 - val_loss: 0.6024
AUC: 0.8679

Epoch 31/80
 - 0s - loss: 0.9668 - val_loss: 0.5903
AUC: 0.8681

Epoch 32/80
 - 0s - loss: 0.9676 - val_loss: 0.6180
AUC: 0.8684

Epoch 33/80
 - 0s - loss: 0.9680 - val_loss: 0.6002
AUC: 0.8686

Epoch 34/80
 - 0s - loss: 0.9639 - val_loss: 0.6196
AUC: 0.8684

Epoch 35/80
 - 0s - loss: 0.9637 - val_loss: 0.5886
AUC: 0.8682

Epoch 36/80
 - 0s - loss: 0.9643 - val_loss: 0.6004
AUC: 0.8683

Epoch 37/80
 - 0s - loss: 0.9648 - val_loss: 0.5957
AUC: 0.8684

Epoch 38/80
 - 0s - loss: 0.9582 - val_loss: 0.6086
AUC: 0.8683

Epoch 39/80
 - 0s - loss: 0.9598 - val_loss: 0.6204
AUC: 0.8683

Epoch 40/80
 - 0s - loss: 0.9613 - val_loss: 0.5976
AUC: 0.8684

Epoch 41/80
 - 0s - loss: 0.9565 - val_loss: 0.6021
AUC: 0.8684

Epoch 42/80
 - 0s - loss: 0.9572 - val_loss: 0.6089
AUC: 0.8685

Epoch 43/80
 - 0s - loss: 0.9572 - val_loss: 0.6009
AUC: 0.8685

Epoch 44/80
 - 0s - loss: 0.9584 - val_loss: 0.6007
AUC: 0.8685

Epoch 45/80
 - 0s - loss: 0.9568 - val_loss: 0.5994
AUC: 0.8684

Epoch 46/80
 - 0s - loss: 0.9578 - val_loss: 0.6070
AUC: 0.8685

Epoch 47/80
 - 0s - loss: 0.9564 - val_loss: 0.6106
AUC: 0.8685

Epoch 48/80
 - 0s - loss: 0.9579 - val_loss: 0.6085
AUC: 0.8685

Epoch 49/80
 - 0s - loss: 0.9577 - val_loss: 0.5988
AUC: 0.8685

Epoch 50/80
 - 0s - loss: 0.9546 - val_loss: 0.6002
AUC: 0.8685

Epoch 51/80
 - 0s - loss: 0.9534 - val_loss: 0.5997
AUC: 0.8685

Epoch 52/80
 - 0s - loss: 0.9542 - val_loss: 0.6006
AUC: 0.8685

Epoch 53/80
 - 0s - loss: 0.9556 - val_loss: 0.6003
AUC: 0.8685

Epoch 54/80
 - 0s - loss: 0.9554 - val_loss: 0.6017
AUC: 0.8685

Epoch 55/80
 - 0s - loss: 0.9527 - val_loss: 0.6007
AUC: 0.8685

Epoch 56/80
 - 0s - loss: 0.9585 - val_loss: 0.6016
AUC: 0.8685

Epoch 57/80
 - 0s - loss: 0.9564 - val_loss: 0.6020
AUC: 0.8685

Epoch 58/80
 - 0s - loss: 0.9534 - val_loss: 0.6003
AUC: 0.8685

Epoch 59/80
 - 0s - loss: 0.9557 - val_loss: 0.6000
AUC: 0.8685

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9637 - val_loss: 0.6071
AUC: 0.8684

Epoch 2/30
 - 0s - loss: 0.9629 - val_loss: 0.6076
AUC: 0.8685

Epoch 3/30
 - 0s - loss: 0.9596 - val_loss: 0.6153
AUC: 0.8685

Epoch 4/30
 - 0s - loss: 0.9577 - val_loss: 0.6058
AUC: 0.8686

Epoch 5/30
 - 0s - loss: 0.9604 - val_loss: 0.5988
AUC: 0.8690

Epoch 6/30
 - 0s - loss: 0.9525 - val_loss: 0.6131
AUC: 0.8689

Epoch 7/30
 - 0s - loss: 0.9564 - val_loss: 0.6053
AUC: 0.8691

Epoch 8/30
 - 0s - loss: 0.9498 - val_loss: 0.5927
AUC: 0.8691

Epoch 9/30
 - 0s - loss: 0.9527 - val_loss: 0.5923
AUC: 0.8692

Epoch 10/30
 - 0s - loss: 0.9509 - val_loss: 0.5876
AUC: 0.8692

Epoch 11/30
 - 0s - loss: 0.9498 - val_loss: 0.5874
AUC: 0.8692

Epoch 12/30
 - 0s - loss: 0.9447 - val_loss: 0.6059
AUC: 0.8693

Epoch 13/30
 - 0s - loss: 0.9469 - val_loss: 0.6071
AUC: 0.8695

Epoch 14/30
 - 0s - loss: 0.9465 - val_loss: 0.5779
AUC: 0.8694

Epoch 15/30
 - 0s - loss: 0.9442 - val_loss: 0.6029
AUC: 0.8694

Epoch 16/30
 - 0s - loss: 0.9404 - val_loss: 0.5960
AUC: 0.8695

Epoch 17/30
 - 0s - loss: 0.9405 - val_loss: 0.5809
AUC: 0.8694

Epoch 18/30
 - 0s - loss: 0.9331 - val_loss: 0.6152
AUC: 0.8697

Epoch 19/30
 - 0s - loss: 0.9382 - val_loss: 0.5877
AUC: 0.8698

Epoch 20/30
 - 0s - loss: 0.9333 - val_loss: 0.5827
AUC: 0.8700

Epoch 21/30
 - 0s - loss: 0.9445 - val_loss: 0.5994
AUC: 0.8702

Epoch 22/30
 - 0s - loss: 0.9365 - val_loss: 0.5965
AUC: 0.8700

Epoch 23/30
 - 0s - loss: 0.9319 - val_loss: 0.5725
AUC: 0.8699

Epoch 24/30
 - 0s - loss: 0.9310 - val_loss: 0.6013
AUC: 0.8701

Epoch 25/30
 - 0s - loss: 0.9304 - val_loss: 0.5609
AUC: 0.8700

Epoch 26/30
 - 0s - loss: 0.9216 - val_loss: 0.5989
AUC: 0.8704

Epoch 27/30
 - 0s - loss: 0.9297 - val_loss: 0.5825
AUC: 0.8704

Epoch 28/30
 - 0s - loss: 0.9241 - val_loss: 0.5921
AUC: 0.8704

Epoch 29/30
 - 0s - loss: 0.9302 - val_loss: 0.5758
AUC: 0.8704

Epoch 30/30
 - 0s - loss: 0.9253 - val_loss: 0.5735
Using TensorFlow backend.
AUC: 0.8705

2019-03-08 07:19:17.681939: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:19:17.845398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:19:17.845441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:19:18.135374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:19:18.135426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:19:18.135435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:19:18.135688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0575
Epoch 2/80
 - 1s - loss: 0.1946
Epoch 3/80
 - 1s - loss: 0.1681
Epoch 4/80
 - 1s - loss: 0.1569
Epoch 5/80
 - 1s - loss: 0.1447
Epoch 6/80
 - 1s - loss: 0.1332
Epoch 7/80
 - 1s - loss: 0.1227
Epoch 8/80
 - 1s - loss: 0.1123
Epoch 9/80
 - 1s - loss: 0.1026
Epoch 10/80
 - 1s - loss: 0.0938
Epoch 11/80
 - 1s - loss: 0.0861
Epoch 12/80
 - 1s - loss: 0.0796
Epoch 13/80
 - 1s - loss: 0.0743
Epoch 14/80
 - 1s - loss: 0.0698
Epoch 15/80
 - 1s - loss: 0.0659
Epoch 16/80
 - 1s - loss: 0.0627
Epoch 17/80
 - 1s - loss: 0.0600
Epoch 18/80
 - 1s - loss: 0.0578
Epoch 19/80
 - 1s - loss: 0.0559
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:20:06.471471: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:20:06.633043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:20:06.633088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:20:06.922837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:20:06.922887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:20:06.922896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:20:06.923148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0670
Epoch 2/80
 - 1s - loss: 0.1959
Epoch 3/80
 - 1s - loss: 0.1645
Epoch 4/80
 - 1s - loss: 0.1498
Epoch 5/80
 - 1s - loss: 0.1376
Epoch 6/80
 - 1s - loss: 0.1271
Epoch 7/80
 - 1s - loss: 0.1166
Epoch 8/80
 - 1s - loss: 0.1065
Epoch 9/80
 - 1s - loss: 0.0975
Epoch 10/80
 - 1s - loss: 0.0898
Epoch 11/80
 - 1s - loss: 0.0831
Epoch 12/80
 - 1s - loss: 0.0774
Epoch 13/80
 - 1s - loss: 0.0726
Epoch 14/80
 - 1s - loss: 0.0685
Epoch 15/80
 - 1s - loss: 0.0650
Epoch 16/80
 - 1s - loss: 0.0620
Epoch 17/80
 - 1s - loss: 0.0595
Epoch 18/80
 - 1s - loss: 0.0573
Epoch 19/80
 - 1s - loss: 0.0555
Epoch 20/80
 - 1s - loss: 0.0539
Epoch 21/80
 - 1s - loss: 0.0526
Epoch 22/80
 - 1s - loss: 0.0515
Epoch 23/80
 - 1s - loss: 0.0505
Epoch 24/80
 - 1s - loss: 0.0496
Epoch 25/80
 - 1s - loss: 0.0489
Epoch 26/80
 - 1s - loss: 0.0483
Epoch 27/80
 - 1s - loss: 0.0477
Epoch 28/80
 - 1s - loss: 0.0473
Epoch 29/80
 - 1s - loss: 0.0469
Epoch 30/80
 - 1s - loss: 0.0465
Epoch 31/80
 - 1s - loss: 0.0462
Epoch 32/80
 - 1s - loss: 0.0459
Epoch 33/80
 - 1s - loss: 0.0457
Epoch 34/80
 - 1s - loss: 0.0455
Epoch 35/80
 - 1s - loss: 0.0453
Epoch 36/80
 - 1s - loss: 0.0451
Epoch 37/80
 - 2s - loss: 0.0450
Epoch 38/80
 - 2s - loss: 0.0449
Epoch 39/80
 - 2s - loss: 0.0447
Epoch 40/80
 - 1s - loss: 0.0446
Epoch 41/80
 - 1s - loss: 0.0445
Epoch 42/80
 - 1s - loss: 0.0445
Epoch 43/80
 - 1s - loss: 0.0444
Epoch 44/80
 - 1s - loss: 0.0443
Epoch 45/80
 - 1s - loss: 0.0442
Epoch 46/80
 - 1s - loss: 0.0442
Epoch 47/80
 - 1s - loss: 0.0441
Epoch 48/80
 - 1s - loss: 0.0440
Epoch 49/80
 - 1s - loss: 0.0440
Epoch 50/80
 - 1s - loss: 0.0439
Epoch 51/80
 - 1s - loss: 0.0439
Epoch 52/80
 - 1s - loss: 0.0439
Epoch 53/80
 - 1s - loss: 0.0438
Epoch 54/80
 - 1s - loss: 0.0438
Epoch 55/80
 - 1s - loss: 0.0438
Epoch 56/80
 - 1s - loss: 0.0437
Epoch 57/80
 - 1s - loss: 0.0437
Epoch 58/80
 - 1s - loss: 0.0436
Epoch 59/80
 - 1s - loss: 0.0436
Epoch 60/80
 - 1s - loss: 0.0424
Epoch 61/80
 - 1s - loss: 0.0422
Epoch 62/80
 - 1s - loss: 0.0422
Epoch 63/80
 - 1s - loss: 0.0422
Epoch 64/80
 - 1s - loss: 0.0422
Epoch 65/80
 - 1s - loss: 0.0419
Epoch 66/80
 - 1s - loss: 0.0419
Epoch 67/80
 - 1s - loss: 0.0419
Epoch 68/80
 - 1s - loss: 0.0419
Epoch 69/80
 - 1s - loss: 0.0418
Epoch 70/80
 - 1s - loss: 0.0418
Epoch 71/80
 - 1s - loss: 0.0418
Epoch 72/80
 - 1s - loss: 0.0418
Epoch 73/80
 - 1s - loss: 0.0418
Epoch 74/80
 - 1s - loss: 0.0418
Epoch 75/80
 - 1s - loss: 0.0418
Epoch 76/80
 - 1s - loss: 0.0418
Epoch 77/80
 - 1s - loss: 0.0418
Epoch 78/80
 - 1s - loss: 0.0418
Epoch 79/80
 - 1s - loss: 0.0418
Epoch 80/80
 - 1s - loss: 0.0418
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.3207 - val_loss: 1.0904
AUC: 0.8253

Epoch 2/80
 - 0s - loss: 1.7951 - val_loss: 0.7320
AUC: 0.8420

Epoch 3/80
 - 0s - loss: 1.3499 - val_loss: 0.6771
AUC: 0.8474

Epoch 4/80
 - 0s - loss: 1.2005 - val_loss: 0.7080
AUC: 0.8569

Epoch 5/80
 - 0s - loss: 1.1520 - val_loss: 0.6647
AUC: 0.8599

Epoch 6/80
 - 0s - loss: 1.1183 - val_loss: 0.7152
AUC: 0.8640

Epoch 7/80
 - 0s - loss: 1.0980 - val_loss: 0.6318
AUC: 0.8651

Epoch 8/80
 - 0s - loss: 1.0793 - val_loss: 0.6556
AUC: 0.8666

Epoch 9/80
 - 0s - loss: 1.0849 - val_loss: 0.6183
AUC: 0.8638

Epoch 10/80
 - 0s - loss: 1.0629 - val_loss: 0.5706
AUC: 0.8671

Epoch 11/80
 - 0s - loss: 1.0525 - val_loss: 0.6834
AUC: 0.8696

Epoch 12/80
 - 0s - loss: 1.0540 - val_loss: 0.5890
AUC: 0.8679

Epoch 13/80
 - 0s - loss: 1.0476 - val_loss: 0.6542
AUC: 0.8702

Epoch 14/80
 - 0s - loss: 1.0364 - val_loss: 0.5975
AUC: 0.8686

Epoch 15/80
 - 0s - loss: 1.0286 - val_loss: 0.6225
AUC: 0.8716

Epoch 16/80
 - 0s - loss: 1.0305 - val_loss: 0.6144
AUC: 0.8710

Epoch 17/80
 - 0s - loss: 1.0174 - val_loss: 0.6737
AUC: 0.8726

Epoch 18/80
 - 0s - loss: 1.0195 - val_loss: 0.6851
AUC: 0.8732

Epoch 19/80
 - 0s - loss: 1.0220 - val_loss: 0.6541
AUC: 0.8737

Epoch 20/80
 - 0s - loss: 1.0160 - val_loss: 0.5915
AUC: 0.8720

Epoch 21/80
 - 0s - loss: 1.0025 - val_loss: 0.6106
AUC: 0.8728

Epoch 22/80
 - 0s - loss: 0.9962 - val_loss: 0.6386
AUC: 0.8734

Epoch 23/80
 - 0s - loss: 0.9954 - val_loss: 0.6319
AUC: 0.8733

Epoch 24/80
 - 0s - loss: 0.9977 - val_loss: 0.6398
AUC: 0.8736

Epoch 25/80
 - 0s - loss: 0.9999 - val_loss: 0.6193
AUC: 0.8733

Epoch 26/80
 - 0s - loss: 1.0000 - val_loss: 0.6028
AUC: 0.8733

Epoch 27/80
 - 0s - loss: 0.9954 - val_loss: 0.6107
AUC: 0.8734

Epoch 28/80
 - 0s - loss: 0.9926 - val_loss: 0.6410
AUC: 0.8742

Epoch 29/80
 - 0s - loss: 0.9925 - val_loss: 0.6180
AUC: 0.8737

Epoch 30/80
 - 0s - loss: 0.9941 - val_loss: 0.6175
AUC: 0.8737

Epoch 31/80
 - 0s - loss: 0.9907 - val_loss: 0.6071
AUC: 0.8737

Epoch 32/80
 - 0s - loss: 0.9919 - val_loss: 0.6084
AUC: 0.8738

Epoch 33/80
 - 0s - loss: 0.9921 - val_loss: 0.6085
AUC: 0.8738

Epoch 34/80
 - 0s - loss: 0.9889 - val_loss: 0.6113
AUC: 0.8738

Epoch 35/80
 - 0s - loss: 0.9867 - val_loss: 0.6003
AUC: 0.8737

Epoch 36/80
 - 0s - loss: 0.9931 - val_loss: 0.6081
AUC: 0.8738

Epoch 37/80
 - 0s - loss: 0.9939 - val_loss: 0.6102
AUC: 0.8739

Epoch 38/80
 - 0s - loss: 0.9862 - val_loss: 0.6018
AUC: 0.8738

Epoch 39/80
 - 0s - loss: 0.9867 - val_loss: 0.6071
AUC: 0.8738

Epoch 40/80
 - 0s - loss: 0.9852 - val_loss: 0.6052
AUC: 0.8737

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9897 - val_loss: 0.6012
AUC: 0.8737

Epoch 2/30
 - 0s - loss: 0.9865 - val_loss: 0.6105
AUC: 0.8742

Epoch 3/30
 - 0s - loss: 0.9943 - val_loss: 0.6184
AUC: 0.8743

Epoch 4/30
 - 0s - loss: 0.9854 - val_loss: 0.6094
AUC: 0.8742

Epoch 5/30
 - 0s - loss: 0.9845 - val_loss: 0.6008
AUC: 0.8743

Epoch 6/30
 - 0s - loss: 0.9867 - val_loss: 0.6102
AUC: 0.8746

Epoch 7/30
 - 0s - loss: 0.9849 - val_loss: 0.6039
AUC: 0.8745

Epoch 8/30
 - 0s - loss: 0.9759 - val_loss: 0.6030
AUC: 0.8746

Epoch 9/30
 - 0s - loss: 0.9756 - val_loss: 0.6014
AUC: 0.8747

Epoch 10/30
 - 0s - loss: 0.9776 - val_loss: 0.5887
AUC: 0.8745

Epoch 11/30
 - 0s - loss: 0.9738 - val_loss: 0.6254
AUC: 0.8753

Epoch 12/30
 - 0s - loss: 0.9733 - val_loss: 0.6271
AUC: 0.8755

Epoch 13/30
 - 0s - loss: 0.9758 - val_loss: 0.6148
AUC: 0.8755

Epoch 14/30
 - 0s - loss: 0.9753 - val_loss: 0.6122
AUC: 0.8755

Epoch 15/30
 - 0s - loss: 0.9698 - val_loss: 0.6002
AUC: 0.8753

Epoch 16/30
 - 0s - loss: 0.9654 - val_loss: 0.6179
AUC: 0.8755

Epoch 17/30
 - 0s - loss: 0.9684 - val_loss: 0.6053
AUC: 0.8756

Epoch 18/30
 - 0s - loss: 0.9578 - val_loss: 0.5971
AUC: 0.8757

Epoch 19/30
 - 0s - loss: 0.9593 - val_loss: 0.6000
AUC: 0.8758

Epoch 20/30
 - 0s - loss: 0.9605 - val_loss: 0.5945
AUC: 0.8759

Epoch 21/30
 - 0s - loss: 0.9624 - val_loss: 0.5926
AUC: 0.8758

Epoch 22/30
 - 0s - loss: 0.9615 - val_loss: 0.5940
AUC: 0.8759

Epoch 23/30
 - 0s - loss: 0.9622 - val_loss: 0.5940
AUC: 0.8759

Epoch 24/30
 - 0s - loss: 0.9594 - val_loss: 0.5955
AUC: 0.8759

Epoch 25/30
 - 0s - loss: 0.9551 - val_loss: 0.5994
AUC: 0.8761

Epoch 26/30
 - 0s - loss: 0.9580 - val_loss: 0.5924
AUC: 0.8759

Epoch 27/30
 - 0s - loss: 0.9634 - val_loss: 0.5922
AUC: 0.8759

Epoch 28/30
 - 0s - loss: 0.9571 - val_loss: 0.5892
AUC: 0.8759

Epoch 29/30
 - 0s - loss: 0.9546 - val_loss: 0.5978
AUC: 0.8761

Epoch 30/30
 - 0s - loss: 0.9592 - val_loss: 0.5973
Using TensorFlow backend.
AUC: 0.8760

2019-03-08 07:23:17.865770: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:23:18.029375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:23:18.029418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:23:18.316526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:23:18.316577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:23:18.316585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:23:18.316839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0831
Epoch 2/80
 - 2s - loss: 0.1969
Epoch 3/80
 - 2s - loss: 0.1665
Epoch 4/80
 - 1s - loss: 0.1535
Epoch 5/80
 - 1s - loss: 0.1402
Epoch 6/80
 - 1s - loss: 0.1282
Epoch 7/80
 - 2s - loss: 0.1175
Epoch 8/80
 - 1s - loss: 0.1078
Epoch 9/80
 - 1s - loss: 0.0985
Epoch 10/80
 - 1s - loss: 0.0901
Epoch 11/80
 - 2s - loss: 0.0830
Epoch 12/80
 - 1s - loss: 0.0771
Epoch 13/80
 - 1s - loss: 0.0724
Epoch 14/80
 - 2s - loss: 0.0683
Epoch 15/80
 - 1s - loss: 0.0649
Epoch 16/80
 - 1s - loss: 0.0620
Epoch 17/80
 - 1s - loss: 0.0595
Epoch 18/80
 - 2s - loss: 0.0573
Epoch 19/80
 - 2s - loss: 0.0555
Epoch 20/80
 - 1s - loss: 0.0540
Epoch 21/80
 - 1s - loss: 0.0526
Epoch 22/80
 - 1s - loss: 0.0514
Epoch 23/80
 - 2s - loss: 0.0504
Epoch 24/80
 - 2s - loss: 0.0496
Epoch 25/80
 - 1s - loss: 0.0488
Epoch 26/80
 - 2s - loss: 0.0482
Epoch 27/80
 - 2s - loss: 0.0476
Epoch 28/80
 - 2s - loss: 0.0471
Epoch 29/80
 - 2s - loss: 0.0467
Epoch 30/80
 - 2s - loss: 0.0464
Epoch 31/80
 - 2s - loss: 0.0460
Epoch 32/80
 - 1s - loss: 0.0458
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:24:32.014027: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:24:32.174053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:24:32.174096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:24:32.462585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:24:32.462637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:24:32.462646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:24:32.462899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6512
Epoch 2/80
 - 2s - loss: 0.1037
Epoch 3/80
 - 1s - loss: 0.0688
Epoch 4/80
 - 1s - loss: 0.0616
Epoch 5/80
 - 2s - loss: 0.0564
Epoch 6/80
 - 1s - loss: 0.0522
Epoch 7/80
 - 1s - loss: 0.0486
Epoch 8/80
 - 1s - loss: 0.0454
Epoch 9/80
 - 1s - loss: 0.0422
Epoch 10/80
 - 2s - loss: 0.0389
Epoch 11/80
 - 1s - loss: 0.0357
Epoch 12/80
 - 1s - loss: 0.0328
Epoch 13/80
 - 1s - loss: 0.0303
Epoch 14/80
 - 1s - loss: 0.0280
Epoch 15/80
 - 1s - loss: 0.0261
Epoch 16/80
 - 1s - loss: 0.0244
Epoch 17/80
 - 1s - loss: 0.0230
Epoch 18/80
 - 1s - loss: 0.0218
Epoch 19/80
 - 1s - loss: 0.0208
Epoch 20/80
 - 1s - loss: 0.0199
Epoch 21/80
 - 1s - loss: 0.0192
Epoch 22/80
 - 1s - loss: 0.0185
Epoch 23/80
 - 1s - loss: 0.0180
Epoch 24/80
 - 1s - loss: 0.0175
Epoch 25/80
 - 1s - loss: 0.0171
Epoch 26/80
 - 1s - loss: 0.0167
Epoch 27/80
 - 1s - loss: 0.0164
Epoch 28/80
 - 1s - loss: 0.0162
Epoch 29/80
 - 1s - loss: 0.0159
Epoch 30/80
 - 1s - loss: 0.0157
Epoch 31/80
 - 1s - loss: 0.0155
Epoch 32/80
 - 1s - loss: 0.0154
Epoch 33/80
 - 1s - loss: 0.0152
Epoch 34/80
 - 1s - loss: 0.0151
Epoch 35/80
 - 1s - loss: 0.0150
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:25:50.321185: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:25:50.482900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:25:50.482944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:25:50.770277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:25:50.770330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:25:50.770340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:25:50.770646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6438
Epoch 2/80
 - 1s - loss: 0.0984
Epoch 3/80
 - 1s - loss: 0.0690
Epoch 4/80
 - 1s - loss: 0.0650
Epoch 5/80
 - 1s - loss: 0.0629
Epoch 6/80
 - 1s - loss: 0.0604
Epoch 7/80
 - 1s - loss: 0.0573
Epoch 8/80
 - 1s - loss: 0.0533
Epoch 9/80
 - 1s - loss: 0.0484
Epoch 10/80
 - 1s - loss: 0.0431
Epoch 11/80
 - 1s - loss: 0.0383
Epoch 12/80
 - 1s - loss: 0.0343
Epoch 13/80
 - 1s - loss: 0.0312
Epoch 14/80
 - 1s - loss: 0.0287
Epoch 15/80
 - 1s - loss: 0.0266
Epoch 16/80
 - 1s - loss: 0.0248
Epoch 17/80
 - 1s - loss: 0.0233
Epoch 18/80
 - 1s - loss: 0.0220
Epoch 19/80
 - 1s - loss: 0.0209
Epoch 20/80
 - 1s - loss: 0.0200
Epoch 21/80
 - 1s - loss: 0.0192
Epoch 22/80
 - 1s - loss: 0.0186
Epoch 23/80
 - 1s - loss: 0.0180
Epoch 24/80
 - 1s - loss: 0.0175
Epoch 25/80
 - 1s - loss: 0.0171
Epoch 26/80
 - 1s - loss: 0.0168
Epoch 27/80
 - 1s - loss: 0.0165
Epoch 28/80
 - 1s - loss: 0.0162
Epoch 29/80
 - 1s - loss: 0.0160
Epoch 30/80
 - 1s - loss: 0.0158
Epoch 31/80
 - 1s - loss: 0.0156
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:27:01.655011: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:27:01.818019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:27:01.818052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:27:02.126117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:27:02.126185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:27:02.126195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:27:02.126448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6491
Epoch 2/80
 - 2s - loss: 0.1012
Epoch 3/80
 - 2s - loss: 0.0682
Epoch 4/80
 - 2s - loss: 0.0620
Epoch 5/80
 - 2s - loss: 0.0575
Epoch 6/80
 - 2s - loss: 0.0530
Epoch 7/80
 - 2s - loss: 0.0488
Epoch 8/80
 - 2s - loss: 0.0452
Epoch 9/80
 - 2s - loss: 0.0419
Epoch 10/80
 - 2s - loss: 0.0388
Epoch 11/80
 - 2s - loss: 0.0356
Epoch 12/80
 - 2s - loss: 0.0326
Epoch 13/80
 - 2s - loss: 0.0301
Epoch 14/80
 - 2s - loss: 0.0278
Epoch 15/80
 - 2s - loss: 0.0259
Epoch 16/80
 - 2s - loss: 0.0243
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:27:46.072380: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:27:46.235356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:27:46.235400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:27:46.524627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:27:46.524676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:27:46.524685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:27:46.524937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2855
Epoch 2/80
 - 1s - loss: 0.3334
Epoch 3/80
 - 1s - loss: 0.3046
Epoch 4/80
 - 1s - loss: 0.2858
Epoch 5/80
 - 1s - loss: 0.2603
Epoch 6/80
 - 1s - loss: 0.2349
Epoch 7/80
 - 1s - loss: 0.2130
Epoch 8/80
 - 1s - loss: 0.1944
Epoch 9/80
 - 1s - loss: 0.1791
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:28:24.064539: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:28:24.225441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:28:24.225490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:28:24.516038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:28:24.516088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:28:24.516097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:28:24.516358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2834
Epoch 2/80
 - 2s - loss: 0.3320
Epoch 3/80
 - 2s - loss: 0.2927
Epoch 4/80
 - 2s - loss: 0.2636
Epoch 5/80
 - 2s - loss: 0.2386
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:28:51.247185: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:28:51.410082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:28:51.410124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:28:51.702452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:28:51.702502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:28:51.702511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:28:51.702763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3311
Epoch 2/80
 - 1s - loss: 0.3327
Epoch 3/80
 - 1s - loss: 0.2901
Epoch 4/80
 - 1s - loss: 0.2614
Epoch 5/80
 - 2s - loss: 0.2403
Epoch 6/80
 - 2s - loss: 0.2226
Epoch 7/80
 - 2s - loss: 0.2057
Epoch 8/80
 - 1s - loss: 0.1899
Epoch 9/80
 - 2s - loss: 0.1757
Epoch 10/80
 - 1s - loss: 0.1639
Epoch 11/80
 - 1s - loss: 0.1545
Epoch 12/80
 - 1s - loss: 0.1470
Epoch 13/80
 - 1s - loss: 0.1408
Epoch 14/80
 - 2s - loss: 0.1353
Epoch 15/80
 - 2s - loss: 0.1307
Epoch 16/80
 - 1s - loss: 0.1268
Epoch 17/80
 - 1s - loss: 0.1235
Epoch 18/80
 - 1s - loss: 0.1207
Epoch 19/80
 - 1s - loss: 0.1183
Epoch 20/80
 - 1s - loss: 0.1162
Epoch 21/80
 - 1s - loss: 0.1144
Epoch 22/80
 - 1s - loss: 0.1128
Epoch 23/80
 - 1s - loss: 0.1114
Epoch 24/80
 - 1s - loss: 0.1102
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:29:52.287045: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:29:52.449084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:29:52.449132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:29:52.740430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:29:52.740495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:29:52.740504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:29:52.740935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2971
Epoch 2/80
 - 2s - loss: 0.3306
Epoch 3/80
 - 2s - loss: 0.2889
Epoch 4/80
 - 2s - loss: 0.2583
Epoch 5/80
 - 2s - loss: 0.2359
Epoch 6/80
 - 2s - loss: 0.2196
Epoch 7/80
 - 2s - loss: 0.2052
Epoch 8/80
 - 2s - loss: 0.1911
Epoch 9/80
 - 2s - loss: 0.1779
Epoch 10/80
 - 2s - loss: 0.1663
Epoch 11/80
 - 2s - loss: 0.1564
Epoch 12/80
 - 2s - loss: 0.1478
Epoch 13/80
 - 2s - loss: 0.1406
Epoch 14/80
 - 2s - loss: 0.1346
Epoch 15/80
 - 2s - loss: 0.1300
Epoch 16/80
 - 2s - loss: 0.1261
Epoch 17/80
 - 2s - loss: 0.1229
Epoch 18/80
 - 2s - loss: 0.1202
Epoch 19/80
 - 2s - loss: 0.1179
Epoch 20/80
 - 1s - loss: 0.1159
Epoch 21/80
 - 2s - loss: 0.1142
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:30:44.529745: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:30:44.691348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:30:44.691392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:30:44.979030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:30:44.979079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:30:44.979088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:30:44.979351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0705
Epoch 2/80
 - 1s - loss: 0.1940
Epoch 3/80
 - 1s - loss: 0.1683
Epoch 4/80
 - 1s - loss: 0.1582
Epoch 5/80
 - 1s - loss: 0.1456
Epoch 6/80
 - 1s - loss: 0.1304
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:31:18.198084: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:31:18.359623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:31:18.359686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:31:18.649073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:31:18.649124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:31:18.649134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:31:18.649393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0917
Epoch 2/80
 - 1s - loss: 0.1973
Epoch 3/80
 - 1s - loss: 0.1699
Epoch 4/80
 - 1s - loss: 0.1603
Epoch 5/80
 - 1s - loss: 0.1473
Epoch 6/80
 - 1s - loss: 0.1323
Epoch 7/80
 - 1s - loss: 0.1184
Epoch 8/80
 - 1s - loss: 0.1065
Epoch 9/80
 - 1s - loss: 0.0965
Epoch 10/80
 - 1s - loss: 0.0883
Epoch 11/80
 - 1s - loss: 0.0819
Epoch 12/80
 - 1s - loss: 0.0767
Epoch 13/80
 - 1s - loss: 0.0723
Epoch 14/80
 - 1s - loss: 0.0684
Epoch 15/80
 - 1s - loss: 0.0651
Epoch 16/80
 - 1s - loss: 0.0622
Epoch 17/80
 - 1s - loss: 0.0598
Epoch 18/80
 - 1s - loss: 0.0576
Epoch 19/80
 - 1s - loss: 0.0559
Epoch 20/80
 - 1s - loss: 0.0543
Epoch 21/80
 - 1s - loss: 0.0530
Epoch 22/80
 - 2s - loss: 0.0519
Epoch 23/80
 - 1s - loss: 0.0509
Epoch 24/80
 - 1s - loss: 0.0500
Epoch 25/80
 - 1s - loss: 0.0493
Epoch 26/80
 - 1s - loss: 0.0486
Epoch 27/80
 - 1s - loss: 0.0481
Epoch 28/80
 - 1s - loss: 0.0476
Epoch 29/80
 - 1s - loss: 0.0472
Epoch 30/80
 - 1s - loss: 0.0468
Epoch 31/80
 - 1s - loss: 0.0465
Epoch 32/80
 - 1s - loss: 0.0462
Epoch 33/80
 - 1s - loss: 0.0459
Epoch 34/80
 - 1s - loss: 0.0457
Epoch 35/80
 - 1s - loss: 0.0455
Epoch 36/80
 - 1s - loss: 0.0454
Epoch 37/80
 - 1s - loss: 0.0452
Epoch 38/80
 - 1s - loss: 0.0451
Epoch 39/80
 - 1s - loss: 0.0449
Epoch 40/80
 - 1s - loss: 0.0448
Epoch 41/80
 - 1s - loss: 0.0447
Epoch 42/80
 - 1s - loss: 0.0446
Epoch 43/80
 - 1s - loss: 0.0445
Epoch 44/80
 - 1s - loss: 0.0445
Epoch 45/80
 - 1s - loss: 0.0444
Epoch 46/80
 - 1s - loss: 0.0443
Epoch 47/80
 - 1s - loss: 0.0443
Epoch 48/80
 - 1s - loss: 0.0442
Epoch 49/80
 - 1s - loss: 0.0441
Epoch 50/80
 - 1s - loss: 0.0441
Epoch 51/80
 - 1s - loss: 0.0440
Epoch 52/80
 - 1s - loss: 0.0440
Epoch 53/80
 - 1s - loss: 0.0439
Epoch 54/80
 - 1s - loss: 0.0439
Epoch 55/80
 - 1s - loss: 0.0439
Epoch 56/80
 - 1s - loss: 0.0438
Epoch 57/80
 - 1s - loss: 0.0438
Epoch 58/80
 - 1s - loss: 0.0438
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 07:33:11.194192: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:33:11.358742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:33:11.358787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:33:11.648557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:33:11.648609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:33:11.648618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:33:11.648869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0585
Epoch 2/80
 - 2s - loss: 0.1949
Epoch 3/80
 - 2s - loss: 0.1635
Epoch 4/80
 - 2s - loss: 0.1443
Epoch 5/80
 - 2s - loss: 0.1293
Epoch 6/80
 - 2s - loss: 0.1195
Epoch 7/80
 - 2s - loss: 0.1119
Epoch 8/80
 - 2s - loss: 0.1049
Epoch 9/80
 - 2s - loss: 0.0979
Epoch 10/80
 - 2s - loss: 0.0909
Epoch 11/80
 - 2s - loss: 0.0845
Epoch 12/80
 - 2s - loss: 0.0787
Epoch 13/80
 - 2s - loss: 0.0736
Epoch 14/80
 - 2s - loss: 0.0693
Epoch 15/80
 - 2s - loss: 0.0658
Epoch 16/80
 - 2s - loss: 0.0628
Epoch 17/80
 - 2s - loss: 0.0603
Epoch 18/80
 - 2s - loss: 0.0581
Epoch 19/80
 - 2s - loss: 0.0562
Epoch 20/80
 - 2s - loss: 0.0546
Epoch 21/80
 - 2s - loss: 0.0532
Epoch 22/80
 - 2s - loss: 0.0519
Epoch 23/80
 - 2s - loss: 0.0509
Epoch 24/80
 - 2s - loss: 0.0499
Epoch 25/80
 - 2s - loss: 0.0491
Epoch 26/80
 - 2s - loss: 0.0485
Epoch 27/80
 - 2s - loss: 0.0479
Epoch 28/80
 - 2s - loss: 0.0474
Epoch 29/80
 - 2s - loss: 0.0469
Epoch 30/80
 - 2s - loss: 0.0466
Epoch 31/80
 - 2s - loss: 0.0462
Epoch 32/80
 - 2s - loss: 0.0459
Epoch 33/80
 - 2s - loss: 0.0457
Epoch 34/80
 - 2s - loss: 0.0455
Epoch 35/80
 - 2s - loss: 0.0453
Epoch 36/80
 - 2s - loss: 0.0451
Epoch 37/80
 - 2s - loss: 0.0449
Epoch 38/80
 - 2s - loss: 0.0448
Epoch 39/80
 - 2s - loss: 0.0446
Epoch 40/80
 - 2s - loss: 0.0445
Epoch 41/80
 - 2s - loss: 0.0444
Epoch 42/80
 - 2s - loss: 0.0443
Epoch 43/80
 - 2s - loss: 0.0443
Epoch 44/80
 - 2s - loss: 0.0442
Epoch 45/80
 - 2s - loss: 0.0441
Epoch 46/80
 - 2s - loss: 0.0440
Epoch 47/80
 - 2s - loss: 0.0440
Epoch 48/80
 - 2s - loss: 0.0439
Epoch 49/80
 - 2s - loss: 0.0438
Epoch 50/80
 - 2s - loss: 0.0438
Epoch 51/80
 - 2s - loss: 0.0437
Epoch 52/80
 - 2s - loss: 0.0437
Epoch 53/80
 - 2s - loss: 0.0436
Epoch 54/80
 - 2s - loss: 0.0436
Epoch 55/80
 - 2s - loss: 0.0436
Epoch 56/80
 - 2s - loss: 0.0435
Epoch 57/80
 - 2s - loss: 0.0423
Epoch 58/80
 - 2s - loss: 0.0421
Epoch 59/80
 - 2s - loss: 0.0421
Epoch 60/80
 - 2s - loss: 0.0421
Epoch 61/80
 - 2s - loss: 0.0421
Epoch 62/80
 - 2s - loss: 0.0418
Epoch 63/80
 - 2s - loss: 0.0418
Epoch 64/80
 - 2s - loss: 0.0418
Epoch 65/80
 - 2s - loss: 0.0418
Epoch 66/80
 - 2s - loss: 0.0417
Epoch 67/80
 - 2s - loss: 0.0417
Epoch 68/80
 - 2s - loss: 0.0417
Epoch 69/80
 - 2s - loss: 0.0417
Epoch 70/80
 - 2s - loss: 0.0417
Epoch 71/80
 - 2s - loss: 0.0417
Epoch 72/80
 - 2s - loss: 0.0417
Epoch 73/80
 - 2s - loss: 0.0417
Epoch 74/80
 - 2s - loss: 0.0417
Epoch 75/80
 - 2s - loss: 0.0417
Epoch 76/80
 - 2s - loss: 0.0417
Epoch 77/80
 - 2s - loss: 0.0417
Epoch 78/80
 - 2s - loss: 0.0417
Epoch 79/80
 - 2s - loss: 0.0417
Epoch 80/80
 - 2s - loss: 0.0417
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 7.9555 - val_loss: 1.8363
AUC: 0.7552

Epoch 2/80
 - 0s - loss: 2.7171 - val_loss: 1.0425
AUC: 0.8093

Epoch 3/80
 - 0s - loss: 1.7648 - val_loss: 0.6431
AUC: 0.8354

Epoch 4/80
 - 0s - loss: 1.3229 - val_loss: 0.6791
AUC: 0.8478

Epoch 5/80
 - 0s - loss: 1.1927 - val_loss: 0.6734
AUC: 0.8526

Epoch 6/80
 - 0s - loss: 1.1388 - val_loss: 0.6726
AUC: 0.8546

Epoch 7/80
 - 0s - loss: 1.1098 - val_loss: 0.5854
AUC: 0.8572

Epoch 8/80
 - 0s - loss: 1.0862 - val_loss: 0.7226
AUC: 0.8616

Epoch 9/80
 - 0s - loss: 1.0724 - val_loss: 0.5791
AUC: 0.8606

Epoch 10/80
 - 0s - loss: 1.0569 - val_loss: 0.6581
AUC: 0.8650

Epoch 11/80
 - 0s - loss: 1.0460 - val_loss: 0.6159
AUC: 0.8647

Epoch 12/80
 - 0s - loss: 1.0403 - val_loss: 0.5970
AUC: 0.8617

Epoch 13/80
 - 0s - loss: 1.0327 - val_loss: 0.6354
AUC: 0.8680

Epoch 14/80
 - 0s - loss: 1.0250 - val_loss: 0.6106
AUC: 0.8667

Epoch 15/80
 - 0s - loss: 1.0201 - val_loss: 0.6713
AUC: 0.8678

Epoch 16/80
 - 0s - loss: 1.0199 - val_loss: 0.5985
AUC: 0.8684

Epoch 17/80
 - 0s - loss: 1.0069 - val_loss: 0.6319
AUC: 0.8687

Epoch 18/80
 - 0s - loss: 1.0061 - val_loss: 0.5615
AUC: 0.8692

Epoch 19/80
 - 0s - loss: 1.0003 - val_loss: 0.5454
AUC: 0.8681

Epoch 20/80
 - 0s - loss: 1.0025 - val_loss: 0.5823
AUC: 0.8701

Epoch 21/80
 - 0s - loss: 0.9941 - val_loss: 0.6429
AUC: 0.8708

Epoch 22/80
 - 0s - loss: 0.9877 - val_loss: 0.6394
AUC: 0.8709

Epoch 23/80
 - 0s - loss: 0.9879 - val_loss: 0.5777
AUC: 0.8705

Epoch 24/80
 - 0s - loss: 0.9804 - val_loss: 0.5731
AUC: 0.8699

Epoch 25/80
 - 0s - loss: 0.9807 - val_loss: 0.5430
AUC: 0.8716

Epoch 26/80
 - 0s - loss: 0.9787 - val_loss: 0.6402
AUC: 0.8731

Epoch 27/80
 - 0s - loss: 0.9714 - val_loss: 0.6098
AUC: 0.8727

Epoch 28/80
 - 0s - loss: 0.9694 - val_loss: 0.6006
AUC: 0.8720

Epoch 29/80
 - 0s - loss: 0.9688 - val_loss: 0.6119
AUC: 0.8731

Epoch 30/80
 - 0s - loss: 0.9590 - val_loss: 0.6410
AUC: 0.8729

Epoch 31/80
 - 0s - loss: 0.9612 - val_loss: 0.6260
AUC: 0.8738

Epoch 32/80
 - 0s - loss: 0.9494 - val_loss: 0.6531
AUC: 0.8749

Epoch 33/80
 - 0s - loss: 0.9581 - val_loss: 0.6025
AUC: 0.8739

Epoch 34/80
 - 0s - loss: 0.9585 - val_loss: 0.6298
AUC: 0.8743

Epoch 35/80
 - 0s - loss: 0.9470 - val_loss: 0.6019
AUC: 0.8741

Epoch 36/80
 - 0s - loss: 0.9320 - val_loss: 0.5790
AUC: 0.8750

Epoch 37/80
 - 0s - loss: 0.9381 - val_loss: 0.5703
AUC: 0.8747

Epoch 38/80
 - 0s - loss: 0.9365 - val_loss: 0.5612
AUC: 0.8744

Epoch 39/80
 - 0s - loss: 0.9274 - val_loss: 0.5908
AUC: 0.8750

Epoch 40/80
 - 0s - loss: 0.9307 - val_loss: 0.5633
AUC: 0.8749

Epoch 41/80
 - 0s - loss: 0.9328 - val_loss: 0.5878
AUC: 0.8752

Epoch 42/80
 - 0s - loss: 0.9221 - val_loss: 0.5540
AUC: 0.8748

Epoch 43/80
 - 0s - loss: 0.9325 - val_loss: 0.6049
AUC: 0.8756

Epoch 44/80
 - 0s - loss: 0.9304 - val_loss: 0.5894
AUC: 0.8756

Epoch 45/80
 - 0s - loss: 0.9236 - val_loss: 0.6017
AUC: 0.8755

Epoch 46/80
 - 0s - loss: 0.9239 - val_loss: 0.5775
AUC: 0.8753

Epoch 47/80
 - 0s - loss: 0.9231 - val_loss: 0.5710
AUC: 0.8753

Epoch 48/80
 - 0s - loss: 0.9145 - val_loss: 0.5769
AUC: 0.8754

Epoch 49/80
 - 0s - loss: 0.9217 - val_loss: 0.5687
AUC: 0.8753

Epoch 50/80
 - 0s - loss: 0.9259 - val_loss: 0.5767
AUC: 0.8754

Epoch 51/80
 - 0s - loss: 0.9194 - val_loss: 0.5719
AUC: 0.8754

Epoch 52/80
 - 0s - loss: 0.9165 - val_loss: 0.5736
AUC: 0.8754

Epoch 53/80
 - 0s - loss: 0.9227 - val_loss: 0.5832
AUC: 0.8756

Epoch 54/80
 - 0s - loss: 0.9190 - val_loss: 0.5678
AUC: 0.8753

Epoch 55/80
 - 0s - loss: 0.9198 - val_loss: 0.5769
AUC: 0.8755

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9269 - val_loss: 0.5665
AUC: 0.8755

Epoch 2/30
 - 0s - loss: 0.9172 - val_loss: 0.5851
AUC: 0.8757

Epoch 3/30
 - 0s - loss: 0.9195 - val_loss: 0.5603
AUC: 0.8755

Epoch 4/30
 - 0s - loss: 0.9175 - val_loss: 0.5770
AUC: 0.8758

Epoch 5/30
 - 0s - loss: 0.9224 - val_loss: 0.5716
AUC: 0.8758

Epoch 6/30
 - 0s - loss: 0.9169 - val_loss: 0.5858
AUC: 0.8762

Epoch 7/30
 - 0s - loss: 0.9132 - val_loss: 0.5640
AUC: 0.8758

Epoch 8/30
 - 0s - loss: 0.9134 - val_loss: 0.5607
AUC: 0.8760

Epoch 9/30
 - 0s - loss: 0.9137 - val_loss: 0.5736
AUC: 0.8762

Epoch 10/30
 - 0s - loss: 0.9070 - val_loss: 0.5688
AUC: 0.8761

Epoch 11/30
 - 0s - loss: 0.9126 - val_loss: 0.5574
AUC: 0.8758

Epoch 12/30
 - 0s - loss: 0.9116 - val_loss: 0.5662
AUC: 0.8762

Epoch 13/30
 - 0s - loss: 0.9095 - val_loss: 0.5700
AUC: 0.8765

Epoch 14/30
 - 0s - loss: 0.9026 - val_loss: 0.5804
AUC: 0.8767

Epoch 15/30
 - 0s - loss: 0.9044 - val_loss: 0.5719
AUC: 0.8766

Epoch 16/30
 - 0s - loss: 0.8969 - val_loss: 0.5653
AUC: 0.8766

Epoch 17/30
 - 0s - loss: 0.9034 - val_loss: 0.5595
AUC: 0.8766

Epoch 18/30
 - 0s - loss: 0.8957 - val_loss: 0.5585
AUC: 0.8768

Epoch 19/30
 - 0s - loss: 0.8971 - val_loss: 0.5718
AUC: 0.8769

Epoch 20/30
 - 0s - loss: 0.8953 - val_loss: 0.5624
AUC: 0.8768

Epoch 21/30
 - 0s - loss: 0.8951 - val_loss: 0.5690
AUC: 0.8769

Epoch 22/30
 - 0s - loss: 0.8898 - val_loss: 0.5660
AUC: 0.8769

Epoch 23/30
 - 0s - loss: 0.8932 - val_loss: 0.5682
AUC: 0.8770

Epoch 24/30
 - 0s - loss: 0.8904 - val_loss: 0.5669
AUC: 0.8770

Epoch 25/30
 - 0s - loss: 0.8913 - val_loss: 0.5657
AUC: 0.8770

Epoch 26/30
 - 0s - loss: 0.8877 - val_loss: 0.5689
AUC: 0.8770

Epoch 27/30
 - 0s - loss: 0.8939 - val_loss: 0.5694
AUC: 0.8771

Epoch 28/30
 - 0s - loss: 0.8890 - val_loss: 0.5638
AUC: 0.8770

Epoch 29/30
 - 0s - loss: 0.8903 - val_loss: 0.5665
AUC: 0.8770

Epoch 30/30
 - 0s - loss: 0.8826 - val_loss: 0.5575
Using TensorFlow backend.
AUC: 0.8768

2019-03-08 07:36:38.085733: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:36:38.249046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:36:38.249090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:36:38.539536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:36:38.539587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:36:38.539596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:36:38.539855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6373
Epoch 2/80
 - 2s - loss: 0.0985
Epoch 3/80
 - 2s - loss: 0.0695
Epoch 4/80
 - 2s - loss: 0.0657
Epoch 5/80
 - 2s - loss: 0.0639
Epoch 6/80
 - 2s - loss: 0.0618
Epoch 7/80
 - 2s - loss: 0.0588
Epoch 8/80
 - 1s - loss: 0.0548
Epoch 9/80
 - 2s - loss: 0.0498
Epoch 10/80
 - 1s - loss: 0.0443
Epoch 11/80
 - 2s - loss: 0.0392
Epoch 12/80
 - 1s - loss: 0.0349
Epoch 13/80
 - 2s - loss: 0.0314
Epoch 14/80
 - 2s - loss: 0.0287
Epoch 15/80
 - 2s - loss: 0.0264
Epoch 16/80
 - 2s - loss: 0.0245
Epoch 17/80
 - 2s - loss: 0.0229
Epoch 18/80
 - 2s - loss: 0.0217
Epoch 19/80
 - 1s - loss: 0.0206
Epoch 20/80
 - 2s - loss: 0.0197
Epoch 21/80
 - 1s - loss: 0.0190
Epoch 22/80
 - 1s - loss: 0.0184
Epoch 23/80
 - 2s - loss: 0.0178
Epoch 24/80
 - 2s - loss: 0.0174
Epoch 25/80
 - 1s - loss: 0.0170
Epoch 26/80
 - 2s - loss: 0.0166
Epoch 27/80
 - 2s - loss: 0.0163
Epoch 28/80
 - 2s - loss: 0.0161
Epoch 29/80
 - 1s - loss: 0.0158
Epoch 30/80
 - 2s - loss: 0.0156
Epoch 31/80
 - 2s - loss: 0.0155
Epoch 32/80
 - 2s - loss: 0.0153
Epoch 33/80
 - 1s - loss: 0.0152
Epoch 34/80
 - 1s - loss: 0.0151
Epoch 35/80
 - 2s - loss: 0.0150
Epoch 36/80
 - 1s - loss: 0.0149
Epoch 37/80
 - 2s - loss: 0.0148
Epoch 38/80
 - 1s - loss: 0.0147
Epoch 39/80
 - 1s - loss: 0.0146
Epoch 40/80
 - 1s - loss: 0.0146
Epoch 41/80
 - 1s - loss: 0.0145
Epoch 42/80
 - 1s - loss: 0.0145
Epoch 43/80
 - 1s - loss: 0.0144
Epoch 44/80
 - 1s - loss: 0.0144
Epoch 45/80
 - 1s - loss: 0.0143
Epoch 46/80
 - 1s - loss: 0.0143
Epoch 47/80
 - 1s - loss: 0.0143
Epoch 48/80
 - 1s - loss: 0.0142
Epoch 49/80
 - 1s - loss: 0.0142
Epoch 50/80
 - 1s - loss: 0.0142
Epoch 51/80
 - 1s - loss: 0.0137
Epoch 52/80
 - 2s - loss: 0.0137
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 1s - loss: 0.0137
Epoch 55/80
 - 2s - loss: 0.0136
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 1s - loss: 0.0135
Epoch 60/80
 - 1s - loss: 0.0135
Epoch 61/80
 - 1s - loss: 0.0135
Epoch 62/80
 - 2s - loss: 0.0135
Epoch 63/80
 - 1s - loss: 0.0135
Epoch 64/80
 - 2s - loss: 0.0135
Epoch 65/80
 - 1s - loss: 0.0135
Epoch 66/80
 - 2s - loss: 0.0135
Epoch 67/80
 - 1s - loss: 0.0135
Epoch 68/80
 - 1s - loss: 0.0135
Epoch 69/80
 - 1s - loss: 0.0135
Epoch 70/80
 - 1s - loss: 0.0135
Epoch 71/80
 - 1s - loss: 0.0135
Epoch 72/80
 - 2s - loss: 0.0135
Epoch 73/80
 - 1s - loss: 0.0135
Epoch 74/80
 - 2s - loss: 0.0135
Epoch 75/80
 - 2s - loss: 0.0135
Epoch 76/80
 - 2s - loss: 0.0135
Epoch 77/80
 - 2s - loss: 0.0135
Epoch 78/80
 - 2s - loss: 0.0135
Epoch 79/80
 - 1s - loss: 0.0135
Epoch 80/80
 - 1s - loss: 0.0135
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.4671 - val_loss: 0.7359
AUC: 0.8113

Epoch 2/80
 - 0s - loss: 1.3624 - val_loss: 0.6873
AUC: 0.8353

Epoch 3/80
 - 0s - loss: 1.1627 - val_loss: 0.6578
AUC: 0.8444

Epoch 4/80
 - 0s - loss: 1.1123 - val_loss: 0.6558
AUC: 0.8481

Epoch 5/80
 - 0s - loss: 1.0885 - val_loss: 0.6210
AUC: 0.8484

Epoch 6/80
 - 0s - loss: 1.0727 - val_loss: 0.7180
AUC: 0.8552

Epoch 7/80
 - 0s - loss: 1.0590 - val_loss: 0.6520
AUC: 0.8552

Epoch 8/80
 - 0s - loss: 1.0429 - val_loss: 0.6191
AUC: 0.8553

Epoch 9/80
 - 0s - loss: 1.0275 - val_loss: 0.6082
AUC: 0.8568

Epoch 10/80
 - 0s - loss: 1.0310 - val_loss: 0.7026
AUC: 0.8598

Epoch 11/80
 - 0s - loss: 1.0132 - val_loss: 0.6492
AUC: 0.8603

Epoch 12/80
 - 0s - loss: 1.0106 - val_loss: 0.6997
AUC: 0.8609

Epoch 13/80
 - 0s - loss: 1.0169 - val_loss: 0.6115
AUC: 0.8606

Epoch 14/80
 - 0s - loss: 1.0053 - val_loss: 0.6332
AUC: 0.8602

Epoch 15/80
 - 0s - loss: 0.9919 - val_loss: 0.6617
AUC: 0.8626

Epoch 16/80
 - 0s - loss: 0.9909 - val_loss: 0.6040
AUC: 0.8599

Epoch 17/80
 - 0s - loss: 0.9897 - val_loss: 0.6223
AUC: 0.8626

Epoch 18/80
 - 0s - loss: 0.9828 - val_loss: 0.6193
AUC: 0.8629

Epoch 19/80
 - 0s - loss: 0.9845 - val_loss: 0.6112
AUC: 0.8637

Epoch 20/80
 - 0s - loss: 0.9728 - val_loss: 0.6825
AUC: 0.8638

Epoch 21/80
 - 0s - loss: 0.9727 - val_loss: 0.5696
AUC: 0.8612

Epoch 22/80
 - 0s - loss: 0.9809 - val_loss: 0.6996
AUC: 0.8634

Epoch 23/80
 - 0s - loss: 0.9691 - val_loss: 0.5743
AUC: 0.8620

Epoch 24/80
 - 0s - loss: 0.9634 - val_loss: 0.6725
AUC: 0.8650

Epoch 25/80
 - 0s - loss: 0.9643 - val_loss: 0.6644
AUC: 0.8644

Epoch 26/80
 - 0s - loss: 0.9582 - val_loss: 0.5552
AUC: 0.8615

Epoch 27/80
 - 0s - loss: 0.9530 - val_loss: 0.6367
AUC: 0.8649

Epoch 28/80
 - 0s - loss: 0.9526 - val_loss: 0.6644
AUC: 0.8658

Epoch 29/80
 - 0s - loss: 0.9566 - val_loss: 0.6116
AUC: 0.8658

Epoch 30/80
 - 0s - loss: 0.9499 - val_loss: 0.5535
AUC: 0.8597

Epoch 31/80
 - 0s - loss: 0.9518 - val_loss: 0.5625
AUC: 0.8627

Epoch 32/80
 - 0s - loss: 0.9412 - val_loss: 0.6040
AUC: 0.8643

Epoch 33/80
 - 0s - loss: 0.9451 - val_loss: 0.6186
AUC: 0.8636

Epoch 34/80
 - 0s - loss: 0.9430 - val_loss: 0.6987
AUC: 0.8661

Epoch 35/80
 - 0s - loss: 0.9386 - val_loss: 0.6250
AUC: 0.8627

Epoch 36/80
 - 0s - loss: 0.9318 - val_loss: 0.5640
AUC: 0.8652

Epoch 37/80
 - 0s - loss: 0.9330 - val_loss: 0.6726
AUC: 0.8641

Epoch 38/80
 - 0s - loss: 0.9299 - val_loss: 0.5882
AUC: 0.8642

Epoch 39/80
 - 0s - loss: 0.9275 - val_loss: 0.5166
AUC: 0.8623

Epoch 40/80
 - 0s - loss: 0.9245 - val_loss: 0.6036
AUC: 0.8664

Epoch 41/80
 - 0s - loss: 0.9204 - val_loss: 0.6393
AUC: 0.8652

Epoch 42/80
 - 0s - loss: 0.9202 - val_loss: 0.5946
AUC: 0.8666

Epoch 43/80
 - 0s - loss: 0.9191 - val_loss: 0.4887
AUC: 0.8640

Epoch 44/80
 - 0s - loss: 0.9183 - val_loss: 0.5502
AUC: 0.8622

Epoch 45/80
 - 0s - loss: 0.9121 - val_loss: 0.6541
AUC: 0.8653

Epoch 46/80
 - 0s - loss: 0.9096 - val_loss: 0.5680
AUC: 0.8641

Epoch 47/80
 - 0s - loss: 0.9053 - val_loss: 0.6093
AUC: 0.8654

Epoch 48/80
 - 0s - loss: 0.9104 - val_loss: 0.6043
AUC: 0.8650

Epoch 49/80
 - 0s - loss: 0.9031 - val_loss: 0.6096
AUC: 0.8635

Epoch 50/80
 - 0s - loss: 0.9007 - val_loss: 0.5711
AUC: 0.8650

Epoch 51/80
 - 0s - loss: 0.8941 - val_loss: 0.5631
AUC: 0.8646

Epoch 52/80
 - 0s - loss: 0.8974 - val_loss: 0.5809
AUC: 0.8655

Epoch 53/80
 - 0s - loss: 0.8913 - val_loss: 0.5925
AUC: 0.8655

Epoch 54/80
 - 0s - loss: 0.8727 - val_loss: 0.5547
AUC: 0.8652

Epoch 55/80
 - 0s - loss: 0.8698 - val_loss: 0.5626
AUC: 0.8651

Epoch 56/80
 - 0s - loss: 0.8692 - val_loss: 0.5572
AUC: 0.8647

Epoch 57/80
 - 0s - loss: 0.8715 - val_loss: 0.5813
AUC: 0.8657

Epoch 58/80
 - 0s - loss: 0.8681 - val_loss: 0.5598
AUC: 0.8655

Epoch 59/80
 - 0s - loss: 0.8682 - val_loss: 0.5574
AUC: 0.8653

Epoch 60/80
 - 0s - loss: 0.8639 - val_loss: 0.5618
AUC: 0.8649

Epoch 61/80
 - 0s - loss: 0.8640 - val_loss: 0.5516
AUC: 0.8654

Epoch 62/80
 - 0s - loss: 0.8647 - val_loss: 0.5670
AUC: 0.8647

Epoch 63/80
 - 0s - loss: 0.8625 - val_loss: 0.5513
AUC: 0.8647

Epoch 64/80
 - 0s - loss: 0.8602 - val_loss: 0.5651
AUC: 0.8648

Epoch 65/80
 - 0s - loss: 0.8588 - val_loss: 0.5634
AUC: 0.8650

Epoch 66/80
 - 0s - loss: 0.8625 - val_loss: 0.5636
AUC: 0.8651

Epoch 67/80
 - 0s - loss: 0.8613 - val_loss: 0.5687
AUC: 0.8652

Epoch 68/80
 - 0s - loss: 0.8586 - val_loss: 0.5705
AUC: 0.8652

Epoch 69/80
 - 0s - loss: 0.8604 - val_loss: 0.5784
AUC: 0.8651

Epoch 70/80
 - 0s - loss: 0.8591 - val_loss: 0.5533
AUC: 0.8649

Epoch 71/80
 - 0s - loss: 0.8589 - val_loss: 0.5584
AUC: 0.8650

Epoch 72/80
 - 0s - loss: 0.8550 - val_loss: 0.5641
AUC: 0.8651

Epoch 73/80
 - 0s - loss: 0.8573 - val_loss: 0.5582
AUC: 0.8650

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9024 - val_loss: 0.5629
AUC: 0.8657

Epoch 2/30
 - 0s - loss: 0.9047 - val_loss: 0.5684
AUC: 0.8650

Epoch 3/30
 - 0s - loss: 0.8965 - val_loss: 0.5671
AUC: 0.8648

Epoch 4/30
 - 0s - loss: 0.8965 - val_loss: 0.5794
AUC: 0.8653

Epoch 5/30
 - 0s - loss: 0.8934 - val_loss: 0.5675
AUC: 0.8652

Epoch 6/30
 - 0s - loss: 0.8951 - val_loss: 0.5849
AUC: 0.8653

Epoch 7/30
 - 0s - loss: 0.8911 - val_loss: 0.5855
AUC: 0.8651

Epoch 8/30
 - 0s - loss: 0.8847 - val_loss: 0.5772
AUC: 0.8651

Epoch 9/30
 - 0s - loss: 0.8868 - val_loss: 0.5600
AUC: 0.8648

Epoch 10/30
 - 0s - loss: 0.8801 - val_loss: 0.5645
AUC: 0.8650

Epoch 11/30
 - 0s - loss: 0.8829 - val_loss: 0.5865
AUC: 0.8652

Epoch 12/30
 - 0s - loss: 0.8833 - val_loss: 0.5771
AUC: 0.8654

Epoch 13/30
 - 0s - loss: 0.8843 - val_loss: 0.5607
AUC: 0.8650

Epoch 14/30
 - 0s - loss: 0.8779 - val_loss: 0.5829
AUC: 0.8653

Epoch 15/30
 - 0s - loss: 0.8747 - val_loss: 0.5718
AUC: 0.8655

Epoch 16/30
 - 0s - loss: 0.8748 - val_loss: 0.5871
AUC: 0.8652

Epoch 17/30
 - 0s - loss: 0.8794 - val_loss: 0.5883
AUC: 0.8655

Epoch 18/30
 - 0s - loss: 0.8711 - val_loss: 0.5598
AUC: 0.8651

Epoch 19/30
 - 0s - loss: 0.8708 - val_loss: 0.5846
AUC: 0.8652

Epoch 20/30
 - 0s - loss: 0.8736 - val_loss: 0.5710
AUC: 0.8653

Epoch 21/30
 - 0s - loss: 0.8665 - val_loss: 0.5617
AUC: 0.8653

Epoch 22/30
 - 0s - loss: 0.8729 - val_loss: 0.5632
AUC: 0.8652

Epoch 23/30
 - 0s - loss: 0.8652 - val_loss: 0.5842
AUC: 0.8657

Epoch 24/30
 - 0s - loss: 0.8645 - val_loss: 0.5765
AUC: 0.8652

Epoch 25/30
 - 0s - loss: 0.8648 - val_loss: 0.5960
AUC: 0.8657

Epoch 26/30
 - 0s - loss: 0.8643 - val_loss: 0.5899
AUC: 0.8653

Epoch 27/30
 - 0s - loss: 0.8626 - val_loss: 0.5577
AUC: 0.8650

Epoch 28/30
 - 0s - loss: 0.8672 - val_loss: 0.5889
AUC: 0.8653

Epoch 29/30
 - 0s - loss: 0.8575 - val_loss: 0.5548
AUC: 0.8648

Epoch 30/30
 - 0s - loss: 0.8585 - val_loss: 0.5448
Using TensorFlow backend.
AUC: 0.8644

2019-03-08 07:40:15.111930: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:40:15.277898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:40:15.277941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:40:15.569710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:40:15.569761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:40:15.569770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:40:15.570026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6567
Epoch 2/80
 - 1s - loss: 0.1039
Epoch 3/80
 - 1s - loss: 0.0694
Epoch 4/80
 - 1s - loss: 0.0637
Epoch 5/80
 - 1s - loss: 0.0597
Epoch 6/80
 - 1s - loss: 0.0554
Epoch 7/80
 - 1s - loss: 0.0510
Epoch 8/80
 - 1s - loss: 0.0466
Epoch 9/80
 - 1s - loss: 0.0424
Epoch 10/80
 - 1s - loss: 0.0388
Epoch 11/80
 - 1s - loss: 0.0355
Epoch 12/80
 - 1s - loss: 0.0325
Epoch 13/80
 - 1s - loss: 0.0299
Epoch 14/80
 - 1s - loss: 0.0277
Epoch 15/80
 - 1s - loss: 0.0258
Epoch 16/80
 - 1s - loss: 0.0242
Epoch 17/80
 - 1s - loss: 0.0229
Epoch 18/80
 - 1s - loss: 0.0218
Epoch 19/80
 - 1s - loss: 0.0208
Epoch 20/80
 - 1s - loss: 0.0199
Epoch 21/80
 - 1s - loss: 0.0192
Epoch 22/80
 - 1s - loss: 0.0186
Epoch 23/80
 - 1s - loss: 0.0180
Epoch 24/80
 - 1s - loss: 0.0176
Epoch 25/80
 - 1s - loss: 0.0172
Epoch 26/80
 - 1s - loss: 0.0168
Epoch 27/80
 - 1s - loss: 0.0165
Epoch 28/80
 - 1s - loss: 0.0162
Epoch 29/80
 - 1s - loss: 0.0160
Epoch 30/80
 - 1s - loss: 0.0158
Epoch 31/80
 - 1s - loss: 0.0156
Epoch 32/80
 - 1s - loss: 0.0154
Epoch 33/80
 - 1s - loss: 0.0153
Epoch 34/80
 - 1s - loss: 0.0151
Epoch 35/80
 - 1s - loss: 0.0150
Epoch 36/80
 - 1s - loss: 0.0149
Epoch 37/80
 - 1s - loss: 0.0148
Epoch 38/80
 - 1s - loss: 0.0147
Epoch 39/80
 - 1s - loss: 0.0147
Epoch 40/80
 - 1s - loss: 0.0146
Epoch 41/80
 - 1s - loss: 0.0145
Epoch 42/80
 - 1s - loss: 0.0145
Epoch 43/80
 - 1s - loss: 0.0144
Epoch 44/80
 - 1s - loss: 0.0144
Epoch 45/80
 - 1s - loss: 0.0144
Epoch 46/80
 - 1s - loss: 0.0143
Epoch 47/80
 - 1s - loss: 0.0143
Epoch 48/80
 - 1s - loss: 0.0143
Epoch 49/80
 - 1s - loss: 0.0138
Epoch 50/80
 - 1s - loss: 0.0137
Epoch 51/80
 - 1s - loss: 0.0137
Epoch 52/80
 - 1s - loss: 0.0137
Epoch 53/80
 - 1s - loss: 0.0136
Epoch 54/80
 - 1s - loss: 0.0136
Epoch 55/80
 - 1s - loss: 0.0136
Epoch 56/80
 - 1s - loss: 0.0136
Epoch 57/80
 - 1s - loss: 0.0136
Epoch 58/80
 - 1s - loss: 0.0136
Epoch 59/80
 - 1s - loss: 0.0136
Epoch 60/80
 - 1s - loss: 0.0136
Epoch 61/80
 - 1s - loss: 0.0136
Epoch 62/80
 - 1s - loss: 0.0136
Epoch 63/80
 - 1s - loss: 0.0136
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:42:15.270246: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:42:15.433363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:42:15.433417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:42:15.726123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:42:15.726178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:42:15.726188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:42:15.726469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6447
Epoch 2/80
 - 1s - loss: 0.0995
Epoch 3/80
 - 1s - loss: 0.0696
Epoch 4/80
 - 1s - loss: 0.0654
Epoch 5/80
 - 1s - loss: 0.0631
Epoch 6/80
 - 1s - loss: 0.0603
Epoch 7/80
 - 1s - loss: 0.0565
Epoch 8/80
 - 1s - loss: 0.0516
Epoch 9/80
 - 2s - loss: 0.0462
Epoch 10/80
 - 1s - loss: 0.0414
Epoch 11/80
 - 1s - loss: 0.0373
Epoch 12/80
 - 1s - loss: 0.0338
Epoch 13/80
 - 1s - loss: 0.0307
Epoch 14/80
 - 1s - loss: 0.0282
Epoch 15/80
 - 2s - loss: 0.0262
Epoch 16/80
 - 1s - loss: 0.0245
Epoch 17/80
 - 1s - loss: 0.0231
Epoch 18/80
 - 1s - loss: 0.0220
Epoch 19/80
 - 1s - loss: 0.0210
Epoch 20/80
 - 1s - loss: 0.0201
Epoch 21/80
 - 1s - loss: 0.0194
Epoch 22/80
 - 1s - loss: 0.0188
Epoch 23/80
 - 1s - loss: 0.0182
Epoch 24/80
 - 1s - loss: 0.0178
Epoch 25/80
 - 1s - loss: 0.0174
Epoch 26/80
 - 2s - loss: 0.0170
Epoch 27/80
 - 1s - loss: 0.0167
Epoch 28/80
 - 1s - loss: 0.0164
Epoch 29/80
 - 2s - loss: 0.0162
Epoch 30/80
 - 1s - loss: 0.0159
Epoch 31/80
 - 1s - loss: 0.0157
Epoch 32/80
 - 2s - loss: 0.0156
Epoch 33/80
 - 1s - loss: 0.0154
Epoch 34/80
 - 1s - loss: 0.0153
Epoch 35/80
 - 1s - loss: 0.0152
Epoch 36/80
 - 1s - loss: 0.0151
Epoch 37/80
 - 1s - loss: 0.0150
Epoch 38/80
 - 2s - loss: 0.0149
Epoch 39/80
 - 1s - loss: 0.0148
Epoch 40/80
 - 1s - loss: 0.0147
Epoch 41/80
 - 1s - loss: 0.0147
Epoch 42/80
 - 1s - loss: 0.0146
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:43:44.315132: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:43:44.478269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:43:44.478313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:43:44.769089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:43:44.769141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:43:44.769150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:43:44.769430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2875
Epoch 2/80
 - 2s - loss: 0.3325
Epoch 3/80
 - 2s - loss: 0.2960
Epoch 4/80
 - 2s - loss: 0.2675
Epoch 5/80
 - 2s - loss: 0.2401
Epoch 6/80
 - 2s - loss: 0.2191
Epoch 7/80
 - 2s - loss: 0.2013
Epoch 8/80
 - 2s - loss: 0.1864
Epoch 9/80
 - 2s - loss: 0.1745
Epoch 10/80
 - 2s - loss: 0.1648
Epoch 11/80
 - 2s - loss: 0.1566
Epoch 12/80
 - 2s - loss: 0.1492
Epoch 13/80
 - 2s - loss: 0.1426
Epoch 14/80
 - 2s - loss: 0.1368
Epoch 15/80
 - 2s - loss: 0.1318
Epoch 16/80
 - 2s - loss: 0.1276
Epoch 17/80
 - 1s - loss: 0.1241
Epoch 18/80
 - 2s - loss: 0.1211
Epoch 19/80
 - 2s - loss: 0.1186
Epoch 20/80
 - 2s - loss: 0.1164
Epoch 21/80
 - 2s - loss: 0.1145
Epoch 22/80
 - 2s - loss: 0.1129
Epoch 23/80
 - 2s - loss: 0.1115
Epoch 24/80
 - 2s - loss: 0.1103
Epoch 25/80
 - 2s - loss: 0.1092
Epoch 26/80
 - 2s - loss: 0.1083
Epoch 27/80
 - 2s - loss: 0.1076
Epoch 28/80
 - 2s - loss: 0.1069
Epoch 29/80
 - 2s - loss: 0.1063
Epoch 30/80
 - 1s - loss: 0.1058
Epoch 31/80
 - 1s - loss: 0.1053
Epoch 32/80
 - 2s - loss: 0.1049
Epoch 33/80
 - 2s - loss: 0.1045
Epoch 34/80
 - 2s - loss: 0.1043
Epoch 35/80
 - 2s - loss: 0.1039
Epoch 36/80
 - 1s - loss: 0.1037
Epoch 37/80
 - 2s - loss: 0.1035
Epoch 38/80
 - 2s - loss: 0.1032
Epoch 39/80
 - 2s - loss: 0.1030
Epoch 40/80
 - 2s - loss: 0.1029
Epoch 41/80
 - 2s - loss: 0.1027
Epoch 42/80
 - 2s - loss: 0.1026
Epoch 43/80
 - 2s - loss: 0.1024
Epoch 44/80
 - 1s - loss: 0.1023
Epoch 45/80
 - 2s - loss: 0.1022
Epoch 46/80
 - 2s - loss: 0.1021
Epoch 47/80
 - 1s - loss: 0.1020
Epoch 48/80
 - 2s - loss: 0.1019
Epoch 49/80
 - 2s - loss: 0.1018
Epoch 50/80
 - 2s - loss: 0.1017
Epoch 51/80
 - 2s - loss: 0.1017
Epoch 52/80
 - 2s - loss: 0.1016
Epoch 53/80
 - 2s - loss: 0.1015
Epoch 54/80
 - 2s - loss: 0.1014
Epoch 55/80
 - 2s - loss: 0.1014
Epoch 56/80
 - 1s - loss: 0.1013
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:45:35.338926: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:45:35.500997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:45:35.501040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:45:35.792641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:45:35.792691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:45:35.792700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:45:35.792952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2968
Epoch 2/80
 - 2s - loss: 0.3328
Epoch 3/80
 - 1s - loss: 0.2995
Epoch 4/80
 - 2s - loss: 0.2778
Epoch 5/80
 - 2s - loss: 0.2513
Epoch 6/80
 - 1s - loss: 0.2266
Epoch 7/80
 - 1s - loss: 0.2078
Epoch 8/80
 - 1s - loss: 0.1913
Epoch 9/80
 - 1s - loss: 0.1766
Epoch 10/80
 - 1s - loss: 0.1645
Epoch 11/80
 - 1s - loss: 0.1548
Epoch 12/80
 - 1s - loss: 0.1467
Epoch 13/80
 - 2s - loss: 0.1400
Epoch 14/80
 - 1s - loss: 0.1345
Epoch 15/80
 - 1s - loss: 0.1301
Epoch 16/80
 - 1s - loss: 0.1264
Epoch 17/80
 - 1s - loss: 0.1234
Epoch 18/80
 - 2s - loss: 0.1207
Epoch 19/80
 - 2s - loss: 0.1184
Epoch 20/80
 - 1s - loss: 0.1164
Epoch 21/80
 - 1s - loss: 0.1147
Epoch 22/80
 - 1s - loss: 0.1133
Epoch 23/80
 - 1s - loss: 0.1119
Epoch 24/80
 - 1s - loss: 0.1108
Epoch 25/80
 - 1s - loss: 0.1099
Epoch 26/80
 - 1s - loss: 0.1090
Epoch 27/80
 - 1s - loss: 0.1082
Epoch 28/80
 - 1s - loss: 0.1076
Epoch 29/80
 - 1s - loss: 0.1071
Epoch 30/80
 - 1s - loss: 0.1066
Epoch 31/80
 - 1s - loss: 0.1061
Epoch 32/80
 - 1s - loss: 0.1057
Epoch 33/80
 - 1s - loss: 0.1054
Epoch 34/80
 - 1s - loss: 0.1051
Epoch 35/80
 - 2s - loss: 0.1048
Epoch 36/80
 - 1s - loss: 0.1046
Epoch 37/80
 - 1s - loss: 0.1043
Epoch 38/80
 - 1s - loss: 0.1041
Epoch 39/80
 - 2s - loss: 0.1039
Epoch 40/80
 - 1s - loss: 0.1037
Epoch 41/80
 - 1s - loss: 0.1036
Epoch 42/80
 - 1s - loss: 0.1034
Epoch 43/80
 - 1s - loss: 0.1033
Epoch 44/80
 - 1s - loss: 0.1031
Epoch 45/80
 - 1s - loss: 0.1030
Epoch 46/80
 - 1s - loss: 0.1029
Epoch 47/80
 - 1s - loss: 0.1028
Epoch 48/80
 - 1s - loss: 0.1027
Epoch 49/80
 - 1s - loss: 0.1026
Epoch 50/80
 - 1s - loss: 0.1025
Epoch 51/80
 - 1s - loss: 0.1024
Epoch 52/80
 - 2s - loss: 0.1023
Epoch 53/80
 - 1s - loss: 0.1023
Epoch 54/80
 - 1s - loss: 0.1022
Epoch 55/80
 - 1s - loss: 0.1021
Epoch 56/80
 - 1s - loss: 0.1021
Epoch 57/80
 - 2s - loss: 0.1019
Epoch 58/80
 - 1s - loss: 0.1019
Epoch 59/80
 - 2s - loss: 0.1019
Epoch 60/80
 - 1s - loss: 0.1018
Epoch 61/80
 - 1s - loss: 0.1017
Epoch 62/80
 - 1s - loss: 0.1017
Epoch 63/80
 - 1s - loss: 0.1017
Epoch 64/80
 - 1s - loss: 0.1016
Epoch 65/80
 - 1s - loss: 0.1015
Epoch 66/80
 - 1s - loss: 0.1015
Epoch 67/80
 - 1s - loss: 0.1014
Epoch 68/80
 - 1s - loss: 0.1014
Epoch 69/80
 - 1s - loss: 0.1013
Epoch 70/80
 - 1s - loss: 0.1013
Epoch 71/80
 - 1s - loss: 0.0987
Epoch 72/80
 - 1s - loss: 0.0984
Epoch 73/80
 - 1s - loss: 0.0984
Epoch 74/80
 - 1s - loss: 0.0983
Epoch 75/80
 - 2s - loss: 0.0983
Epoch 76/80
 - 1s - loss: 0.0977
Epoch 77/80
 - 1s - loss: 0.0977
Epoch 78/80
 - 1s - loss: 0.0977
Epoch 79/80
 - 1s - loss: 0.0976
Epoch 80/80
 - 1s - loss: 0.0975
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.9842 - val_loss: 1.4983
AUC: 0.7657

Epoch 2/80
 - 0s - loss: 3.3935 - val_loss: 1.4540
AUC: 0.7971

Epoch 3/80
 - 0s - loss: 2.6475 - val_loss: 0.9129
AUC: 0.8161

Epoch 4/80
 - 0s - loss: 2.0322 - val_loss: 1.0508
AUC: 0.8380

Epoch 5/80
 - 0s - loss: 1.6447 - val_loss: 0.7750
AUC: 0.8417

Epoch 6/80
 - 0s - loss: 1.3842 - val_loss: 0.6855
AUC: 0.8505

Epoch 7/80
 - 0s - loss: 1.2417 - val_loss: 0.8337
AUC: 0.8524

Epoch 8/80
 - 0s - loss: 1.1958 - val_loss: 0.6805
AUC: 0.8541

Epoch 9/80
 - 0s - loss: 1.1485 - val_loss: 0.6168
AUC: 0.8568

Epoch 10/80
 - 0s - loss: 1.1179 - val_loss: 0.6621
AUC: 0.8580

Epoch 11/80
 - 0s - loss: 1.0930 - val_loss: 0.6430
AUC: 0.8613

Epoch 12/80
 - 0s - loss: 1.0833 - val_loss: 0.6220
AUC: 0.8612

Epoch 13/80
 - 0s - loss: 1.0652 - val_loss: 0.6489
AUC: 0.8627

Epoch 14/80
 - 0s - loss: 1.0610 - val_loss: 0.6992
AUC: 0.8637

Epoch 15/80
 - 0s - loss: 1.0375 - val_loss: 0.6422
AUC: 0.8649

Epoch 16/80
 - 0s - loss: 1.0469 - val_loss: 0.6033
AUC: 0.8639

Epoch 17/80
 - 0s - loss: 1.0445 - val_loss: 0.6283
AUC: 0.8666

Epoch 18/80
 - 0s - loss: 1.0334 - val_loss: 0.6442
AUC: 0.8661

Epoch 19/80
 - 0s - loss: 1.0283 - val_loss: 0.6026
AUC: 0.8654

Epoch 20/80
 - 0s - loss: 1.0227 - val_loss: 0.5928
AUC: 0.8663

Epoch 21/80
 - 0s - loss: 1.0191 - val_loss: 0.6278
AUC: 0.8668

Epoch 22/80
 - 0s - loss: 1.0159 - val_loss: 0.5515
AUC: 0.8655

Epoch 23/80
 - 0s - loss: 1.0096 - val_loss: 0.5622
AUC: 0.8665

Epoch 24/80
 - 0s - loss: 1.0083 - val_loss: 0.5972
AUC: 0.8677

Epoch 25/80
 - 0s - loss: 0.9986 - val_loss: 0.6105
AUC: 0.8684

Epoch 26/80
 - 0s - loss: 1.0019 - val_loss: 0.6870
AUC: 0.8696

Epoch 27/80
 - 0s - loss: 1.0065 - val_loss: 0.6262
AUC: 0.8700

Epoch 28/80
 - 0s - loss: 0.9945 - val_loss: 0.6047
AUC: 0.8693

Epoch 29/80
 - 0s - loss: 0.9921 - val_loss: 0.5740
AUC: 0.8690

Epoch 30/80
 - 0s - loss: 0.9870 - val_loss: 0.6054
AUC: 0.8708

Epoch 31/80
 - 0s - loss: 0.9970 - val_loss: 0.5724
AUC: 0.8690

Epoch 32/80
 - 0s - loss: 0.9844 - val_loss: 0.5990
AUC: 0.8686

Epoch 33/80
 - 0s - loss: 0.9779 - val_loss: 0.5769
AUC: 0.8701

Epoch 34/80
 - 0s - loss: 0.9770 - val_loss: 0.6208
AUC: 0.8707

Epoch 35/80
 - 0s - loss: 0.9774 - val_loss: 0.5790
AUC: 0.8703

Epoch 36/80
 - 0s - loss: 0.9735 - val_loss: 0.6197
AUC: 0.8707

Epoch 37/80
 - 0s - loss: 0.9709 - val_loss: 0.5946
AUC: 0.8704

Epoch 38/80
 - 0s - loss: 0.9691 - val_loss: 0.5823
AUC: 0.8705

Epoch 39/80
 - 0s - loss: 0.9721 - val_loss: 0.6004
AUC: 0.8706

Epoch 40/80
 - 0s - loss: 0.9727 - val_loss: 0.6097
AUC: 0.8713

Epoch 41/80
 - 0s - loss: 0.9733 - val_loss: 0.5785
AUC: 0.8706

Epoch 42/80
 - 0s - loss: 0.9671 - val_loss: 0.6020
AUC: 0.8710

Epoch 43/80
 - 0s - loss: 0.9698 - val_loss: 0.5975
AUC: 0.8710

Epoch 44/80
 - 0s - loss: 0.9651 - val_loss: 0.5903
AUC: 0.8709

Epoch 45/80
 - 0s - loss: 0.9696 - val_loss: 0.5957
AUC: 0.8709

Epoch 46/80
 - 0s - loss: 0.9707 - val_loss: 0.5922
AUC: 0.8709

Epoch 47/80
 - 0s - loss: 0.9650 - val_loss: 0.5869
AUC: 0.8709

Epoch 48/80
 - 0s - loss: 0.9652 - val_loss: 0.5940
AUC: 0.8709

Epoch 49/80
 - 0s - loss: 0.9668 - val_loss: 0.5912
AUC: 0.8709

Epoch 50/80
 - 0s - loss: 0.9660 - val_loss: 0.5881
AUC: 0.8709

Epoch 51/80
 - 0s - loss: 0.9685 - val_loss: 0.5956
AUC: 0.8710

Epoch 52/80
 - 0s - loss: 0.9643 - val_loss: 0.5955
AUC: 0.8711

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9684 - val_loss: 0.5950
AUC: 0.8711

Epoch 2/30
 - 0s - loss: 0.9649 - val_loss: 0.5821
AUC: 0.8711

Epoch 3/30
 - 0s - loss: 0.9724 - val_loss: 0.6000
AUC: 0.8713

Epoch 4/30
 - 0s - loss: 0.9640 - val_loss: 0.5686
AUC: 0.8710

Epoch 5/30
 - 0s - loss: 0.9597 - val_loss: 0.5933
AUC: 0.8714

Epoch 6/30
 - 0s - loss: 0.9584 - val_loss: 0.5850
AUC: 0.8715

Epoch 7/30
 - 0s - loss: 0.9610 - val_loss: 0.5745
AUC: 0.8715

Epoch 8/30
 - 0s - loss: 0.9584 - val_loss: 0.5878
AUC: 0.8718

Epoch 9/30
 - 0s - loss: 0.9579 - val_loss: 0.5901
AUC: 0.8719

Epoch 10/30
 - 0s - loss: 0.9597 - val_loss: 0.5940
AUC: 0.8720

Epoch 11/30
 - 0s - loss: 0.9535 - val_loss: 0.5934
AUC: 0.8722

Epoch 12/30
 - 0s - loss: 0.9558 - val_loss: 0.5883
AUC: 0.8722

Epoch 13/30
 - 0s - loss: 0.9496 - val_loss: 0.5864
AUC: 0.8724

Epoch 14/30
 - 0s - loss: 0.9488 - val_loss: 0.5664
AUC: 0.8722

Epoch 15/30
 - 0s - loss: 0.9454 - val_loss: 0.5653
AUC: 0.8722

Epoch 16/30
 - 0s - loss: 0.9506 - val_loss: 0.5781
AUC: 0.8727

Epoch 17/30
 - 0s - loss: 0.9470 - val_loss: 0.5942
AUC: 0.8728

Epoch 18/30
 - 0s - loss: 0.9459 - val_loss: 0.5802
AUC: 0.8725

Epoch 19/30
 - 0s - loss: 0.9423 - val_loss: 0.5779
AUC: 0.8726

Epoch 20/30
 - 0s - loss: 0.9397 - val_loss: 0.5840
AUC: 0.8729

Epoch 21/30
 - 0s - loss: 0.9411 - val_loss: 0.5689
AUC: 0.8729

Epoch 22/30
 - 0s - loss: 0.9377 - val_loss: 0.5777
AUC: 0.8729

Epoch 23/30
 - 0s - loss: 0.9376 - val_loss: 0.6033
AUC: 0.8733

Epoch 24/30
 - 0s - loss: 0.9395 - val_loss: 0.5934
AUC: 0.8733

Epoch 25/30
 - 0s - loss: 0.9367 - val_loss: 0.5548
AUC: 0.8729

Epoch 26/30
 - 0s - loss: 0.9314 - val_loss: 0.5698
AUC: 0.8733

Epoch 27/30
 - 0s - loss: 0.9378 - val_loss: 0.5854
AUC: 0.8734

Epoch 28/30
 - 0s - loss: 0.9329 - val_loss: 0.5853
AUC: 0.8737

Epoch 29/30
 - 0s - loss: 0.9350 - val_loss: 0.5889
AUC: 0.8737

Epoch 30/30
 - 0s - loss: 0.9321 - val_loss: 0.5974
Using TensorFlow backend.
AUC: 0.8737

2019-03-08 07:48:51.927054: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:48:52.091516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:48:52.091559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:48:52.381335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:48:52.381386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:48:52.381395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:48:52.381647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3020
Epoch 2/80
 - 2s - loss: 0.3319
Epoch 3/80
 - 1s - loss: 0.2949
Epoch 4/80
 - 2s - loss: 0.2639
Epoch 5/80
 - 2s - loss: 0.2364
Epoch 6/80
 - 2s - loss: 0.2164
Epoch 7/80
 - 2s - loss: 0.2009
Epoch 8/80
 - 2s - loss: 0.1880
Epoch 9/80
 - 2s - loss: 0.1766
Epoch 10/80
 - 1s - loss: 0.1664
Epoch 11/80
 - 2s - loss: 0.1571
Epoch 12/80
 - 1s - loss: 0.1487
Epoch 13/80
 - 1s - loss: 0.1413
Epoch 14/80
 - 1s - loss: 0.1352
Epoch 15/80
 - 1s - loss: 0.1302
Epoch 16/80
 - 1s - loss: 0.1264
Epoch 17/80
 - 1s - loss: 0.1232
Epoch 18/80
 - 1s - loss: 0.1205
Epoch 19/80
 - 1s - loss: 0.1182
Epoch 20/80
 - 2s - loss: 0.1162
Epoch 21/80
 - 1s - loss: 0.1144
Epoch 22/80
 - 1s - loss: 0.1127
Epoch 23/80
 - 1s - loss: 0.1114
Epoch 24/80
 - 2s - loss: 0.1102
Epoch 25/80
 - 1s - loss: 0.1092
Epoch 26/80
 - 1s - loss: 0.1083
Epoch 27/80
 - 1s - loss: 0.1075
Epoch 28/80
 - 2s - loss: 0.1069
Epoch 29/80
 - 1s - loss: 0.1063
Epoch 30/80
 - 1s - loss: 0.1058
Epoch 31/80
 - 1s - loss: 0.1053
Epoch 32/80
 - 1s - loss: 0.1049
Epoch 33/80
 - 1s - loss: 0.1046
Epoch 34/80
 - 1s - loss: 0.1043
Epoch 35/80
 - 1s - loss: 0.1040
Epoch 36/80
 - 1s - loss: 0.1038
Epoch 37/80
 - 1s - loss: 0.1035
Epoch 38/80
 - 1s - loss: 0.1033
Epoch 39/80
 - 1s - loss: 0.1032
Epoch 40/80
 - 1s - loss: 0.1030
Epoch 41/80
 - 2s - loss: 0.1028
Epoch 42/80
 - 1s - loss: 0.1027
Epoch 43/80
 - 1s - loss: 0.1026
Epoch 44/80
 - 1s - loss: 0.1024
Epoch 45/80
 - 1s - loss: 0.1023
Epoch 46/80
 - 2s - loss: 0.1022
Epoch 47/80
 - 1s - loss: 0.1021
Epoch 48/80
 - 2s - loss: 0.1020
Epoch 49/80
 - 1s - loss: 0.1019
Epoch 50/80
 - 1s - loss: 0.1018
Epoch 51/80
 - 1s - loss: 0.1018
Epoch 52/80
 - 1s - loss: 0.1017
Epoch 53/80
 - 2s - loss: 0.1016
Epoch 54/80
 - 1s - loss: 0.1016
Epoch 55/80
 - 1s - loss: 0.1015
Epoch 56/80
 - 1s - loss: 0.1015
Epoch 57/80
 - 1s - loss: 0.1014
Epoch 58/80
 - 1s - loss: 0.1014
Epoch 59/80
 - 1s - loss: 0.1013
Epoch 60/80
 - 1s - loss: 0.1013
Epoch 61/80
 - 1s - loss: 0.1012
Epoch 62/80
 - 1s - loss: 0.1012
Epoch 63/80
 - 2s - loss: 0.1012
Epoch 64/80
 - 1s - loss: 0.0985
Epoch 65/80
 - 1s - loss: 0.0982
Epoch 66/80
 - 1s - loss: 0.0982
Epoch 67/80
 - 2s - loss: 0.0982
Epoch 68/80
 - 2s - loss: 0.0982
Epoch 69/80
 - 1s - loss: 0.0975
Epoch 70/80
 - 2s - loss: 0.0975
Epoch 71/80
 - 1s - loss: 0.0975
Epoch 72/80
 - 1s - loss: 0.0975
Epoch 73/80
 - 1s - loss: 0.0974
Epoch 74/80
 - 1s - loss: 0.0974
Epoch 75/80
 - 1s - loss: 0.0974
Epoch 76/80
 - 1s - loss: 0.0974
Epoch 77/80
 - 1s - loss: 0.0973
Epoch 78/80
 - 1s - loss: 0.0973
Epoch 79/80
 - 1s - loss: 0.0973
Epoch 80/80
 - 1s - loss: 0.0973
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.3137 - val_loss: 1.3044
AUC: 0.8102

Epoch 2/80
 - 0s - loss: 2.0235 - val_loss: 0.8433
AUC: 0.8338

Epoch 3/80
 - 0s - loss: 1.4737 - val_loss: 0.6423
AUC: 0.8398

Epoch 4/80
 - 0s - loss: 1.2305 - val_loss: 0.7853
AUC: 0.8486

Epoch 5/80
 - 0s - loss: 1.1532 - val_loss: 0.6495
AUC: 0.8518

Epoch 6/80
 - 0s - loss: 1.1067 - val_loss: 0.6334
AUC: 0.8545

Epoch 7/80
 - 0s - loss: 1.0865 - val_loss: 0.6820
AUC: 0.8575

Epoch 8/80
 - 0s - loss: 1.0691 - val_loss: 0.6411
AUC: 0.8578

Epoch 9/80
 - 0s - loss: 1.0621 - val_loss: 0.6489
AUC: 0.8595

Epoch 10/80
 - 0s - loss: 1.0561 - val_loss: 0.6611
AUC: 0.8622

Epoch 11/80
 - 0s - loss: 1.0500 - val_loss: 0.6777
AUC: 0.8619

Epoch 12/80
 - 0s - loss: 1.0356 - val_loss: 0.6170
AUC: 0.8618

Epoch 13/80
 - 0s - loss: 1.0292 - val_loss: 0.6772
AUC: 0.8641

Epoch 14/80
 - 0s - loss: 1.0222 - val_loss: 0.7055
AUC: 0.8650

Epoch 15/80
 - 0s - loss: 1.0178 - val_loss: 0.6013
AUC: 0.8639

Epoch 16/80
 - 0s - loss: 1.0055 - val_loss: 0.6203
AUC: 0.8656

Epoch 17/80
 - 0s - loss: 1.0161 - val_loss: 0.6889
AUC: 0.8662

Epoch 18/80
 - 0s - loss: 1.0050 - val_loss: 0.6626
AUC: 0.8656

Epoch 19/80
 - 0s - loss: 1.0051 - val_loss: 0.5883
AUC: 0.8638

Epoch 20/80
 - 0s - loss: 1.0022 - val_loss: 0.6447
AUC: 0.8669

Epoch 21/80
 - 0s - loss: 0.9962 - val_loss: 0.5641
AUC: 0.8671

Epoch 22/80
 - 0s - loss: 0.9896 - val_loss: 0.6354
AUC: 0.8677

Epoch 23/80
 - 0s - loss: 0.9842 - val_loss: 0.5678
AUC: 0.8658

Epoch 24/80
 - 0s - loss: 0.9897 - val_loss: 0.6168
AUC: 0.8666

Epoch 25/80
 - 0s - loss: 0.9875 - val_loss: 0.6071
AUC: 0.8674

Epoch 26/80
 - 0s - loss: 0.9805 - val_loss: 0.6305
AUC: 0.8672

Epoch 27/80
 - 0s - loss: 0.9780 - val_loss: 0.5692
AUC: 0.8671

Epoch 28/80
 - 0s - loss: 0.9748 - val_loss: 0.7017
AUC: 0.8689

Epoch 29/80
 - 0s - loss: 0.9754 - val_loss: 0.5601
AUC: 0.8682

Epoch 30/80
 - 0s - loss: 0.9667 - val_loss: 0.7042
AUC: 0.8688

Epoch 31/80
 - 0s - loss: 0.9699 - val_loss: 0.7236
AUC: 0.8678

Epoch 32/80
 - 0s - loss: 0.9687 - val_loss: 0.5635
AUC: 0.8679

Epoch 33/80
 - 0s - loss: 0.9644 - val_loss: 0.5877
AUC: 0.8690

Epoch 34/80
 - 0s - loss: 0.9695 - val_loss: 0.6493
AUC: 0.8695

Epoch 35/80
 - 0s - loss: 0.9610 - val_loss: 0.5691
AUC: 0.8685

Epoch 36/80
 - 0s - loss: 0.9593 - val_loss: 0.5951
AUC: 0.8682

Epoch 37/80
 - 0s - loss: 0.9561 - val_loss: 0.5345
AUC: 0.8678

Epoch 38/80
 - 0s - loss: 0.9550 - val_loss: 0.5651
AUC: 0.8687

Epoch 39/80
 - 0s - loss: 0.9523 - val_loss: 0.6047
AUC: 0.8695

Epoch 40/80
 - 0s - loss: 0.9495 - val_loss: 0.5902
AUC: 0.8696

Epoch 41/80
 - 0s - loss: 0.9467 - val_loss: 0.5771
AUC: 0.8684

Epoch 42/80
 - 0s - loss: 0.9459 - val_loss: 0.5726
AUC: 0.8705

Epoch 43/80
 - 0s - loss: 0.9462 - val_loss: 0.6109
AUC: 0.8697

Epoch 44/80
 - 0s - loss: 0.9376 - val_loss: 0.5796
AUC: 0.8699

Epoch 45/80
 - 0s - loss: 0.9403 - val_loss: 0.5293
AUC: 0.8701

Epoch 46/80
 - 0s - loss: 0.9344 - val_loss: 0.5789
AUC: 0.8697

Epoch 47/80
 - 0s - loss: 0.9410 - val_loss: 0.6063
AUC: 0.8705

Epoch 48/80
 - 0s - loss: 0.9328 - val_loss: 0.6583
AUC: 0.8712

Epoch 49/80
 - 0s - loss: 0.9351 - val_loss: 0.5625
AUC: 0.8696

Epoch 50/80
 - 0s - loss: 0.9276 - val_loss: 0.5913
AUC: 0.8699

Epoch 51/80
 - 0s - loss: 0.9271 - val_loss: 0.6505
AUC: 0.8697

Epoch 52/80
 - 0s - loss: 0.9296 - val_loss: 0.5462
AUC: 0.8703

Epoch 53/80
 - 0s - loss: 0.9285 - val_loss: 0.5928
AUC: 0.8698

Epoch 54/80
 - 0s - loss: 0.9236 - val_loss: 0.5899
AUC: 0.8701

Epoch 55/80
 - 0s - loss: 0.9222 - val_loss: 0.6086
AUC: 0.8714

Epoch 56/80
 - 0s - loss: 0.9126 - val_loss: 0.5717
AUC: 0.8710

Epoch 57/80
 - 0s - loss: 0.9110 - val_loss: 0.5780
AUC: 0.8711

Epoch 58/80
 - 0s - loss: 0.9096 - val_loss: 0.5637
AUC: 0.8711

Epoch 59/80
 - 0s - loss: 0.9062 - val_loss: 0.5761
AUC: 0.8711

Epoch 60/80
 - 0s - loss: 0.9055 - val_loss: 0.5703
AUC: 0.8713

Epoch 61/80
 - 0s - loss: 0.9068 - val_loss: 0.5740
AUC: 0.8711

Epoch 62/80
 - 0s - loss: 0.9043 - val_loss: 0.5918
AUC: 0.8713

Epoch 63/80
 - 0s - loss: 0.9022 - val_loss: 0.5876
AUC: 0.8713

Epoch 64/80
 - 0s - loss: 0.8998 - val_loss: 0.5767
AUC: 0.8712

Epoch 65/80
 - 0s - loss: 0.9018 - val_loss: 0.5934
AUC: 0.8710

Epoch 66/80
 - 0s - loss: 0.9009 - val_loss: 0.5748
AUC: 0.8710

Epoch 67/80
 - 0s - loss: 0.8963 - val_loss: 0.5758
AUC: 0.8710

Epoch 68/80
 - 0s - loss: 0.8988 - val_loss: 0.5711
AUC: 0.8710

Epoch 69/80
 - 0s - loss: 0.8959 - val_loss: 0.5803
AUC: 0.8710

Epoch 70/80
 - 0s - loss: 0.9041 - val_loss: 0.5780
AUC: 0.8710

Epoch 71/80
 - 0s - loss: 0.8990 - val_loss: 0.5731
AUC: 0.8710

Epoch 72/80
 - 0s - loss: 0.9004 - val_loss: 0.5724
AUC: 0.8710

Epoch 73/80
 - 0s - loss: 0.9004 - val_loss: 0.5771
AUC: 0.8710

Epoch 74/80
 - 0s - loss: 0.8973 - val_loss: 0.5753
AUC: 0.8710

Epoch 75/80
 - 0s - loss: 0.8988 - val_loss: 0.5749
AUC: 0.8711

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9100 - val_loss: 0.5701
AUC: 0.8711

Epoch 2/30
 - 0s - loss: 0.9079 - val_loss: 0.5681
AUC: 0.8712

Epoch 3/30
 - 0s - loss: 0.9058 - val_loss: 0.5873
AUC: 0.8713

Epoch 4/30
 - 0s - loss: 0.9025 - val_loss: 0.5562
AUC: 0.8712

Epoch 5/30
 - 0s - loss: 0.9014 - val_loss: 0.5925
AUC: 0.8717

Epoch 6/30
 - 0s - loss: 0.8996 - val_loss: 0.5792
AUC: 0.8716

Epoch 7/30
 - 0s - loss: 0.9021 - val_loss: 0.5794
AUC: 0.8717

Epoch 8/30
 - 0s - loss: 0.8990 - val_loss: 0.5782
AUC: 0.8717

Epoch 9/30
 - 0s - loss: 0.8952 - val_loss: 0.5933
AUC: 0.8717

Epoch 10/30
 - 0s - loss: 0.8932 - val_loss: 0.5724
AUC: 0.8717

Epoch 11/30
 - 0s - loss: 0.8902 - val_loss: 0.5518
AUC: 0.8716

Epoch 12/30
 - 0s - loss: 0.8898 - val_loss: 0.5828
AUC: 0.8721

Epoch 13/30
 - 0s - loss: 0.8902 - val_loss: 0.5783
AUC: 0.8720

Epoch 14/30
 - 0s - loss: 0.8890 - val_loss: 0.5704
AUC: 0.8720

Epoch 15/30
 - 0s - loss: 0.8861 - val_loss: 0.5785
AUC: 0.8722

Epoch 16/30
 - 0s - loss: 0.8823 - val_loss: 0.5900
AUC: 0.8722

Epoch 17/30
 - 0s - loss: 0.8857 - val_loss: 0.5556
AUC: 0.8719

Epoch 18/30
 - 0s - loss: 0.8845 - val_loss: 0.5665
AUC: 0.8720

Epoch 19/30
 - 0s - loss: 0.8824 - val_loss: 0.5822
AUC: 0.8723

Epoch 20/30
 - 0s - loss: 0.8812 - val_loss: 0.5667
AUC: 0.8721

Epoch 21/30
 - 0s - loss: 0.8832 - val_loss: 0.5735
AUC: 0.8723

Epoch 22/30
 - 0s - loss: 0.8742 - val_loss: 0.5735
AUC: 0.8723

Epoch 23/30
 - 0s - loss: 0.8757 - val_loss: 0.5652
AUC: 0.8722

Epoch 24/30
 - 0s - loss: 0.8753 - val_loss: 0.5684
AUC: 0.8722

Epoch 25/30
 - 0s - loss: 0.8734 - val_loss: 0.5690
AUC: 0.8722

Epoch 26/30
 - 0s - loss: 0.8774 - val_loss: 0.5711
AUC: 0.8722

Epoch 27/30
 - 0s - loss: 0.8780 - val_loss: 0.5684
AUC: 0.8722

Epoch 28/30
 - 0s - loss: 0.8772 - val_loss: 0.5688
AUC: 0.8722

Epoch 29/30
 - 0s - loss: 0.8774 - val_loss: 0.5730
AUC: 0.8722

Epoch 30/30
 - 0s - loss: 0.8697 - val_loss: 0.5680
Using TensorFlow backend.
AUC: 0.8722

2019-03-08 07:52:20.666374: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:52:20.829697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:52:20.829741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:52:21.120479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:52:21.120530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:52:21.120540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:52:21.120796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3046
Epoch 2/80
 - 2s - loss: 0.3324
Epoch 3/80
 - 2s - loss: 0.2907
Epoch 4/80
 - 1s - loss: 0.2628
Epoch 5/80
 - 2s - loss: 0.2386
Epoch 6/80
 - 1s - loss: 0.2179
Epoch 7/80
 - 1s - loss: 0.2012
Epoch 8/80
 - 1s - loss: 0.1875
Epoch 9/80
 - 2s - loss: 0.1756
Epoch 10/80
 - 1s - loss: 0.1650
Epoch 11/80
 - 2s - loss: 0.1558
Epoch 12/80
 - 1s - loss: 0.1478
Epoch 13/80
 - 1s - loss: 0.1411
Epoch 14/80
 - 1s - loss: 0.1353
Epoch 15/80
 - 2s - loss: 0.1305
Epoch 16/80
 - 1s - loss: 0.1266
Epoch 17/80
 - 1s - loss: 0.1233
Epoch 18/80
 - 2s - loss: 0.1205
Epoch 19/80
 - 2s - loss: 0.1182
Epoch 20/80
 - 2s - loss: 0.1161
Epoch 21/80
 - 1s - loss: 0.1143
Epoch 22/80
 - 2s - loss: 0.1127
Epoch 23/80
 - 1s - loss: 0.1114
Epoch 24/80
 - 1s - loss: 0.1102
Epoch 25/80
 - 2s - loss: 0.1092
Epoch 26/80
 - 2s - loss: 0.1083
Epoch 27/80
 - 1s - loss: 0.1076
Epoch 28/80
 - 2s - loss: 0.1069
Epoch 29/80
 - 2s - loss: 0.1064
Epoch 30/80
 - 1s - loss: 0.1059
Epoch 31/80
 - 1s - loss: 0.1055
Epoch 32/80
 - 1s - loss: 0.1051
Epoch 33/80
 - 1s - loss: 0.1048
Epoch 34/80
 - 2s - loss: 0.1045
Epoch 35/80
 - 1s - loss: 0.1042
Epoch 36/80
 - 1s - loss: 0.1040
Epoch 37/80
 - 1s - loss: 0.1038
Epoch 38/80
 - 1s - loss: 0.1036
Epoch 39/80
 - 1s - loss: 0.1035
Epoch 40/80
 - 1s - loss: 0.1032
Epoch 41/80
 - 1s - loss: 0.1031
Epoch 42/80
 - 1s - loss: 0.1030
Epoch 43/80
 - 1s - loss: 0.1029
Epoch 44/80
 - 2s - loss: 0.1027
Epoch 45/80
 - 1s - loss: 0.1026
Epoch 46/80
 - 1s - loss: 0.1026
Epoch 47/80
 - 1s - loss: 0.1024
Epoch 48/80
 - 2s - loss: 0.1024
Epoch 49/80
 - 1s - loss: 0.1023
Epoch 50/80
 - 1s - loss: 0.1022
Epoch 51/80
 - 1s - loss: 0.1021
Epoch 52/80
 - 1s - loss: 0.1021
Epoch 53/80
 - 1s - loss: 0.1020
Epoch 54/80
 - 2s - loss: 0.1019
Epoch 55/80
 - 1s - loss: 0.1019
Epoch 56/80
 - 1s - loss: 0.1018
Epoch 57/80
 - 1s - loss: 0.1018
Epoch 58/80
 - 1s - loss: 0.1017
Epoch 59/80
 - 1s - loss: 0.1017
Epoch 60/80
 - 1s - loss: 0.1016
Epoch 61/80
 - 1s - loss: 0.1016
Epoch 62/80
 - 1s - loss: 0.1015
Epoch 63/80
 - 1s - loss: 0.1015
Epoch 64/80
 - 2s - loss: 0.1015
Epoch 65/80
 - 1s - loss: 0.1014
Epoch 66/80
 - 2s - loss: 0.1014
Epoch 67/80
 - 2s - loss: 0.1014
Epoch 68/80
 - 2s - loss: 0.1013
Epoch 69/80
 - 1s - loss: 0.0987
Epoch 70/80
 - 1s - loss: 0.0984
Epoch 71/80
 - 1s - loss: 0.0984
Epoch 72/80
 - 1s - loss: 0.0984
Epoch 73/80
 - 1s - loss: 0.0984
Epoch 74/80
 - 1s - loss: 0.0977
Epoch 75/80
 - 1s - loss: 0.0977
Epoch 76/80
 - 1s - loss: 0.0977
Epoch 77/80
 - 1s - loss: 0.0977
Epoch 78/80
 - 1s - loss: 0.0975
Epoch 79/80
 - 1s - loss: 0.0975
Epoch 80/80
 - 1s - loss: 0.0975
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0877 - val_loss: 1.0494
AUC: 0.7937

Epoch 2/80
 - 0s - loss: 1.9877 - val_loss: 0.9239
AUC: 0.8208

Epoch 3/80
 - 0s - loss: 1.5104 - val_loss: 0.7824
AUC: 0.8335

Epoch 4/80
 - 0s - loss: 1.2689 - val_loss: 0.7812
AUC: 0.8440

Epoch 5/80
 - 0s - loss: 1.1805 - val_loss: 0.7140
AUC: 0.8484

Epoch 6/80
 - 0s - loss: 1.1327 - val_loss: 0.7500
AUC: 0.8514

Epoch 7/80
 - 0s - loss: 1.0982 - val_loss: 0.6411
AUC: 0.8521

Epoch 8/80
 - 0s - loss: 1.0873 - val_loss: 0.6924
AUC: 0.8536

Epoch 9/80
 - 0s - loss: 1.0657 - val_loss: 0.6503
AUC: 0.8571

Epoch 10/80
 - 0s - loss: 1.0622 - val_loss: 0.7619
AUC: 0.8569

Epoch 11/80
 - 0s - loss: 1.0533 - val_loss: 0.6252
AUC: 0.8583

Epoch 12/80
 - 0s - loss: 1.0397 - val_loss: 0.6273
AUC: 0.8596

Epoch 13/80
 - 0s - loss: 1.0298 - val_loss: 0.6560
AUC: 0.8596

Epoch 14/80
 - 0s - loss: 1.0273 - val_loss: 0.6539
AUC: 0.8616

Epoch 15/80
 - 0s - loss: 1.0214 - val_loss: 0.6491
AUC: 0.8612

Epoch 16/80
 - 0s - loss: 1.0157 - val_loss: 0.5919
AUC: 0.8618

Epoch 17/80
 - 0s - loss: 1.0059 - val_loss: 0.6310
AUC: 0.8630

Epoch 18/80
 - 0s - loss: 1.0111 - val_loss: 0.6012
AUC: 0.8634

Epoch 19/80
 - 0s - loss: 0.9995 - val_loss: 0.5910
AUC: 0.8625

Epoch 20/80
 - 0s - loss: 1.0037 - val_loss: 0.5738
AUC: 0.8627

Epoch 21/80
 - 0s - loss: 0.9915 - val_loss: 0.6335
AUC: 0.8638

Epoch 22/80
 - 0s - loss: 0.9945 - val_loss: 0.5877
AUC: 0.8647

Epoch 23/80
 - 0s - loss: 0.9915 - val_loss: 0.5773
AUC: 0.8650

Epoch 24/80
 - 0s - loss: 0.9864 - val_loss: 0.6717
AUC: 0.8645

Epoch 25/80
 - 0s - loss: 0.9909 - val_loss: 0.5523
AUC: 0.8645

Epoch 26/80
 - 0s - loss: 0.9879 - val_loss: 0.5915
AUC: 0.8658

Epoch 27/80
 - 0s - loss: 0.9864 - val_loss: 0.6872
AUC: 0.8668

Epoch 28/80
 - 0s - loss: 0.9816 - val_loss: 0.5755
AUC: 0.8653

Epoch 29/80
 - 0s - loss: 0.9717 - val_loss: 0.6204
AUC: 0.8666

Epoch 30/80
 - 0s - loss: 0.9705 - val_loss: 0.5895
AUC: 0.8677

Epoch 31/80
 - 0s - loss: 0.9658 - val_loss: 0.5808
AUC: 0.8663

Epoch 32/80
 - 0s - loss: 0.9644 - val_loss: 0.5564
AUC: 0.8660

Epoch 33/80
 - 0s - loss: 0.9688 - val_loss: 0.6182
AUC: 0.8656

Epoch 34/80
 - 0s - loss: 0.9632 - val_loss: 0.5728
AUC: 0.8677

Epoch 35/80
 - 0s - loss: 0.9598 - val_loss: 0.5898
AUC: 0.8685

Epoch 36/80
 - 0s - loss: 0.9516 - val_loss: 0.5888
AUC: 0.8683

Epoch 37/80
 - 0s - loss: 0.9481 - val_loss: 0.6256
AUC: 0.8683

Epoch 38/80
 - 0s - loss: 0.9514 - val_loss: 0.5883
AUC: 0.8690

Epoch 39/80
 - 0s - loss: 0.9436 - val_loss: 0.5840
AUC: 0.8690

Epoch 40/80
 - 0s - loss: 0.9459 - val_loss: 0.5801
AUC: 0.8686

Epoch 41/80
 - 0s - loss: 0.9486 - val_loss: 0.6009
AUC: 0.8693

Epoch 42/80
 - 0s - loss: 0.9448 - val_loss: 0.5982
AUC: 0.8685

Epoch 43/80
 - 0s - loss: 0.9420 - val_loss: 0.5707
AUC: 0.8692

Epoch 44/80
 - 0s - loss: 0.9468 - val_loss: 0.6051
AUC: 0.8689

Epoch 45/80
 - 0s - loss: 0.9434 - val_loss: 0.5935
AUC: 0.8693

Epoch 46/80
 - 0s - loss: 0.9429 - val_loss: 0.6060
AUC: 0.8695

Epoch 47/80
 - 0s - loss: 0.9397 - val_loss: 0.5928
AUC: 0.8693

Epoch 48/80
 - 0s - loss: 0.9402 - val_loss: 0.5942
AUC: 0.8692

Epoch 49/80
 - 0s - loss: 0.9410 - val_loss: 0.5917
AUC: 0.8692

Epoch 50/80
 - 0s - loss: 0.9401 - val_loss: 0.5907
AUC: 0.8692

Epoch 51/80
 - 0s - loss: 0.9426 - val_loss: 0.5978
AUC: 0.8692

Epoch 52/80
 - 0s - loss: 0.9370 - val_loss: 0.5997
AUC: 0.8693

Epoch 53/80
 - 0s - loss: 0.9341 - val_loss: 0.5985
AUC: 0.8693

Epoch 54/80
 - 0s - loss: 0.9368 - val_loss: 0.5957
AUC: 0.8693

Epoch 55/80
 - 0s - loss: 0.9402 - val_loss: 0.5957
AUC: 0.8693

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9440 - val_loss: 0.6093
AUC: 0.8693

Epoch 2/30
 - 0s - loss: 0.9384 - val_loss: 0.5802
AUC: 0.8691

Epoch 3/30
 - 0s - loss: 0.9386 - val_loss: 0.5847
AUC: 0.8694

Epoch 4/30
 - 0s - loss: 0.9412 - val_loss: 0.6065
AUC: 0.8699

Epoch 5/30
 - 0s - loss: 0.9375 - val_loss: 0.6028
AUC: 0.8698

Epoch 6/30
 - 0s - loss: 0.9357 - val_loss: 0.6040
AUC: 0.8701

Epoch 7/30
 - 0s - loss: 0.9329 - val_loss: 0.5856
AUC: 0.8699

Epoch 8/30
 - 0s - loss: 0.9307 - val_loss: 0.5846
AUC: 0.8698

Epoch 9/30
 - 0s - loss: 0.9301 - val_loss: 0.6054
AUC: 0.8699

Epoch 10/30
 - 0s - loss: 0.9296 - val_loss: 0.5845
AUC: 0.8700

Epoch 11/30
 - 0s - loss: 0.9222 - val_loss: 0.5854
AUC: 0.8700

Epoch 12/30
 - 0s - loss: 0.9256 - val_loss: 0.5795
AUC: 0.8701

Epoch 13/30
 - 0s - loss: 0.9260 - val_loss: 0.5832
AUC: 0.8705

Epoch 14/30
 - 0s - loss: 0.9246 - val_loss: 0.5931
AUC: 0.8705

Epoch 15/30
 - 0s - loss: 0.9189 - val_loss: 0.5921
AUC: 0.8707

Epoch 16/30
 - 0s - loss: 0.9174 - val_loss: 0.5926
AUC: 0.8704

Epoch 17/30
 - 0s - loss: 0.9197 - val_loss: 0.5874
AUC: 0.8707

Epoch 18/30
 - 0s - loss: 0.9160 - val_loss: 0.5727
AUC: 0.8706

Epoch 19/30
 - 0s - loss: 0.9156 - val_loss: 0.5689
AUC: 0.8706

Epoch 20/30
 - 0s - loss: 0.9186 - val_loss: 0.5745
AUC: 0.8708

Epoch 21/30
 - 0s - loss: 0.9144 - val_loss: 0.5874
AUC: 0.8707

Epoch 22/30
 - 0s - loss: 0.9142 - val_loss: 0.5690
AUC: 0.8708

Epoch 23/30
 - 0s - loss: 0.9141 - val_loss: 0.5736
AUC: 0.8707

Epoch 24/30
 - 0s - loss: 0.9124 - val_loss: 0.5931
AUC: 0.8712

Epoch 25/30
 - 0s - loss: 0.9063 - val_loss: 0.5969
AUC: 0.8714

Epoch 26/30
 - 0s - loss: 0.9045 - val_loss: 0.5807
AUC: 0.8713

Epoch 27/30
 - 0s - loss: 0.9090 - val_loss: 0.6010
AUC: 0.8715

Epoch 28/30
 - 0s - loss: 0.9044 - val_loss: 0.5764
AUC: 0.8713

Epoch 29/30
 - 0s - loss: 0.9045 - val_loss: 0.5774
AUC: 0.8714

Epoch 30/30
 - 0s - loss: 0.9033 - val_loss: 0.5830
Using TensorFlow backend.
AUC: 0.8714

2019-03-08 07:55:39.831665: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:55:39.994495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:55:39.994540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:55:40.289202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:55:40.289251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:55:40.289261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:55:40.289550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0431
Epoch 2/80
 - 2s - loss: 0.1935
Epoch 3/80
 - 2s - loss: 0.1691
Epoch 4/80
 - 2s - loss: 0.1602
Epoch 5/80
 - 2s - loss: 0.1490
Epoch 6/80
 - 2s - loss: 0.1367
Epoch 7/80
 - 2s - loss: 0.1254
Epoch 8/80
 - 2s - loss: 0.1150
Epoch 9/80
 - 2s - loss: 0.1049
Epoch 10/80
 - 2s - loss: 0.0956
Epoch 11/80
 - 2s - loss: 0.0875
Epoch 12/80
 - 2s - loss: 0.0806
Epoch 13/80
 - 2s - loss: 0.0747
Epoch 14/80
 - 2s - loss: 0.0698
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:56:21.545284: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:56:21.709805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:56:21.709848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:56:21.997904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:56:21.997956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:56:21.997965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:56:21.998224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0714
Epoch 2/80
 - 2s - loss: 0.1950
Epoch 3/80
 - 1s - loss: 0.1698
Epoch 4/80
 - 1s - loss: 0.1599
Epoch 5/80
 - 1s - loss: 0.1463
Epoch 6/80
 - 1s - loss: 0.1311
Epoch 7/80
 - 1s - loss: 0.1183
Epoch 8/80
 - 2s - loss: 0.1078
Epoch 9/80
 - 1s - loss: 0.0987
Epoch 10/80
 - 1s - loss: 0.0909
Epoch 11/80
 - 1s - loss: 0.0841
Epoch 12/80
 - 1s - loss: 0.0783
Epoch 13/80
 - 1s - loss: 0.0734
Epoch 14/80
 - 1s - loss: 0.0693
Epoch 15/80
 - 1s - loss: 0.0657
Epoch 16/80
 - 1s - loss: 0.0628
Epoch 17/80
 - 1s - loss: 0.0602
Epoch 18/80
 - 1s - loss: 0.0581
Epoch 19/80
 - 1s - loss: 0.0562
Epoch 20/80
 - 1s - loss: 0.0546
Epoch 21/80
 - 1s - loss: 0.0533
Epoch 22/80
 - 1s - loss: 0.0521
Epoch 23/80
 - 1s - loss: 0.0511
Epoch 24/80
 - 1s - loss: 0.0502
Epoch 25/80
 - 1s - loss: 0.0494
Epoch 26/80
 - 1s - loss: 0.0488
Epoch 27/80
 - 2s - loss: 0.0483
Epoch 28/80
 - 2s - loss: 0.0478
Epoch 29/80
 - 2s - loss: 0.0473
Epoch 30/80
 - 1s - loss: 0.0470
Epoch 31/80
 - 1s - loss: 0.0467
Epoch 32/80
 - 1s - loss: 0.0464
Epoch 33/80
 - 1s - loss: 0.0461
Epoch 34/80
 - 1s - loss: 0.0459
Epoch 35/80
 - 1s - loss: 0.0457
Epoch 36/80
 - 1s - loss: 0.0455
Epoch 37/80
 - 1s - loss: 0.0454
Epoch 38/80
 - 1s - loss: 0.0452
Epoch 39/80
 - 1s - loss: 0.0451
Epoch 40/80
 - 1s - loss: 0.0450
Epoch 41/80
 - 1s - loss: 0.0449
Epoch 42/80
 - 1s - loss: 0.0448
Epoch 43/80
 - 1s - loss: 0.0447
Epoch 44/80
 - 1s - loss: 0.0446
Epoch 45/80
 - 1s - loss: 0.0446
Epoch 46/80
 - 1s - loss: 0.0445
Epoch 47/80
 - 1s - loss: 0.0444
Epoch 48/80
 - 2s - loss: 0.0443
Epoch 49/80
 - 1s - loss: 0.0443
Epoch 50/80
 - 1s - loss: 0.0442
Epoch 51/80
 - 1s - loss: 0.0442
Epoch 52/80
 - 1s - loss: 0.0441
Epoch 53/80
 - 1s - loss: 0.0441
Epoch 54/80
 - 1s - loss: 0.0441
Epoch 55/80
 - 1s - loss: 0.0440
Epoch 56/80
 - 1s - loss: 0.0440
Epoch 57/80
 - 1s - loss: 0.0439
Epoch 58/80
 - 1s - loss: 0.0439
Epoch 59/80
 - 1s - loss: 0.0439
Epoch 60/80
 - 1s - loss: 0.0438
Epoch 61/80
 - 1s - loss: 0.0438
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 07:58:19.116057: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:58:19.280214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:58:19.280267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:58:19.570588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:58:19.570638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:58:19.570647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:58:19.570895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0610
Epoch 2/80
 - 1s - loss: 0.1945
Epoch 3/80
 - 2s - loss: 0.1703
Epoch 4/80
 - 2s - loss: 0.1615
Epoch 5/80
 - 2s - loss: 0.1496
Epoch 6/80
 - 2s - loss: 0.1348
Epoch 7/80
 - 2s - loss: 0.1195
Epoch 8/80
 - 2s - loss: 0.1072
Epoch 9/80
 - 2s - loss: 0.0981
Epoch 10/80
 - 2s - loss: 0.0906
Epoch 11/80
 - 2s - loss: 0.0842
Epoch 12/80
 - 1s - loss: 0.0787
Epoch 13/80
 - 1s - loss: 0.0740
Epoch 14/80
 - 1s - loss: 0.0697
Epoch 15/80
 - 1s - loss: 0.0659
Epoch 16/80
 - 1s - loss: 0.0627
Epoch 17/80
 - 1s - loss: 0.0600
Epoch 18/80
 - 1s - loss: 0.0577
Epoch 19/80
 - 1s - loss: 0.0559
Epoch 20/80
 - 1s - loss: 0.0543
Epoch 21/80
 - 1s - loss: 0.0529
Epoch 22/80
 - 1s - loss: 0.0518
Epoch 23/80
 - 1s - loss: 0.0508
Epoch 24/80
 - 1s - loss: 0.0499
Epoch 25/80
 - 1s - loss: 0.0492
Epoch 26/80
 - 1s - loss: 0.0485
Epoch 27/80
 - 1s - loss: 0.0479
Epoch 28/80
 - 1s - loss: 0.0475
Epoch 29/80
 - 1s - loss: 0.0470
Epoch 30/80
 - 2s - loss: 0.0466
Epoch 31/80
 - 1s - loss: 0.0463
Epoch 32/80
 - 1s - loss: 0.0460
Epoch 33/80
 - 1s - loss: 0.0457
Epoch 34/80
 - 1s - loss: 0.0455
Epoch 35/80
 - 1s - loss: 0.0453
Epoch 36/80
 - 1s - loss: 0.0451
Epoch 37/80
 - 1s - loss: 0.0449
Epoch 38/80
 - 1s - loss: 0.0448
Epoch 39/80
 - 1s - loss: 0.0446
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 07:59:43.576513: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 07:59:43.739068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 07:59:43.739113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 07:59:44.029563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 07:59:44.029614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 07:59:44.029623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 07:59:44.029875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6434
Epoch 2/80
 - 2s - loss: 0.1016
Epoch 3/80
 - 2s - loss: 0.0693
Epoch 4/80
 - 2s - loss: 0.0643
Epoch 5/80
 - 2s - loss: 0.0608
Epoch 6/80
 - 2s - loss: 0.0564
Epoch 7/80
 - 2s - loss: 0.0518
Epoch 8/80
 - 2s - loss: 0.0479
Epoch 9/80
 - 2s - loss: 0.0443
Epoch 10/80
 - 2s - loss: 0.0407
Epoch 11/80
 - 2s - loss: 0.0372
Epoch 12/80
 - 2s - loss: 0.0340
Epoch 13/80
 - 2s - loss: 0.0311
Epoch 14/80
 - 2s - loss: 0.0288
Epoch 15/80
 - 2s - loss: 0.0269
Epoch 16/80
 - 2s - loss: 0.0252
Epoch 17/80
 - 1s - loss: 0.0237
Epoch 18/80
 - 2s - loss: 0.0225
Epoch 19/80
 - 2s - loss: 0.0214
Epoch 20/80
 - 2s - loss: 0.0205
Epoch 21/80
 - 2s - loss: 0.0197
Epoch 22/80
 - 1s - loss: 0.0190
Epoch 23/80
 - 2s - loss: 0.0184
Epoch 24/80
 - 2s - loss: 0.0179
Epoch 25/80
 - 1s - loss: 0.0174
Epoch 26/80
 - 1s - loss: 0.0171
Epoch 27/80
 - 2s - loss: 0.0167
Epoch 28/80
 - 1s - loss: 0.0164
Epoch 29/80
 - 2s - loss: 0.0162
Epoch 30/80
 - 2s - loss: 0.0159
Epoch 31/80
 - 1s - loss: 0.0157
Epoch 32/80
 - 2s - loss: 0.0155
Epoch 33/80
 - 2s - loss: 0.0154
Epoch 34/80
 - 2s - loss: 0.0153
Epoch 35/80
 - 2s - loss: 0.0151
Epoch 36/80
 - 2s - loss: 0.0150
Epoch 37/80
 - 2s - loss: 0.0149
Epoch 38/80
 - 2s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0148
Epoch 40/80
 - 1s - loss: 0.0147
Epoch 41/80
 - 1s - loss: 0.0146
Epoch 42/80
 - 1s - loss: 0.0146
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0145
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 2s - loss: 0.0144
Epoch 48/80
 - 2s - loss: 0.0143
Epoch 49/80
 - 2s - loss: 0.0143
Epoch 50/80
 - 2s - loss: 0.0143
Epoch 51/80
 - 2s - loss: 0.0142
Epoch 52/80
 - 2s - loss: 0.0138
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 2s - loss: 0.0137
Epoch 55/80
 - 2s - loss: 0.0137
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 1s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0136
Epoch 62/80
 - 2s - loss: 0.0136
Epoch 63/80
 - 1s - loss: 0.0136
Epoch 64/80
 - 2s - loss: 0.0136
Epoch 65/80
 - 2s - loss: 0.0136
Epoch 66/80
 - 2s - loss: 0.0136
Epoch 67/80
 - 2s - loss: 0.0136
Epoch 68/80
 - 2s - loss: 0.0136
Epoch 69/80
 - 2s - loss: 0.0136
Epoch 70/80
 - 2s - loss: 0.0136
Epoch 71/80
 - 2s - loss: 0.0136
Epoch 72/80
 - 2s - loss: 0.0136
Epoch 73/80
 - 2s - loss: 0.0136
Epoch 74/80
 - 1s - loss: 0.0136
Epoch 75/80
 - 2s - loss: 0.0136
Epoch 76/80
 - 1s - loss: 0.0136
Epoch 77/80
 - 1s - loss: 0.0136
Epoch 78/80
 - 2s - loss: 0.0136
Epoch 79/80
 - 2s - loss: 0.0136
Epoch 80/80
 - 1s - loss: 0.0136
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.1428 - val_loss: 1.7351
AUC: 0.7772

Epoch 2/80
 - 0s - loss: 2.7259 - val_loss: 1.2577
AUC: 0.8082

Epoch 3/80
 - 0s - loss: 1.8826 - val_loss: 0.9157
AUC: 0.8257

Epoch 4/80
 - 0s - loss: 1.4071 - val_loss: 0.7367
AUC: 0.8311

Epoch 5/80
 - 0s - loss: 1.2330 - val_loss: 0.7462
AUC: 0.8377

Epoch 6/80
 - 0s - loss: 1.1591 - val_loss: 0.6487
AUC: 0.8395

Epoch 7/80
 - 0s - loss: 1.1128 - val_loss: 0.7262
AUC: 0.8449

Epoch 8/80
 - 0s - loss: 1.0937 - val_loss: 0.7139
AUC: 0.8474

Epoch 9/80
 - 0s - loss: 1.0931 - val_loss: 0.6532
AUC: 0.8478

Epoch 10/80
 - 0s - loss: 1.0685 - val_loss: 0.7053
AUC: 0.8514

Epoch 11/80
 - 0s - loss: 1.0599 - val_loss: 0.6323
AUC: 0.8520

Epoch 12/80
 - 0s - loss: 1.0502 - val_loss: 0.6254
AUC: 0.8527

Epoch 13/80
 - 0s - loss: 1.0318 - val_loss: 0.6201
AUC: 0.8545

Epoch 14/80
 - 0s - loss: 1.0291 - val_loss: 0.5883
AUC: 0.8537

Epoch 15/80
 - 0s - loss: 1.0282 - val_loss: 0.6403
AUC: 0.8523

Epoch 16/80
 - 0s - loss: 1.0247 - val_loss: 0.6453
AUC: 0.8550

Epoch 17/80
 - 0s - loss: 1.0294 - val_loss: 0.5888
AUC: 0.8549

Epoch 18/80
 - 0s - loss: 1.0226 - val_loss: 0.6189
AUC: 0.8567

Epoch 19/80
 - 0s - loss: 1.0242 - val_loss: 0.6585
AUC: 0.8573

Epoch 20/80
 - 0s - loss: 1.0061 - val_loss: 0.6164
AUC: 0.8565

Epoch 21/80
 - 0s - loss: 1.0101 - val_loss: 0.5728
AUC: 0.8574

Epoch 22/80
 - 0s - loss: 1.0061 - val_loss: 0.6975
AUC: 0.8576

Epoch 23/80
 - 0s - loss: 0.9967 - val_loss: 0.6162
AUC: 0.8587

Epoch 24/80
 - 0s - loss: 0.9934 - val_loss: 0.5638
AUC: 0.8583

Epoch 25/80
 - 0s - loss: 0.9909 - val_loss: 0.6353
AUC: 0.8599

Epoch 26/80
 - 0s - loss: 0.9816 - val_loss: 0.6091
AUC: 0.8601

Epoch 27/80
 - 0s - loss: 0.9842 - val_loss: 0.6074
AUC: 0.8584

Epoch 28/80
 - 0s - loss: 0.9874 - val_loss: 0.6177
AUC: 0.8608

Epoch 29/80
 - 0s - loss: 0.9752 - val_loss: 0.5728
AUC: 0.8604

Epoch 30/80
 - 0s - loss: 0.9752 - val_loss: 0.6047
AUC: 0.8603

Epoch 31/80
 - 0s - loss: 0.9765 - val_loss: 0.5628
AUC: 0.8595

Epoch 32/80
 - 0s - loss: 0.9765 - val_loss: 0.6036
AUC: 0.8613

Epoch 33/80
 - 0s - loss: 0.9743 - val_loss: 0.5781
AUC: 0.8617

Epoch 34/80
 - 0s - loss: 0.9703 - val_loss: 0.6210
AUC: 0.8614

Epoch 35/80
 - 0s - loss: 0.9693 - val_loss: 0.6428
AUC: 0.8619

Epoch 36/80
 - 0s - loss: 0.9643 - val_loss: 0.5783
AUC: 0.8618

Epoch 37/80
 - 0s - loss: 0.9659 - val_loss: 0.5841
AUC: 0.8619

Epoch 38/80
 - 0s - loss: 0.9584 - val_loss: 0.6487
AUC: 0.8606

Epoch 39/80
 - 0s - loss: 0.9593 - val_loss: 0.5590
AUC: 0.8617

Epoch 40/80
 - 0s - loss: 0.9540 - val_loss: 0.5692
AUC: 0.8622

Epoch 41/80
 - 0s - loss: 0.9546 - val_loss: 0.6558
AUC: 0.8624

Epoch 42/80
 - 0s - loss: 0.9572 - val_loss: 0.5852
AUC: 0.8626

Epoch 43/80
 - 0s - loss: 0.9509 - val_loss: 0.6162
AUC: 0.8634

Epoch 44/80
 - 0s - loss: 0.9483 - val_loss: 0.5917
AUC: 0.8617

Epoch 45/80
 - 0s - loss: 0.9464 - val_loss: 0.6019
AUC: 0.8639

Epoch 46/80
 - 0s - loss: 0.9430 - val_loss: 0.6109
AUC: 0.8636

Epoch 47/80
 - 0s - loss: 0.9430 - val_loss: 0.5181
AUC: 0.8635

Epoch 48/80
 - 0s - loss: 0.9400 - val_loss: 0.5891
AUC: 0.8622

Epoch 49/80
 - 0s - loss: 0.9421 - val_loss: 0.5442
AUC: 0.8637

Epoch 50/80
 - 0s - loss: 0.9389 - val_loss: 0.5608
AUC: 0.8645

Epoch 51/80
 - 0s - loss: 0.9366 - val_loss: 0.5585
AUC: 0.8640

Epoch 52/80
 - 0s - loss: 0.9294 - val_loss: 0.5984
AUC: 0.8622

Epoch 53/80
 - 0s - loss: 0.9260 - val_loss: 0.5292
AUC: 0.8625

Epoch 54/80
 - 0s - loss: 0.9258 - val_loss: 0.6206
AUC: 0.8634

Epoch 55/80
 - 0s - loss: 0.9388 - val_loss: 0.5322
AUC: 0.8648

Epoch 56/80
 - 0s - loss: 0.9270 - val_loss: 0.5738
AUC: 0.8640

Epoch 57/80
 - 0s - loss: 0.9225 - val_loss: 0.5465
AUC: 0.8644

Epoch 58/80
 - 0s - loss: 0.9171 - val_loss: 0.5941
AUC: 0.8643

Epoch 59/80
 - 0s - loss: 0.9106 - val_loss: 0.5739
AUC: 0.8646

Epoch 60/80
 - 0s - loss: 0.9084 - val_loss: 0.5895
AUC: 0.8647

Epoch 61/80
 - 0s - loss: 0.9088 - val_loss: 0.5726
AUC: 0.8645

Epoch 62/80
 - 0s - loss: 0.9051 - val_loss: 0.5930
AUC: 0.8645

Epoch 63/80
 - 0s - loss: 0.9076 - val_loss: 0.5811
AUC: 0.8645

Epoch 64/80
 - 0s - loss: 0.9036 - val_loss: 0.5673
AUC: 0.8646

Epoch 65/80
 - 0s - loss: 0.9077 - val_loss: 0.5601
AUC: 0.8645

Epoch 66/80
 - 0s - loss: 0.9077 - val_loss: 0.5891
AUC: 0.8647

Epoch 67/80
 - 0s - loss: 0.9073 - val_loss: 0.5961
AUC: 0.8645

Epoch 68/80
 - 0s - loss: 0.9025 - val_loss: 0.5712
AUC: 0.8645

Epoch 69/80
 - 0s - loss: 0.8956 - val_loss: 0.5684
AUC: 0.8644

Epoch 70/80
 - 0s - loss: 0.8967 - val_loss: 0.5821
AUC: 0.8645

Epoch 71/80
 - 0s - loss: 0.9041 - val_loss: 0.5788
AUC: 0.8644

Epoch 72/80
 - 0s - loss: 0.9001 - val_loss: 0.5801
AUC: 0.8645

Epoch 73/80
 - 0s - loss: 0.9014 - val_loss: 0.5835
AUC: 0.8644

Epoch 74/80
 - 0s - loss: 0.9026 - val_loss: 0.5739
AUC: 0.8644

Epoch 75/80
 - 0s - loss: 0.8997 - val_loss: 0.5803
AUC: 0.8644

Epoch 76/80
 - 0s - loss: 0.8988 - val_loss: 0.5684
AUC: 0.8643

Epoch 77/80
 - 0s - loss: 0.8996 - val_loss: 0.5718
AUC: 0.8644

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9181 - val_loss: 0.5629
AUC: 0.8648

Epoch 2/30
 - 0s - loss: 0.9124 - val_loss: 0.5878
AUC: 0.8649

Epoch 3/30
 - 0s - loss: 0.9087 - val_loss: 0.5717
AUC: 0.8644

Epoch 4/30
 - 0s - loss: 0.9091 - val_loss: 0.5761
AUC: 0.8645

Epoch 5/30
 - 0s - loss: 0.9046 - val_loss: 0.5695
AUC: 0.8646

Epoch 6/30
 - 0s - loss: 0.9070 - val_loss: 0.5745
AUC: 0.8647

Epoch 7/30
 - 0s - loss: 0.9013 - val_loss: 0.5768
AUC: 0.8648

Epoch 8/30
 - 0s - loss: 0.8985 - val_loss: 0.5838
AUC: 0.8648

Epoch 9/30
 - 0s - loss: 0.9025 - val_loss: 0.5760
AUC: 0.8648

Epoch 10/30
 - 0s - loss: 0.8962 - val_loss: 0.5637
AUC: 0.8649

Epoch 11/30
 - 0s - loss: 0.8931 - val_loss: 0.5622
AUC: 0.8650

Epoch 12/30
 - 0s - loss: 0.8914 - val_loss: 0.5692
AUC: 0.8650

Epoch 13/30
 - 0s - loss: 0.8919 - val_loss: 0.6000
AUC: 0.8653

Epoch 14/30
 - 0s - loss: 0.8912 - val_loss: 0.5527
AUC: 0.8651

Epoch 15/30
 - 0s - loss: 0.8915 - val_loss: 0.5726
AUC: 0.8652

Epoch 16/30
 - 0s - loss: 0.8881 - val_loss: 0.5571
AUC: 0.8652

Epoch 17/30
 - 0s - loss: 0.8875 - val_loss: 0.5759
AUC: 0.8655

Epoch 18/30
 - 0s - loss: 0.8903 - val_loss: 0.5750
AUC: 0.8652

Epoch 19/30
 - 0s - loss: 0.8845 - val_loss: 0.5700
AUC: 0.8654

Epoch 20/30
 - 0s - loss: 0.8821 - val_loss: 0.5860
AUC: 0.8655

Epoch 21/30
 - 0s - loss: 0.8798 - val_loss: 0.5764
AUC: 0.8655

Epoch 22/30
 - 0s - loss: 0.8852 - val_loss: 0.5731
AUC: 0.8656

Epoch 23/30
 - 0s - loss: 0.8763 - val_loss: 0.5787
AUC: 0.8657

Epoch 24/30
 - 0s - loss: 0.8764 - val_loss: 0.5627
AUC: 0.8657

Epoch 25/30
 - 0s - loss: 0.8752 - val_loss: 0.5706
AUC: 0.8657

Epoch 26/30
 - 0s - loss: 0.8771 - val_loss: 0.5675
AUC: 0.8657

Epoch 27/30
 - 0s - loss: 0.8745 - val_loss: 0.5649
AUC: 0.8656

Epoch 28/30
 - 0s - loss: 0.8757 - val_loss: 0.5662
AUC: 0.8656

Epoch 29/30
 - 0s - loss: 0.8758 - val_loss: 0.5695
AUC: 0.8657

Epoch 30/30
 - 0s - loss: 0.8727 - val_loss: 0.5681
Using TensorFlow backend.
AUC: 0.8657

2019-03-08 08:03:14.301669: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:03:14.465149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:03:14.465199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:03:14.756014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:03:14.756065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:03:14.756075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:03:14.756338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6583
Epoch 2/80
 - 2s - loss: 0.1034
Epoch 3/80
 - 2s - loss: 0.0696
Epoch 4/80
 - 2s - loss: 0.0646
Epoch 5/80
 - 1s - loss: 0.0624
Epoch 6/80
 - 2s - loss: 0.0600
Epoch 7/80
 - 2s - loss: 0.0565
Epoch 8/80
 - 2s - loss: 0.0518
Epoch 9/80
 - 2s - loss: 0.0463
Epoch 10/80
 - 2s - loss: 0.0411
Epoch 11/80
 - 2s - loss: 0.0367
Epoch 12/80
 - 1s - loss: 0.0330
Epoch 13/80
 - 2s - loss: 0.0301
Epoch 14/80
 - 1s - loss: 0.0277
Epoch 15/80
 - 1s - loss: 0.0257
Epoch 16/80
 - 2s - loss: 0.0240
Epoch 17/80
 - 1s - loss: 0.0226
Epoch 18/80
 - 2s - loss: 0.0214
Epoch 19/80
 - 2s - loss: 0.0204
Epoch 20/80
 - 1s - loss: 0.0196
Epoch 21/80
 - 1s - loss: 0.0189
Epoch 22/80
 - 2s - loss: 0.0183
Epoch 23/80
 - 1s - loss: 0.0178
Epoch 24/80
 - 1s - loss: 0.0174
Epoch 25/80
 - 1s - loss: 0.0170
Epoch 26/80
 - 1s - loss: 0.0166
Epoch 27/80
 - 2s - loss: 0.0163
Epoch 28/80
 - 1s - loss: 0.0161
Epoch 29/80
 - 2s - loss: 0.0159
Epoch 30/80
 - 1s - loss: 0.0157
Epoch 31/80
 - 2s - loss: 0.0155
Epoch 32/80
 - 1s - loss: 0.0153
Epoch 33/80
 - 2s - loss: 0.0152
Epoch 34/80
 - 1s - loss: 0.0151
Epoch 35/80
 - 2s - loss: 0.0150
Epoch 36/80
 - 1s - loss: 0.0149
Epoch 37/80
 - 1s - loss: 0.0148
Epoch 38/80
 - 1s - loss: 0.0147
Epoch 39/80
 - 2s - loss: 0.0147
Epoch 40/80
 - 1s - loss: 0.0146
Epoch 41/80
 - 1s - loss: 0.0145
Epoch 42/80
 - 1s - loss: 0.0145
Epoch 43/80
 - 1s - loss: 0.0144
Epoch 44/80
 - 1s - loss: 0.0144
Epoch 45/80
 - 1s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0143
Epoch 47/80
 - 2s - loss: 0.0143
Epoch 48/80
 - 1s - loss: 0.0143
Epoch 49/80
 - 2s - loss: 0.0142
Epoch 50/80
 - 1s - loss: 0.0142
Epoch 51/80
 - 1s - loss: 0.0142
Epoch 52/80
 - 2s - loss: 0.0137
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 1s - loss: 0.0137
Epoch 55/80
 - 1s - loss: 0.0137
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 1s - loss: 0.0135
Epoch 58/80
 - 2s - loss: 0.0135
Epoch 59/80
 - 1s - loss: 0.0135
Epoch 60/80
 - 1s - loss: 0.0135
Epoch 61/80
 - 1s - loss: 0.0135
Epoch 62/80
 - 1s - loss: 0.0135
Epoch 63/80
 - 1s - loss: 0.0135
Epoch 64/80
 - 1s - loss: 0.0135
Epoch 65/80
 - 1s - loss: 0.0135
Epoch 66/80
 - 2s - loss: 0.0135
Epoch 67/80
 - 1s - loss: 0.0135
Epoch 68/80
 - 2s - loss: 0.0135
Epoch 69/80
 - 1s - loss: 0.0135
Epoch 70/80
 - 2s - loss: 0.0135
Epoch 71/80
 - 2s - loss: 0.0135
Epoch 72/80
 - 2s - loss: 0.0135
Epoch 73/80
 - 1s - loss: 0.0135
Epoch 74/80
 - 2s - loss: 0.0135
Epoch 75/80
 - 2s - loss: 0.0135
Epoch 76/80
 - 1s - loss: 0.0135
Epoch 77/80
 - 1s - loss: 0.0135
Epoch 78/80
 - 2s - loss: 0.0135
Epoch 79/80
 - 1s - loss: 0.0135
Epoch 80/80
 - 1s - loss: 0.0135
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.6573 - val_loss: 1.1663
AUC: 0.8059

Epoch 2/80
 - 0s - loss: 2.4337 - val_loss: 0.7414
AUC: 0.8293

Epoch 3/80
 - 0s - loss: 1.7122 - val_loss: 0.7479
AUC: 0.8362

Epoch 4/80
 - 0s - loss: 1.3348 - val_loss: 0.8137
AUC: 0.8415

Epoch 5/80
 - 0s - loss: 1.2200 - val_loss: 0.7261
AUC: 0.8476

Epoch 6/80
 - 0s - loss: 1.1497 - val_loss: 0.6520
AUC: 0.8495

Epoch 7/80
 - 0s - loss: 1.1227 - val_loss: 0.6319
AUC: 0.8519

Epoch 8/80
 - 0s - loss: 1.1011 - val_loss: 0.6590
AUC: 0.8570

Epoch 9/80
 - 0s - loss: 1.0812 - val_loss: 0.6048
AUC: 0.8572

Epoch 10/80
 - 0s - loss: 1.0798 - val_loss: 0.6086
AUC: 0.8577

Epoch 11/80
 - 0s - loss: 1.0582 - val_loss: 0.6388
AUC: 0.8607

Epoch 12/80
 - 0s - loss: 1.0547 - val_loss: 0.6356
AUC: 0.8616

Epoch 13/80
 - 0s - loss: 1.0543 - val_loss: 0.7124
AUC: 0.8623

Epoch 14/80
 - 0s - loss: 1.0498 - val_loss: 0.5471
AUC: 0.8601

Epoch 15/80
 - 0s - loss: 1.0315 - val_loss: 0.5924
AUC: 0.8619

Epoch 16/80
 - 0s - loss: 1.0325 - val_loss: 0.6319
AUC: 0.8639

Epoch 17/80
 - 0s - loss: 1.0226 - val_loss: 0.6634
AUC: 0.8643

Epoch 18/80
 - 0s - loss: 1.0231 - val_loss: 0.6985
AUC: 0.8652

Epoch 19/80
 - 0s - loss: 1.0148 - val_loss: 0.6648
AUC: 0.8668

Epoch 20/80
 - 0s - loss: 1.0163 - val_loss: 0.5934
AUC: 0.8657

Epoch 21/80
 - 0s - loss: 1.0121 - val_loss: 0.6029
AUC: 0.8657

Epoch 22/80
 - 0s - loss: 1.0002 - val_loss: 0.5669
AUC: 0.8661

Epoch 23/80
 - 0s - loss: 1.0017 - val_loss: 0.6451
AUC: 0.8671

Epoch 24/80
 - 0s - loss: 1.0068 - val_loss: 0.6766
AUC: 0.8681

Epoch 25/80
 - 0s - loss: 0.9956 - val_loss: 0.6389
AUC: 0.8681

Epoch 26/80
 - 0s - loss: 0.9925 - val_loss: 0.6370
AUC: 0.8682

Epoch 27/80
 - 0s - loss: 0.9865 - val_loss: 0.6127
AUC: 0.8683

Epoch 28/80
 - 0s - loss: 0.9901 - val_loss: 0.5882
AUC: 0.8681

Epoch 29/80
 - 0s - loss: 0.9850 - val_loss: 0.6103
AUC: 0.8683

Epoch 30/80
 - 0s - loss: 0.9887 - val_loss: 0.6012
AUC: 0.8683

Epoch 31/80
 - 0s - loss: 0.9850 - val_loss: 0.6453
AUC: 0.8685

Epoch 32/80
 - 0s - loss: 0.9871 - val_loss: 0.6489
AUC: 0.8688

Epoch 33/80
 - 0s - loss: 0.9813 - val_loss: 0.6029
AUC: 0.8681

Epoch 34/80
 - 0s - loss: 0.9916 - val_loss: 0.6353
AUC: 0.8686

Epoch 35/80
 - 0s - loss: 0.9742 - val_loss: 0.5972
AUC: 0.8684

Epoch 36/80
 - 0s - loss: 0.9825 - val_loss: 0.6063
AUC: 0.8685

Epoch 37/80
 - 0s - loss: 0.9813 - val_loss: 0.6140
AUC: 0.8685

Epoch 38/80
 - 0s - loss: 0.9784 - val_loss: 0.6109
AUC: 0.8685

Epoch 39/80
 - 0s - loss: 0.9792 - val_loss: 0.6045
AUC: 0.8684

Epoch 40/80
 - 0s - loss: 0.9796 - val_loss: 0.6057
AUC: 0.8684

Epoch 41/80
 - 0s - loss: 0.9762 - val_loss: 0.6018
AUC: 0.8685

Epoch 42/80
 - 0s - loss: 0.9795 - val_loss: 0.6086
AUC: 0.8685

Epoch 43/80
 - 0s - loss: 0.9838 - val_loss: 0.6140
AUC: 0.8686

Epoch 44/80
 - 0s - loss: 0.9787 - val_loss: 0.6187
AUC: 0.8686

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9813 - val_loss: 0.6177
AUC: 0.8688

Epoch 2/30
 - 0s - loss: 0.9838 - val_loss: 0.6256
AUC: 0.8688

Epoch 3/30
 - 0s - loss: 0.9802 - val_loss: 0.6128
AUC: 0.8687

Epoch 4/30
 - 0s - loss: 0.9775 - val_loss: 0.6112
AUC: 0.8689

Epoch 5/30
 - 0s - loss: 0.9751 - val_loss: 0.6199
AUC: 0.8691

Epoch 6/30
 - 0s - loss: 0.9764 - val_loss: 0.6001
AUC: 0.8692

Epoch 7/30
 - 0s - loss: 0.9697 - val_loss: 0.5981
AUC: 0.8693

Epoch 8/30
 - 0s - loss: 0.9711 - val_loss: 0.5941
AUC: 0.8695

Epoch 9/30
 - 0s - loss: 0.9726 - val_loss: 0.6052
AUC: 0.8697

Epoch 10/30
 - 0s - loss: 0.9660 - val_loss: 0.6096
AUC: 0.8699

Epoch 11/30
 - 0s - loss: 0.9650 - val_loss: 0.5898
AUC: 0.8699

Epoch 12/30
 - 0s - loss: 0.9630 - val_loss: 0.6050
AUC: 0.8699

Epoch 13/30
 - 0s - loss: 0.9596 - val_loss: 0.5706
AUC: 0.8697

Epoch 14/30
 - 0s - loss: 0.9621 - val_loss: 0.5922
AUC: 0.8701

Epoch 15/30
 - 0s - loss: 0.9637 - val_loss: 0.5813
AUC: 0.8702

Epoch 16/30
 - 0s - loss: 0.9588 - val_loss: 0.6183
AUC: 0.8707

Epoch 17/30
 - 0s - loss: 0.9586 - val_loss: 0.5994
AUC: 0.8707

Epoch 18/30
 - 0s - loss: 0.9624 - val_loss: 0.6146
AUC: 0.8709

Epoch 19/30
 - 0s - loss: 0.9547 - val_loss: 0.5935
AUC: 0.8708

Epoch 20/30
 - 0s - loss: 0.9543 - val_loss: 0.5776
AUC: 0.8707

Epoch 21/30
 - 0s - loss: 0.9499 - val_loss: 0.5903
AUC: 0.8710

Epoch 22/30
 - 0s - loss: 0.9499 - val_loss: 0.5863
AUC: 0.8708

Epoch 23/30
 - 0s - loss: 0.9490 - val_loss: 0.5878
AUC: 0.8713

Epoch 24/30
 - 0s - loss: 0.9478 - val_loss: 0.5914
AUC: 0.8714

Epoch 25/30
 - 0s - loss: 0.9469 - val_loss: 0.5929
AUC: 0.8714

Epoch 26/30
 - 0s - loss: 0.9469 - val_loss: 0.5997
AUC: 0.8715

Epoch 27/30
 - 0s - loss: 0.9492 - val_loss: 0.5928
AUC: 0.8714

Epoch 28/30
 - 0s - loss: 0.9456 - val_loss: 0.5979
AUC: 0.8714

Epoch 29/30
 - 0s - loss: 0.9477 - val_loss: 0.5908
AUC: 0.8714

Epoch 30/30
 - 0s - loss: 0.9440 - val_loss: 0.5968
Using TensorFlow backend.
AUC: 0.8714

2019-03-08 08:06:27.951693: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:06:28.115225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:06:28.115279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:06:28.409069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:06:28.409119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:06:28.409128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:06:28.409390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6400
Epoch 2/80
 - 1s - loss: 0.0984
Epoch 3/80
 - 1s - loss: 0.0693
Epoch 4/80
 - 2s - loss: 0.0653
Epoch 5/80
 - 1s - loss: 0.0631
Epoch 6/80
 - 1s - loss: 0.0604
Epoch 7/80
 - 1s - loss: 0.0565
Epoch 8/80
 - 1s - loss: 0.0514
Epoch 9/80
 - 1s - loss: 0.0460
Epoch 10/80
 - 1s - loss: 0.0414
Epoch 11/80
 - 1s - loss: 0.0376
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:07:04.427984: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:07:04.597396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:07:04.597442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:07:04.900634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:07:04.900685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:07:04.900704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:07:04.900957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3197
Epoch 2/80
 - 1s - loss: 0.3325
Epoch 3/80
 - 1s - loss: 0.2933
Epoch 4/80
 - 1s - loss: 0.2618
Epoch 5/80
 - 1s - loss: 0.2372
Epoch 6/80
 - 1s - loss: 0.2179
Epoch 7/80
 - 1s - loss: 0.2007
Epoch 8/80
 - 1s - loss: 0.1854
Epoch 9/80
 - 1s - loss: 0.1727
Epoch 10/80
 - 1s - loss: 0.1621
Epoch 11/80
 - 1s - loss: 0.1533
Epoch 12/80
 - 1s - loss: 0.1458
Epoch 13/80
 - 1s - loss: 0.1395
Epoch 14/80
 - 1s - loss: 0.1341
Epoch 15/80
 - 1s - loss: 0.1297
Epoch 16/80
 - 1s - loss: 0.1260
Epoch 17/80
 - 1s - loss: 0.1230
Epoch 18/80
 - 1s - loss: 0.1203
Epoch 19/80
 - 1s - loss: 0.1179
Epoch 20/80
 - 1s - loss: 0.1159
Epoch 21/80
 - 1s - loss: 0.1140
Epoch 22/80
 - 1s - loss: 0.1125
Epoch 23/80
 - 1s - loss: 0.1111
Epoch 24/80
 - 1s - loss: 0.1099
Epoch 25/80
 - 1s - loss: 0.1089
Epoch 26/80
 - 1s - loss: 0.1080
Epoch 27/80
 - 1s - loss: 0.1073
Epoch 28/80
 - 1s - loss: 0.1066
Epoch 29/80
 - 1s - loss: 0.1060
Epoch 30/80
 - 1s - loss: 0.1056
Epoch 31/80
 - 1s - loss: 0.1051
Epoch 32/80
 - 1s - loss: 0.1047
Epoch 33/80
 - 1s - loss: 0.1044
Epoch 34/80
 - 1s - loss: 0.1041
Epoch 35/80
 - 1s - loss: 0.1038
Epoch 36/80
 - 1s - loss: 0.1036
Epoch 37/80
 - 1s - loss: 0.1034
Epoch 38/80
 - 1s - loss: 0.1032
Epoch 39/80
 - 1s - loss: 0.1030
Epoch 40/80
 - 1s - loss: 0.1028
Epoch 41/80
 - 2s - loss: 0.1027
Epoch 42/80
 - 1s - loss: 0.1025
Epoch 43/80
 - 1s - loss: 0.1024
Epoch 44/80
 - 1s - loss: 0.1023
Epoch 45/80
 - 1s - loss: 0.1022
Epoch 46/80
 - 1s - loss: 0.1021
Epoch 47/80
 - 1s - loss: 0.1020
Epoch 48/80
 - 1s - loss: 0.1019
Epoch 49/80
 - 1s - loss: 0.1018
Epoch 50/80
 - 1s - loss: 0.1017
Epoch 51/80
 - 1s - loss: 0.1016
Epoch 52/80
 - 1s - loss: 0.1016
Epoch 53/80
 - 1s - loss: 0.1015
Epoch 54/80
 - 1s - loss: 0.1015
Epoch 55/80
 - 1s - loss: 0.1014
Epoch 56/80
 - 1s - loss: 0.1013
Epoch 57/80
 - 1s - loss: 0.1013
Epoch 58/80
 - 1s - loss: 0.1012
Epoch 59/80
 - 1s - loss: 0.1012
Epoch 60/80
 - 1s - loss: 0.1011
Epoch 61/80
 - 1s - loss: 0.1011
Epoch 62/80
 - 1s - loss: 0.1011
Epoch 63/80
 - 1s - loss: 0.1010
Epoch 64/80
 - 1s - loss: 0.1009
Epoch 65/80
 - 1s - loss: 0.1009
Epoch 66/80
 - 1s - loss: 0.1009
Epoch 67/80
 - 1s - loss: 0.1009
Epoch 68/80
 - 1s - loss: 0.0982
Epoch 69/80
 - 1s - loss: 0.0979
Epoch 70/80
 - 1s - loss: 0.0979
Epoch 71/80
 - 1s - loss: 0.0979
Epoch 72/80
 - 1s - loss: 0.0979
Epoch 73/80
 - 1s - loss: 0.0972
Epoch 74/80
 - 1s - loss: 0.0972
Epoch 75/80
 - 1s - loss: 0.0972
Epoch 76/80
 - 1s - loss: 0.0972
Epoch 77/80
 - 1s - loss: 0.0971
Epoch 78/80
 - 2s - loss: 0.0971
Epoch 79/80
 - 2s - loss: 0.0971
Epoch 80/80
 - 2s - loss: 0.0971
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.3913 - val_loss: 1.3003
AUC: 0.8039

Epoch 2/80
 - 0s - loss: 2.3045 - val_loss: 1.0537
AUC: 0.8386

Epoch 3/80
 - 0s - loss: 1.6637 - val_loss: 0.7543
AUC: 0.8470

Epoch 4/80
 - 0s - loss: 1.3266 - val_loss: 0.6707
AUC: 0.8505

Epoch 5/80
 - 0s - loss: 1.2038 - val_loss: 0.6880
AUC: 0.8540

Epoch 6/80
 - 0s - loss: 1.1446 - val_loss: 0.7588
AUC: 0.8604

Epoch 7/80
 - 0s - loss: 1.1245 - val_loss: 0.6608
AUC: 0.8599

Epoch 8/80
 - 0s - loss: 1.0974 - val_loss: 0.6442
AUC: 0.8637

Epoch 9/80
 - 0s - loss: 1.0692 - val_loss: 0.6538
AUC: 0.8650

Epoch 10/80
 - 0s - loss: 1.0583 - val_loss: 0.7552
AUC: 0.8665

Epoch 11/80
 - 0s - loss: 1.0486 - val_loss: 0.6588
AUC: 0.8661

Epoch 12/80
 - 0s - loss: 1.0431 - val_loss: 0.7366
AUC: 0.8686

Epoch 13/80
 - 0s - loss: 1.0406 - val_loss: 0.6676
AUC: 0.8700

Epoch 14/80
 - 0s - loss: 1.0264 - val_loss: 0.6435
AUC: 0.8677

Epoch 15/80
 - 0s - loss: 1.0222 - val_loss: 0.6755
AUC: 0.8681

Epoch 16/80
 - 0s - loss: 1.0226 - val_loss: 0.5644
AUC: 0.8700

Epoch 17/80
 - 0s - loss: 1.0155 - val_loss: 0.6787
AUC: 0.8722

Epoch 18/80
 - 0s - loss: 1.0134 - val_loss: 0.6538
AUC: 0.8714

Epoch 19/80
 - 0s - loss: 1.0048 - val_loss: 0.6257
AUC: 0.8713

Epoch 20/80
 - 0s - loss: 1.0023 - val_loss: 0.6105
AUC: 0.8722

Epoch 21/80
 - 0s - loss: 0.9891 - val_loss: 0.5972
AUC: 0.8725

Epoch 22/80
 - 0s - loss: 0.9934 - val_loss: 0.5967
AUC: 0.8730

Epoch 23/80
 - 0s - loss: 0.9926 - val_loss: 0.6762
AUC: 0.8731

Epoch 24/80
 - 0s - loss: 0.9875 - val_loss: 0.5993
AUC: 0.8719

Epoch 25/80
 - 0s - loss: 0.9815 - val_loss: 0.5506
AUC: 0.8731

Epoch 26/80
 - 0s - loss: 0.9821 - val_loss: 0.5978
AUC: 0.8721

Epoch 27/80
 - 0s - loss: 0.9838 - val_loss: 0.6675
AUC: 0.8710

Epoch 28/80
 - 0s - loss: 0.9797 - val_loss: 0.6449
AUC: 0.8746

Epoch 29/80
 - 0s - loss: 0.9670 - val_loss: 0.6457
AUC: 0.8731

Epoch 30/80
 - 0s - loss: 0.9712 - val_loss: 0.5981
AUC: 0.8742

Epoch 31/80
 - 0s - loss: 0.9638 - val_loss: 0.5830
AUC: 0.8737

Epoch 32/80
 - 0s - loss: 0.9606 - val_loss: 0.6479
AUC: 0.8758

Epoch 33/80
 - 0s - loss: 0.9573 - val_loss: 0.6457
AUC: 0.8737

Epoch 34/80
 - 0s - loss: 0.9619 - val_loss: 0.6287
AUC: 0.8757

Epoch 35/80
 - 0s - loss: 0.9541 - val_loss: 0.5502
AUC: 0.8748

Epoch 36/80
 - 0s - loss: 0.9549 - val_loss: 0.5290
AUC: 0.8747

Epoch 37/80
 - 0s - loss: 0.9500 - val_loss: 0.6381
AUC: 0.8755

Epoch 38/80
 - 0s - loss: 0.9487 - val_loss: 0.6011
AUC: 0.8753

Epoch 39/80
 - 0s - loss: 0.9404 - val_loss: 0.6857
AUC: 0.8754

Epoch 40/80
 - 0s - loss: 0.9433 - val_loss: 0.5471
AUC: 0.8749

Epoch 41/80
 - 0s - loss: 0.9394 - val_loss: 0.6250
AUC: 0.8748

Epoch 42/80
 - 0s - loss: 0.9364 - val_loss: 0.6128
AUC: 0.8764

Epoch 43/80
 - 0s - loss: 0.9306 - val_loss: 0.5716
AUC: 0.8746

Epoch 44/80
 - 0s - loss: 0.9332 - val_loss: 0.5429
AUC: 0.8748

Epoch 45/80
 - 0s - loss: 0.9313 - val_loss: 0.6074
AUC: 0.8761

Epoch 46/80
 - 0s - loss: 0.9296 - val_loss: 0.5011
AUC: 0.8743

Epoch 47/80
 - 0s - loss: 0.9277 - val_loss: 0.6357
AUC: 0.8757

Epoch 48/80
 - 0s - loss: 0.9290 - val_loss: 0.6100
AUC: 0.8753

Epoch 49/80
 - 0s - loss: 0.9276 - val_loss: 0.5822
AUC: 0.8751

Epoch 50/80
 - 0s - loss: 0.9202 - val_loss: 0.6205
AUC: 0.8763

Epoch 51/80
 - 0s - loss: 0.9168 - val_loss: 0.5825
AUC: 0.8745

Epoch 52/80
 - 0s - loss: 0.9102 - val_loss: 0.6433
AUC: 0.8743

Epoch 53/80
 - 0s - loss: 0.9194 - val_loss: 0.4856
AUC: 0.8751

Epoch 54/80
 - 0s - loss: 0.9163 - val_loss: 0.5138
AUC: 0.8730

Epoch 55/80
 - 0s - loss: 0.9129 - val_loss: 0.5134
AUC: 0.8747

Epoch 56/80
 - 0s - loss: 0.9047 - val_loss: 0.5796
AUC: 0.8740

Epoch 57/80
 - 0s - loss: 0.9077 - val_loss: 0.5997
AUC: 0.8760

Epoch 58/80
 - 0s - loss: 0.9110 - val_loss: 0.5894
AUC: 0.8734

Epoch 59/80
 - 0s - loss: 0.9044 - val_loss: 0.6346
AUC: 0.8746

Epoch 60/80
 - 0s - loss: 0.8989 - val_loss: 0.5473
AUC: 0.8741

Epoch 61/80
 - 0s - loss: 0.8904 - val_loss: 0.5999
AUC: 0.8752

Epoch 62/80
 - 0s - loss: 0.8989 - val_loss: 0.6326
AUC: 0.8746

Epoch 63/80
 - 0s - loss: 0.8998 - val_loss: 0.5707
AUC: 0.8739

Epoch 64/80
 - 0s - loss: 0.8785 - val_loss: 0.5835
AUC: 0.8743

Epoch 65/80
 - 0s - loss: 0.8743 - val_loss: 0.5392
AUC: 0.8748

Epoch 66/80
 - 0s - loss: 0.8715 - val_loss: 0.5828
AUC: 0.8749

Epoch 67/80
 - 0s - loss: 0.8711 - val_loss: 0.5422
AUC: 0.8751

Epoch 68/80
 - 0s - loss: 0.8648 - val_loss: 0.5713
AUC: 0.8748

Epoch 69/80
 - 0s - loss: 0.8701 - val_loss: 0.5825
AUC: 0.8748

Epoch 70/80
 - 0s - loss: 0.8708 - val_loss: 0.5743
AUC: 0.8744

Epoch 71/80
 - 0s - loss: 0.8629 - val_loss: 0.5453
AUC: 0.8744

Epoch 72/80
 - 0s - loss: 0.8642 - val_loss: 0.5379
AUC: 0.8743

Epoch 73/80
 - 0s - loss: 0.8666 - val_loss: 0.5581
AUC: 0.8739

Epoch 74/80
 - 0s - loss: 0.8595 - val_loss: 0.5559
AUC: 0.8742

Epoch 75/80
 - 0s - loss: 0.8609 - val_loss: 0.5620
AUC: 0.8744

Epoch 76/80
 - 0s - loss: 0.8613 - val_loss: 0.5647
AUC: 0.8744

Epoch 77/80
 - 0s - loss: 0.8591 - val_loss: 0.5748
AUC: 0.8745

Epoch 78/80
 - 0s - loss: 0.8592 - val_loss: 0.5496
AUC: 0.8743

Epoch 79/80
 - 0s - loss: 0.8561 - val_loss: 0.5660
AUC: 0.8744

Epoch 80/80
 - 0s - loss: 0.8574 - val_loss: 0.5539
AUC: 0.8743

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9271 - val_loss: 0.5806
AUC: 0.8761

Epoch 2/30
 - 0s - loss: 0.9154 - val_loss: 0.5735
AUC: 0.8759

Epoch 3/30
 - 0s - loss: 0.9184 - val_loss: 0.5932
AUC: 0.8760

Epoch 4/30
 - 0s - loss: 0.9164 - val_loss: 0.5738
AUC: 0.8755

Epoch 5/30
 - 0s - loss: 0.9126 - val_loss: 0.5869
AUC: 0.8759

Epoch 6/30
 - 0s - loss: 0.9136 - val_loss: 0.5937
AUC: 0.8757

Epoch 7/30
 - 0s - loss: 0.9110 - val_loss: 0.5865
AUC: 0.8761

Epoch 8/30
 - 0s - loss: 0.9134 - val_loss: 0.5934
AUC: 0.8761

Epoch 9/30
 - 0s - loss: 0.9080 - val_loss: 0.5839
AUC: 0.8762

Epoch 10/30
 - 0s - loss: 0.9039 - val_loss: 0.5777
AUC: 0.8759

Epoch 11/30
 - 0s - loss: 0.9037 - val_loss: 0.5549
AUC: 0.8756

Epoch 12/30
 - 0s - loss: 0.9029 - val_loss: 0.5791
AUC: 0.8759

Epoch 13/30
 - 0s - loss: 0.8989 - val_loss: 0.5408
AUC: 0.8758

Epoch 14/30
 - 0s - loss: 0.8966 - val_loss: 0.5655
AUC: 0.8760

Epoch 15/30
 - 0s - loss: 0.8955 - val_loss: 0.5711
AUC: 0.8759

Epoch 16/30
 - 0s - loss: 0.8943 - val_loss: 0.5654
AUC: 0.8759

Epoch 17/30
 - 0s - loss: 0.8949 - val_loss: 0.5720
AUC: 0.8761

Epoch 18/30
 - 0s - loss: 0.8937 - val_loss: 0.5849
AUC: 0.8759

Epoch 19/30
 - 0s - loss: 0.8887 - val_loss: 0.5654
AUC: 0.8759

Epoch 20/30
 - 0s - loss: 0.8967 - val_loss: 0.5963
AUC: 0.8762

Epoch 21/30
 - 0s - loss: 0.8909 - val_loss: 0.5424
AUC: 0.8758

Epoch 22/30
 - 0s - loss: 0.8897 - val_loss: 0.5520
AUC: 0.8760

Epoch 23/30
 - 0s - loss: 0.8850 - val_loss: 0.5665
AUC: 0.8759

Epoch 24/30
 - 0s - loss: 0.8825 - val_loss: 0.5634
AUC: 0.8759

Epoch 25/30
 - 0s - loss: 0.8807 - val_loss: 0.5615
AUC: 0.8760

Epoch 26/30
 - 0s - loss: 0.8864 - val_loss: 0.5674
AUC: 0.8760

Epoch 27/30
 - 0s - loss: 0.8822 - val_loss: 0.5695
AUC: 0.8760

Epoch 28/30
 - 0s - loss: 0.8831 - val_loss: 0.5654
AUC: 0.8759

Epoch 29/30
 - 0s - loss: 0.8848 - val_loss: 0.5671
AUC: 0.8759

Epoch 30/30
 - 0s - loss: 0.8842 - val_loss: 0.5638
Using TensorFlow backend.
AUC: 0.8759

2019-03-08 08:10:37.578661: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:10:37.742952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:10:37.742994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:10:38.033996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:10:38.034047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:10:38.034056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:10:38.034317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2729
Epoch 2/80
 - 2s - loss: 0.3312
Epoch 3/80
 - 1s - loss: 0.3008
Epoch 4/80
 - 1s - loss: 0.2755
Epoch 5/80
 - 1s - loss: 0.2461
Epoch 6/80
 - 1s - loss: 0.2231
Epoch 7/80
 - 1s - loss: 0.2047
Epoch 8/80
 - 1s - loss: 0.1891
Epoch 9/80
 - 1s - loss: 0.1762
Epoch 10/80
 - 1s - loss: 0.1658
Epoch 11/80
 - 1s - loss: 0.1570
Epoch 12/80
 - 1s - loss: 0.1491
Epoch 13/80
 - 1s - loss: 0.1422
Epoch 14/80
 - 1s - loss: 0.1362
Epoch 15/80
 - 1s - loss: 0.1313
Epoch 16/80
 - 1s - loss: 0.1273
Epoch 17/80
 - 1s - loss: 0.1238
Epoch 18/80
 - 1s - loss: 0.1209
Epoch 19/80
 - 1s - loss: 0.1184
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:11:26.235256: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:11:26.398082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:11:26.398126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:11:26.687294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:11:26.687344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:11:26.687354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:11:26.687606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3122
Epoch 2/80
 - 2s - loss: 0.3352
Epoch 3/80
 - 1s - loss: 0.3042
Epoch 4/80
 - 1s - loss: 0.2866
Epoch 5/80
 - 2s - loss: 0.2639
Epoch 6/80
 - 2s - loss: 0.2381
Epoch 7/80
 - 1s - loss: 0.2152
Epoch 8/80
 - 1s - loss: 0.1959
Epoch 9/80
 - 1s - loss: 0.1799
Epoch 10/80
 - 1s - loss: 0.1672
Epoch 11/80
 - 2s - loss: 0.1571
Epoch 12/80
 - 1s - loss: 0.1487
Epoch 13/80
 - 1s - loss: 0.1417
Epoch 14/80
 - 1s - loss: 0.1360
Epoch 15/80
 - 2s - loss: 0.1313
Epoch 16/80
 - 1s - loss: 0.1273
Epoch 17/80
 - 1s - loss: 0.1240
Epoch 18/80
 - 1s - loss: 0.1212
Epoch 19/80
 - 2s - loss: 0.1187
Epoch 20/80
 - 1s - loss: 0.1166
Epoch 21/80
 - 2s - loss: 0.1148
Epoch 22/80
 - 1s - loss: 0.1132
Epoch 23/80
 - 2s - loss: 0.1118
Epoch 24/80
 - 2s - loss: 0.1105
Epoch 25/80
 - 2s - loss: 0.1095
Epoch 26/80
 - 2s - loss: 0.1085
Epoch 27/80
 - 1s - loss: 0.1077
Epoch 28/80
 - 1s - loss: 0.1070
Epoch 29/80
 - 1s - loss: 0.1064
Epoch 30/80
 - 1s - loss: 0.1059
Epoch 31/80
 - 2s - loss: 0.1054
Epoch 32/80
 - 1s - loss: 0.1050
Epoch 33/80
 - 2s - loss: 0.1046
Epoch 34/80
 - 1s - loss: 0.1043
Epoch 35/80
 - 1s - loss: 0.1040
Epoch 36/80
 - 2s - loss: 0.1037
Epoch 37/80
 - 2s - loss: 0.1035
Epoch 38/80
 - 2s - loss: 0.1033
Epoch 39/80
 - 2s - loss: 0.1031
Epoch 40/80
 - 2s - loss: 0.1029
Epoch 41/80
 - 2s - loss: 0.1027
Epoch 42/80
 - 2s - loss: 0.1026
Epoch 43/80
 - 2s - loss: 0.1024
Epoch 44/80
 - 2s - loss: 0.1023
Epoch 45/80
 - 2s - loss: 0.1022
Epoch 46/80
 - 2s - loss: 0.1021
Epoch 47/80
 - 2s - loss: 0.1020
Epoch 48/80
 - 1s - loss: 0.1019
Epoch 49/80
 - 1s - loss: 0.1018
Epoch 50/80
 - 1s - loss: 0.1017
Epoch 51/80
 - 1s - loss: 0.1016
Epoch 52/80
 - 1s - loss: 0.1016
Epoch 53/80
 - 1s - loss: 0.1015
Epoch 54/80
 - 1s - loss: 0.1014
Epoch 55/80
 - 1s - loss: 0.1014
Epoch 56/80
 - 1s - loss: 0.1013
Epoch 57/80
 - 1s - loss: 0.1012
Epoch 58/80
 - 1s - loss: 0.1012
Epoch 59/80
 - 1s - loss: 0.1012
Epoch 60/80
 - 2s - loss: 0.1011
Epoch 61/80
 - 1s - loss: 0.1010
Epoch 62/80
 - 2s - loss: 0.1010
Epoch 63/80
 - 1s - loss: 0.1010
Epoch 64/80
 - 2s - loss: 0.1010
Epoch 65/80
 - 1s - loss: 0.1009
Epoch 66/80
 - 1s - loss: 0.1009
Epoch 67/80
 - 1s - loss: 0.1008
Epoch 68/80
 - 1s - loss: 0.1008
Epoch 69/80
 - 1s - loss: 0.0982
Epoch 70/80
 - 2s - loss: 0.0979
Epoch 71/80
 - 1s - loss: 0.0979
Epoch 72/80
 - 1s - loss: 0.0978
Epoch 73/80
 - 1s - loss: 0.0978
Epoch 74/80
 - 1s - loss: 0.0972
Epoch 75/80
 - 1s - loss: 0.0972
Epoch 76/80
 - 1s - loss: 0.0972
Epoch 77/80
 - 2s - loss: 0.0972
Epoch 78/80
 - 2s - loss: 0.0970
Epoch 79/80
 - 1s - loss: 0.0970
Epoch 80/80
 - 2s - loss: 0.0970
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.3750 - val_loss: 1.2687
AUC: 0.7672

Epoch 2/80
 - 0s - loss: 2.3494 - val_loss: 1.0343
AUC: 0.8212

Epoch 3/80
 - 0s - loss: 1.7862 - val_loss: 0.7652
AUC: 0.8385

Epoch 4/80
 - 0s - loss: 1.4506 - val_loss: 0.7672
AUC: 0.8478

Epoch 5/80
 - 0s - loss: 1.2698 - val_loss: 0.6894
AUC: 0.8502

Epoch 6/80
 - 0s - loss: 1.1691 - val_loss: 0.7052
AUC: 0.8553

Epoch 7/80
 - 0s - loss: 1.1279 - val_loss: 0.6796
AUC: 0.8583

Epoch 8/80
 - 0s - loss: 1.1011 - val_loss: 0.6578
AUC: 0.8597

Epoch 9/80
 - 0s - loss: 1.0800 - val_loss: 0.6230
AUC: 0.8614

Epoch 10/80
 - 0s - loss: 1.0601 - val_loss: 0.6128
AUC: 0.8624

Epoch 11/80
 - 0s - loss: 1.0499 - val_loss: 0.6576
AUC: 0.8640

Epoch 12/80
 - 0s - loss: 1.0429 - val_loss: 0.6010
AUC: 0.8626

Epoch 13/80
 - 0s - loss: 1.0319 - val_loss: 0.6391
AUC: 0.8639

Epoch 14/80
 - 0s - loss: 1.0348 - val_loss: 0.5918
AUC: 0.8650

Epoch 15/80
 - 0s - loss: 1.0224 - val_loss: 0.6723
AUC: 0.8639

Epoch 16/80
 - 0s - loss: 1.0150 - val_loss: 0.5928
AUC: 0.8645

Epoch 17/80
 - 0s - loss: 1.0140 - val_loss: 0.6347
AUC: 0.8661

Epoch 18/80
 - 0s - loss: 1.0008 - val_loss: 0.6060
AUC: 0.8649

Epoch 19/80
 - 0s - loss: 1.0013 - val_loss: 0.6418
AUC: 0.8663

Epoch 20/80
 - 0s - loss: 0.9980 - val_loss: 0.6869
AUC: 0.8668

Epoch 21/80
 - 0s - loss: 0.9953 - val_loss: 0.6063
AUC: 0.8667

Epoch 22/80
 - 0s - loss: 0.9996 - val_loss: 0.6871
AUC: 0.8662

Epoch 23/80
 - 0s - loss: 0.9862 - val_loss: 0.6492
AUC: 0.8670

Epoch 24/80
 - 0s - loss: 0.9882 - val_loss: 0.5509
AUC: 0.8660

Epoch 25/80
 - 0s - loss: 0.9763 - val_loss: 0.5212
AUC: 0.8660

Epoch 26/80
 - 0s - loss: 0.9792 - val_loss: 0.5696
AUC: 0.8666

Epoch 27/80
 - 0s - loss: 0.9766 - val_loss: 0.6658
AUC: 0.8673

Epoch 28/80
 - 0s - loss: 0.9743 - val_loss: 0.6406
AUC: 0.8670

Epoch 29/80
 - 0s - loss: 0.9638 - val_loss: 0.6709
AUC: 0.8685

Epoch 30/80
 - 0s - loss: 0.9684 - val_loss: 0.7104
AUC: 0.8692

Epoch 31/80
 - 0s - loss: 0.9650 - val_loss: 0.5840
AUC: 0.8658

Epoch 32/80
 - 0s - loss: 0.9616 - val_loss: 0.5000
AUC: 0.8661

Epoch 33/80
 - 0s - loss: 0.9599 - val_loss: 0.6168
AUC: 0.8682

Epoch 34/80
 - 0s - loss: 0.9548 - val_loss: 0.5628
AUC: 0.8678

Epoch 35/80
 - 0s - loss: 0.9511 - val_loss: 0.6132
AUC: 0.8682

Epoch 36/80
 - 0s - loss: 0.9509 - val_loss: 0.6071
AUC: 0.8682

Epoch 37/80
 - 0s - loss: 0.9461 - val_loss: 0.5881
AUC: 0.8678

Epoch 38/80
 - 0s - loss: 0.9427 - val_loss: 0.5225
AUC: 0.8671

Epoch 39/80
 - 0s - loss: 0.9398 - val_loss: 0.5944
AUC: 0.8678

Epoch 40/80
 - 0s - loss: 0.9460 - val_loss: 0.5375
AUC: 0.8674

Epoch 41/80
 - 0s - loss: 0.9413 - val_loss: 0.6098
AUC: 0.8688

Epoch 42/80
 - 0s - loss: 0.9367 - val_loss: 0.6330
AUC: 0.8692

Epoch 43/80
 - 0s - loss: 0.9215 - val_loss: 0.6002
AUC: 0.8690

Epoch 44/80
 - 0s - loss: 0.9209 - val_loss: 0.5940
AUC: 0.8691

Epoch 45/80
 - 0s - loss: 0.9160 - val_loss: 0.5727
AUC: 0.8686

Epoch 46/80
 - 0s - loss: 0.9134 - val_loss: 0.5725
AUC: 0.8689

Epoch 47/80
 - 0s - loss: 0.9138 - val_loss: 0.5985
AUC: 0.8691

Epoch 48/80
 - 0s - loss: 0.9182 - val_loss: 0.5869
AUC: 0.8690

Epoch 49/80
 - 0s - loss: 0.9079 - val_loss: 0.5906
AUC: 0.8690

Epoch 50/80
 - 0s - loss: 0.9069 - val_loss: 0.5570
AUC: 0.8689

Epoch 51/80
 - 0s - loss: 0.9103 - val_loss: 0.5911
AUC: 0.8687

Epoch 52/80
 - 0s - loss: 0.9111 - val_loss: 0.5676
AUC: 0.8686

Epoch 53/80
 - 0s - loss: 0.9067 - val_loss: 0.5862
AUC: 0.8688

Epoch 54/80
 - 0s - loss: 0.9031 - val_loss: 0.5843
AUC: 0.8689

Epoch 55/80
 - 0s - loss: 0.9053 - val_loss: 0.5864
AUC: 0.8691

Epoch 56/80
 - 0s - loss: 0.9042 - val_loss: 0.5749
AUC: 0.8689

Epoch 57/80
 - 0s - loss: 0.9032 - val_loss: 0.5796
AUC: 0.8690

Epoch 58/80
 - 0s - loss: 0.9012 - val_loss: 0.5722
AUC: 0.8690

Epoch 59/80
 - 0s - loss: 0.8997 - val_loss: 0.5789
AUC: 0.8691

Epoch 60/80
 - 0s - loss: 0.9048 - val_loss: 0.5715
AUC: 0.8690

Epoch 61/80
 - 0s - loss: 0.9041 - val_loss: 0.5646
AUC: 0.8689

Epoch 62/80
 - 0s - loss: 0.8973 - val_loss: 0.5785
AUC: 0.8691

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9539 - val_loss: 0.5971
AUC: 0.8683

Epoch 2/30
 - 0s - loss: 0.9523 - val_loss: 0.5970
AUC: 0.8683

Epoch 3/30
 - 0s - loss: 0.9437 - val_loss: 0.5783
AUC: 0.8680

Epoch 4/30
 - 0s - loss: 0.9469 - val_loss: 0.5868
AUC: 0.8681

Epoch 5/30
 - 0s - loss: 0.9408 - val_loss: 0.5898
AUC: 0.8683

Epoch 6/30
 - 0s - loss: 0.9382 - val_loss: 0.5896
AUC: 0.8685

Epoch 7/30
 - 0s - loss: 0.9390 - val_loss: 0.5961
AUC: 0.8685

Epoch 8/30
 - 0s - loss: 0.9372 - val_loss: 0.5887
AUC: 0.8689

Epoch 9/30
 - 0s - loss: 0.9378 - val_loss: 0.5913
AUC: 0.8690

Epoch 10/30
 - 0s - loss: 0.9328 - val_loss: 0.5828
AUC: 0.8691

Epoch 11/30
 - 0s - loss: 0.9321 - val_loss: 0.5918
AUC: 0.8691

Epoch 12/30
 - 0s - loss: 0.9318 - val_loss: 0.5997
AUC: 0.8693

Epoch 13/30
 - 0s - loss: 0.9288 - val_loss: 0.5965
AUC: 0.8694

Epoch 14/30
 - 0s - loss: 0.9258 - val_loss: 0.5875
AUC: 0.8692

Epoch 15/30
 - 0s - loss: 0.9218 - val_loss: 0.5919
AUC: 0.8693

Epoch 16/30
 - 0s - loss: 0.9261 - val_loss: 0.5929
AUC: 0.8693

Epoch 17/30
 - 0s - loss: 0.9258 - val_loss: 0.5958
AUC: 0.8694

Epoch 18/30
 - 0s - loss: 0.9292 - val_loss: 0.5934
AUC: 0.8694

Epoch 19/30
 - 0s - loss: 0.9209 - val_loss: 0.5841
AUC: 0.8693

Epoch 20/30
 - 0s - loss: 0.9254 - val_loss: 0.5872
AUC: 0.8693

Epoch 21/30
 - 0s - loss: 0.9219 - val_loss: 0.5893
AUC: 0.8694

Epoch 22/30
 - 0s - loss: 0.9206 - val_loss: 0.5914
AUC: 0.8694

Epoch 23/30
 - 0s - loss: 0.9238 - val_loss: 0.5881
AUC: 0.8694

Epoch 24/30
 - 0s - loss: 0.9221 - val_loss: 0.5881
AUC: 0.8694

Epoch 25/30
 - 0s - loss: 0.9253 - val_loss: 0.5890
AUC: 0.8695

Epoch 26/30
 - 0s - loss: 0.9224 - val_loss: 0.5890
AUC: 0.8695

Epoch 27/30
 - 0s - loss: 0.9232 - val_loss: 0.5883
AUC: 0.8695

Epoch 28/30
 - 0s - loss: 0.9268 - val_loss: 0.5885
AUC: 0.8695

Epoch 29/30
 - 0s - loss: 0.9218 - val_loss: 0.5900
AUC: 0.8695

Epoch 30/30
 - 0s - loss: 0.9238 - val_loss: 0.5901
Using TensorFlow backend.
AUC: 0.8695

2019-03-08 08:14:51.209267: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:14:51.372133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:14:51.372183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:14:51.665546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:14:51.665605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:14:51.665614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:14:51.665869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3188
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b02542d8668>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 08:15:12.468671: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:15:12.630551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:15:12.630602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:15:12.922695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:15:12.922744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:15:12.922753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:15:12.923007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0675
Epoch 2/80
 - 1s - loss: 0.1958
Epoch 3/80
 - 1s - loss: 0.1699
Epoch 4/80
 - 1s - loss: 0.1606
Epoch 5/80
 - 1s - loss: 0.1478
Epoch 6/80
 - 1s - loss: 0.1321
Epoch 7/80
 - 2s - loss: 0.1185
Epoch 8/80
 - 1s - loss: 0.1082
Epoch 9/80
 - 1s - loss: 0.0996
Epoch 10/80
 - 1s - loss: 0.0914
Epoch 11/80
 - 2s - loss: 0.0841
Epoch 12/80
 - 1s - loss: 0.0780
Epoch 13/80
 - 1s - loss: 0.0728
Epoch 14/80
 - 1s - loss: 0.0685
Epoch 15/80
 - 1s - loss: 0.0649
Epoch 16/80
 - 2s - loss: 0.0619
Epoch 17/80
 - 1s - loss: 0.0594
Epoch 18/80
 - 1s - loss: 0.0573
Epoch 19/80
 - 1s - loss: 0.0555
Epoch 20/80
 - 1s - loss: 0.0539
Epoch 21/80
 - 1s - loss: 0.0526
Epoch 22/80
 - 1s - loss: 0.0515
Epoch 23/80
 - 1s - loss: 0.0505
Epoch 24/80
 - 1s - loss: 0.0497
Epoch 25/80
 - 1s - loss: 0.0490
Epoch 26/80
 - 1s - loss: 0.0484
Epoch 27/80
 - 1s - loss: 0.0478
Epoch 28/80
 - 2s - loss: 0.0474
Epoch 29/80
 - 1s - loss: 0.0470
Epoch 30/80
 - 2s - loss: 0.0466
Epoch 31/80
 - 1s - loss: 0.0463
Epoch 32/80
 - 2s - loss: 0.0461
Epoch 33/80
 - 1s - loss: 0.0458
Epoch 34/80
 - 2s - loss: 0.0456
Epoch 35/80
 - 1s - loss: 0.0454
Epoch 36/80
 - 1s - loss: 0.0453
Epoch 37/80
 - 2s - loss: 0.0451
Epoch 38/80
 - 2s - loss: 0.0449
Epoch 39/80
 - 1s - loss: 0.0448
Epoch 40/80
 - 2s - loss: 0.0447
Epoch 41/80
 - 1s - loss: 0.0446
Epoch 42/80
 - 1s - loss: 0.0445
Epoch 43/80
 - 1s - loss: 0.0444
Epoch 44/80
 - 1s - loss: 0.0443
Epoch 45/80
 - 1s - loss: 0.0442
Epoch 46/80
 - 1s - loss: 0.0442
Epoch 47/80
 - 2s - loss: 0.0441
Epoch 48/80
 - 1s - loss: 0.0440
Epoch 49/80
 - 1s - loss: 0.0440
Epoch 50/80
 - 2s - loss: 0.0439
Epoch 51/80
 - 1s - loss: 0.0439
Epoch 52/80
 - 1s - loss: 0.0438
Epoch 53/80
 - 1s - loss: 0.0438
Epoch 54/80
 - 2s - loss: 0.0438
Epoch 55/80
 - 1s - loss: 0.0437
Epoch 56/80
 - 2s - loss: 0.0437
Epoch 57/80
 - 2s - loss: 0.0436
Epoch 58/80
 - 2s - loss: 0.0436
Epoch 59/80
 - 1s - loss: 0.0436
Epoch 60/80
 - 1s - loss: 0.0436
Epoch 61/80
 - 1s - loss: 0.0423
Epoch 62/80
 - 1s - loss: 0.0422
Epoch 63/80
 - 1s - loss: 0.0421
Epoch 64/80
 - 1s - loss: 0.0421
Epoch 65/80
 - 1s - loss: 0.0421
Epoch 66/80
 - 1s - loss: 0.0418
Epoch 67/80
 - 1s - loss: 0.0418
Epoch 68/80
 - 2s - loss: 0.0418
Epoch 69/80
 - 1s - loss: 0.0418
Epoch 70/80
 - 1s - loss: 0.0417
Epoch 71/80
 - 1s - loss: 0.0417
Epoch 72/80
 - 2s - loss: 0.0417
Epoch 73/80
 - 2s - loss: 0.0417
Epoch 74/80
 - 2s - loss: 0.0417
Epoch 75/80
 - 1s - loss: 0.0417
Epoch 76/80
 - 1s - loss: 0.0417
Epoch 77/80
 - 1s - loss: 0.0417
Epoch 78/80
 - 1s - loss: 0.0417
Epoch 79/80
 - 1s - loss: 0.0417
Epoch 80/80
 - 1s - loss: 0.0417
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.9107 - val_loss: 1.2996
AUC: 0.7932

Epoch 2/80
 - 0s - loss: 2.3754 - val_loss: 1.1089
AUC: 0.8282

Epoch 3/80
 - 0s - loss: 1.7543 - val_loss: 0.7661
AUC: 0.8405

Epoch 4/80
 - 0s - loss: 1.3835 - val_loss: 0.6145
AUC: 0.8448

Epoch 5/80
 - 0s - loss: 1.2173 - val_loss: 0.6628
AUC: 0.8442

Epoch 6/80
 - 0s - loss: 1.1408 - val_loss: 0.6566
AUC: 0.8524

Epoch 7/80
 - 0s - loss: 1.1013 - val_loss: 0.6797
AUC: 0.8535

Epoch 8/80
 - 0s - loss: 1.0756 - val_loss: 0.6514
AUC: 0.8554

Epoch 9/80
 - 0s - loss: 1.0594 - val_loss: 0.5900
AUC: 0.8538

Epoch 10/80
 - 0s - loss: 1.0535 - val_loss: 0.6300
AUC: 0.8566

Epoch 11/80
 - 0s - loss: 1.0396 - val_loss: 0.6769
AUC: 0.8586

Epoch 12/80
 - 0s - loss: 1.0238 - val_loss: 0.7245
AUC: 0.8610

Epoch 13/80
 - 0s - loss: 1.0274 - val_loss: 0.6542
AUC: 0.8622

Epoch 14/80
 - 0s - loss: 1.0203 - val_loss: 0.6407
AUC: 0.8616

Epoch 15/80
 - 0s - loss: 1.0105 - val_loss: 0.6424
AUC: 0.8616

Epoch 16/80
 - 0s - loss: 1.0091 - val_loss: 0.6774
AUC: 0.8606

Epoch 17/80
 - 0s - loss: 0.9996 - val_loss: 0.6217
AUC: 0.8619

Epoch 18/80
 - 0s - loss: 0.9921 - val_loss: 0.6978
AUC: 0.8633

Epoch 19/80
 - 0s - loss: 0.9900 - val_loss: 0.6015
AUC: 0.8637

Epoch 20/80
 - 0s - loss: 0.9751 - val_loss: 0.6035
AUC: 0.8642

Epoch 21/80
 - 0s - loss: 0.9830 - val_loss: 0.5949
AUC: 0.8636

Epoch 22/80
 - 0s - loss: 0.9692 - val_loss: 0.6168
AUC: 0.8641

Epoch 23/80
 - 0s - loss: 0.9757 - val_loss: 0.6328
AUC: 0.8642

Epoch 24/80
 - 0s - loss: 0.9696 - val_loss: 0.6064
AUC: 0.8637

Epoch 25/80
 - 0s - loss: 0.9749 - val_loss: 0.6676
AUC: 0.8649

Epoch 26/80
 - 0s - loss: 0.9714 - val_loss: 0.6017
AUC: 0.8635

Epoch 27/80
 - 0s - loss: 0.9648 - val_loss: 0.6161
AUC: 0.8642

Epoch 28/80
 - 0s - loss: 0.9646 - val_loss: 0.5881
AUC: 0.8634

Epoch 29/80
 - 0s - loss: 0.9698 - val_loss: 0.5977
AUC: 0.8639

Epoch 30/80
 - 0s - loss: 0.9677 - val_loss: 0.5964
AUC: 0.8644

Epoch 31/80
 - 0s - loss: 0.9632 - val_loss: 0.5860
AUC: 0.8638

Epoch 32/80
 - 0s - loss: 0.9638 - val_loss: 0.6161
AUC: 0.8645

Epoch 33/80
 - 0s - loss: 0.9678 - val_loss: 0.6385
AUC: 0.8649

Epoch 34/80
 - 0s - loss: 0.9632 - val_loss: 0.6155
AUC: 0.8642

Epoch 35/80
 - 0s - loss: 0.9639 - val_loss: 0.6118
AUC: 0.8646

Epoch 36/80
 - 0s - loss: 0.9592 - val_loss: 0.6157
AUC: 0.8643

Epoch 37/80
 - 0s - loss: 0.9558 - val_loss: 0.5893
AUC: 0.8645

Epoch 38/80
 - 0s - loss: 0.9611 - val_loss: 0.6055
AUC: 0.8648

Epoch 39/80
 - 0s - loss: 0.9552 - val_loss: 0.6082
AUC: 0.8647

Epoch 40/80
 - 0s - loss: 0.9553 - val_loss: 0.5806
AUC: 0.8640

Epoch 41/80
 - 0s - loss: 0.9552 - val_loss: 0.5855
AUC: 0.8643

Epoch 42/80
 - 0s - loss: 0.9508 - val_loss: 0.6069
AUC: 0.8649

Epoch 43/80
 - 0s - loss: 0.9525 - val_loss: 0.6105
AUC: 0.8652

Epoch 44/80
 - 0s - loss: 0.9462 - val_loss: 0.5983
AUC: 0.8650

Epoch 45/80
 - 0s - loss: 0.9522 - val_loss: 0.5968
AUC: 0.8652

Epoch 46/80
 - 0s - loss: 0.9501 - val_loss: 0.6433
AUC: 0.8652

Epoch 47/80
 - 0s - loss: 0.9513 - val_loss: 0.5765
AUC: 0.8645

Epoch 48/80
 - 0s - loss: 0.9455 - val_loss: 0.6052
AUC: 0.8649

Epoch 49/80
 - 0s - loss: 0.9491 - val_loss: 0.5757
AUC: 0.8648

Epoch 50/80
 - 0s - loss: 0.9491 - val_loss: 0.5541
AUC: 0.8643

Epoch 51/80
 - 0s - loss: 0.9435 - val_loss: 0.6052
AUC: 0.8657

Epoch 52/80
 - 0s - loss: 0.9442 - val_loss: 0.6287
AUC: 0.8656

Epoch 53/80
 - 0s - loss: 0.9426 - val_loss: 0.5810
AUC: 0.8652

Epoch 54/80
 - 0s - loss: 0.9432 - val_loss: 0.6149
AUC: 0.8655

Epoch 55/80
 - 0s - loss: 0.9450 - val_loss: 0.6295
AUC: 0.8658

Epoch 56/80
 - 0s - loss: 0.9446 - val_loss: 0.6390
AUC: 0.8659

Epoch 57/80
 - 0s - loss: 0.9394 - val_loss: 0.6009
AUC: 0.8660

Epoch 58/80
 - 0s - loss: 0.9401 - val_loss: 0.5755
AUC: 0.8657

Epoch 59/80
 - 0s - loss: 0.9369 - val_loss: 0.6021
AUC: 0.8654

Epoch 60/80
 - 0s - loss: 0.9343 - val_loss: 0.6211
AUC: 0.8659

Epoch 61/80
 - 0s - loss: 0.9313 - val_loss: 0.5991
AUC: 0.8658

Epoch 62/80
 - 0s - loss: 0.9308 - val_loss: 0.5950
AUC: 0.8658

Epoch 63/80
 - 0s - loss: 0.9314 - val_loss: 0.5859
AUC: 0.8655

Epoch 64/80
 - 0s - loss: 0.9311 - val_loss: 0.6053
AUC: 0.8659

Epoch 65/80
 - 0s - loss: 0.9326 - val_loss: 0.5894
AUC: 0.8657

Epoch 66/80
 - 0s - loss: 0.9291 - val_loss: 0.6018
AUC: 0.8658

Epoch 67/80
 - 0s - loss: 0.9284 - val_loss: 0.5929
AUC: 0.8658

Epoch 68/80
 - 0s - loss: 0.9313 - val_loss: 0.5965
AUC: 0.8657

Epoch 69/80
 - 0s - loss: 0.9281 - val_loss: 0.5885
AUC: 0.8656

Epoch 70/80
 - 0s - loss: 0.9327 - val_loss: 0.5967
AUC: 0.8658

Epoch 71/80
 - 0s - loss: 0.9294 - val_loss: 0.5970
AUC: 0.8658

Epoch 72/80
 - 0s - loss: 0.9294 - val_loss: 0.5910
AUC: 0.8657

Epoch 73/80
 - 0s - loss: 0.9292 - val_loss: 0.5936
AUC: 0.8658

Epoch 74/80
 - 0s - loss: 0.9269 - val_loss: 0.5913
AUC: 0.8658

Epoch 75/80
 - 0s - loss: 0.9270 - val_loss: 0.5944
AUC: 0.8658

Epoch 76/80
 - 0s - loss: 0.9309 - val_loss: 0.5935
AUC: 0.8658

Epoch 77/80
 - 0s - loss: 0.9301 - val_loss: 0.5933
AUC: 0.8659

Epoch 78/80
 - 0s - loss: 0.9269 - val_loss: 0.5913
AUC: 0.8658

Epoch 79/80
 - 0s - loss: 0.9288 - val_loss: 0.5924
AUC: 0.8658

Epoch 80/80
 - 0s - loss: 0.9269 - val_loss: 0.5931
AUC: 0.8658

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9397 - val_loss: 0.5857
AUC: 0.8653

Epoch 2/30
 - 0s - loss: 0.9354 - val_loss: 0.5928
AUC: 0.8654

Epoch 3/30
 - 0s - loss: 0.9343 - val_loss: 0.5852
AUC: 0.8654

Epoch 4/30
 - 0s - loss: 0.9331 - val_loss: 0.5877
AUC: 0.8659

Epoch 5/30
 - 0s - loss: 0.9313 - val_loss: 0.5819
AUC: 0.8660

Epoch 6/30
 - 0s - loss: 0.9248 - val_loss: 0.5924
AUC: 0.8662

Epoch 7/30
 - 0s - loss: 0.9287 - val_loss: 0.5974
AUC: 0.8662

Epoch 8/30
 - 0s - loss: 0.9232 - val_loss: 0.6000
AUC: 0.8662

Epoch 9/30
 - 0s - loss: 0.9233 - val_loss: 0.5899
AUC: 0.8662

Epoch 10/30
 - 0s - loss: 0.9214 - val_loss: 0.5603
AUC: 0.8658

Epoch 11/30
 - 0s - loss: 0.9227 - val_loss: 0.5940
AUC: 0.8663

Epoch 12/30
 - 0s - loss: 0.9227 - val_loss: 0.5883
AUC: 0.8666

Epoch 13/30
 - 0s - loss: 0.9197 - val_loss: 0.5814
AUC: 0.8668

Epoch 14/30
 - 0s - loss: 0.9143 - val_loss: 0.5859
AUC: 0.8668

Epoch 15/30
 - 0s - loss: 0.9143 - val_loss: 0.5685
AUC: 0.8667

Epoch 16/30
 - 0s - loss: 0.9140 - val_loss: 0.5942
AUC: 0.8671

Epoch 17/30
 - 0s - loss: 0.9093 - val_loss: 0.5946
AUC: 0.8673

Epoch 18/30
 - 0s - loss: 0.9061 - val_loss: 0.6007
AUC: 0.8671

Epoch 19/30
 - 0s - loss: 0.9070 - val_loss: 0.5754
AUC: 0.8669

Epoch 20/30
 - 0s - loss: 0.9075 - val_loss: 0.6104
AUC: 0.8675

Epoch 21/30
 - 0s - loss: 0.9054 - val_loss: 0.5841
AUC: 0.8672

Epoch 22/30
 - 0s - loss: 0.9112 - val_loss: 0.5866
AUC: 0.8672

Epoch 23/30
 - 0s - loss: 0.9079 - val_loss: 0.5832
AUC: 0.8672

Epoch 24/30
 - 0s - loss: 0.9058 - val_loss: 0.5884
AUC: 0.8672

Epoch 25/30
 - 0s - loss: 0.9050 - val_loss: 0.5819
AUC: 0.8671

Epoch 26/30
 - 0s - loss: 0.9056 - val_loss: 0.5843
AUC: 0.8671

Epoch 27/30
 - 0s - loss: 0.9056 - val_loss: 0.5855
AUC: 0.8672

Epoch 28/30
 - 0s - loss: 0.9059 - val_loss: 0.5808
AUC: 0.8671

Epoch 29/30
 - 0s - loss: 0.9020 - val_loss: 0.5856
AUC: 0.8672

Epoch 30/30
 - 0s - loss: 0.9040 - val_loss: 0.5784
Using TensorFlow backend.
AUC: 0.8671

2019-03-08 08:18:47.326360: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:18:47.488750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:18:47.488795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:18:47.782372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:18:47.782425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:18:47.782434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:18:47.782691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0661
Epoch 2/80
 - 1s - loss: 0.1953
Epoch 3/80
 - 1s - loss: 0.1701
Epoch 4/80
 - 2s - loss: 0.1588
Epoch 5/80
 - 1s - loss: 0.1449
Epoch 6/80
 - 1s - loss: 0.1317
Epoch 7/80
 - 1s - loss: 0.1199
Epoch 8/80
 - 1s - loss: 0.1094
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:19:19.161651: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:19:19.325533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:19:19.325577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:19:19.615122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:19:19.615174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:19:19.615184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:19:19.615437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0651
Epoch 2/80
 - 1s - loss: 0.1947
Epoch 3/80
 - 1s - loss: 0.1651
Epoch 4/80
 - 1s - loss: 0.1492
Epoch 5/80
 - 1s - loss: 0.1327
Epoch 6/80
 - 1s - loss: 0.1197
Epoch 7/80
 - 1s - loss: 0.1096
Epoch 8/80
 - 1s - loss: 0.1013
Epoch 9/80
 - 1s - loss: 0.0939
Epoch 10/80
 - 2s - loss: 0.0872
Epoch 11/80
 - 1s - loss: 0.0815
Epoch 12/80
 - 1s - loss: 0.0764
Epoch 13/80
 - 1s - loss: 0.0721
Epoch 14/80
 - 1s - loss: 0.0682
Epoch 15/80
 - 1s - loss: 0.0648
Epoch 16/80
 - 1s - loss: 0.0619
Epoch 17/80
 - 1s - loss: 0.0595
Epoch 18/80
 - 1s - loss: 0.0575
Epoch 19/80
 - 1s - loss: 0.0558
Epoch 20/80
 - 1s - loss: 0.0543
Epoch 21/80
 - 1s - loss: 0.0529
Epoch 22/80
 - 1s - loss: 0.0518
Epoch 23/80
 - 1s - loss: 0.0508
Epoch 24/80
 - 1s - loss: 0.0499
Epoch 25/80
 - 1s - loss: 0.0492
Epoch 26/80
 - 1s - loss: 0.0485
Epoch 27/80
 - 1s - loss: 0.0479
Epoch 28/80
 - 2s - loss: 0.0474
Epoch 29/80
 - 2s - loss: 0.0470
Epoch 30/80
 - 2s - loss: 0.0466
Epoch 31/80
 - 2s - loss: 0.0463
Epoch 32/80
 - 2s - loss: 0.0460
Epoch 33/80
 - 1s - loss: 0.0457
Epoch 34/80
 - 2s - loss: 0.0455
Epoch 35/80
 - 1s - loss: 0.0453
Epoch 36/80
 - 2s - loss: 0.0451
Epoch 37/80
 - 1s - loss: 0.0450
Epoch 38/80
 - 2s - loss: 0.0448
Epoch 39/80
 - 1s - loss: 0.0447
Epoch 40/80
 - 1s - loss: 0.0446
Epoch 41/80
 - 2s - loss: 0.0445
Epoch 42/80
 - 1s - loss: 0.0444
Epoch 43/80
 - 1s - loss: 0.0443
Epoch 44/80
 - 1s - loss: 0.0442
Epoch 45/80
 - 1s - loss: 0.0441
Epoch 46/80
 - 1s - loss: 0.0441
Epoch 47/80
 - 1s - loss: 0.0440
Epoch 48/80
 - 1s - loss: 0.0439
Epoch 49/80
 - 1s - loss: 0.0439
Epoch 50/80
 - 2s - loss: 0.0438
Epoch 51/80
 - 2s - loss: 0.0438
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:21:02.069015: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:21:02.237008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:21:02.237050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:21:02.540522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:21:02.540573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:21:02.540582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:21:02.540834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6470
Epoch 2/80
 - 2s - loss: 0.1005
Epoch 3/80
 - 2s - loss: 0.0693
Epoch 4/80
 - 1s - loss: 0.0647
Epoch 5/80
 - 1s - loss: 0.0622
Epoch 6/80
 - 1s - loss: 0.0589
Epoch 7/80
 - 1s - loss: 0.0544
Epoch 8/80
 - 1s - loss: 0.0495
Epoch 9/80
 - 1s - loss: 0.0448
Epoch 10/80
 - 1s - loss: 0.0406
Epoch 11/80
 - 1s - loss: 0.0369
Epoch 12/80
 - 1s - loss: 0.0336
Epoch 13/80
 - 1s - loss: 0.0308
Epoch 14/80
 - 1s - loss: 0.0285
Epoch 15/80
 - 1s - loss: 0.0264
Epoch 16/80
 - 1s - loss: 0.0248
Epoch 17/80
 - 1s - loss: 0.0233
Epoch 18/80
 - 1s - loss: 0.0221
Epoch 19/80
 - 1s - loss: 0.0210
Epoch 20/80
 - 1s - loss: 0.0202
Epoch 21/80
 - 1s - loss: 0.0194
Epoch 22/80
 - 1s - loss: 0.0188
Epoch 23/80
 - 1s - loss: 0.0182
Epoch 24/80
 - 1s - loss: 0.0177
Epoch 25/80
 - 1s - loss: 0.0173
Epoch 26/80
 - 1s - loss: 0.0169
Epoch 27/80
 - 1s - loss: 0.0166
Epoch 28/80
 - 1s - loss: 0.0163
Epoch 29/80
 - 1s - loss: 0.0161
Epoch 30/80
 - 1s - loss: 0.0158
Epoch 31/80
 - 1s - loss: 0.0157
Epoch 32/80
 - 1s - loss: 0.0155
Epoch 33/80
 - 1s - loss: 0.0153
Epoch 34/80
 - 1s - loss: 0.0152
Epoch 35/80
 - 1s - loss: 0.0151
Epoch 36/80
 - 1s - loss: 0.0150
Epoch 37/80
 - 1s - loss: 0.0149
Epoch 38/80
 - 1s - loss: 0.0148
Epoch 39/80
 - 1s - loss: 0.0147
Epoch 40/80
 - 1s - loss: 0.0146
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 1s - loss: 0.0145
Epoch 43/80
 - 1s - loss: 0.0145
Epoch 44/80
 - 1s - loss: 0.0144
Epoch 45/80
 - 1s - loss: 0.0144
Epoch 46/80
 - 1s - loss: 0.0144
Epoch 47/80
 - 1s - loss: 0.0143
Epoch 48/80
 - 1s - loss: 0.0143
Epoch 49/80
 - 1s - loss: 0.0142
Epoch 50/80
 - 1s - loss: 0.0142
Epoch 51/80
 - 1s - loss: 0.0142
Epoch 52/80
 - 1s - loss: 0.0137
Epoch 53/80
 - 1s - loss: 0.0137
Epoch 54/80
 - 1s - loss: 0.0137
Epoch 55/80
 - 1s - loss: 0.0137
Epoch 56/80
 - 1s - loss: 0.0136
Epoch 57/80
 - 1s - loss: 0.0136
Epoch 58/80
 - 1s - loss: 0.0136
Epoch 59/80
 - 1s - loss: 0.0136
Epoch 60/80
 - 1s - loss: 0.0135
Epoch 61/80
 - 2s - loss: 0.0135
Epoch 62/80
 - 1s - loss: 0.0135
Epoch 63/80
 - 1s - loss: 0.0135
Epoch 64/80
 - 1s - loss: 0.0135
Epoch 65/80
 - 1s - loss: 0.0135
Epoch 66/80
 - 1s - loss: 0.0135
Epoch 67/80
 - 2s - loss: 0.0135
Epoch 68/80
 - 1s - loss: 0.0135
Epoch 69/80
 - 1s - loss: 0.0135
Epoch 70/80
 - 1s - loss: 0.0135
Epoch 71/80
 - 1s - loss: 0.0135
Epoch 72/80
 - 1s - loss: 0.0135
Epoch 73/80
 - 1s - loss: 0.0135
Epoch 74/80
 - 1s - loss: 0.0135
Epoch 75/80
 - 1s - loss: 0.0135
Epoch 76/80
 - 1s - loss: 0.0135
Epoch 77/80
 - 1s - loss: 0.0135
Epoch 78/80
 - 1s - loss: 0.0135
Epoch 79/80
 - 1s - loss: 0.0135
Epoch 80/80
 - 1s - loss: 0.0135
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.9098 - val_loss: 1.0500
AUC: 0.8090

Epoch 2/80
 - 0s - loss: 1.8071 - val_loss: 0.8846
AUC: 0.8304

Epoch 3/80
 - 0s - loss: 1.3396 - val_loss: 0.6860
AUC: 0.8382

Epoch 4/80
 - 0s - loss: 1.2030 - val_loss: 0.6789
AUC: 0.8400

Epoch 5/80
 - 0s - loss: 1.1146 - val_loss: 0.6538
AUC: 0.8457

Epoch 6/80
 - 0s - loss: 1.0856 - val_loss: 0.6669
AUC: 0.8485

Epoch 7/80
 - 0s - loss: 1.0707 - val_loss: 0.6231
AUC: 0.8518

Epoch 8/80
 - 0s - loss: 1.0575 - val_loss: 0.5936
AUC: 0.8522

Epoch 9/80
 - 0s - loss: 1.0475 - val_loss: 0.6078
AUC: 0.8552

Epoch 10/80
 - 0s - loss: 1.0358 - val_loss: 0.7051
AUC: 0.8550

Epoch 11/80
 - 0s - loss: 1.0292 - val_loss: 0.6411
AUC: 0.8559

Epoch 12/80
 - 0s - loss: 1.0248 - val_loss: 0.6141
AUC: 0.8577

Epoch 13/80
 - 0s - loss: 1.0135 - val_loss: 0.6559
AUC: 0.8599

Epoch 14/80
 - 0s - loss: 1.0112 - val_loss: 0.6755
AUC: 0.8598

Epoch 15/80
 - 0s - loss: 1.0079 - val_loss: 0.6357
AUC: 0.8587

Epoch 16/80
 - 0s - loss: 0.9991 - val_loss: 0.5801
AUC: 0.8590

Epoch 17/80
 - 0s - loss: 0.9982 - val_loss: 0.5813
AUC: 0.8589

Epoch 18/80
 - 0s - loss: 0.9877 - val_loss: 0.6270
AUC: 0.8598

Epoch 19/80
 - 0s - loss: 0.9869 - val_loss: 0.6758
AUC: 0.8603

Epoch 20/80
 - 0s - loss: 0.9917 - val_loss: 0.6561
AUC: 0.8610

Epoch 21/80
 - 0s - loss: 0.9828 - val_loss: 0.5832
AUC: 0.8613

Epoch 22/80
 - 0s - loss: 0.9785 - val_loss: 0.6329
AUC: 0.8619

Epoch 23/80
 - 0s - loss: 0.9813 - val_loss: 0.6148
AUC: 0.8629

Epoch 24/80
 - 0s - loss: 0.9661 - val_loss: 0.5738
AUC: 0.8622

Epoch 25/80
 - 0s - loss: 0.9692 - val_loss: 0.5690
AUC: 0.8618

Epoch 26/80
 - 0s - loss: 0.9635 - val_loss: 0.6210
AUC: 0.8617

Epoch 27/80
 - 0s - loss: 0.9646 - val_loss: 0.5893
AUC: 0.8619

Epoch 28/80
 - 0s - loss: 0.9579 - val_loss: 0.6564
AUC: 0.8646

Epoch 29/80
 - 0s - loss: 0.9524 - val_loss: 0.5616
AUC: 0.8631

Epoch 30/80
 - 0s - loss: 0.9542 - val_loss: 0.6635
AUC: 0.8633

Epoch 31/80
 - 0s - loss: 0.9512 - val_loss: 0.6840
AUC: 0.8650

Epoch 32/80
 - 0s - loss: 0.9557 - val_loss: 0.6022
AUC: 0.8633

Epoch 33/80
 - 0s - loss: 0.9436 - val_loss: 0.6441
AUC: 0.8638

Epoch 34/80
 - 0s - loss: 0.9400 - val_loss: 0.5386
AUC: 0.8635

Epoch 35/80
 - 0s - loss: 0.9384 - val_loss: 0.5744
AUC: 0.8653

Epoch 36/80
 - 0s - loss: 0.9408 - val_loss: 0.6374
AUC: 0.8644

Epoch 37/80
 - 0s - loss: 0.9365 - val_loss: 0.5723
AUC: 0.8651

Epoch 38/80
 - 0s - loss: 0.9245 - val_loss: 0.5664
AUC: 0.8641

Epoch 39/80
 - 0s - loss: 0.9330 - val_loss: 0.6423
AUC: 0.8650

Epoch 40/80
 - 0s - loss: 0.9310 - val_loss: 0.6505
AUC: 0.8666

Epoch 41/80
 - 0s - loss: 0.9259 - val_loss: 0.6062
AUC: 0.8658

Epoch 42/80
 - 0s - loss: 0.9211 - val_loss: 0.5499
AUC: 0.8634

Epoch 43/80
 - 0s - loss: 0.9192 - val_loss: 0.6107
AUC: 0.8663

Epoch 44/80
 - 0s - loss: 0.9172 - val_loss: 0.5998
AUC: 0.8642

Epoch 45/80
 - 0s - loss: 0.9042 - val_loss: 0.5834
AUC: 0.8650

Epoch 46/80
 - 0s - loss: 0.8972 - val_loss: 0.5385
AUC: 0.8655

Epoch 47/80
 - 0s - loss: 0.8996 - val_loss: 0.5622
AUC: 0.8652

Epoch 48/80
 - 0s - loss: 0.8997 - val_loss: 0.5798
AUC: 0.8658

Epoch 49/80
 - 0s - loss: 0.8951 - val_loss: 0.6005
AUC: 0.8657

Epoch 50/80
 - 0s - loss: 0.8900 - val_loss: 0.5651
AUC: 0.8653

Epoch 51/80
 - 0s - loss: 0.8924 - val_loss: 0.5864
AUC: 0.8654

Epoch 52/80
 - 0s - loss: 0.8953 - val_loss: 0.5586
AUC: 0.8646

Epoch 53/80
 - 0s - loss: 0.8930 - val_loss: 0.5824
AUC: 0.8655

Epoch 54/80
 - 0s - loss: 0.8962 - val_loss: 0.5809
AUC: 0.8654

Epoch 55/80
 - 0s - loss: 0.8845 - val_loss: 0.5689
AUC: 0.8653

Epoch 56/80
 - 0s - loss: 0.8889 - val_loss: 0.5718
AUC: 0.8656

Epoch 57/80
 - 0s - loss: 0.8902 - val_loss: 0.5666
AUC: 0.8657

Epoch 58/80
 - 0s - loss: 0.8891 - val_loss: 0.5789
AUC: 0.8657

Epoch 59/80
 - 0s - loss: 0.8901 - val_loss: 0.5795
AUC: 0.8655

Epoch 60/80
 - 0s - loss: 0.8829 - val_loss: 0.5719
AUC: 0.8655

Epoch 61/80
 - 0s - loss: 0.8846 - val_loss: 0.5777
AUC: 0.8657

Epoch 62/80
 - 0s - loss: 0.8855 - val_loss: 0.5795
AUC: 0.8655

Epoch 63/80
 - 0s - loss: 0.8866 - val_loss: 0.5802
AUC: 0.8656

Epoch 64/80
 - 0s - loss: 0.8862 - val_loss: 0.5840
AUC: 0.8656

Epoch 65/80
 - 0s - loss: 0.8803 - val_loss: 0.5703
AUC: 0.8654

Epoch 66/80
 - 0s - loss: 0.8865 - val_loss: 0.5663
AUC: 0.8653

Epoch 67/80
 - 0s - loss: 0.8797 - val_loss: 0.5692
AUC: 0.8653

Epoch 68/80
 - 0s - loss: 0.8826 - val_loss: 0.5698
AUC: 0.8654

Epoch 69/80
 - 0s - loss: 0.8846 - val_loss: 0.5701
AUC: 0.8654

Epoch 70/80
 - 0s - loss: 0.8852 - val_loss: 0.5713
AUC: 0.8654

Epoch 71/80
 - 0s - loss: 0.8851 - val_loss: 0.5720
AUC: 0.8655

Epoch 72/80
 - 0s - loss: 0.8815 - val_loss: 0.5717
AUC: 0.8655

Epoch 73/80
 - 0s - loss: 0.8837 - val_loss: 0.5721
AUC: 0.8655

Epoch 74/80
 - 0s - loss: 0.8866 - val_loss: 0.5719
AUC: 0.8655

Epoch 75/80
 - 0s - loss: 0.8890 - val_loss: 0.5734
AUC: 0.8656

Epoch 76/80
 - 0s - loss: 0.8849 - val_loss: 0.5728
AUC: 0.8655

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9176 - val_loss: 0.5796
AUC: 0.8659

Epoch 2/30
 - 0s - loss: 0.9097 - val_loss: 0.5785
AUC: 0.8658

Epoch 3/30
 - 0s - loss: 0.9077 - val_loss: 0.5721
AUC: 0.8655

Epoch 4/30
 - 0s - loss: 0.9028 - val_loss: 0.5810
AUC: 0.8655

Epoch 5/30
 - 0s - loss: 0.9022 - val_loss: 0.6003
AUC: 0.8654

Epoch 6/30
 - 0s - loss: 0.9008 - val_loss: 0.5708
AUC: 0.8653

Epoch 7/30
 - 0s - loss: 0.9030 - val_loss: 0.5733
AUC: 0.8653

Epoch 8/30
 - 0s - loss: 0.8976 - val_loss: 0.5967
AUC: 0.8656

Epoch 9/30
 - 0s - loss: 0.8938 - val_loss: 0.5979
AUC: 0.8659

Epoch 10/30
 - 0s - loss: 0.8929 - val_loss: 0.5835
AUC: 0.8657

Epoch 11/30
 - 0s - loss: 0.8961 - val_loss: 0.5788
AUC: 0.8657

Epoch 12/30
 - 0s - loss: 0.8907 - val_loss: 0.5743
AUC: 0.8655

Epoch 13/30
 - 0s - loss: 0.8886 - val_loss: 0.5681
AUC: 0.8657

Epoch 14/30
 - 0s - loss: 0.8878 - val_loss: 0.5736
AUC: 0.8657

Epoch 15/30
 - 0s - loss: 0.8812 - val_loss: 0.5646
AUC: 0.8657

Epoch 16/30
 - 0s - loss: 0.8848 - val_loss: 0.5693
AUC: 0.8659

Epoch 17/30
 - 0s - loss: 0.8820 - val_loss: 0.5542
AUC: 0.8655

Epoch 18/30
 - 0s - loss: 0.8844 - val_loss: 0.5694
AUC: 0.8652

Epoch 19/30
 - 0s - loss: 0.8797 - val_loss: 0.5614
AUC: 0.8654

Epoch 20/30
 - 0s - loss: 0.8804 - val_loss: 0.5813
AUC: 0.8657

Epoch 21/30
 - 0s - loss: 0.8766 - val_loss: 0.5753
AUC: 0.8654

Epoch 22/30
 - 0s - loss: 0.8730 - val_loss: 0.5732
AUC: 0.8655

Epoch 23/30
 - 0s - loss: 0.8760 - val_loss: 0.5615
AUC: 0.8655

Epoch 24/30
 - 0s - loss: 0.8724 - val_loss: 0.5951
AUC: 0.8660

Epoch 25/30
 - 0s - loss: 0.8691 - val_loss: 0.5705
AUC: 0.8658

Epoch 26/30
 - 0s - loss: 0.8692 - val_loss: 0.5492
AUC: 0.8653

Epoch 27/30
 - 0s - loss: 0.8695 - val_loss: 0.5581
AUC: 0.8654

Epoch 28/30
 - 0s - loss: 0.8694 - val_loss: 0.5460
AUC: 0.8655

Epoch 29/30
 - 0s - loss: 0.8669 - val_loss: 0.5770
AUC: 0.8656

Epoch 30/30
 - 0s - loss: 0.8602 - val_loss: 0.5714
Using TensorFlow backend.
AUC: 0.8656

2019-03-08 08:24:32.964148: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:24:33.126276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:24:33.126321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:24:33.419576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:24:33.419626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:24:33.419635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:24:33.419889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6598
Epoch 2/80
 - 1s - loss: 0.1052
Epoch 3/80
 - 2s - loss: 0.0691
Epoch 4/80
 - 1s - loss: 0.0635
Epoch 5/80
 - 1s - loss: 0.0592
Epoch 6/80
 - 1s - loss: 0.0539
Epoch 7/80
 - 1s - loss: 0.0487
Epoch 8/80
 - 1s - loss: 0.0443
Epoch 9/80
 - 1s - loss: 0.0405
Epoch 10/80
 - 1s - loss: 0.0372
Epoch 11/80
 - 1s - loss: 0.0343
Epoch 12/80
 - 1s - loss: 0.0317
Epoch 13/80
 - 1s - loss: 0.0294
Epoch 14/80
 - 1s - loss: 0.0274
Epoch 15/80
 - 1s - loss: 0.0257
Epoch 16/80
 - 1s - loss: 0.0241
Epoch 17/80
 - 1s - loss: 0.0228
Epoch 18/80
 - 1s - loss: 0.0217
Epoch 19/80
 - 2s - loss: 0.0207
Epoch 20/80
 - 1s - loss: 0.0199
Epoch 21/80
 - 2s - loss: 0.0192
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b2f16cdf1d0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 08:25:24.793465: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:25:24.957937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:25:24.957979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:25:25.251563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:25:25.251612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:25:25.251621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:25:25.251877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6668
Epoch 2/80
 - 1s - loss: 0.1058
Epoch 3/80
 - 1s - loss: 0.0701
Epoch 4/80
 - 1s - loss: 0.0651
Epoch 5/80
 - 1s - loss: 0.0622
Epoch 6/80
 - 2s - loss: 0.0587
Epoch 7/80
 - 1s - loss: 0.0543
Epoch 8/80
 - 1s - loss: 0.0495
Epoch 9/80
 - 1s - loss: 0.0448
Epoch 10/80
 - 1s - loss: 0.0403
Epoch 11/80
 - 1s - loss: 0.0364
Epoch 12/80
 - 1s - loss: 0.0330
Epoch 13/80
 - 1s - loss: 0.0302
Epoch 14/80
 - 1s - loss: 0.0279
Epoch 15/80
 - 1s - loss: 0.0259
Epoch 16/80
 - 1s - loss: 0.0243
Epoch 17/80
 - 1s - loss: 0.0230
Epoch 18/80
 - 1s - loss: 0.0219
Epoch 19/80
 - 1s - loss: 0.0209
Epoch 20/80
 - 1s - loss: 0.0201
Epoch 21/80
 - 1s - loss: 0.0194
Epoch 22/80
 - 1s - loss: 0.0188
Epoch 23/80
 - 1s - loss: 0.0182
Epoch 24/80
 - 1s - loss: 0.0178
Epoch 25/80
 - 1s - loss: 0.0173
Epoch 26/80
 - 1s - loss: 0.0170
Epoch 27/80
 - 1s - loss: 0.0166
Epoch 28/80
 - 1s - loss: 0.0164
Epoch 29/80
 - 1s - loss: 0.0161
Epoch 30/80
 - 1s - loss: 0.0159
Epoch 31/80
 - 1s - loss: 0.0157
Epoch 32/80
 - 1s - loss: 0.0155
Epoch 33/80
 - 1s - loss: 0.0154
Epoch 34/80
 - 1s - loss: 0.0152
Epoch 35/80
 - 1s - loss: 0.0151
Epoch 36/80
 - 1s - loss: 0.0150
Epoch 37/80
 - 1s - loss: 0.0149
Epoch 38/80
 - 1s - loss: 0.0148
Epoch 39/80
 - 1s - loss: 0.0148
Epoch 40/80
 - 1s - loss: 0.0147
Epoch 41/80
 - 1s - loss: 0.0146
Epoch 42/80
 - 1s - loss: 0.0146
Epoch 43/80
 - 1s - loss: 0.0145
Epoch 44/80
 - 1s - loss: 0.0145
Epoch 45/80
 - 1s - loss: 0.0145
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 1s - loss: 0.0144
Epoch 48/80
 - 1s - loss: 0.0143
Epoch 49/80
 - 1s - loss: 0.0143
Epoch 50/80
 - 1s - loss: 0.0143
Epoch 51/80
 - 1s - loss: 0.0143
Epoch 52/80
 - 1s - loss: 0.0138
Epoch 53/80
 - 1s - loss: 0.0138
Epoch 54/80
 - 1s - loss: 0.0138
Epoch 55/80
 - 1s - loss: 0.0138
Epoch 56/80
 - 1s - loss: 0.0136
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 08:27:14.414247: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:27:14.576058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:27:14.576101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:27:14.868581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:27:14.868632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:27:14.868641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:27:14.868898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3098
Epoch 2/80
 - 2s - loss: 0.3324
Epoch 3/80
 - 1s - loss: 0.2868
Epoch 4/80
 - 1s - loss: 0.2497
Epoch 5/80
 - 1s - loss: 0.2229
Epoch 6/80
 - 1s - loss: 0.2061
Epoch 7/80
 - 2s - loss: 0.1925
Epoch 8/80
 - 1s - loss: 0.1809
Epoch 9/80
 - 2s - loss: 0.1711
Epoch 10/80
 - 1s - loss: 0.1624
Epoch 11/80
 - 1s - loss: 0.1545
Epoch 12/80
 - 1s - loss: 0.1472
Epoch 13/80
 - 2s - loss: 0.1406
Epoch 14/80
 - 1s - loss: 0.1347
Epoch 15/80
 - 1s - loss: 0.1299
Epoch 16/80
 - 1s - loss: 0.1259
Epoch 17/80
 - 1s - loss: 0.1225
Epoch 18/80
 - 1s - loss: 0.1196
Epoch 19/80
 - 1s - loss: 0.1171
Epoch 20/80
 - 1s - loss: 0.1151
Epoch 21/80
 - 1s - loss: 0.1133
Epoch 22/80
 - 1s - loss: 0.1117
Epoch 23/80
 - 1s - loss: 0.1104
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:28:09.504821: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:28:09.667786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:28:09.667830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:28:09.958507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:28:09.958558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:28:09.958567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:28:09.958823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3235
Epoch 2/80
 - 2s - loss: 0.3345
Epoch 3/80
 - 2s - loss: 0.2937
Epoch 4/80
 - 2s - loss: 0.2595
Epoch 5/80
 - 2s - loss: 0.2326
Epoch 6/80
 - 2s - loss: 0.2138
Epoch 7/80
 - 2s - loss: 0.1985
Epoch 8/80
 - 2s - loss: 0.1845
Epoch 9/80
 - 2s - loss: 0.1721
Epoch 10/80
 - 2s - loss: 0.1620
Epoch 11/80
 - 2s - loss: 0.1536
Epoch 12/80
 - 2s - loss: 0.1464
Epoch 13/80
 - 2s - loss: 0.1402
Epoch 14/80
 - 2s - loss: 0.1347
Epoch 15/80
 - 2s - loss: 0.1301
Epoch 16/80
 - 2s - loss: 0.1263
Epoch 17/80
 - 2s - loss: 0.1230
Epoch 18/80
 - 2s - loss: 0.1203
Epoch 19/80
 - 2s - loss: 0.1179
Epoch 20/80
 - 2s - loss: 0.1159
Epoch 21/80
 - 2s - loss: 0.1141
Epoch 22/80
 - 2s - loss: 0.1126
Epoch 23/80
 - 2s - loss: 0.1113
Epoch 24/80
 - 2s - loss: 0.1101
Epoch 25/80
 - 2s - loss: 0.1091
Epoch 26/80
 - 2s - loss: 0.1083
Epoch 27/80
 - 2s - loss: 0.1076
Epoch 28/80
 - 2s - loss: 0.1069
Epoch 29/80
 - 2s - loss: 0.1063
Epoch 30/80
 - 2s - loss: 0.1058
Epoch 31/80
 - 2s - loss: 0.1054
Epoch 32/80
 - 2s - loss: 0.1050
Epoch 33/80
 - 2s - loss: 0.1046
Epoch 34/80
 - 2s - loss: 0.1043
Epoch 35/80
 - 2s - loss: 0.1040
Epoch 36/80
 - 2s - loss: 0.1038
Epoch 37/80
 - 2s - loss: 0.1036
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:29:31.596841: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:29:31.757321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:29:31.757365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:29:32.050185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:29:32.050248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:29:32.050258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:29:32.050523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3090
Epoch 2/80
 - 2s - loss: 0.3338
Epoch 3/80
 - 1s - loss: 0.3005
Epoch 4/80
 - 1s - loss: 0.2782
Epoch 5/80
 - 1s - loss: 0.2499
Epoch 6/80
 - 1s - loss: 0.2243
Epoch 7/80
 - 1s - loss: 0.2055
Epoch 8/80
 - 1s - loss: 0.1905
Epoch 9/80
 - 1s - loss: 0.1775
Epoch 10/80
 - 1s - loss: 0.1660
Epoch 11/80
 - 1s - loss: 0.1561
Epoch 12/80
 - 1s - loss: 0.1478
Epoch 13/80
 - 1s - loss: 0.1410
Epoch 14/80
 - 1s - loss: 0.1354
Epoch 15/80
 - 1s - loss: 0.1308
Epoch 16/80
 - 1s - loss: 0.1268
Epoch 17/80
 - 1s - loss: 0.1234
Epoch 18/80
 - 1s - loss: 0.1206
Epoch 19/80
 - 1s - loss: 0.1180
Epoch 20/80
 - 2s - loss: 0.1159
Epoch 21/80
 - 2s - loss: 0.1141
Epoch 22/80
 - 2s - loss: 0.1125
Epoch 23/80
 - 2s - loss: 0.1111
Epoch 24/80
 - 1s - loss: 0.1099
Epoch 25/80
 - 1s - loss: 0.1089
Epoch 26/80
 - 1s - loss: 0.1080
Epoch 27/80
 - 1s - loss: 0.1073
Epoch 28/80
 - 1s - loss: 0.1066
Epoch 29/80
 - 1s - loss: 0.1061
Epoch 30/80
 - 1s - loss: 0.1056
Epoch 31/80
 - 1s - loss: 0.1051
Epoch 32/80
 - 1s - loss: 0.1048
Epoch 33/80
 - 1s - loss: 0.1045
Epoch 34/80
 - 1s - loss: 0.1041
Epoch 35/80
 - 1s - loss: 0.1039
Epoch 36/80
 - 1s - loss: 0.1036
Epoch 37/80
 - 1s - loss: 0.1035
Epoch 38/80
 - 2s - loss: 0.1033
Epoch 39/80
 - 1s - loss: 0.1031
Epoch 40/80
 - 1s - loss: 0.1029
Epoch 41/80
 - 1s - loss: 0.1028
Epoch 42/80
 - 1s - loss: 0.1027
Epoch 43/80
 - 1s - loss: 0.1025
Epoch 44/80
 - 1s - loss: 0.1024
Epoch 45/80
 - 1s - loss: 0.1023
Epoch 46/80
 - 1s - loss: 0.1022
Epoch 47/80
 - 1s - loss: 0.1021
Epoch 48/80
 - 1s - loss: 0.1020
Epoch 49/80
 - 1s - loss: 0.1020
Epoch 50/80
 - 1s - loss: 0.1019
Epoch 51/80
 - 1s - loss: 0.1018
Epoch 52/80
 - 1s - loss: 0.1018
Epoch 53/80
 - 1s - loss: 0.1017
Epoch 54/80
 - 1s - loss: 0.1016
Epoch 55/80
 - 1s - loss: 0.1016
Epoch 56/80
 - 1s - loss: 0.1015
Epoch 57/80
 - 1s - loss: 0.1015
Epoch 58/80
 - 1s - loss: 0.1014
Epoch 59/80
 - 1s - loss: 0.1013
Epoch 60/80
 - 1s - loss: 0.1013
Epoch 61/80
 - 1s - loss: 0.1013
Epoch 62/80
 - 1s - loss: 0.1012
Epoch 63/80
 - 1s - loss: 0.0986
Epoch 64/80
 - 1s - loss: 0.0983
Epoch 65/80
 - 1s - loss: 0.0983
Epoch 66/80
 - 1s - loss: 0.0983
Epoch 67/80
 - 2s - loss: 0.0983
Epoch 68/80
 - 1s - loss: 0.0976
Epoch 69/80
 - 1s - loss: 0.0976
Epoch 70/80
 - 2s - loss: 0.0976
Epoch 71/80
 - 1s - loss: 0.0976
Epoch 72/80
 - 1s - loss: 0.0974
Epoch 73/80
 - 1s - loss: 0.0974
Epoch 74/80
 - 1s - loss: 0.0974
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2aea58208668>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 08:31:48.672466: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:31:48.835104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:31:48.835150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:31:49.127518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:31:49.127570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:31:49.127579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:31:49.127834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2947
Epoch 2/80
 - 1s - loss: 0.3287
Epoch 3/80
 - 1s - loss: 0.2904
Epoch 4/80
 - 1s - loss: 0.2637
Epoch 5/80
 - 1s - loss: 0.2409
Epoch 6/80
 - 1s - loss: 0.2227
Epoch 7/80
 - 2s - loss: 0.2071
Epoch 8/80
 - 1s - loss: 0.1919
Epoch 9/80
 - 2s - loss: 0.1779
Epoch 10/80
 - 2s - loss: 0.1666
Epoch 11/80
 - 2s - loss: 0.1573
Epoch 12/80
 - 1s - loss: 0.1493
Epoch 13/80
 - 1s - loss: 0.1423
Epoch 14/80
 - 1s - loss: 0.1363
Epoch 15/80
 - 1s - loss: 0.1313
Epoch 16/80
 - 1s - loss: 0.1273
Epoch 17/80
 - 1s - loss: 0.1239
Epoch 18/80
 - 1s - loss: 0.1211
Epoch 19/80
 - 1s - loss: 0.1187
Epoch 20/80
 - 1s - loss: 0.1165
Epoch 21/80
 - 1s - loss: 0.1147
Epoch 22/80
 - 1s - loss: 0.1131
Epoch 23/80
 - 1s - loss: 0.1117
Epoch 24/80
 - 1s - loss: 0.1105
Epoch 25/80
 - 1s - loss: 0.1095
Epoch 26/80
 - 2s - loss: 0.1086
Epoch 27/80
 - 1s - loss: 0.1078
Epoch 28/80
 - 1s - loss: 0.1072
Epoch 29/80
 - 1s - loss: 0.1066
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:32:57.873981: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:32:58.035447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:32:58.035497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:32:58.325480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:32:58.325533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:32:58.325541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:32:58.325792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0903
Epoch 2/80
 - 2s - loss: 0.1963
Epoch 3/80
 - 2s - loss: 0.1659
Epoch 4/80
 - 2s - loss: 0.1526
Epoch 5/80
 - 2s - loss: 0.1395
Epoch 6/80
 - 2s - loss: 0.1275
Epoch 7/80
 - 1s - loss: 0.1164
Epoch 8/80
 - 1s - loss: 0.1063
Epoch 9/80
 - 1s - loss: 0.0975
Epoch 10/80
 - 1s - loss: 0.0899
Epoch 11/80
 - 1s - loss: 0.0831
Epoch 12/80
 - 1s - loss: 0.0773
Epoch 13/80
 - 1s - loss: 0.0724
Epoch 14/80
 - 1s - loss: 0.0682
Epoch 15/80
 - 1s - loss: 0.0648
Epoch 16/80
 - 1s - loss: 0.0620
Epoch 17/80
 - 1s - loss: 0.0596
Epoch 18/80
 - 1s - loss: 0.0576
Epoch 19/80
 - 1s - loss: 0.0559
Epoch 20/80
 - 1s - loss: 0.0544
Epoch 21/80
 - 1s - loss: 0.0531
Epoch 22/80
 - 1s - loss: 0.0520
Epoch 23/80
 - 1s - loss: 0.0509
Epoch 24/80
 - 2s - loss: 0.0501
Epoch 25/80
 - 1s - loss: 0.0493
Epoch 26/80
 - 1s - loss: 0.0486
Epoch 27/80
 - 1s - loss: 0.0481
Epoch 28/80
 - 1s - loss: 0.0476
Epoch 29/80
 - 1s - loss: 0.0471
Epoch 30/80
 - 1s - loss: 0.0468
Epoch 31/80
 - 1s - loss: 0.0464
Epoch 32/80
 - 1s - loss: 0.0461
Epoch 33/80
 - 1s - loss: 0.0459
Epoch 34/80
 - 1s - loss: 0.0457
Epoch 35/80
 - 1s - loss: 0.0455
Epoch 36/80
 - 1s - loss: 0.0453
Epoch 37/80
 - 1s - loss: 0.0451
Epoch 38/80
 - 1s - loss: 0.0450
Epoch 39/80
 - 1s - loss: 0.0448
Epoch 40/80
 - 1s - loss: 0.0447
Epoch 41/80
 - 1s - loss: 0.0446
Epoch 42/80
 - 1s - loss: 0.0445
Epoch 43/80
 - 1s - loss: 0.0444
Epoch 44/80
 - 2s - loss: 0.0443
Epoch 45/80
 - 1s - loss: 0.0442
Epoch 46/80
 - 1s - loss: 0.0442
Epoch 47/80
 - 1s - loss: 0.0441
Epoch 48/80
 - 1s - loss: 0.0440
Epoch 49/80
 - 1s - loss: 0.0440
Epoch 50/80
 - 1s - loss: 0.0439
Epoch 51/80
 - 1s - loss: 0.0439
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:34:40.619638: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:34:40.783981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:34:40.784024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:34:41.076641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:34:41.076693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:34:41.076702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:34:41.076958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0819
Epoch 2/80
 - 1s - loss: 0.1924
Epoch 3/80
 - 1s - loss: 0.1597
Epoch 4/80
 - 1s - loss: 0.1439
Epoch 5/80
 - 1s - loss: 0.1327
Epoch 6/80
 - 1s - loss: 0.1232
Epoch 7/80
 - 1s - loss: 0.1138
Epoch 8/80
 - 1s - loss: 0.1046
Epoch 9/80
 - 2s - loss: 0.0960
Epoch 10/80
 - 1s - loss: 0.0884
Epoch 11/80
 - 1s - loss: 0.0819
Epoch 12/80
 - 2s - loss: 0.0763
Epoch 13/80
 - 1s - loss: 0.0716
Epoch 14/80
 - 2s - loss: 0.0677
Epoch 15/80
 - 1s - loss: 0.0644
Epoch 16/80
 - 2s - loss: 0.0617
Epoch 17/80
 - 1s - loss: 0.0594
Epoch 18/80
 - 1s - loss: 0.0574
Epoch 19/80
 - 1s - loss: 0.0557
Epoch 20/80
 - 2s - loss: 0.0542
Epoch 21/80
 - 1s - loss: 0.0530
Epoch 22/80
 - 2s - loss: 0.0519
Epoch 23/80
 - 1s - loss: 0.0509
Epoch 24/80
 - 1s - loss: 0.0501
Epoch 25/80
 - 1s - loss: 0.0493
Epoch 26/80
 - 1s - loss: 0.0487
Epoch 27/80
 - 1s - loss: 0.0482
Epoch 28/80
 - 1s - loss: 0.0477
Epoch 29/80
 - 1s - loss: 0.0472
Epoch 30/80
 - 1s - loss: 0.0469
Epoch 31/80
 - 1s - loss: 0.0466
Epoch 32/80
 - 2s - loss: 0.0463
Epoch 33/80
 - 1s - loss: 0.0460
Epoch 34/80
 - 1s - loss: 0.0458
Epoch 35/80
 - 2s - loss: 0.0456
Epoch 36/80
 - 1s - loss: 0.0454
Epoch 37/80
 - 1s - loss: 0.0453
Epoch 38/80
 - 1s - loss: 0.0451
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:36:03.718033: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:36:03.884856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:36:03.884899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:36:04.187722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:36:04.187773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:36:04.187783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:36:04.188035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0610
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:36:25.312118: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:36:25.473109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:36:25.473152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:36:25.766237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:36:25.766288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:36:25.766297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:36:25.766555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6645
Epoch 2/80
 - 2s - loss: 0.1063
Epoch 3/80
 - 2s - loss: 0.0702
Epoch 4/80
 - 2s - loss: 0.0645
Epoch 5/80
 - 2s - loss: 0.0614
Epoch 6/80
 - 2s - loss: 0.0578
Epoch 7/80
 - 2s - loss: 0.0530
Epoch 8/80
 - 2s - loss: 0.0478
Epoch 9/80
 - 2s - loss: 0.0428
Epoch 10/80
 - 2s - loss: 0.0385
Epoch 11/80
 - 2s - loss: 0.0350
Epoch 12/80
 - 2s - loss: 0.0320
Epoch 13/80
 - 2s - loss: 0.0295
Epoch 14/80
 - 2s - loss: 0.0273
Epoch 15/80
 - 1s - loss: 0.0254
Epoch 16/80
 - 2s - loss: 0.0238
Epoch 17/80
 - 1s - loss: 0.0224
Epoch 18/80
 - 2s - loss: 0.0213
Epoch 19/80
 - 2s - loss: 0.0204
Epoch 20/80
 - 2s - loss: 0.0196
Epoch 21/80
 - 2s - loss: 0.0190
Epoch 22/80
 - 2s - loss: 0.0184
Epoch 23/80
 - 1s - loss: 0.0179
Epoch 24/80
 - 2s - loss: 0.0174
Epoch 25/80
 - 2s - loss: 0.0170
Epoch 26/80
 - 2s - loss: 0.0167
Epoch 27/80
 - 2s - loss: 0.0164
Epoch 28/80
 - 2s - loss: 0.0161
Epoch 29/80
 - 2s - loss: 0.0159
Epoch 30/80
 - 1s - loss: 0.0157
Epoch 31/80
 - 1s - loss: 0.0155
Epoch 32/80
 - 2s - loss: 0.0154
Epoch 33/80
 - 1s - loss: 0.0153
Epoch 34/80
 - 2s - loss: 0.0151
Epoch 35/80
 - 1s - loss: 0.0150
Epoch 36/80
 - 2s - loss: 0.0149
Epoch 37/80
 - 2s - loss: 0.0148
Epoch 38/80
 - 1s - loss: 0.0148
Epoch 39/80
 - 2s - loss: 0.0147
Epoch 40/80
 - 2s - loss: 0.0146
Epoch 41/80
 - 2s - loss: 0.0146
Epoch 42/80
 - 2s - loss: 0.0145
Epoch 43/80
 - 2s - loss: 0.0145
Epoch 44/80
 - 2s - loss: 0.0144
Epoch 45/80
 - 2s - loss: 0.0144
Epoch 46/80
 - 1s - loss: 0.0143
Epoch 47/80
 - 1s - loss: 0.0143
Epoch 48/80
 - 2s - loss: 0.0143
Epoch 49/80
 - 1s - loss: 0.0142
Epoch 50/80
 - 2s - loss: 0.0138
Epoch 51/80
 - 2s - loss: 0.0137
Epoch 52/80
 - 2s - loss: 0.0137
Epoch 53/80
 - 2s - loss: 0.0137
Epoch 54/80
 - 2s - loss: 0.0136
Epoch 55/80
 - 2s - loss: 0.0136
Epoch 56/80
 - 2s - loss: 0.0136
Epoch 57/80
 - 2s - loss: 0.0136
Epoch 58/80
 - 2s - loss: 0.0136
Epoch 59/80
 - 2s - loss: 0.0136
Epoch 60/80
 - 1s - loss: 0.0136
Epoch 61/80
 - 2s - loss: 0.0136
Epoch 62/80
 - 2s - loss: 0.0136
Epoch 63/80
 - 2s - loss: 0.0136
Epoch 64/80
 - 2s - loss: 0.0136
Epoch 65/80
 - 2s - loss: 0.0136
Epoch 66/80
 - 2s - loss: 0.0136
Epoch 67/80
 - 1s - loss: 0.0136
Epoch 68/80
 - 2s - loss: 0.0136
Epoch 69/80
 - 2s - loss: 0.0136
Epoch 70/80
 - 2s - loss: 0.0136
Epoch 71/80
 - 2s - loss: 0.0136
Epoch 72/80
 - 1s - loss: 0.0136
Epoch 73/80
 - 1s - loss: 0.0136
Epoch 74/80
 - 1s - loss: 0.0136
Epoch 75/80
 - 1s - loss: 0.0136
Epoch 76/80
 - 1s - loss: 0.0136
Epoch 77/80
 - 2s - loss: 0.0136
Epoch 78/80
 - 2s - loss: 0.0136
Epoch 79/80
 - 1s - loss: 0.0136
Epoch 80/80
 - 2s - loss: 0.0136
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.7751 - val_loss: 1.2100
AUC: 0.8255

Epoch 2/80
 - 0s - loss: 1.6431 - val_loss: 0.7037
AUC: 0.8407

Epoch 3/80
 - 0s - loss: 1.2656 - val_loss: 0.7134
AUC: 0.8466

Epoch 4/80
 - 0s - loss: 1.1396 - val_loss: 0.7185
AUC: 0.8525

Epoch 5/80
 - 0s - loss: 1.0887 - val_loss: 0.6500
AUC: 0.8541

Epoch 6/80
 - 0s - loss: 1.0800 - val_loss: 0.7153
AUC: 0.8559

Epoch 7/80
 - 0s - loss: 1.0519 - val_loss: 0.6794
AUC: 0.8568

Epoch 8/80
 - 0s - loss: 1.0371 - val_loss: 0.6755
AUC: 0.8578

Epoch 9/80
 - 0s - loss: 1.0333 - val_loss: 0.6157
AUC: 0.8570

Epoch 10/80
 - 0s - loss: 1.0237 - val_loss: 0.6735
AUC: 0.8610

Epoch 11/80
 - 0s - loss: 1.0073 - val_loss: 0.5485
AUC: 0.8579

Epoch 12/80
 - 0s - loss: 1.0058 - val_loss: 0.6551
AUC: 0.8605

Epoch 13/80
 - 0s - loss: 0.9973 - val_loss: 0.6010
AUC: 0.8602

Epoch 14/80
 - 0s - loss: 0.9930 - val_loss: 0.6844
AUC: 0.8630

Epoch 15/80
 - 0s - loss: 0.9942 - val_loss: 0.5890
AUC: 0.8595

Epoch 16/80
 - 0s - loss: 0.9872 - val_loss: 0.6285
AUC: 0.8627

Epoch 17/80
 - 0s - loss: 0.9810 - val_loss: 0.5497
AUC: 0.8628

Epoch 18/80
 - 0s - loss: 0.9726 - val_loss: 0.6145
AUC: 0.8631

Epoch 19/80
 - 0s - loss: 0.9666 - val_loss: 0.5999
AUC: 0.8635

Epoch 20/80
 - 0s - loss: 0.9651 - val_loss: 0.5948
AUC: 0.8639

Epoch 21/80
 - 0s - loss: 0.9545 - val_loss: 0.6390
AUC: 0.8641

Epoch 22/80
 - 0s - loss: 0.9455 - val_loss: 0.6101
AUC: 0.8646

Epoch 23/80
 - 0s - loss: 0.9438 - val_loss: 0.6177
AUC: 0.8650

Epoch 24/80
 - 0s - loss: 0.9409 - val_loss: 0.5519
AUC: 0.8641

Epoch 25/80
 - 0s - loss: 0.9442 - val_loss: 0.5896
AUC: 0.8648

Epoch 26/80
 - 0s - loss: 0.9442 - val_loss: 0.6190
AUC: 0.8647

Epoch 27/80
 - 0s - loss: 0.9415 - val_loss: 0.6012
AUC: 0.8647

Epoch 28/80
 - 0s - loss: 0.9380 - val_loss: 0.6102
AUC: 0.8651

Epoch 29/80
 - 0s - loss: 0.9390 - val_loss: 0.5849
AUC: 0.8650

Epoch 30/80
 - 0s - loss: 0.9394 - val_loss: 0.6125
AUC: 0.8654

Epoch 31/80
 - 0s - loss: 0.9369 - val_loss: 0.6016
AUC: 0.8645

Epoch 32/80
 - 0s - loss: 0.9367 - val_loss: 0.5966
AUC: 0.8647

Epoch 33/80
 - 0s - loss: 0.9344 - val_loss: 0.5914
AUC: 0.8649

Epoch 34/80
 - 0s - loss: 0.9330 - val_loss: 0.5935
AUC: 0.8650

Epoch 35/80
 - 0s - loss: 0.9308 - val_loss: 0.5891
AUC: 0.8652

Epoch 36/80
 - 0s - loss: 0.9321 - val_loss: 0.5868
AUC: 0.8651

Epoch 37/80
 - 0s - loss: 0.9268 - val_loss: 0.5781
AUC: 0.8652

Epoch 38/80
 - 0s - loss: 0.9277 - val_loss: 0.5957
AUC: 0.8653

Epoch 39/80
 - 0s - loss: 0.9320 - val_loss: 0.5925
AUC: 0.8653

Epoch 40/80
 - 0s - loss: 0.9295 - val_loss: 0.5978
AUC: 0.8653

Epoch 41/80
 - 0s - loss: 0.9316 - val_loss: 0.5769
AUC: 0.8652

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9358 - val_loss: 0.5715
AUC: 0.8650

Epoch 2/30
 - 0s - loss: 0.9293 - val_loss: 0.5603
AUC: 0.8652

Epoch 3/30
 - 0s - loss: 0.9295 - val_loss: 0.5802
AUC: 0.8655

Epoch 4/30
 - 0s - loss: 0.9243 - val_loss: 0.6038
AUC: 0.8656

Epoch 5/30
 - 0s - loss: 0.9254 - val_loss: 0.5845
AUC: 0.8653

Epoch 6/30
 - 0s - loss: 0.9254 - val_loss: 0.5767
AUC: 0.8654

Epoch 7/30
 - 0s - loss: 0.9285 - val_loss: 0.5909
AUC: 0.8654

Epoch 8/30
 - 0s - loss: 0.9233 - val_loss: 0.5934
AUC: 0.8657

Epoch 9/30
 - 0s - loss: 0.9143 - val_loss: 0.5747
AUC: 0.8656

Epoch 10/30
 - 0s - loss: 0.9172 - val_loss: 0.5743
AUC: 0.8656

Epoch 11/30
 - 0s - loss: 0.9179 - val_loss: 0.5694
AUC: 0.8655

Epoch 12/30
 - 0s - loss: 0.9114 - val_loss: 0.5919
AUC: 0.8655

Epoch 13/30
 - 0s - loss: 0.9125 - val_loss: 0.5824
AUC: 0.8657

Epoch 14/30
 - 0s - loss: 0.9094 - val_loss: 0.5700
AUC: 0.8657

Epoch 15/30
 - 0s - loss: 0.9089 - val_loss: 0.5823
AUC: 0.8658

Epoch 16/30
 - 0s - loss: 0.9127 - val_loss: 0.5797
AUC: 0.8658

Epoch 17/30
 - 0s - loss: 0.9096 - val_loss: 0.5781
AUC: 0.8658

Epoch 18/30
 - 0s - loss: 0.9122 - val_loss: 0.5828
AUC: 0.8659

Epoch 19/30
 - 0s - loss: 0.9096 - val_loss: 0.5829
AUC: 0.8658

Epoch 20/30
 - 0s - loss: 0.9084 - val_loss: 0.5785
AUC: 0.8658

Epoch 21/30
 - 0s - loss: 0.9087 - val_loss: 0.5812
AUC: 0.8657

Epoch 22/30
 - 0s - loss: 0.9052 - val_loss: 0.5794
AUC: 0.8658

Epoch 23/30
 - 0s - loss: 0.9064 - val_loss: 0.5818
AUC: 0.8658

Epoch 24/30
 - 0s - loss: 0.9068 - val_loss: 0.5803
AUC: 0.8658

Epoch 25/30
 - 0s - loss: 0.9075 - val_loss: 0.5813
AUC: 0.8658

Epoch 26/30
 - 0s - loss: 0.9065 - val_loss: 0.5819
AUC: 0.8658

Epoch 27/30
 - 0s - loss: 0.9078 - val_loss: 0.5801
AUC: 0.8658

Epoch 28/30
 - 0s - loss: 0.9030 - val_loss: 0.5786
AUC: 0.8658

Epoch 29/30
 - 0s - loss: 0.9043 - val_loss: 0.5808
AUC: 0.8658

Epoch 30/30
 - 0s - loss: 0.9053 - val_loss: 0.5826
Using TensorFlow backend.
AUC: 0.8659

2019-03-08 08:39:45.071242: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:39:45.238808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:39:45.238852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:39:45.532705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:39:45.532756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:39:45.532766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:39:45.533022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6580
Epoch 2/80
 - 2s - loss: 0.1038
Epoch 3/80
 - 1s - loss: 0.0691
Epoch 4/80
 - 1s - loss: 0.0638
Epoch 5/80
 - 1s - loss: 0.0606
Epoch 6/80
 - 1s - loss: 0.0570
Epoch 7/80
 - 1s - loss: 0.0529
Epoch 8/80
 - 1s - loss: 0.0486
Epoch 9/80
 - 1s - loss: 0.0441
Epoch 10/80
 - 1s - loss: 0.0397
Epoch 11/80
 - 2s - loss: 0.0359
Epoch 12/80
 - 1s - loss: 0.0327
Epoch 13/80
 - 2s - loss: 0.0301
Epoch 14/80
 - 1s - loss: 0.0277
Epoch 15/80
 - 1s - loss: 0.0258
Epoch 16/80
 - 1s - loss: 0.0241
Epoch 17/80
 - 1s - loss: 0.0227
Epoch 18/80
 - 1s - loss: 0.0215
Epoch 19/80
 - 1s - loss: 0.0206
Epoch 20/80
 - 1s - loss: 0.0197
Epoch 21/80
 - 1s - loss: 0.0190
Epoch 22/80
 - 1s - loss: 0.0185
Epoch 23/80
 - 1s - loss: 0.0180
Epoch 24/80
 - 1s - loss: 0.0175
Epoch 25/80
 - 1s - loss: 0.0171
Epoch 26/80
 - 1s - loss: 0.0168
Epoch 27/80
 - 1s - loss: 0.0165
Epoch 28/80
 - 1s - loss: 0.0163
Epoch 29/80
 - 2s - loss: 0.0160
Epoch 30/80
 - 1s - loss: 0.0158
Epoch 31/80
 - 1s - loss: 0.0156
Epoch 32/80
 - 2s - loss: 0.0155
Epoch 33/80
 - 2s - loss: 0.0153
Epoch 34/80
 - 1s - loss: 0.0152
Epoch 35/80
 - 1s - loss: 0.0151
Epoch 36/80
 - 1s - loss: 0.0150
Epoch 37/80
 - 1s - loss: 0.0149
Epoch 38/80
 - 1s - loss: 0.0148
Epoch 39/80
 - 1s - loss: 0.0147
Epoch 40/80
 - 1s - loss: 0.0146
Epoch 41/80
 - 1s - loss: 0.0146
Epoch 42/80
 - 1s - loss: 0.0145
Epoch 43/80
 - 1s - loss: 0.0145
Epoch 44/80
 - 1s - loss: 0.0144
Epoch 45/80
 - 1s - loss: 0.0144
Epoch 46/80
 - 2s - loss: 0.0144
Epoch 47/80
 - 1s - loss: 0.0143
Epoch 48/80
 - 1s - loss: 0.0143
Epoch 49/80
 - 1s - loss: 0.0143
Epoch 50/80
 - 2s - loss: 0.0142
Epoch 51/80
 - 1s - loss: 0.0142
Epoch 52/80
 - 2s - loss: 0.0138
Epoch 53/80
 - 1s - loss: 0.0137
Epoch 54/80
 - 1s - loss: 0.0137
Epoch 55/80
 - 1s - loss: 0.0137
Epoch 56/80
 - 1s - loss: 0.0136
Epoch 57/80
 - 1s - loss: 0.0136
Epoch 58/80
 - 1s - loss: 0.0136
Epoch 59/80
 - 1s - loss: 0.0136
Epoch 60/80
 - 1s - loss: 0.0136
Epoch 61/80
 - 1s - loss: 0.0136
Epoch 62/80
 - 1s - loss: 0.0136
Epoch 63/80
 - 1s - loss: 0.0136
Epoch 64/80
 - 1s - loss: 0.0136
Epoch 65/80
 - 1s - loss: 0.0136
Epoch 66/80
 - 1s - loss: 0.0136
Epoch 67/80
 - 1s - loss: 0.0136
Epoch 68/80
 - 1s - loss: 0.0136
Epoch 69/80
 - 1s - loss: 0.0136
Epoch 70/80
 - 1s - loss: 0.0136
Epoch 71/80
 - 1s - loss: 0.0136
Epoch 72/80
 - 2s - loss: 0.0136
Epoch 73/80
 - 1s - loss: 0.0136
Epoch 74/80
 - 1s - loss: 0.0136
Epoch 75/80
 - 1s - loss: 0.0136
Epoch 76/80
 - 1s - loss: 0.0136
Epoch 77/80
 - 1s - loss: 0.0136
Epoch 78/80
 - 1s - loss: 0.0136
Epoch 79/80
 - 1s - loss: 0.0136
Epoch 80/80
 - 1s - loss: 0.0136
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.8090 - val_loss: 1.1950
AUC: 0.8266

Epoch 2/80
 - 0s - loss: 1.6987 - val_loss: 0.6324
AUC: 0.8450

Epoch 3/80
 - 0s - loss: 1.2939 - val_loss: 0.6938
AUC: 0.8526

Epoch 4/80
 - 0s - loss: 1.1456 - val_loss: 0.6253
AUC: 0.8584

Epoch 5/80
 - 0s - loss: 1.1007 - val_loss: 0.6478
AUC: 0.8562

Epoch 6/80
 - 0s - loss: 1.0811 - val_loss: 0.6717
AUC: 0.8610

Epoch 7/80
 - 0s - loss: 1.0663 - val_loss: 0.6789
AUC: 0.8641

Epoch 8/80
 - 0s - loss: 1.0479 - val_loss: 0.6607
AUC: 0.8652

Epoch 9/80
 - 0s - loss: 1.0411 - val_loss: 0.6547
AUC: 0.8646

Epoch 10/80
 - 0s - loss: 1.0376 - val_loss: 0.6461
AUC: 0.8674

Epoch 11/80
 - 0s - loss: 1.0232 - val_loss: 0.5909
AUC: 0.8674

Epoch 12/80
 - 0s - loss: 1.0183 - val_loss: 0.5967
AUC: 0.8674

Epoch 13/80
 - 0s - loss: 1.0156 - val_loss: 0.5590
AUC: 0.8673

Epoch 14/80
 - 0s - loss: 1.0011 - val_loss: 0.5714
AUC: 0.8692

Epoch 15/80
 - 0s - loss: 1.0032 - val_loss: 0.5787
AUC: 0.8685

Epoch 16/80
 - 0s - loss: 0.9929 - val_loss: 0.5590
AUC: 0.8688

Epoch 17/80
 - 0s - loss: 0.9950 - val_loss: 0.6653
AUC: 0.8693

Epoch 18/80
 - 0s - loss: 0.9911 - val_loss: 0.6032
AUC: 0.8700

Epoch 19/80
 - 0s - loss: 0.9819 - val_loss: 0.6568
AUC: 0.8709

Epoch 20/80
 - 0s - loss: 0.9812 - val_loss: 0.6015
AUC: 0.8707

Epoch 21/80
 - 0s - loss: 0.9759 - val_loss: 0.5532
AUC: 0.8695

Epoch 22/80
 - 0s - loss: 0.9731 - val_loss: 0.5988
AUC: 0.8720

Epoch 23/80
 - 0s - loss: 0.9780 - val_loss: 0.5490
AUC: 0.8713

Epoch 24/80
 - 0s - loss: 0.9643 - val_loss: 0.5624
AUC: 0.8712

Epoch 25/80
 - 0s - loss: 0.9640 - val_loss: 0.6262
AUC: 0.8702

Epoch 26/80
 - 0s - loss: 0.9652 - val_loss: 0.5477
AUC: 0.8721

Epoch 27/80
 - 0s - loss: 0.9538 - val_loss: 0.6463
AUC: 0.8732

Epoch 28/80
 - 0s - loss: 0.9547 - val_loss: 0.5792
AUC: 0.8728

Epoch 29/80
 - 0s - loss: 0.9516 - val_loss: 0.5943
AUC: 0.8725

Epoch 30/80
 - 0s - loss: 0.9509 - val_loss: 0.6658
AUC: 0.8729

Epoch 31/80
 - 0s - loss: 0.9505 - val_loss: 0.6439
AUC: 0.8731

Epoch 32/80
 - 0s - loss: 0.9407 - val_loss: 0.5947
AUC: 0.8715

Epoch 33/80
 - 0s - loss: 0.9408 - val_loss: 0.5274
AUC: 0.8731

Epoch 34/80
 - 0s - loss: 0.9366 - val_loss: 0.6395
AUC: 0.8738

Epoch 35/80
 - 0s - loss: 0.9326 - val_loss: 0.5395
AUC: 0.8732

Epoch 36/80
 - 0s - loss: 0.9287 - val_loss: 0.6002
AUC: 0.8713

Epoch 37/80
 - 0s - loss: 0.9301 - val_loss: 0.5261
AUC: 0.8731

Epoch 38/80
 - 0s - loss: 0.9235 - val_loss: 0.5354
AUC: 0.8741

Epoch 39/80
 - 0s - loss: 0.9256 - val_loss: 0.5833
AUC: 0.8735

Epoch 40/80
 - 0s - loss: 0.9196 - val_loss: 0.6564
AUC: 0.8737

Epoch 41/80
 - 0s - loss: 0.9255 - val_loss: 0.6765
AUC: 0.8737

Epoch 42/80
 - 0s - loss: 0.9131 - val_loss: 0.6010
AUC: 0.8744

Epoch 43/80
 - 0s - loss: 0.9068 - val_loss: 0.6040
AUC: 0.8731

Epoch 44/80
 - 0s - loss: 0.9134 - val_loss: 0.6149
AUC: 0.8735

Epoch 45/80
 - 0s - loss: 0.9102 - val_loss: 0.6129
AUC: 0.8735

Epoch 46/80
 - 0s - loss: 0.9046 - val_loss: 0.6383
AUC: 0.8740

Epoch 47/80
 - 0s - loss: 0.9042 - val_loss: 0.5486
AUC: 0.8743

Epoch 48/80
 - 0s - loss: 0.8902 - val_loss: 0.5538
AUC: 0.8735

Epoch 49/80
 - 0s - loss: 0.8786 - val_loss: 0.5523
AUC: 0.8735

Epoch 50/80
 - 0s - loss: 0.8799 - val_loss: 0.5293
AUC: 0.8731

Epoch 51/80
 - 0s - loss: 0.8789 - val_loss: 0.5588
AUC: 0.8731

Epoch 52/80
 - 0s - loss: 0.8755 - val_loss: 0.5567
AUC: 0.8729

Epoch 53/80
 - 0s - loss: 0.8747 - val_loss: 0.5622
AUC: 0.8724

Epoch 54/80
 - 0s - loss: 0.8700 - val_loss: 0.5750
AUC: 0.8732

Epoch 55/80
 - 0s - loss: 0.8713 - val_loss: 0.5549
AUC: 0.8729

Epoch 56/80
 - 0s - loss: 0.8641 - val_loss: 0.5726
AUC: 0.8732

Epoch 57/80
 - 0s - loss: 0.8671 - val_loss: 0.5765
AUC: 0.8732

Epoch 58/80
 - 0s - loss: 0.8645 - val_loss: 0.5447
AUC: 0.8730

Epoch 59/80
 - 0s - loss: 0.8648 - val_loss: 0.5530
AUC: 0.8730

Epoch 60/80
 - 0s - loss: 0.8631 - val_loss: 0.5560
AUC: 0.8730

Epoch 61/80
 - 0s - loss: 0.8594 - val_loss: 0.5539
AUC: 0.8732

Epoch 62/80
 - 0s - loss: 0.8594 - val_loss: 0.5558
AUC: 0.8732

Epoch 63/80
 - 0s - loss: 0.8638 - val_loss: 0.5490
AUC: 0.8731

Epoch 64/80
 - 0s - loss: 0.8638 - val_loss: 0.5613
AUC: 0.8731

Epoch 65/80
 - 0s - loss: 0.8556 - val_loss: 0.5592
AUC: 0.8732

Epoch 66/80
 - 0s - loss: 0.8617 - val_loss: 0.5476
AUC: 0.8731

Epoch 67/80
 - 0s - loss: 0.8606 - val_loss: 0.5525
AUC: 0.8729

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.8954 - val_loss: 0.5665
AUC: 0.8743

Epoch 2/30
 - 0s - loss: 0.8905 - val_loss: 0.5391
AUC: 0.8735

Epoch 3/30
 - 0s - loss: 0.8893 - val_loss: 0.5732
AUC: 0.8739

Epoch 4/30
 - 0s - loss: 0.8898 - val_loss: 0.5666
AUC: 0.8739

Epoch 5/30
 - 0s - loss: 0.8841 - val_loss: 0.5538
AUC: 0.8738

Epoch 6/30
 - 0s - loss: 0.8828 - val_loss: 0.5638
AUC: 0.8739

Epoch 7/30
 - 0s - loss: 0.8792 - val_loss: 0.5622
AUC: 0.8737

Epoch 8/30
 - 0s - loss: 0.8786 - val_loss: 0.5584
AUC: 0.8739

Epoch 9/30
 - 0s - loss: 0.8748 - val_loss: 0.5540
AUC: 0.8737

Epoch 10/30
 - 0s - loss: 0.8782 - val_loss: 0.5926
AUC: 0.8744

Epoch 11/30
 - 0s - loss: 0.8755 - val_loss: 0.5634
AUC: 0.8741

Epoch 12/30
 - 0s - loss: 0.8725 - val_loss: 0.5433
AUC: 0.8740

Epoch 13/30
 - 0s - loss: 0.8689 - val_loss: 0.5572
AUC: 0.8741

Epoch 14/30
 - 0s - loss: 0.8656 - val_loss: 0.5611
AUC: 0.8742

Epoch 15/30
 - 0s - loss: 0.8653 - val_loss: 0.5611
AUC: 0.8741

Epoch 16/30
 - 0s - loss: 0.8628 - val_loss: 0.5607
AUC: 0.8741

Epoch 17/30
 - 0s - loss: 0.8656 - val_loss: 0.5544
AUC: 0.8742

Epoch 18/30
 - 0s - loss: 0.8672 - val_loss: 0.5549
AUC: 0.8741

Epoch 19/30
 - 0s - loss: 0.8659 - val_loss: 0.5591
AUC: 0.8741

Epoch 20/30
 - 0s - loss: 0.8601 - val_loss: 0.5573
AUC: 0.8741

Epoch 21/30
 - 0s - loss: 0.8681 - val_loss: 0.5588
AUC: 0.8740

Epoch 22/30
 - 0s - loss: 0.8674 - val_loss: 0.5587
AUC: 0.8741

Epoch 23/30
 - 0s - loss: 0.8658 - val_loss: 0.5585
AUC: 0.8741

Epoch 24/30
 - 0s - loss: 0.8604 - val_loss: 0.5563
AUC: 0.8741

Epoch 25/30
 - 0s - loss: 0.8642 - val_loss: 0.5561
AUC: 0.8741

Epoch 26/30
 - 0s - loss: 0.8616 - val_loss: 0.5548
AUC: 0.8741

Epoch 27/30
 - 0s - loss: 0.8647 - val_loss: 0.5567
AUC: 0.8741

Epoch 28/30
 - 0s - loss: 0.8603 - val_loss: 0.5555
AUC: 0.8741

Epoch 29/30
 - 0s - loss: 0.8677 - val_loss: 0.5561
AUC: 0.8741

Epoch 30/30
 - 0s - loss: 0.8593 - val_loss: 0.5551
Using TensorFlow backend.
AUC: 0.8741

2019-03-08 08:43:18.984876: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:43:19.149050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:43:19.149093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:43:19.445900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:43:19.445951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:43:19.445960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:43:19.446220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6545
Epoch 2/80
 - 2s - loss: 0.1020
Epoch 3/80
 - 2s - loss: 0.0693
Epoch 4/80
 - 1s - loss: 0.0647
Epoch 5/80
 - 1s - loss: 0.0616
Epoch 6/80
 - 2s - loss: 0.0577
Epoch 7/80
 - 2s - loss: 0.0529
Epoch 8/80
 - 2s - loss: 0.0483
Epoch 9/80
 - 1s - loss: 0.0443
Epoch 10/80
 - 2s - loss: 0.0408
Epoch 11/80
 - 2s - loss: 0.0374
Epoch 12/80
 - 1s - loss: 0.0343
Epoch 13/80
 - 2s - loss: 0.0314
Epoch 14/80
 - 2s - loss: 0.0289
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:44:00.143768: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:44:00.307514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:44:00.307558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:44:00.595572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:44:00.595622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:44:00.595631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:44:00.595885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1889
Epoch 2/80
 - 2s - loss: 0.3104
Epoch 3/80
 - 2s - loss: 0.2646
Epoch 4/80
 - 2s - loss: 0.2306
Epoch 5/80
 - 2s - loss: 0.2052
Epoch 6/80
 - 2s - loss: 0.1858
Epoch 7/80
 - 2s - loss: 0.1707
Epoch 8/80
 - 2s - loss: 0.1583
Epoch 9/80
 - 2s - loss: 0.1478
Epoch 10/80
 - 2s - loss: 0.1388
Epoch 11/80
 - 2s - loss: 0.1313
Epoch 12/80
 - 2s - loss: 0.1252
Epoch 13/80
 - 2s - loss: 0.1201
Epoch 14/80
 - 2s - loss: 0.1158
Epoch 15/80
 - 2s - loss: 0.1120
Epoch 16/80
 - 2s - loss: 0.1087
Epoch 17/80
 - 2s - loss: 0.1058
Epoch 18/80
 - 2s - loss: 0.1032
Epoch 19/80
 - 2s - loss: 0.1010
Epoch 20/80
 - 2s - loss: 0.0990
Epoch 21/80
 - 2s - loss: 0.0974
Epoch 22/80
 - 2s - loss: 0.0960
Epoch 23/80
 - 2s - loss: 0.0947
Epoch 24/80
 - 2s - loss: 0.0937
Epoch 25/80
 - 2s - loss: 0.0928
Epoch 26/80
 - 2s - loss: 0.0920
Epoch 27/80
 - 2s - loss: 0.0913
Epoch 28/80
 - 2s - loss: 0.0908
Epoch 29/80
 - 2s - loss: 0.0902
Epoch 30/80
 - 2s - loss: 0.0898
Epoch 31/80
 - 2s - loss: 0.0893
Epoch 32/80
 - 2s - loss: 0.0890
Epoch 33/80
 - 2s - loss: 0.0887
Epoch 34/80
 - 2s - loss: 0.0884
Epoch 35/80
 - 2s - loss: 0.0881
Epoch 36/80
 - 2s - loss: 0.0879
Epoch 37/80
 - 2s - loss: 0.0876
Epoch 38/80
 - 2s - loss: 0.0874
Epoch 39/80
 - 2s - loss: 0.0873
Epoch 40/80
 - 2s - loss: 0.0871
Epoch 41/80
 - 2s - loss: 0.0870
Epoch 42/80
 - 2s - loss: 0.0868
Epoch 43/80
 - 2s - loss: 0.0867
Epoch 44/80
 - 2s - loss: 0.0866
Epoch 45/80
 - 2s - loss: 0.0864
Epoch 46/80
 - 2s - loss: 0.0863
Epoch 47/80
 - 2s - loss: 0.0862
Epoch 48/80
 - 2s - loss: 0.0861
Epoch 49/80
 - 2s - loss: 0.0860
Epoch 50/80
 - 2s - loss: 0.0859
Epoch 51/80
 - 2s - loss: 0.0858
Epoch 52/80
 - 2s - loss: 0.0858
Epoch 53/80
 - 2s - loss: 0.0856
Epoch 54/80
 - 2s - loss: 0.0856
Epoch 55/80
 - 2s - loss: 0.0855
Epoch 56/80
 - 2s - loss: 0.0854
Epoch 57/80
 - 2s - loss: 0.0854
Epoch 58/80
 - 2s - loss: 0.0854
Epoch 59/80
 - 2s - loss: 0.0853
Epoch 60/80
 - 2s - loss: 0.0852
Epoch 61/80
 - 2s - loss: 0.0852
Epoch 62/80
 - 2s - loss: 0.0852
Epoch 63/80
 - 2s - loss: 0.0851
Epoch 64/80
 - 2s - loss: 0.0851
Epoch 65/80
 - 2s - loss: 0.0850
Epoch 66/80
 - 2s - loss: 0.0850
Epoch 67/80
 - 2s - loss: 0.0849
Epoch 68/80
 - 2s - loss: 0.0849
Epoch 69/80
 - 2s - loss: 0.0848
Epoch 70/80
 - 2s - loss: 0.0848
Epoch 71/80
 - 2s - loss: 0.0815
Epoch 72/80
 - 2s - loss: 0.0812
Epoch 73/80
 - 2s - loss: 0.0812
Epoch 74/80
 - 2s - loss: 0.0812
Epoch 75/80
 - 2s - loss: 0.0811
Epoch 76/80
 - 2s - loss: 0.0804
Epoch 77/80
 - 2s - loss: 0.0803
Epoch 78/80
 - 2s - loss: 0.0803
Epoch 79/80
 - 2s - loss: 0.0803
Epoch 80/80
 - 2s - loss: 0.0801
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 6.3477 - val_loss: 1.7832
AUC: 0.7500

Epoch 2/80
 - 0s - loss: 4.0946 - val_loss: 1.7043
AUC: 0.7951

Epoch 3/80
 - 0s - loss: 3.1021 - val_loss: 1.2510
AUC: 0.8187

Epoch 4/80
 - 0s - loss: 2.1620 - val_loss: 0.8916
AUC: 0.8227

Epoch 5/80
 - 0s - loss: 1.5556 - val_loss: 0.7265
AUC: 0.8293

Epoch 6/80
 - 0s - loss: 1.3354 - val_loss: 0.6964
AUC: 0.8344

Epoch 7/80
 - 0s - loss: 1.2660 - val_loss: 0.7152
AUC: 0.8405

Epoch 8/80
 - 0s - loss: 1.2196 - val_loss: 0.7186
AUC: 0.8441

Epoch 9/80
 - 0s - loss: 1.1791 - val_loss: 0.6883
AUC: 0.8466

Epoch 10/80
 - 0s - loss: 1.1567 - val_loss: 0.6734
AUC: 0.8497

Epoch 11/80
 - 0s - loss: 1.1406 - val_loss: 0.6612
AUC: 0.8524

Epoch 12/80
 - 0s - loss: 1.1319 - val_loss: 0.6564
AUC: 0.8553

Epoch 13/80
 - 0s - loss: 1.1246 - val_loss: 0.6643
AUC: 0.8573

Epoch 14/80
 - 0s - loss: 1.1160 - val_loss: 0.6429
AUC: 0.8582

Epoch 15/80
 - 0s - loss: 1.1055 - val_loss: 0.6882
AUC: 0.8599

Epoch 16/80
 - 0s - loss: 1.1028 - val_loss: 0.6655
AUC: 0.8617

Epoch 17/80
 - 0s - loss: 1.0804 - val_loss: 0.6572
AUC: 0.8610

Epoch 18/80
 - 0s - loss: 1.0826 - val_loss: 0.6325
AUC: 0.8624

Epoch 19/80
 - 0s - loss: 1.0719 - val_loss: 0.5905
AUC: 0.8613

Epoch 20/80
 - 0s - loss: 1.0754 - val_loss: 0.6573
AUC: 0.8639

Epoch 21/80
 - 0s - loss: 1.0662 - val_loss: 0.6795
AUC: 0.8646

Epoch 22/80
 - 0s - loss: 1.0588 - val_loss: 0.6315
AUC: 0.8645

Epoch 23/80
 - 0s - loss: 1.0641 - val_loss: 0.6453
AUC: 0.8656

Epoch 24/80
 - 0s - loss: 1.0574 - val_loss: 0.6770
AUC: 0.8657

Epoch 25/80
 - 0s - loss: 1.0595 - val_loss: 0.6446
AUC: 0.8658

Epoch 26/80
 - 0s - loss: 1.0587 - val_loss: 0.5877
AUC: 0.8656

Epoch 27/80
 - 0s - loss: 1.0521 - val_loss: 0.6187
AUC: 0.8661

Epoch 28/80
 - 0s - loss: 1.0433 - val_loss: 0.6156
AUC: 0.8664

Epoch 29/80
 - 0s - loss: 1.0462 - val_loss: 0.6551
AUC: 0.8676

Epoch 30/80
 - 0s - loss: 1.0380 - val_loss: 0.6311
AUC: 0.8674

Epoch 31/80
 - 0s - loss: 1.0443 - val_loss: 0.6747
AUC: 0.8680

Epoch 32/80
 - 0s - loss: 1.0459 - val_loss: 0.6176
AUC: 0.8687

Epoch 33/80
 - 0s - loss: 1.0432 - val_loss: 0.6308
AUC: 0.8688

Epoch 34/80
 - 0s - loss: 1.0385 - val_loss: 0.5852
AUC: 0.8689

Epoch 35/80
 - 0s - loss: 1.0336 - val_loss: 0.5998
AUC: 0.8687

Epoch 36/80
 - 0s - loss: 1.0352 - val_loss: 0.6681
AUC: 0.8690

Epoch 37/80
 - 0s - loss: 1.0344 - val_loss: 0.6195
AUC: 0.8693

Epoch 38/80
 - 0s - loss: 1.0350 - val_loss: 0.5874
AUC: 0.8691

Epoch 39/80
 - 0s - loss: 1.0241 - val_loss: 0.6348
AUC: 0.8697

Epoch 40/80
 - 0s - loss: 1.0301 - val_loss: 0.5855
AUC: 0.8698

Epoch 41/80
 - 0s - loss: 1.0271 - val_loss: 0.6470
AUC: 0.8700

Epoch 42/80
 - 0s - loss: 1.0272 - val_loss: 0.6046
AUC: 0.8701

Epoch 43/80
 - 0s - loss: 1.0231 - val_loss: 0.5722
AUC: 0.8697

Epoch 44/80
 - 0s - loss: 1.0195 - val_loss: 0.6355
AUC: 0.8708

Epoch 45/80
 - 0s - loss: 1.0185 - val_loss: 0.6620
AUC: 0.8705

Epoch 46/80
 - 0s - loss: 1.0126 - val_loss: 0.6680
AUC: 0.8709

Epoch 47/80
 - 0s - loss: 1.0126 - val_loss: 0.6193
AUC: 0.8704

Epoch 48/80
 - 0s - loss: 1.0172 - val_loss: 0.6270
AUC: 0.8719

Epoch 49/80
 - 0s - loss: 1.0048 - val_loss: 0.6340
AUC: 0.8722

Epoch 50/80
 - 0s - loss: 1.0130 - val_loss: 0.6187
AUC: 0.8714

Epoch 51/80
 - 0s - loss: 1.0113 - val_loss: 0.6184
AUC: 0.8724

Epoch 52/80
 - 0s - loss: 1.0073 - val_loss: 0.6432
AUC: 0.8722

Epoch 53/80
 - 0s - loss: 1.0078 - val_loss: 0.6151
AUC: 0.8724

Epoch 54/80
 - 0s - loss: 0.9931 - val_loss: 0.6046
AUC: 0.8723

Epoch 55/80
 - 0s - loss: 1.0010 - val_loss: 0.6025
AUC: 0.8723

Epoch 56/80
 - 0s - loss: 0.9985 - val_loss: 0.6137
AUC: 0.8725

Epoch 57/80
 - 0s - loss: 0.9960 - val_loss: 0.6282
AUC: 0.8724

Epoch 58/80
 - 0s - loss: 0.9910 - val_loss: 0.6043
AUC: 0.8722

Epoch 59/80
 - 0s - loss: 0.9933 - val_loss: 0.5899
AUC: 0.8721

Epoch 60/80
 - 0s - loss: 0.9982 - val_loss: 0.5924
AUC: 0.8720

Epoch 61/80
 - 0s - loss: 0.9978 - val_loss: 0.5996
AUC: 0.8721

Epoch 62/80
 - 0s - loss: 0.9974 - val_loss: 0.6338
AUC: 0.8721

Epoch 63/80
 - 0s - loss: 0.9952 - val_loss: 0.6013
AUC: 0.8723

Epoch 64/80
 - 0s - loss: 0.9951 - val_loss: 0.6056
AUC: 0.8723

Epoch 65/80
 - 0s - loss: 0.9905 - val_loss: 0.6089
AUC: 0.8723

Epoch 66/80
 - 0s - loss: 0.9933 - val_loss: 0.6021
AUC: 0.8722

Epoch 67/80
 - 0s - loss: 0.9931 - val_loss: 0.6030
AUC: 0.8722

Epoch 68/80
 - 0s - loss: 0.9945 - val_loss: 0.6059
AUC: 0.8722

Epoch 69/80
 - 0s - loss: 0.9931 - val_loss: 0.6073
AUC: 0.8723

Epoch 70/80
 - 0s - loss: 0.9974 - val_loss: 0.6082
AUC: 0.8723

Epoch 71/80
 - 0s - loss: 0.9953 - val_loss: 0.5980
AUC: 0.8722

Epoch 72/80
 - 0s - loss: 0.9986 - val_loss: 0.5984
AUC: 0.8722

Epoch 73/80
 - 0s - loss: 0.9984 - val_loss: 0.6030
AUC: 0.8723

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0034 - val_loss: 0.6026
AUC: 0.8723

Epoch 2/30
 - 0s - loss: 1.0008 - val_loss: 0.6018
AUC: 0.8722

Epoch 3/30
 - 0s - loss: 0.9954 - val_loss: 0.6139
AUC: 0.8723

Epoch 4/30
 - 0s - loss: 0.9944 - val_loss: 0.6111
AUC: 0.8725

Epoch 5/30
 - 0s - loss: 0.9869 - val_loss: 0.6118
AUC: 0.8724

Epoch 6/30
 - 0s - loss: 0.9907 - val_loss: 0.6079
AUC: 0.8727

Epoch 7/30
 - 0s - loss: 0.9908 - val_loss: 0.5970
AUC: 0.8725

Epoch 8/30
 - 0s - loss: 0.9877 - val_loss: 0.6065
AUC: 0.8725

Epoch 9/30
 - 0s - loss: 0.9889 - val_loss: 0.5983
AUC: 0.8726

Epoch 10/30
 - 0s - loss: 0.9793 - val_loss: 0.6133
AUC: 0.8728

Epoch 11/30
 - 0s - loss: 0.9808 - val_loss: 0.5947
AUC: 0.8727

Epoch 12/30
 - 0s - loss: 0.9824 - val_loss: 0.5957
AUC: 0.8729

Epoch 13/30
 - 0s - loss: 0.9815 - val_loss: 0.6037
AUC: 0.8727

Epoch 14/30
 - 0s - loss: 0.9802 - val_loss: 0.6026
AUC: 0.8730

Epoch 15/30
 - 0s - loss: 0.9729 - val_loss: 0.5786
AUC: 0.8728

Epoch 16/30
 - 0s - loss: 0.9716 - val_loss: 0.5870
AUC: 0.8728

Epoch 17/30
 - 0s - loss: 0.9787 - val_loss: 0.6042
AUC: 0.8730

Epoch 18/30
 - 0s - loss: 0.9727 - val_loss: 0.6112
AUC: 0.8732

Epoch 19/30
 - 0s - loss: 0.9717 - val_loss: 0.5982
AUC: 0.8732

Epoch 20/30
 - 0s - loss: 0.9656 - val_loss: 0.6111
AUC: 0.8733

Epoch 21/30
 - 0s - loss: 0.9758 - val_loss: 0.6013
AUC: 0.8733

Epoch 22/30
 - 0s - loss: 0.9673 - val_loss: 0.5976
AUC: 0.8732

Epoch 23/30
 - 0s - loss: 0.9670 - val_loss: 0.5808
AUC: 0.8733

Epoch 24/30
 - 0s - loss: 0.9620 - val_loss: 0.5896
AUC: 0.8734

Epoch 25/30
 - 0s - loss: 0.9700 - val_loss: 0.5914
AUC: 0.8732

Epoch 26/30
 - 0s - loss: 0.9656 - val_loss: 0.5922
AUC: 0.8733

Epoch 27/30
 - 0s - loss: 0.9646 - val_loss: 0.5931
AUC: 0.8733

Epoch 28/30
 - 0s - loss: 0.9645 - val_loss: 0.5937
AUC: 0.8733

Epoch 29/30
 - 0s - loss: 0.9612 - val_loss: 0.5945
AUC: 0.8733

Epoch 30/30
 - 0s - loss: 0.9573 - val_loss: 0.5921
Using TensorFlow backend.
AUC: 0.8733

2019-03-08 08:47:31.953006: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:47:32.115821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:47:32.115864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:47:32.405916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:47:32.405975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:47:32.405984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:47:32.406262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2338
Epoch 2/80
 - 2s - loss: 0.3150
Epoch 3/80
 - 2s - loss: 0.2695
Epoch 4/80
 - 2s - loss: 0.2290
Epoch 5/80
 - 2s - loss: 0.2020
Epoch 6/80
 - 2s - loss: 0.1824
Epoch 7/80
 - 2s - loss: 0.1669
Epoch 8/80
 - 2s - loss: 0.1548
Epoch 9/80
 - 2s - loss: 0.1450
Epoch 10/80
 - 2s - loss: 0.1368
Epoch 11/80
 - 2s - loss: 0.1297
Epoch 12/80
 - 2s - loss: 0.1238
Epoch 13/80
 - 2s - loss: 0.1190
Epoch 14/80
 - 2s - loss: 0.1148
Epoch 15/80
 - 2s - loss: 0.1113
Epoch 16/80
 - 2s - loss: 0.1081
Epoch 17/80
 - 2s - loss: 0.1054
Epoch 18/80
 - 2s - loss: 0.1029
Epoch 19/80
 - 2s - loss: 0.1007
Epoch 20/80
 - 2s - loss: 0.0989
Epoch 21/80
 - 2s - loss: 0.0973
Epoch 22/80
 - 2s - loss: 0.0959
Epoch 23/80
 - 2s - loss: 0.0947
Epoch 24/80
 - 2s - loss: 0.0937
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0921
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0909
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0900
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0892
Epoch 33/80
 - 2s - loss: 0.0889
Epoch 34/80
 - 2s - loss: 0.0887
Epoch 35/80
 - 2s - loss: 0.0884
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0879
Epoch 38/80
 - 2s - loss: 0.0878
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0874
Epoch 41/80
 - 2s - loss: 0.0872
Epoch 42/80
 - 2s - loss: 0.0871
Epoch 43/80
 - 2s - loss: 0.0869
Epoch 44/80
 - 2s - loss: 0.0868
Epoch 45/80
 - 2s - loss: 0.0867
Epoch 46/80
 - 2s - loss: 0.0866
Epoch 47/80
 - 2s - loss: 0.0865
Epoch 48/80
 - 2s - loss: 0.0864
Epoch 49/80
 - 2s - loss: 0.0863
Epoch 50/80
 - 2s - loss: 0.0862
Epoch 51/80
 - 2s - loss: 0.0861
Epoch 52/80
 - 2s - loss: 0.0861
Epoch 53/80
 - 2s - loss: 0.0860
Epoch 54/80
 - 2s - loss: 0.0859
Epoch 55/80
 - 2s - loss: 0.0858
Epoch 56/80
 - 2s - loss: 0.0858
Epoch 57/80
 - 2s - loss: 0.0857
Epoch 58/80
 - 2s - loss: 0.0857
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0856
Epoch 61/80
 - 2s - loss: 0.0855
Epoch 62/80
 - 2s - loss: 0.0855
Epoch 63/80
 - 2s - loss: 0.0854
Epoch 64/80
 - 2s - loss: 0.0854
Epoch 65/80
 - 2s - loss: 0.0854
Epoch 66/80
 - 2s - loss: 0.0853
Epoch 67/80
 - 2s - loss: 0.0853
Epoch 68/80
 - 2s - loss: 0.0853
Epoch 69/80
 - 2s - loss: 0.0852
Epoch 70/80
 - 2s - loss: 0.0851
Epoch 71/80
 - 2s - loss: 0.0852
Epoch 72/80
 - 2s - loss: 0.0851
Epoch 73/80
 - 2s - loss: 0.0851
Epoch 74/80
 - 2s - loss: 0.0817
Epoch 75/80
 - 2s - loss: 0.0815
Epoch 76/80
 - 2s - loss: 0.0814
Epoch 77/80
 - 2s - loss: 0.0814
Epoch 78/80
 - 2s - loss: 0.0814
Epoch 79/80
 - 2s - loss: 0.0806
Epoch 80/80
 - 2s - loss: 0.0806
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 7.4062 - val_loss: 2.1879
AUC: 0.7158

Epoch 2/80
 - 0s - loss: 4.0841 - val_loss: 1.3671
AUC: 0.7659

Epoch 3/80
 - 0s - loss: 2.7621 - val_loss: 1.0077
AUC: 0.7983

Epoch 4/80
 - 0s - loss: 1.9108 - val_loss: 0.7940
AUC: 0.8194

Epoch 5/80
 - 0s - loss: 1.4940 - val_loss: 0.7468
AUC: 0.8317

Epoch 6/80
 - 0s - loss: 1.3265 - val_loss: 0.7343
AUC: 0.8396

Epoch 7/80
 - 0s - loss: 1.2541 - val_loss: 0.6926
AUC: 0.8437

Epoch 8/80
 - 0s - loss: 1.2280 - val_loss: 0.6507
AUC: 0.8443

Epoch 9/80
 - 0s - loss: 1.1973 - val_loss: 0.6728
AUC: 0.8483

Epoch 10/80
 - 0s - loss: 1.1685 - val_loss: 0.6828
AUC: 0.8519

Epoch 11/80
 - 0s - loss: 1.1451 - val_loss: 0.6599
AUC: 0.8534

Epoch 12/80
 - 0s - loss: 1.1289 - val_loss: 0.6722
AUC: 0.8574

Epoch 13/80
 - 0s - loss: 1.1268 - val_loss: 0.6310
AUC: 0.8576

Epoch 14/80
 - 0s - loss: 1.1091 - val_loss: 0.6574
AUC: 0.8589

Epoch 15/80
 - 0s - loss: 1.1020 - val_loss: 0.6936
AUC: 0.8618

Epoch 16/80
 - 0s - loss: 1.1009 - val_loss: 0.6220
AUC: 0.8611

Epoch 17/80
 - 0s - loss: 1.0912 - val_loss: 0.6566
AUC: 0.8635

Epoch 18/80
 - 0s - loss: 1.0847 - val_loss: 0.6720
AUC: 0.8633

Epoch 19/80
 - 0s - loss: 1.0682 - val_loss: 0.6081
AUC: 0.8630

Epoch 20/80
 - 0s - loss: 1.0639 - val_loss: 0.5972
AUC: 0.8645

Epoch 21/80
 - 0s - loss: 1.0619 - val_loss: 0.5888
AUC: 0.8658

Epoch 22/80
 - 0s - loss: 1.0613 - val_loss: 0.6356
AUC: 0.8654

Epoch 23/80
 - 0s - loss: 1.0577 - val_loss: 0.6422
AUC: 0.8664

Epoch 24/80
 - 0s - loss: 1.0540 - val_loss: 0.6873
AUC: 0.8675

Epoch 25/80
 - 0s - loss: 1.0435 - val_loss: 0.6230
AUC: 0.8678

Epoch 26/80
 - 0s - loss: 1.0471 - val_loss: 0.5796
AUC: 0.8674

Epoch 27/80
 - 0s - loss: 1.0348 - val_loss: 0.5976
AUC: 0.8681

Epoch 28/80
 - 0s - loss: 1.0377 - val_loss: 0.6177
AUC: 0.8694

Epoch 29/80
 - 0s - loss: 1.0380 - val_loss: 0.6070
AUC: 0.8686

Epoch 30/80
 - 0s - loss: 1.0360 - val_loss: 0.6287
AUC: 0.8688

Epoch 31/80
 - 0s - loss: 1.0280 - val_loss: 0.5979
AUC: 0.8688

Epoch 32/80
 - 0s - loss: 1.0226 - val_loss: 0.6203
AUC: 0.8700

Epoch 33/80
 - 0s - loss: 1.0241 - val_loss: 0.6359
AUC: 0.8700

Epoch 34/80
 - 0s - loss: 1.0249 - val_loss: 0.6049
AUC: 0.8708

Epoch 35/80
 - 0s - loss: 1.0204 - val_loss: 0.5632
AUC: 0.8698

Epoch 36/80
 - 0s - loss: 1.0177 - val_loss: 0.6105
AUC: 0.8711

Epoch 37/80
 - 0s - loss: 1.0146 - val_loss: 0.6186
AUC: 0.8708

Epoch 38/80
 - 0s - loss: 1.0185 - val_loss: 0.6355
AUC: 0.8712

Epoch 39/80
 - 0s - loss: 1.0159 - val_loss: 0.6408
AUC: 0.8716

Epoch 40/80
 - 0s - loss: 1.0146 - val_loss: 0.5598
AUC: 0.8713

Epoch 41/80
 - 0s - loss: 1.0079 - val_loss: 0.5870
AUC: 0.8706

Epoch 42/80
 - 0s - loss: 1.0175 - val_loss: 0.5602
AUC: 0.8708

Epoch 43/80
 - 0s - loss: 1.0061 - val_loss: 0.6180
AUC: 0.8720

Epoch 44/80
 - 0s - loss: 1.0032 - val_loss: 0.6055
AUC: 0.8718

Epoch 45/80
 - 0s - loss: 0.9986 - val_loss: 0.5953
AUC: 0.8722

Epoch 46/80
 - 0s - loss: 0.9956 - val_loss: 0.5974
AUC: 0.8720

Epoch 47/80
 - 0s - loss: 0.9983 - val_loss: 0.6035
AUC: 0.8711

Epoch 48/80
 - 0s - loss: 0.9993 - val_loss: 0.5093
AUC: 0.8714

Epoch 49/80
 - 0s - loss: 0.9990 - val_loss: 0.5580
AUC: 0.8720

Epoch 50/80
 - 0s - loss: 1.0051 - val_loss: 0.5910
AUC: 0.8723

Epoch 51/80
 - 0s - loss: 0.9930 - val_loss: 0.5808
AUC: 0.8727

Epoch 52/80
 - 0s - loss: 0.9917 - val_loss: 0.5387
AUC: 0.8723

Epoch 53/80
 - 0s - loss: 0.9891 - val_loss: 0.5998
AUC: 0.8735

Epoch 54/80
 - 0s - loss: 0.9794 - val_loss: 0.5546
AUC: 0.8712

Epoch 55/80
 - 0s - loss: 0.9844 - val_loss: 0.5968
AUC: 0.8730

Epoch 56/80
 - 0s - loss: 0.9850 - val_loss: 0.6594
AUC: 0.8727

Epoch 57/80
 - 0s - loss: 0.9853 - val_loss: 0.5689
AUC: 0.8732

Epoch 58/80
 - 0s - loss: 0.9809 - val_loss: 0.6174
AUC: 0.8735

Epoch 59/80
 - 0s - loss: 0.9710 - val_loss: 0.6130
AUC: 0.8740

Epoch 60/80
 - 0s - loss: 0.9743 - val_loss: 0.5808
AUC: 0.8738

Epoch 61/80
 - 0s - loss: 0.9745 - val_loss: 0.5721
AUC: 0.8736

Epoch 62/80
 - 0s - loss: 0.9754 - val_loss: 0.5867
AUC: 0.8739

Epoch 63/80
 - 0s - loss: 0.9773 - val_loss: 0.5997
AUC: 0.8738

Epoch 64/80
 - 0s - loss: 0.9743 - val_loss: 0.5771
AUC: 0.8736

Epoch 65/80
 - 0s - loss: 0.9772 - val_loss: 0.5682
AUC: 0.8737

Epoch 66/80
 - 0s - loss: 0.9713 - val_loss: 0.5738
AUC: 0.8738

Epoch 67/80
 - 0s - loss: 0.9767 - val_loss: 0.5836
AUC: 0.8739

Epoch 68/80
 - 0s - loss: 0.9694 - val_loss: 0.5635
AUC: 0.8737

Epoch 69/80
 - 0s - loss: 0.9726 - val_loss: 0.5803
AUC: 0.8739

Epoch 70/80
 - 0s - loss: 0.9686 - val_loss: 0.5821
AUC: 0.8739

Epoch 71/80
 - 0s - loss: 0.9640 - val_loss: 0.5789
AUC: 0.8739

Epoch 72/80
 - 0s - loss: 0.9688 - val_loss: 0.5843
AUC: 0.8740

Epoch 73/80
 - 0s - loss: 0.9636 - val_loss: 0.5819
AUC: 0.8739

Epoch 74/80
 - 0s - loss: 0.9666 - val_loss: 0.5824
AUC: 0.8739

Epoch 75/80
 - 0s - loss: 0.9709 - val_loss: 0.5797
AUC: 0.8740

Epoch 76/80
 - 0s - loss: 0.9754 - val_loss: 0.5891
AUC: 0.8740

Epoch 77/80
 - 0s - loss: 0.9668 - val_loss: 0.5820
AUC: 0.8740

Epoch 78/80
 - 0s - loss: 0.9655 - val_loss: 0.5890
AUC: 0.8741

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9715 - val_loss: 0.5857
AUC: 0.8742

Epoch 2/30
 - 0s - loss: 0.9622 - val_loss: 0.5765
AUC: 0.8743

Epoch 3/30
 - 0s - loss: 0.9619 - val_loss: 0.5842
AUC: 0.8744

Epoch 4/30
 - 0s - loss: 0.9656 - val_loss: 0.5718
AUC: 0.8744

Epoch 5/30
 - 0s - loss: 0.9622 - val_loss: 0.5698
AUC: 0.8745

Epoch 6/30
 - 0s - loss: 0.9587 - val_loss: 0.5822
AUC: 0.8746

Epoch 7/30
 - 0s - loss: 0.9633 - val_loss: 0.5942
AUC: 0.8748

Epoch 8/30
 - 0s - loss: 0.9630 - val_loss: 0.5779
AUC: 0.8747

Epoch 9/30
 - 0s - loss: 0.9575 - val_loss: 0.5929
AUC: 0.8749

Epoch 10/30
 - 0s - loss: 0.9479 - val_loss: 0.5671
AUC: 0.8748

Epoch 11/30
 - 0s - loss: 0.9555 - val_loss: 0.5850
AUC: 0.8750

Epoch 12/30
 - 0s - loss: 0.9522 - val_loss: 0.5779
AUC: 0.8751

Epoch 13/30
 - 0s - loss: 0.9522 - val_loss: 0.5714
AUC: 0.8752

Epoch 14/30
 - 0s - loss: 0.9442 - val_loss: 0.5782
AUC: 0.8752

Epoch 15/30
 - 0s - loss: 0.9513 - val_loss: 0.5870
AUC: 0.8753

Epoch 16/30
 - 0s - loss: 0.9508 - val_loss: 0.5816
AUC: 0.8754

Epoch 17/30
 - 0s - loss: 0.9474 - val_loss: 0.5786
AUC: 0.8754

Epoch 18/30
 - 0s - loss: 0.9423 - val_loss: 0.5820
AUC: 0.8755

Epoch 19/30
 - 0s - loss: 0.9433 - val_loss: 0.5843
AUC: 0.8756

Epoch 20/30
 - 0s - loss: 0.9460 - val_loss: 0.5615
AUC: 0.8755

Epoch 21/30
 - 0s - loss: 0.9422 - val_loss: 0.5777
AUC: 0.8757

Epoch 22/30
 - 0s - loss: 0.9381 - val_loss: 0.5754
AUC: 0.8757

Epoch 23/30
 - 0s - loss: 0.9370 - val_loss: 0.5716
AUC: 0.8758

Epoch 24/30
 - 0s - loss: 0.9369 - val_loss: 0.5608
AUC: 0.8756

Epoch 25/30
 - 0s - loss: 0.9315 - val_loss: 0.5661
AUC: 0.8758

Epoch 26/30
 - 0s - loss: 0.9401 - val_loss: 0.5692
AUC: 0.8758

Epoch 27/30
 - 0s - loss: 0.9294 - val_loss: 0.5803
AUC: 0.8758

Epoch 28/30
 - 0s - loss: 0.9384 - val_loss: 0.5798
AUC: 0.8759

Epoch 29/30
 - 0s - loss: 0.9299 - val_loss: 0.5918
AUC: 0.8760

Epoch 30/30
 - 0s - loss: 0.9302 - val_loss: 0.5856
Using TensorFlow backend.
AUC: 0.8761

2019-03-08 08:51:05.064597: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:51:05.229647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:51:05.229690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:51:05.524932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:51:05.524977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:51:05.524986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:51:05.525257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2143
Epoch 2/80
 - 2s - loss: 0.3128
Epoch 3/80
 - 2s - loss: 0.2588
Epoch 4/80
 - 2s - loss: 0.2246
Epoch 5/80
 - 2s - loss: 0.2037
Epoch 6/80
 - 2s - loss: 0.1852
Epoch 7/80
 - 2s - loss: 0.1690
Epoch 8/80
 - 2s - loss: 0.1558
Epoch 9/80
 - 2s - loss: 0.1450
Epoch 10/80
 - 2s - loss: 0.1363
Epoch 11/80
 - 2s - loss: 0.1295
Epoch 12/80
 - 2s - loss: 0.1238
Epoch 13/80
 - 2s - loss: 0.1190
Epoch 14/80
 - 2s - loss: 0.1149
Epoch 15/80
 - 2s - loss: 0.1113
Epoch 16/80
 - 2s - loss: 0.1082
Epoch 17/80
 - 2s - loss: 0.1054
Epoch 18/80
 - 2s - loss: 0.1030
Epoch 19/80
 - 2s - loss: 0.1009
Epoch 20/80
 - 2s - loss: 0.0991
Epoch 21/80
 - 2s - loss: 0.0975
Epoch 22/80
 - 2s - loss: 0.0961
Epoch 23/80
 - 2s - loss: 0.0949
Epoch 24/80
 - 2s - loss: 0.0939
Epoch 25/80
 - 2s - loss: 0.0930
Epoch 26/80
 - 2s - loss: 0.0923
Epoch 27/80
 - 2s - loss: 0.0916
Epoch 28/80
 - 2s - loss: 0.0910
Epoch 29/80
 - 2s - loss: 0.0905
Epoch 30/80
 - 2s - loss: 0.0901
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0893
Epoch 33/80
 - 2s - loss: 0.0890
Epoch 34/80
 - 2s - loss: 0.0887
Epoch 35/80
 - 2s - loss: 0.0885
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0880
Epoch 38/80
 - 2s - loss: 0.0878
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0875
Epoch 41/80
 - 2s - loss: 0.0873
Epoch 42/80
 - 2s - loss: 0.0872
Epoch 43/80
 - 2s - loss: 0.0870
Epoch 44/80
 - 2s - loss: 0.0869
Epoch 45/80
 - 2s - loss: 0.0868
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:52:40.302641: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:52:40.464572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:52:40.464615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:52:40.756333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:52:40.756383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:52:40.756392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:52:40.756670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2147
Epoch 2/80
 - 2s - loss: 0.3142
Epoch 3/80
 - 2s - loss: 0.2719
Epoch 4/80
 - 2s - loss: 0.2389
Epoch 5/80
 - 2s - loss: 0.2117
Epoch 6/80
 - 2s - loss: 0.1902
Epoch 7/80
 - 2s - loss: 0.1726
Epoch 8/80
 - 2s - loss: 0.1584
Epoch 9/80
 - 2s - loss: 0.1468
Epoch 10/80
 - 2s - loss: 0.1375
Epoch 11/80
 - 2s - loss: 0.1300
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:53:17.370593: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:53:17.534431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:53:17.534476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:53:17.823311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:53:17.823365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:53:17.823375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:53:17.823653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9869
Epoch 2/80
 - 2s - loss: 0.1819
Epoch 3/80
 - 2s - loss: 0.1590
Epoch 4/80
 - 2s - loss: 0.1346
Epoch 5/80
 - 2s - loss: 0.1148
Epoch 6/80
 - 2s - loss: 0.1017
Epoch 7/80
 - 2s - loss: 0.0917
Epoch 8/80
 - 2s - loss: 0.0833
Epoch 9/80
 - 2s - loss: 0.0761
Epoch 10/80
 - 2s - loss: 0.0700
Epoch 11/80
 - 2s - loss: 0.0651
Epoch 12/80
 - 2s - loss: 0.0611
Epoch 13/80
 - 2s - loss: 0.0579
Epoch 14/80
 - 2s - loss: 0.0551
Epoch 15/80
 - 2s - loss: 0.0528
Epoch 16/80
 - 2s - loss: 0.0508
Epoch 17/80
 - 2s - loss: 0.0490
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0462
Epoch 20/80
 - 2s - loss: 0.0450
Epoch 21/80
 - 2s - loss: 0.0440
Epoch 22/80
 - 2s - loss: 0.0431
Epoch 23/80
 - 2s - loss: 0.0423
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0405
Epoch 27/80
 - 2s - loss: 0.0401
Epoch 28/80
 - 2s - loss: 0.0397
Epoch 29/80
 - 2s - loss: 0.0393
Epoch 30/80
 - 2s - loss: 0.0390
Epoch 31/80
 - 2s - loss: 0.0387
Epoch 32/80
 - 2s - loss: 0.0385
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0381
Epoch 35/80
 - 2s - loss: 0.0379
Epoch 36/80
 - 2s - loss: 0.0378
Epoch 37/80
 - 2s - loss: 0.0376
Epoch 38/80
 - 2s - loss: 0.0375
Epoch 39/80
 - 2s - loss: 0.0374
Epoch 40/80
 - 2s - loss: 0.0373
Epoch 41/80
 - 2s - loss: 0.0372
Epoch 42/80
 - 2s - loss: 0.0371
Epoch 43/80
 - 2s - loss: 0.0370
Epoch 44/80
 - 2s - loss: 0.0369
Epoch 45/80
 - 2s - loss: 0.0369
Epoch 46/80
 - 2s - loss: 0.0368
Epoch 47/80
 - 2s - loss: 0.0367
Epoch 48/80
 - 2s - loss: 0.0367
Epoch 49/80
 - 2s - loss: 0.0366
Epoch 50/80
 - 2s - loss: 0.0366
Epoch 51/80
 - 2s - loss: 0.0365
Epoch 52/80
 - 2s - loss: 0.0365
Epoch 53/80
 - 2s - loss: 0.0365
Epoch 54/80
 - 2s - loss: 0.0364
Epoch 55/80
 - 2s - loss: 0.0364
Epoch 56/80
 - 2s - loss: 0.0364
Epoch 57/80
 - 2s - loss: 0.0363
Epoch 58/80
 - 2s - loss: 0.0363
Epoch 59/80
 - 2s - loss: 0.0362
Epoch 60/80
 - 2s - loss: 0.0362
Epoch 61/80
 - 2s - loss: 0.0362
Epoch 62/80
 - 2s - loss: 0.0347
Epoch 63/80
 - 2s - loss: 0.0345
Epoch 64/80
 - 2s - loss: 0.0345
Epoch 65/80
 - 2s - loss: 0.0345
Epoch 66/80
 - 2s - loss: 0.0345
Epoch 67/80
 - 2s - loss: 0.0341
Epoch 68/80
 - 2s - loss: 0.0341
Epoch 69/80
 - 2s - loss: 0.0341
Epoch 70/80
 - 2s - loss: 0.0341
Epoch 71/80
 - 2s - loss: 0.0340
Epoch 72/80
 - 2s - loss: 0.0340
Epoch 73/80
 - 2s - loss: 0.0340
Epoch 74/80
 - 2s - loss: 0.0340
Epoch 75/80
 - 2s - loss: 0.0340
Epoch 76/80
 - 2s - loss: 0.0340
Epoch 77/80
 - 2s - loss: 0.0340
Epoch 78/80
 - 2s - loss: 0.0340
Epoch 79/80
 - 2s - loss: 0.0340
Epoch 80/80
 - 2s - loss: 0.0340
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.6736 - val_loss: 1.5332
AUC: 0.7262

Epoch 2/80
 - 0s - loss: 2.3493 - val_loss: 0.8959
AUC: 0.7856

Epoch 3/80
 - 0s - loss: 1.5029 - val_loss: 0.8388
AUC: 0.8044

Epoch 4/80
 - 0s - loss: 1.3006 - val_loss: 0.7279
AUC: 0.8147

Epoch 5/80
 - 0s - loss: 1.2276 - val_loss: 0.6992
AUC: 0.8245

Epoch 6/80
 - 0s - loss: 1.1815 - val_loss: 0.7061
AUC: 0.8308

Epoch 7/80
 - 0s - loss: 1.1599 - val_loss: 0.7081
AUC: 0.8367

Epoch 8/80
 - 0s - loss: 1.1349 - val_loss: 0.7365
AUC: 0.8416

Epoch 9/80
 - 0s - loss: 1.1171 - val_loss: 0.7044
AUC: 0.8450

Epoch 10/80
 - 0s - loss: 1.1032 - val_loss: 0.6558
AUC: 0.8454

Epoch 11/80
 - 0s - loss: 1.0905 - val_loss: 0.6989
AUC: 0.8491

Epoch 12/80
 - 0s - loss: 1.0837 - val_loss: 0.6441
AUC: 0.8495

Epoch 13/80
 - 0s - loss: 1.0747 - val_loss: 0.6562
AUC: 0.8518

Epoch 14/80
 - 0s - loss: 1.0638 - val_loss: 0.6495
AUC: 0.8537

Epoch 15/80
 - 0s - loss: 1.0575 - val_loss: 0.6350
AUC: 0.8545

Epoch 16/80
 - 0s - loss: 1.0476 - val_loss: 0.6696
AUC: 0.8551

Epoch 17/80
 - 0s - loss: 1.0491 - val_loss: 0.6288
AUC: 0.8566

Epoch 18/80
 - 0s - loss: 1.0478 - val_loss: 0.6567
AUC: 0.8567

Epoch 19/80
 - 0s - loss: 1.0382 - val_loss: 0.6527
AUC: 0.8575

Epoch 20/80
 - 0s - loss: 1.0400 - val_loss: 0.6515
AUC: 0.8579

Epoch 21/80
 - 0s - loss: 1.0257 - val_loss: 0.6701
AUC: 0.8587

Epoch 22/80
 - 0s - loss: 1.0334 - val_loss: 0.6607
AUC: 0.8596

Epoch 23/80
 - 0s - loss: 1.0187 - val_loss: 0.6297
AUC: 0.8583

Epoch 24/80
 - 0s - loss: 1.0240 - val_loss: 0.6275
AUC: 0.8583

Epoch 25/80
 - 0s - loss: 1.0189 - val_loss: 0.6454
AUC: 0.8598

Epoch 26/80
 - 0s - loss: 1.0161 - val_loss: 0.5772
AUC: 0.8593

Epoch 27/80
 - 0s - loss: 1.0137 - val_loss: 0.6235
AUC: 0.8599

Epoch 28/80
 - 0s - loss: 1.0062 - val_loss: 0.6637
AUC: 0.8614

Epoch 29/80
 - 0s - loss: 1.0095 - val_loss: 0.6373
AUC: 0.8614

Epoch 30/80
 - 0s - loss: 1.0079 - val_loss: 0.6375
AUC: 0.8623

Epoch 31/80
 - 0s - loss: 1.0074 - val_loss: 0.6310
AUC: 0.8608

Epoch 32/80
 - 0s - loss: 1.0035 - val_loss: 0.6702
AUC: 0.8613

Epoch 33/80
 - 0s - loss: 1.0005 - val_loss: 0.6229
AUC: 0.8623

Epoch 34/80
 - 0s - loss: 0.9971 - val_loss: 0.6345
AUC: 0.8627

Epoch 35/80
 - 0s - loss: 0.9963 - val_loss: 0.6145
AUC: 0.8621

Epoch 36/80
 - 0s - loss: 0.9887 - val_loss: 0.6225
AUC: 0.8628

Epoch 37/80
 - 0s - loss: 0.9873 - val_loss: 0.6446
AUC: 0.8631

Epoch 38/80
 - 0s - loss: 0.9870 - val_loss: 0.6085
AUC: 0.8629

Epoch 39/80
 - 0s - loss: 0.9882 - val_loss: 0.6123
AUC: 0.8631

Epoch 40/80
 - 0s - loss: 0.9881 - val_loss: 0.6252
AUC: 0.8634

Epoch 41/80
 - 0s - loss: 0.9947 - val_loss: 0.6149
AUC: 0.8634

Epoch 42/80
 - 0s - loss: 0.9864 - val_loss: 0.6319
AUC: 0.8632

Epoch 43/80
 - 0s - loss: 0.9856 - val_loss: 0.6262
AUC: 0.8634

Epoch 44/80
 - 0s - loss: 0.9794 - val_loss: 0.6118
AUC: 0.8635

Epoch 45/80
 - 0s - loss: 0.9864 - val_loss: 0.6021
AUC: 0.8632

Epoch 46/80
 - 0s - loss: 0.9809 - val_loss: 0.6056
AUC: 0.8634

Epoch 47/80
 - 0s - loss: 0.9875 - val_loss: 0.6121
AUC: 0.8635

Epoch 48/80
 - 0s - loss: 0.9793 - val_loss: 0.6082
AUC: 0.8634

Epoch 49/80
 - 0s - loss: 0.9813 - val_loss: 0.6104
AUC: 0.8635

Epoch 50/80
 - 0s - loss: 0.9770 - val_loss: 0.6112
AUC: 0.8635

Epoch 51/80
 - 0s - loss: 0.9819 - val_loss: 0.6065
AUC: 0.8634

Epoch 52/80
 - 0s - loss: 0.9777 - val_loss: 0.6116
AUC: 0.8635

Epoch 53/80
 - 0s - loss: 0.9816 - val_loss: 0.6030
AUC: 0.8634

Epoch 54/80
 - 0s - loss: 0.9853 - val_loss: 0.6136
AUC: 0.8636

Epoch 55/80
 - 0s - loss: 0.9783 - val_loss: 0.6080
AUC: 0.8635

Epoch 56/80
 - 0s - loss: 0.9795 - val_loss: 0.6103
AUC: 0.8636

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9846 - val_loss: 0.6003
AUC: 0.8636

Epoch 2/30
 - 0s - loss: 0.9764 - val_loss: 0.6052
AUC: 0.8637

Epoch 3/30
 - 0s - loss: 0.9758 - val_loss: 0.6109
AUC: 0.8640

Epoch 4/30
 - 0s - loss: 0.9721 - val_loss: 0.6166
AUC: 0.8641

Epoch 5/30
 - 0s - loss: 0.9736 - val_loss: 0.6067
AUC: 0.8642

Epoch 6/30
 - 0s - loss: 0.9701 - val_loss: 0.5980
AUC: 0.8642

Epoch 7/30
 - 0s - loss: 0.9760 - val_loss: 0.6062
AUC: 0.8644

Epoch 8/30
 - 0s - loss: 0.9674 - val_loss: 0.6064
AUC: 0.8647

Epoch 9/30
 - 0s - loss: 0.9716 - val_loss: 0.6081
AUC: 0.8649

Epoch 10/30
 - 0s - loss: 0.9698 - val_loss: 0.5950
AUC: 0.8648

Epoch 11/30
 - 0s - loss: 0.9669 - val_loss: 0.6007
AUC: 0.8649

Epoch 12/30
 - 0s - loss: 0.9617 - val_loss: 0.6137
AUC: 0.8652

Epoch 13/30
 - 0s - loss: 0.9583 - val_loss: 0.5886
AUC: 0.8650

Epoch 14/30
 - 0s - loss: 0.9594 - val_loss: 0.5850
AUC: 0.8650

Epoch 15/30
 - 0s - loss: 0.9602 - val_loss: 0.6019
AUC: 0.8655

Epoch 16/30
 - 0s - loss: 0.9531 - val_loss: 0.6152
AUC: 0.8655

Epoch 17/30
 - 0s - loss: 0.9580 - val_loss: 0.6017
AUC: 0.8656

Epoch 18/30
 - 0s - loss: 0.9564 - val_loss: 0.6106
AUC: 0.8656

Epoch 19/30
 - 0s - loss: 0.9497 - val_loss: 0.6017
AUC: 0.8657

Epoch 20/30
 - 0s - loss: 0.9482 - val_loss: 0.6136
AUC: 0.8660

Epoch 21/30
 - 0s - loss: 0.9546 - val_loss: 0.6001
AUC: 0.8659

Epoch 22/30
 - 0s - loss: 0.9475 - val_loss: 0.5903
AUC: 0.8659

Epoch 23/30
 - 0s - loss: 0.9509 - val_loss: 0.5987
AUC: 0.8661

Epoch 24/30
 - 0s - loss: 0.9465 - val_loss: 0.5918
AUC: 0.8663

Epoch 25/30
 - 0s - loss: 0.9445 - val_loss: 0.5975
AUC: 0.8663

Epoch 26/30
 - 0s - loss: 0.9459 - val_loss: 0.5972
AUC: 0.8663

Epoch 27/30
 - 0s - loss: 0.9437 - val_loss: 0.5953
AUC: 0.8663

Epoch 28/30
 - 0s - loss: 0.9450 - val_loss: 0.5958
AUC: 0.8663

Epoch 29/30
 - 0s - loss: 0.9426 - val_loss: 0.5940
AUC: 0.8662

Epoch 30/30
 - 0s - loss: 0.9416 - val_loss: 0.5925
Using TensorFlow backend.
AUC: 0.8662

2019-03-08 08:56:38.951488: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:56:39.116056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:56:39.116109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:56:39.407448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:56:39.407498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:56:39.407507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:56:39.407764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9788
Epoch 2/80
 - 2s - loss: 0.1803
Epoch 3/80
 - 2s - loss: 0.1519
Epoch 4/80
 - 2s - loss: 0.1304
Epoch 5/80
 - 2s - loss: 0.1140
Epoch 6/80
 - 2s - loss: 0.1008
Epoch 7/80
 - 2s - loss: 0.0907
Epoch 8/80
 - 2s - loss: 0.0828
Epoch 9/80
 - 2s - loss: 0.0764
Epoch 10/80
 - 2s - loss: 0.0707
Epoch 11/80
 - 2s - loss: 0.0658
Epoch 12/80
 - 2s - loss: 0.0618
Epoch 13/80
 - 2s - loss: 0.0585
Epoch 14/80
 - 2s - loss: 0.0557
Epoch 15/80
 - 2s - loss: 0.0533
Epoch 16/80
 - 2s - loss: 0.0512
Epoch 17/80
 - 2s - loss: 0.0495
Epoch 18/80
 - 2s - loss: 0.0479
Epoch 19/80
 - 2s - loss: 0.0465
Epoch 20/80
 - 2s - loss: 0.0454
Epoch 21/80
 - 2s - loss: 0.0443
Epoch 22/80
 - 2s - loss: 0.0434
Epoch 23/80
 - 2s - loss: 0.0426
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:57:39.820922: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:57:39.982745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:57:39.982797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:57:40.275888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:57:40.275939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:57:40.275948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:57:40.276210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0001
Epoch 2/80
 - 2s - loss: 0.1824
Epoch 3/80
 - 2s - loss: 0.1565
Epoch 4/80
 - 2s - loss: 0.1333
Epoch 5/80
 - 2s - loss: 0.1157
Epoch 6/80
 - 2s - loss: 0.1023
Epoch 7/80
 - 2s - loss: 0.0918
Epoch 8/80
 - 2s - loss: 0.0835
Epoch 9/80
 - 2s - loss: 0.0765
Epoch 10/80
 - 2s - loss: 0.0704
Epoch 11/80
 - 2s - loss: 0.0653
Epoch 12/80
 - 2s - loss: 0.0611
Epoch 13/80
 - 2s - loss: 0.0577
Epoch 14/80
 - 2s - loss: 0.0550
Epoch 15/80
 - 2s - loss: 0.0526
Epoch 16/80
 - 2s - loss: 0.0506
Epoch 17/80
 - 2s - loss: 0.0488
Epoch 18/80
 - 2s - loss: 0.0473
Epoch 19/80
 - 2s - loss: 0.0459
Epoch 20/80
 - 2s - loss: 0.0448
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 08:58:30.850690: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 08:58:31.011625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 08:58:31.011676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 08:58:31.302084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 08:58:31.302135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 08:58:31.302143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 08:58:31.302402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5985
Epoch 2/80
 - 2s - loss: 0.0821
Epoch 3/80
 - 2s - loss: 0.0633
Epoch 4/80
 - 2s - loss: 0.0561
Epoch 5/80
 - 2s - loss: 0.0498
Epoch 6/80
 - 2s - loss: 0.0444
Epoch 7/80
 - 2s - loss: 0.0396
Epoch 8/80
 - 2s - loss: 0.0355
Epoch 9/80
 - 2s - loss: 0.0319
Epoch 10/80
 - 2s - loss: 0.0289
Epoch 11/80
 - 2s - loss: 0.0264
Epoch 12/80
 - 2s - loss: 0.0242
Epoch 13/80
 - 2s - loss: 0.0225
Epoch 14/80
 - 2s - loss: 0.0210
Epoch 15/80
 - 2s - loss: 0.0198
Epoch 16/80
 - 2s - loss: 0.0187
Epoch 17/80
 - 2s - loss: 0.0178
Epoch 18/80
 - 2s - loss: 0.0170
Epoch 19/80
 - 2s - loss: 0.0164
Epoch 20/80
 - 2s - loss: 0.0158
Epoch 21/80
 - 2s - loss: 0.0153
Epoch 22/80
 - 2s - loss: 0.0149
Epoch 23/80
 - 2s - loss: 0.0145
Epoch 24/80
 - 2s - loss: 0.0142
Epoch 25/80
 - 2s - loss: 0.0139
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0134
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0129
Epoch 31/80
 - 2s - loss: 0.0128
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0114
Epoch 48/80
 - 2s - loss: 0.0113
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0111
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.8270 - val_loss: 1.1738
AUC: 0.7137

Epoch 2/80
 - 0s - loss: 1.8851 - val_loss: 0.8714
AUC: 0.7605

Epoch 3/80
 - 0s - loss: 1.4039 - val_loss: 0.7778
AUC: 0.7905

Epoch 4/80
 - 0s - loss: 1.2579 - val_loss: 0.7269
AUC: 0.8050

Epoch 5/80
 - 0s - loss: 1.2118 - val_loss: 0.7103
AUC: 0.8152

Epoch 6/80
 - 0s - loss: 1.1952 - val_loss: 0.7198
AUC: 0.8223

Epoch 7/80
 - 0s - loss: 1.1577 - val_loss: 0.6730
AUC: 0.8271

Epoch 8/80
 - 0s - loss: 1.1284 - val_loss: 0.7159
AUC: 0.8336

Epoch 9/80
 - 0s - loss: 1.1229 - val_loss: 0.6977
AUC: 0.8353

Epoch 10/80
 - 0s - loss: 1.0927 - val_loss: 0.7198
AUC: 0.8407

Epoch 11/80
 - 0s - loss: 1.0861 - val_loss: 0.7038
AUC: 0.8451

Epoch 12/80
 - 0s - loss: 1.0702 - val_loss: 0.6690
AUC: 0.8474

Epoch 13/80
 - 0s - loss: 1.0577 - val_loss: 0.6627
AUC: 0.8494

Epoch 14/80
 - 0s - loss: 1.0574 - val_loss: 0.6496
AUC: 0.8497

Epoch 15/80
 - 0s - loss: 1.0473 - val_loss: 0.6898
AUC: 0.8531

Epoch 16/80
 - 0s - loss: 1.0395 - val_loss: 0.5887
AUC: 0.8516

Epoch 17/80
 - 0s - loss: 1.0355 - val_loss: 0.6309
AUC: 0.8543

Epoch 18/80
 - 0s - loss: 1.0295 - val_loss: 0.6168
AUC: 0.8548

Epoch 19/80
 - 0s - loss: 1.0271 - val_loss: 0.6529
AUC: 0.8559

Epoch 20/80
 - 0s - loss: 1.0216 - val_loss: 0.6990
AUC: 0.8560

Epoch 21/80
 - 0s - loss: 1.0249 - val_loss: 0.6537
AUC: 0.8571

Epoch 22/80
 - 0s - loss: 1.0109 - val_loss: 0.5941
AUC: 0.8560

Epoch 23/80
 - 0s - loss: 1.0189 - val_loss: 0.6344
AUC: 0.8572

Epoch 24/80
 - 0s - loss: 1.0095 - val_loss: 0.6743
AUC: 0.8593

Epoch 25/80
 - 0s - loss: 1.0094 - val_loss: 0.6928
AUC: 0.8594

Epoch 26/80
 - 0s - loss: 0.9968 - val_loss: 0.7209
AUC: 0.8603

Epoch 27/80
 - 0s - loss: 0.9983 - val_loss: 0.6319
AUC: 0.8595

Epoch 28/80
 - 0s - loss: 0.9982 - val_loss: 0.6015
AUC: 0.8592

Epoch 29/80
 - 0s - loss: 0.9974 - val_loss: 0.6532
AUC: 0.8598

Epoch 30/80
 - 0s - loss: 0.9965 - val_loss: 0.6179
AUC: 0.8594

Epoch 31/80
 - 0s - loss: 0.9954 - val_loss: 0.6260
AUC: 0.8596

Epoch 32/80
 - 0s - loss: 0.9996 - val_loss: 0.5934
AUC: 0.8593

Epoch 33/80
 - 0s - loss: 0.9987 - val_loss: 0.6254
AUC: 0.8598

Epoch 34/80
 - 0s - loss: 0.9980 - val_loss: 0.6102
AUC: 0.8596

Epoch 35/80
 - 0s - loss: 0.9913 - val_loss: 0.6201
AUC: 0.8597

Epoch 36/80
 - 0s - loss: 0.9947 - val_loss: 0.6106
AUC: 0.8597

Epoch 37/80
 - 0s - loss: 0.9890 - val_loss: 0.6070
AUC: 0.8597

Epoch 38/80
 - 0s - loss: 0.9912 - val_loss: 0.6177
AUC: 0.8598

Epoch 39/80
 - 0s - loss: 0.9932 - val_loss: 0.6123
AUC: 0.8598

Epoch 40/80
 - 0s - loss: 0.9970 - val_loss: 0.6170
AUC: 0.8599

Epoch 41/80
 - 0s - loss: 0.9913 - val_loss: 0.6112
AUC: 0.8599

Epoch 42/80
 - 0s - loss: 0.9944 - val_loss: 0.6094
AUC: 0.8598

Epoch 43/80
 - 0s - loss: 0.9916 - val_loss: 0.6128
AUC: 0.8599

Epoch 44/80
 - 0s - loss: 0.9889 - val_loss: 0.6144
AUC: 0.8600

Epoch 45/80
 - 0s - loss: 0.9920 - val_loss: 0.6124
AUC: 0.8599

Epoch 46/80
 - 0s - loss: 0.9942 - val_loss: 0.6213
AUC: 0.8600

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.0004 - val_loss: 0.6394
AUC: 0.8598

Epoch 2/30
 - 0s - loss: 0.9960 - val_loss: 0.6233
AUC: 0.8597

Epoch 3/30
 - 0s - loss: 0.9915 - val_loss: 0.6078
AUC: 0.8597

Epoch 4/30
 - 0s - loss: 0.9892 - val_loss: 0.6053
AUC: 0.8598

Epoch 5/30
 - 0s - loss: 0.9916 - val_loss: 0.6097
AUC: 0.8600

Epoch 6/30
 - 0s - loss: 0.9823 - val_loss: 0.5978
AUC: 0.8600

Epoch 7/30
 - 0s - loss: 0.9884 - val_loss: 0.5989
AUC: 0.8601

Epoch 8/30
 - 0s - loss: 0.9887 - val_loss: 0.6104
AUC: 0.8605

Epoch 9/30
 - 0s - loss: 0.9848 - val_loss: 0.6106
AUC: 0.8605

Epoch 10/30
 - 0s - loss: 0.9764 - val_loss: 0.6180
AUC: 0.8607

Epoch 11/30
 - 0s - loss: 0.9761 - val_loss: 0.5962
AUC: 0.8604

Epoch 12/30
 - 0s - loss: 0.9809 - val_loss: 0.6146
AUC: 0.8609

Epoch 13/30
 - 0s - loss: 0.9751 - val_loss: 0.6003
AUC: 0.8609

Epoch 14/30
 - 0s - loss: 0.9702 - val_loss: 0.6137
AUC: 0.8612

Epoch 15/30
 - 0s - loss: 0.9772 - val_loss: 0.6012
AUC: 0.8612

Epoch 16/30
 - 0s - loss: 0.9698 - val_loss: 0.6162
AUC: 0.8613

Epoch 17/30
 - 0s - loss: 0.9693 - val_loss: 0.5893
AUC: 0.8611

Epoch 18/30
 - 0s - loss: 0.9690 - val_loss: 0.6112
AUC: 0.8615

Epoch 19/30
 - 0s - loss: 0.9691 - val_loss: 0.6041
AUC: 0.8616

Epoch 20/30
 - 0s - loss: 0.9673 - val_loss: 0.5966
AUC: 0.8616

Epoch 21/30
 - 0s - loss: 0.9638 - val_loss: 0.5960
AUC: 0.8616

Epoch 22/30
 - 0s - loss: 0.9671 - val_loss: 0.6049
AUC: 0.8618

Epoch 23/30
 - 0s - loss: 0.9561 - val_loss: 0.6143
AUC: 0.8619

Epoch 24/30
 - 0s - loss: 0.9615 - val_loss: 0.5983
AUC: 0.8619

Epoch 25/30
 - 0s - loss: 0.9592 - val_loss: 0.6033
AUC: 0.8619

Epoch 26/30
 - 0s - loss: 0.9588 - val_loss: 0.5948
AUC: 0.8619

Epoch 27/30
 - 0s - loss: 0.9551 - val_loss: 0.6006
AUC: 0.8619

Epoch 28/30
 - 0s - loss: 0.9495 - val_loss: 0.5975
AUC: 0.8619

Epoch 29/30
 - 0s - loss: 0.9492 - val_loss: 0.5987
AUC: 0.8619

Epoch 30/30
 - 0s - loss: 0.9493 - val_loss: 0.5979
Using TensorFlow backend.
AUC: 0.8619

2019-03-08 09:01:45.958234: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:01:46.121862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:01:46.121905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:01:46.416291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:01:46.416344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:01:46.416353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:01:46.416628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5959
Epoch 2/80
 - 2s - loss: 0.0848
Epoch 3/80
 - 2s - loss: 0.0659
Epoch 4/80
 - 2s - loss: 0.0600
Epoch 5/80
 - 2s - loss: 0.0540
Epoch 6/80
 - 2s - loss: 0.0481
Epoch 7/80
 - 2s - loss: 0.0424
Epoch 8/80
 - 2s - loss: 0.0374
Epoch 9/80
 - 2s - loss: 0.0333
Epoch 10/80
 - 2s - loss: 0.0299
Epoch 11/80
 - 2s - loss: 0.0271
Epoch 12/80
 - 2s - loss: 0.0248
Epoch 13/80
 - 2s - loss: 0.0229
Epoch 14/80
 - 2s - loss: 0.0213
Epoch 15/80
 - 2s - loss: 0.0200
Epoch 16/80
 - 2s - loss: 0.0190
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0172
Epoch 19/80
 - 2s - loss: 0.0166
Epoch 20/80
 - 2s - loss: 0.0160
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0134
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0128
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0126
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0123
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0121
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0114
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0113
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0112
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:04:05.457524: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:04:05.619157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:04:05.619207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:04:05.911427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:04:05.911488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:04:05.911497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:04:05.911749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6019
Epoch 2/80
 - 2s - loss: 0.0823
Epoch 3/80
 - 2s - loss: 0.0645
Epoch 4/80
 - 2s - loss: 0.0580
Epoch 5/80
 - 2s - loss: 0.0520
Epoch 6/80
 - 2s - loss: 0.0468
Epoch 7/80
 - 2s - loss: 0.0419
Epoch 8/80
 - 2s - loss: 0.0372
Epoch 9/80
 - 2s - loss: 0.0332
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 09:04:39.424006: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:04:39.586929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:04:39.586974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:04:39.878676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:04:39.878728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:04:39.878737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:04:39.878990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2103
Epoch 2/80
 - 2s - loss: 0.3169
Epoch 3/80
 - 2s - loss: 0.2761
Epoch 4/80
 - 2s - loss: 0.2338
Epoch 5/80
 - 2s - loss: 0.2068
Epoch 6/80
 - 2s - loss: 0.1869
Epoch 7/80
 - 2s - loss: 0.1709
Epoch 8/80
 - 2s - loss: 0.1579
Epoch 9/80
 - 2s - loss: 0.1470
Epoch 10/80
 - 2s - loss: 0.1381
Epoch 11/80
 - 2s - loss: 0.1309
Epoch 12/80
 - 2s - loss: 0.1248
Epoch 13/80
 - 2s - loss: 0.1197
Epoch 14/80
 - 2s - loss: 0.1153
Epoch 15/80
 - 2s - loss: 0.1114
Epoch 16/80
 - 2s - loss: 0.1082
Epoch 17/80
 - 2s - loss: 0.1053
Epoch 18/80
 - 2s - loss: 0.1028
Epoch 19/80
 - 2s - loss: 0.1006
Epoch 20/80
 - 2s - loss: 0.0988
Epoch 21/80
 - 2s - loss: 0.0971
Epoch 22/80
 - 2s - loss: 0.0957
Epoch 23/80
 - 2s - loss: 0.0945
Epoch 24/80
 - 2s - loss: 0.0935
Epoch 25/80
 - 2s - loss: 0.0926
Epoch 26/80
 - 2s - loss: 0.0919
Epoch 27/80
 - 2s - loss: 0.0911
Epoch 28/80
 - 2s - loss: 0.0906
Epoch 29/80
 - 2s - loss: 0.0901
Epoch 30/80
 - 2s - loss: 0.0896
Epoch 31/80
 - 2s - loss: 0.0892
Epoch 32/80
 - 2s - loss: 0.0889
Epoch 33/80
 - 2s - loss: 0.0886
Epoch 34/80
 - 2s - loss: 0.0883
Epoch 35/80
 - 2s - loss: 0.0880
Epoch 36/80
 - 2s - loss: 0.0878
Epoch 37/80
 - 2s - loss: 0.0876
Epoch 38/80
 - 2s - loss: 0.0874
Epoch 39/80
 - 2s - loss: 0.0872
Epoch 40/80
 - 2s - loss: 0.0870
Epoch 41/80
 - 2s - loss: 0.0869
Epoch 42/80
 - 2s - loss: 0.0867
Epoch 43/80
 - 2s - loss: 0.0866
Epoch 44/80
 - 2s - loss: 0.0865
Epoch 45/80
 - 2s - loss: 0.0864
Epoch 46/80
 - 2s - loss: 0.0862
Epoch 47/80
 - 2s - loss: 0.0862
Epoch 48/80
 - 2s - loss: 0.0861
Epoch 49/80
 - 2s - loss: 0.0860
Epoch 50/80
 - 2s - loss: 0.0859
Epoch 51/80
 - 2s - loss: 0.0858
Epoch 52/80
 - 2s - loss: 0.0857
Epoch 53/80
 - 2s - loss: 0.0856
Epoch 54/80
 - 2s - loss: 0.0856
Epoch 55/80
 - 2s - loss: 0.0855
Epoch 56/80
 - 2s - loss: 0.0855
Epoch 57/80
 - 2s - loss: 0.0855
Epoch 58/80
 - 2s - loss: 0.0854
Epoch 59/80
 - 2s - loss: 0.0853
Epoch 60/80
 - 2s - loss: 0.0853
Epoch 61/80
 - 2s - loss: 0.0852
Epoch 62/80
 - 2s - loss: 0.0852
Epoch 63/80
 - 2s - loss: 0.0851
Epoch 64/80
 - 2s - loss: 0.0851
Epoch 65/80
 - 2s - loss: 0.0850
Epoch 66/80
 - 2s - loss: 0.0850
Epoch 67/80
 - 2s - loss: 0.0850
Epoch 68/80
 - 2s - loss: 0.0850
Epoch 69/80
 - 2s - loss: 0.0849
Epoch 70/80
 - 2s - loss: 0.0849
Epoch 71/80
 - 2s - loss: 0.0815
Epoch 72/80
 - 2s - loss: 0.0812
Epoch 73/80
 - 2s - loss: 0.0812
Epoch 74/80
 - 2s - loss: 0.0812
Epoch 75/80
 - 2s - loss: 0.0812
Epoch 76/80
 - 2s - loss: 0.0804
Epoch 77/80
 - 2s - loss: 0.0804
Epoch 78/80
 - 2s - loss: 0.0804
Epoch 79/80
 - 2s - loss: 0.0804
Epoch 80/80
 - 2s - loss: 0.0802
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.7274 - val_loss: 1.1267
AUC: 0.7807

Epoch 2/80
 - 0s - loss: 1.7866 - val_loss: 0.8204
AUC: 0.8138

Epoch 3/80
 - 0s - loss: 1.3676 - val_loss: 0.7253
AUC: 0.8198

Epoch 4/80
 - 0s - loss: 1.2645 - val_loss: 0.7382
AUC: 0.8288

Epoch 5/80
 - 0s - loss: 1.2136 - val_loss: 0.7412
AUC: 0.8398

Epoch 6/80
 - 0s - loss: 1.1721 - val_loss: 0.6271
AUC: 0.8446

Epoch 7/80
 - 0s - loss: 1.1459 - val_loss: 0.7305
AUC: 0.8521

Epoch 8/80
 - 0s - loss: 1.1169 - val_loss: 0.6554
AUC: 0.8549

Epoch 9/80
 - 0s - loss: 1.1093 - val_loss: 0.6740
AUC: 0.8589

Epoch 10/80
 - 0s - loss: 1.0937 - val_loss: 0.7370
AUC: 0.8609

Epoch 11/80
 - 0s - loss: 1.0793 - val_loss: 0.6556
AUC: 0.8618

Epoch 12/80
 - 0s - loss: 1.0669 - val_loss: 0.6242
AUC: 0.8632

Epoch 13/80
 - 0s - loss: 1.0622 - val_loss: 0.6792
AUC: 0.8649

Epoch 14/80
 - 0s - loss: 1.0622 - val_loss: 0.6496
AUC: 0.8658

Epoch 15/80
 - 0s - loss: 1.0542 - val_loss: 0.6187
AUC: 0.8662

Epoch 16/80
 - 0s - loss: 1.0547 - val_loss: 0.6547
AUC: 0.8674

Epoch 17/80
 - 0s - loss: 1.0479 - val_loss: 0.6848
AUC: 0.8692

Epoch 18/80
 - 0s - loss: 1.0361 - val_loss: 0.6303
AUC: 0.8686

Epoch 19/80
 - 0s - loss: 1.0307 - val_loss: 0.6089
AUC: 0.8685

Epoch 20/80
 - 0s - loss: 1.0336 - val_loss: 0.6371
AUC: 0.8704

Epoch 21/80
 - 0s - loss: 1.0305 - val_loss: 0.5719
AUC: 0.8682

Epoch 22/80
 - 0s - loss: 1.0257 - val_loss: 0.5959
AUC: 0.8697

Epoch 23/80
 - 0s - loss: 1.0211 - val_loss: 0.6102
AUC: 0.8698

Epoch 24/80
 - 0s - loss: 1.0210 - val_loss: 0.6010
AUC: 0.8696

Epoch 25/80
 - 0s - loss: 1.0247 - val_loss: 0.6204
AUC: 0.8722

Epoch 26/80
 - 0s - loss: 1.0194 - val_loss: 0.5561
AUC: 0.8716

Epoch 27/80
 - 0s - loss: 1.0140 - val_loss: 0.6440
AUC: 0.8736

Epoch 28/80
 - 0s - loss: 1.0041 - val_loss: 0.6174
AUC: 0.8731

Epoch 29/80
 - 0s - loss: 1.0071 - val_loss: 0.5925
AUC: 0.8733

Epoch 30/80
 - 0s - loss: 1.0020 - val_loss: 0.6541
AUC: 0.8738

Epoch 31/80
 - 0s - loss: 0.9968 - val_loss: 0.5937
AUC: 0.8726

Epoch 32/80
 - 0s - loss: 0.9950 - val_loss: 0.6061
AUC: 0.8742

Epoch 33/80
 - 0s - loss: 0.9941 - val_loss: 0.6323
AUC: 0.8742

Epoch 34/80
 - 0s - loss: 0.9906 - val_loss: 0.6178
AUC: 0.8746

Epoch 35/80
 - 0s - loss: 0.9852 - val_loss: 0.5891
AUC: 0.8738

Epoch 36/80
 - 0s - loss: 0.9874 - val_loss: 0.5529
AUC: 0.8738

Epoch 37/80
 - 0s - loss: 0.9877 - val_loss: 0.6324
AUC: 0.8745

Epoch 38/80
 - 0s - loss: 0.9841 - val_loss: 0.6635
AUC: 0.8755

Epoch 39/80
 - 0s - loss: 0.9876 - val_loss: 0.5679
AUC: 0.8727

Epoch 40/80
 - 0s - loss: 0.9857 - val_loss: 0.6250
AUC: 0.8743

Epoch 41/80
 - 0s - loss: 0.9762 - val_loss: 0.5697
AUC: 0.8745

Epoch 42/80
 - 0s - loss: 0.9720 - val_loss: 0.5691
AUC: 0.8744

Epoch 43/80
 - 0s - loss: 0.9721 - val_loss: 0.6848
AUC: 0.8761

Epoch 44/80
 - 0s - loss: 0.9728 - val_loss: 0.5894
AUC: 0.8754

Epoch 45/80
 - 0s - loss: 0.9736 - val_loss: 0.5663
AUC: 0.8751

Epoch 46/80
 - 0s - loss: 0.9658 - val_loss: 0.5511
AUC: 0.8753

Epoch 47/80
 - 0s - loss: 0.9652 - val_loss: 0.6788
AUC: 0.8758

Epoch 48/80
 - 0s - loss: 0.9599 - val_loss: 0.5727
AUC: 0.8759

Epoch 49/80
 - 0s - loss: 0.9637 - val_loss: 0.5816
AUC: 0.8742

Epoch 50/80
 - 0s - loss: 0.9613 - val_loss: 0.6097
AUC: 0.8756

Epoch 51/80
 - 0s - loss: 0.9584 - val_loss: 0.6307
AUC: 0.8761

Epoch 52/80
 - 0s - loss: 0.9585 - val_loss: 0.5908
AUC: 0.8755

Epoch 53/80
 - 0s - loss: 0.9558 - val_loss: 0.5425
AUC: 0.8752

Epoch 54/80
 - 0s - loss: 0.9550 - val_loss: 0.5204
AUC: 0.8745

Epoch 55/80
 - 0s - loss: 0.9488 - val_loss: 0.5753
AUC: 0.8750

Epoch 56/80
 - 0s - loss: 0.9552 - val_loss: 0.5688
AUC: 0.8757

Epoch 57/80
 - 0s - loss: 0.9455 - val_loss: 0.5836
AUC: 0.8763

Epoch 58/80
 - 0s - loss: 0.9406 - val_loss: 0.5880
AUC: 0.8754

Epoch 59/80
 - 0s - loss: 0.9462 - val_loss: 0.5888
AUC: 0.8762

Epoch 60/80
 - 0s - loss: 0.9417 - val_loss: 0.6673
AUC: 0.8761

Epoch 61/80
 - 0s - loss: 0.9372 - val_loss: 0.5966
AUC: 0.8751

Epoch 62/80
 - 0s - loss: 0.9431 - val_loss: 0.5315
AUC: 0.8753

Epoch 63/80
 - 0s - loss: 0.9374 - val_loss: 0.5580
AUC: 0.8748

Epoch 64/80
 - 0s - loss: 0.9294 - val_loss: 0.5781
AUC: 0.8758

Epoch 65/80
 - 0s - loss: 0.9204 - val_loss: 0.5949
AUC: 0.8756

Epoch 66/80
 - 0s - loss: 0.9190 - val_loss: 0.5656
AUC: 0.8760

Epoch 67/80
 - 0s - loss: 0.9196 - val_loss: 0.5688
AUC: 0.8759

Epoch 68/80
 - 0s - loss: 0.9162 - val_loss: 0.5764
AUC: 0.8753

Epoch 69/80
 - 0s - loss: 0.9166 - val_loss: 0.5516
AUC: 0.8750

Epoch 70/80
 - 0s - loss: 0.9180 - val_loss: 0.5670
AUC: 0.8758

Epoch 71/80
 - 0s - loss: 0.9112 - val_loss: 0.5769
AUC: 0.8758

Epoch 72/80
 - 0s - loss: 0.9140 - val_loss: 0.5645
AUC: 0.8761

Epoch 73/80
 - 0s - loss: 0.9147 - val_loss: 0.5686
AUC: 0.8759

Epoch 74/80
 - 0s - loss: 0.9142 - val_loss: 0.5958
AUC: 0.8762

Epoch 75/80
 - 0s - loss: 0.9130 - val_loss: 0.5669
AUC: 0.8759

Epoch 76/80
 - 0s - loss: 0.9148 - val_loss: 0.5697
AUC: 0.8759

Epoch 77/80
 - 0s - loss: 0.9155 - val_loss: 0.5720
AUC: 0.8759

Epoch 78/80
 - 0s - loss: 0.9095 - val_loss: 0.5752
AUC: 0.8759

Epoch 79/80
 - 0s - loss: 0.9099 - val_loss: 0.5726
AUC: 0.8758

Epoch 80/80
 - 0s - loss: 0.9077 - val_loss: 0.5797
AUC: 0.8758

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9362 - val_loss: 0.5817
AUC: 0.8762

Epoch 2/30
 - 0s - loss: 0.9354 - val_loss: 0.5729
AUC: 0.8763

Epoch 3/30
 - 0s - loss: 0.9262 - val_loss: 0.5789
AUC: 0.8765

Epoch 4/30
 - 0s - loss: 0.9273 - val_loss: 0.5902
AUC: 0.8765

Epoch 5/30
 - 0s - loss: 0.9253 - val_loss: 0.5801
AUC: 0.8764

Epoch 6/30
 - 0s - loss: 0.9281 - val_loss: 0.5660
AUC: 0.8761

Epoch 7/30
 - 0s - loss: 0.9170 - val_loss: 0.5724
AUC: 0.8759

Epoch 8/30
 - 0s - loss: 0.9230 - val_loss: 0.5847
AUC: 0.8764

Epoch 9/30
 - 0s - loss: 0.9256 - val_loss: 0.5817
AUC: 0.8762

Epoch 10/30
 - 0s - loss: 0.9247 - val_loss: 0.5657
AUC: 0.8762

Epoch 11/30
 - 0s - loss: 0.9142 - val_loss: 0.5615
AUC: 0.8762

Epoch 12/30
 - 0s - loss: 0.9141 - val_loss: 0.5690
AUC: 0.8764

Epoch 13/30
 - 0s - loss: 0.9155 - val_loss: 0.5691
AUC: 0.8763

Epoch 14/30
 - 0s - loss: 0.9130 - val_loss: 0.5746
AUC: 0.8763

Epoch 15/30
 - 0s - loss: 0.9083 - val_loss: 0.5677
AUC: 0.8766

Epoch 16/30
 - 0s - loss: 0.9101 - val_loss: 0.5645
AUC: 0.8764

Epoch 17/30
 - 0s - loss: 0.9031 - val_loss: 0.5764
AUC: 0.8763

Epoch 18/30
 - 0s - loss: 0.9093 - val_loss: 0.5663
AUC: 0.8764

Epoch 19/30
 - 0s - loss: 0.9010 - val_loss: 0.5636
AUC: 0.8761

Epoch 20/30
 - 0s - loss: 0.9048 - val_loss: 0.5705
AUC: 0.8764

Epoch 21/30
 - 0s - loss: 0.9037 - val_loss: 0.5632
AUC: 0.8761

Epoch 22/30
 - 0s - loss: 0.9032 - val_loss: 0.5715
AUC: 0.8763

Epoch 23/30
 - 0s - loss: 0.8996 - val_loss: 0.5690
AUC: 0.8762

Epoch 24/30
 - 0s - loss: 0.8968 - val_loss: 0.5673
AUC: 0.8762

Epoch 25/30
 - 0s - loss: 0.8944 - val_loss: 0.5669
AUC: 0.8762

Epoch 26/30
 - 0s - loss: 0.9014 - val_loss: 0.5677
AUC: 0.8762

Epoch 27/30
 - 0s - loss: 0.8986 - val_loss: 0.5693
AUC: 0.8762

Epoch 28/30
 - 0s - loss: 0.8961 - val_loss: 0.5689
AUC: 0.8763

Epoch 29/30
 - 0s - loss: 0.9039 - val_loss: 0.5666
AUC: 0.8762

Epoch 30/30
 - 0s - loss: 0.8928 - val_loss: 0.5660
Using TensorFlow backend.
AUC: 0.8761

2019-03-08 09:08:15.462177: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:08:15.626932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:08:15.626975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:08:15.917053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:08:15.917105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:08:15.917113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:08:15.917373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1954
Epoch 2/80
 - 2s - loss: 0.3183
Epoch 3/80
 - 2s - loss: 0.2827
Epoch 4/80
 - 2s - loss: 0.2418
Epoch 5/80
 - 2s - loss: 0.2132
Epoch 6/80
 - 2s - loss: 0.1921
Epoch 7/80
 - 2s - loss: 0.1747
Epoch 8/80
 - 2s - loss: 0.1604
Epoch 9/80
 - 2s - loss: 0.1488
Epoch 10/80
 - 2s - loss: 0.1393
Epoch 11/80
 - 2s - loss: 0.1315
Epoch 12/80
 - 2s - loss: 0.1251
Epoch 13/80
 - 2s - loss: 0.1197
Epoch 14/80
 - 2s - loss: 0.1152
Epoch 15/80
 - 2s - loss: 0.1114
Epoch 16/80
 - 2s - loss: 0.1081
Epoch 17/80
 - 2s - loss: 0.1053
Epoch 18/80
 - 2s - loss: 0.1028
Epoch 19/80
 - 2s - loss: 0.1007
Epoch 20/80
 - 2s - loss: 0.0990
Epoch 21/80
 - 1s - loss: 0.0974
Epoch 22/80
 - 2s - loss: 0.0960
Epoch 23/80
 - 2s - loss: 0.0948
Epoch 24/80
 - 2s - loss: 0.0938
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0922
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0909
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0900
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0893
Epoch 33/80
 - 2s - loss: 0.0890
Epoch 34/80
 - 2s - loss: 0.0887
Epoch 35/80
 - 2s - loss: 0.0884
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0879
Epoch 38/80
 - 2s - loss: 0.0878
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:09:39.152033: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:09:39.316327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:09:39.316369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:09:39.606960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:09:39.607013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:09:39.607029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:09:39.607289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2122
Epoch 2/80
 - 2s - loss: 0.3154
Epoch 3/80
 - 2s - loss: 0.2677
Epoch 4/80
 - 2s - loss: 0.2289
Epoch 5/80
 - 2s - loss: 0.2041
Epoch 6/80
 - 1s - loss: 0.1854
Epoch 7/80
 - 2s - loss: 0.1705
Epoch 8/80
 - 1s - loss: 0.1579
Epoch 9/80
 - 2s - loss: 0.1471
Epoch 10/80
 - 2s - loss: 0.1378
Epoch 11/80
 - 1s - loss: 0.1303
Epoch 12/80
 - 2s - loss: 0.1243
Epoch 13/80
 - 2s - loss: 0.1193
Epoch 14/80
 - 2s - loss: 0.1151
Epoch 15/80
 - 2s - loss: 0.1115
Epoch 16/80
 - 2s - loss: 0.1083
Epoch 17/80
 - 2s - loss: 0.1056
Epoch 18/80
 - 2s - loss: 0.1032
Epoch 19/80
 - 2s - loss: 0.1010
Epoch 20/80
 - 2s - loss: 0.0992
Epoch 21/80
 - 2s - loss: 0.0976
Epoch 22/80
 - 2s - loss: 0.0962
Epoch 23/80
 - 2s - loss: 0.0950
Epoch 24/80
 - 2s - loss: 0.0939
Epoch 25/80
 - 2s - loss: 0.0930
Epoch 26/80
 - 2s - loss: 0.0922
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0910
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0900
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0892
Epoch 33/80
 - 2s - loss: 0.0889
Epoch 34/80
 - 2s - loss: 0.0886
Epoch 35/80
 - 2s - loss: 0.0884
Epoch 36/80
 - 2s - loss: 0.0881
Epoch 37/80
 - 2s - loss: 0.0879
Epoch 38/80
 - 2s - loss: 0.0877
Epoch 39/80
 - 1s - loss: 0.0875
Epoch 40/80
 - 2s - loss: 0.0873
Epoch 41/80
 - 1s - loss: 0.0872
Epoch 42/80
 - 2s - loss: 0.0871
Epoch 43/80
 - 2s - loss: 0.0869
Epoch 44/80
 - 1s - loss: 0.0868
Epoch 45/80
 - 1s - loss: 0.0867
Epoch 46/80
 - 1s - loss: 0.0866
Epoch 47/80
 - 1s - loss: 0.0865
Epoch 48/80
 - 1s - loss: 0.0864
Epoch 49/80
 - 2s - loss: 0.0863
Epoch 50/80
 - 2s - loss: 0.0862
Epoch 51/80
 - 1s - loss: 0.0861
Epoch 52/80
 - 2s - loss: 0.0861
Epoch 53/80
 - 2s - loss: 0.0860
Epoch 54/80
 - 1s - loss: 0.0859
Epoch 55/80
 - 2s - loss: 0.0859
Epoch 56/80
 - 2s - loss: 0.0858
Epoch 57/80
 - 1s - loss: 0.0857
Epoch 58/80
 - 1s - loss: 0.0857
Epoch 59/80
 - 2s - loss: 0.0856
Epoch 60/80
 - 2s - loss: 0.0856
Epoch 61/80
 - 2s - loss: 0.0855
Epoch 62/80
 - 2s - loss: 0.0855
Epoch 63/80
 - 1s - loss: 0.0854
Epoch 64/80
 - 1s - loss: 0.0854
Epoch 65/80
 - 2s - loss: 0.0853
Epoch 66/80
 - 2s - loss: 0.0853
Epoch 67/80
 - 1s - loss: 0.0853
Epoch 68/80
 - 2s - loss: 0.0852
Epoch 69/80
 - 2s - loss: 0.0852
Epoch 70/80
 - 2s - loss: 0.0852
Epoch 71/80
 - 2s - loss: 0.0851
Epoch 72/80
 - 2s - loss: 0.0851
Epoch 73/80
 - 1s - loss: 0.0851
Epoch 74/80
 - 2s - loss: 0.0851
Epoch 75/80
 - 2s - loss: 0.0817
Epoch 76/80
 - 1s - loss: 0.0814
Epoch 77/80
 - 1s - loss: 0.0814
Epoch 78/80
 - 1s - loss: 0.0814
Epoch 79/80
 - 2s - loss: 0.0814
Epoch 80/80
 - 2s - loss: 0.0806
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.1125 - val_loss: 1.1041
AUC: 0.7956

Epoch 2/80
 - 0s - loss: 1.4843 - val_loss: 0.7632
AUC: 0.8242

Epoch 3/80
 - 0s - loss: 1.2540 - val_loss: 0.7175
AUC: 0.8369

Epoch 4/80
 - 0s - loss: 1.1868 - val_loss: 0.6876
AUC: 0.8456

Epoch 5/80
 - 0s - loss: 1.1438 - val_loss: 0.7030
AUC: 0.8522

Epoch 6/80
 - 0s - loss: 1.1212 - val_loss: 0.6708
AUC: 0.8539

Epoch 7/80
 - 0s - loss: 1.1040 - val_loss: 0.6468
AUC: 0.8559

Epoch 8/80
 - 0s - loss: 1.0917 - val_loss: 0.6460
AUC: 0.8588

Epoch 9/80
 - 0s - loss: 1.0751 - val_loss: 0.6256
AUC: 0.8579

Epoch 10/80
 - 0s - loss: 1.0627 - val_loss: 0.6566
AUC: 0.8589

Epoch 11/80
 - 0s - loss: 1.0578 - val_loss: 0.6150
AUC: 0.8584

Epoch 12/80
 - 0s - loss: 1.0481 - val_loss: 0.6553
AUC: 0.8622

Epoch 13/80
 - 0s - loss: 1.0500 - val_loss: 0.7189
AUC: 0.8622

Epoch 14/80
 - 0s - loss: 1.0320 - val_loss: 0.6206
AUC: 0.8615

Epoch 15/80
 - 0s - loss: 1.0353 - val_loss: 0.5928
AUC: 0.8608

Epoch 16/80
 - 0s - loss: 1.0336 - val_loss: 0.5885
AUC: 0.8624

Epoch 17/80
 - 0s - loss: 1.0264 - val_loss: 0.6210
AUC: 0.8626

Epoch 18/80
 - 0s - loss: 1.0115 - val_loss: 0.6203
AUC: 0.8632

Epoch 19/80
 - 0s - loss: 1.0156 - val_loss: 0.6017
AUC: 0.8633

Epoch 20/80
 - 0s - loss: 1.0152 - val_loss: 0.7058
AUC: 0.8645

Epoch 21/80
 - 0s - loss: 1.0124 - val_loss: 0.5700
AUC: 0.8612

Epoch 22/80
 - 0s - loss: 1.0049 - val_loss: 0.5502
AUC: 0.8637

Epoch 23/80
 - 0s - loss: 1.0001 - val_loss: 0.6041
AUC: 0.8642

Epoch 24/80
 - 0s - loss: 0.9970 - val_loss: 0.5729
AUC: 0.8642

Epoch 25/80
 - 0s - loss: 0.9976 - val_loss: 0.6290
AUC: 0.8643

Epoch 26/80
 - 0s - loss: 0.9925 - val_loss: 0.6106
AUC: 0.8642

Epoch 27/80
 - 0s - loss: 0.9952 - val_loss: 0.6543
AUC: 0.8650

Epoch 28/80
 - 0s - loss: 0.9890 - val_loss: 0.5417
AUC: 0.8646

Epoch 29/80
 - 0s - loss: 0.9835 - val_loss: 0.5827
AUC: 0.8647

Epoch 30/80
 - 0s - loss: 0.9850 - val_loss: 0.5992
AUC: 0.8665

Epoch 31/80
 - 0s - loss: 0.9862 - val_loss: 0.6008
AUC: 0.8665

Epoch 32/80
 - 0s - loss: 0.9736 - val_loss: 0.5968
AUC: 0.8663

Epoch 33/80
 - 0s - loss: 0.9764 - val_loss: 0.5900
AUC: 0.8664

Epoch 34/80
 - 0s - loss: 0.9769 - val_loss: 0.5581
AUC: 0.8655

Epoch 35/80
 - 0s - loss: 0.9761 - val_loss: 0.5999
AUC: 0.8660

Epoch 36/80
 - 0s - loss: 0.9675 - val_loss: 0.5898
AUC: 0.8663

Epoch 37/80
 - 0s - loss: 0.9634 - val_loss: 0.5591
AUC: 0.8665

Epoch 38/80
 - 0s - loss: 0.9660 - val_loss: 0.5596
AUC: 0.8664

Epoch 39/80
 - 0s - loss: 0.9578 - val_loss: 0.5714
AUC: 0.8666

Epoch 40/80
 - 0s - loss: 0.9550 - val_loss: 0.5916
AUC: 0.8670

Epoch 41/80
 - 0s - loss: 0.9585 - val_loss: 0.6013
AUC: 0.8671

Epoch 42/80
 - 0s - loss: 0.9493 - val_loss: 0.6036
AUC: 0.8668

Epoch 43/80
 - 0s - loss: 0.9476 - val_loss: 0.5807
AUC: 0.8667

Epoch 44/80
 - 0s - loss: 0.9498 - val_loss: 0.5697
AUC: 0.8668

Epoch 45/80
 - 0s - loss: 0.9524 - val_loss: 0.6079
AUC: 0.8671

Epoch 46/80
 - 0s - loss: 0.9501 - val_loss: 0.5807
AUC: 0.8665

Epoch 47/80
 - 0s - loss: 0.9497 - val_loss: 0.5977
AUC: 0.8668

Epoch 48/80
 - 0s - loss: 0.9446 - val_loss: 0.5664
AUC: 0.8665

Epoch 49/80
 - 0s - loss: 0.9450 - val_loss: 0.5942
AUC: 0.8669

Epoch 50/80
 - 0s - loss: 0.9491 - val_loss: 0.5914
AUC: 0.8667

Epoch 51/80
 - 0s - loss: 0.9447 - val_loss: 0.5959
AUC: 0.8668

Epoch 52/80
 - 0s - loss: 0.9486 - val_loss: 0.5910
AUC: 0.8668

Epoch 53/80
 - 0s - loss: 0.9414 - val_loss: 0.5841
AUC: 0.8665

Epoch 54/80
 - 0s - loss: 0.9452 - val_loss: 0.6004
AUC: 0.8669

Epoch 55/80
 - 0s - loss: 0.9460 - val_loss: 0.6008
AUC: 0.8669

Epoch 56/80
 - 0s - loss: 0.9440 - val_loss: 0.5917
AUC: 0.8666

Epoch 57/80
 - 0s - loss: 0.9385 - val_loss: 0.5862
AUC: 0.8667

Epoch 58/80
 - 0s - loss: 0.9438 - val_loss: 0.6043
AUC: 0.8669

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9480 - val_loss: 0.5844
AUC: 0.8669

Epoch 2/30
 - 0s - loss: 0.9462 - val_loss: 0.6116
AUC: 0.8672

Epoch 3/30
 - 0s - loss: 0.9497 - val_loss: 0.5913
AUC: 0.8671

Epoch 4/30
 - 0s - loss: 0.9461 - val_loss: 0.5809
AUC: 0.8671

Epoch 5/30
 - 0s - loss: 0.9372 - val_loss: 0.6007
AUC: 0.8674

Epoch 6/30
 - 0s - loss: 0.9413 - val_loss: 0.5835
AUC: 0.8671

Epoch 7/30
 - 0s - loss: 0.9396 - val_loss: 0.5947
AUC: 0.8673

Epoch 8/30
 - 0s - loss: 0.9404 - val_loss: 0.6093
AUC: 0.8677

Epoch 9/30
 - 0s - loss: 0.9354 - val_loss: 0.5843
AUC: 0.8672

Epoch 10/30
 - 0s - loss: 0.9347 - val_loss: 0.5918
AUC: 0.8674

Epoch 11/30
 - 0s - loss: 0.9339 - val_loss: 0.6018
AUC: 0.8675

Epoch 12/30
 - 0s - loss: 0.9328 - val_loss: 0.5711
AUC: 0.8672

Epoch 13/30
 - 0s - loss: 0.9268 - val_loss: 0.5878
AUC: 0.8675

Epoch 14/30
 - 0s - loss: 0.9293 - val_loss: 0.5783
AUC: 0.8676

Epoch 15/30
 - 0s - loss: 0.9234 - val_loss: 0.6008
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.9288 - val_loss: 0.5911
AUC: 0.8676

Epoch 17/30
 - 0s - loss: 0.9215 - val_loss: 0.5904
AUC: 0.8674

Epoch 18/30
 - 0s - loss: 0.9189 - val_loss: 0.5902
AUC: 0.8677

Epoch 19/30
 - 0s - loss: 0.9161 - val_loss: 0.5779
AUC: 0.8675

Epoch 20/30
 - 0s - loss: 0.9167 - val_loss: 0.5772
AUC: 0.8675

Epoch 21/30
 - 0s - loss: 0.9221 - val_loss: 0.5784
AUC: 0.8676

Epoch 22/30
 - 0s - loss: 0.9177 - val_loss: 0.5922
AUC: 0.8677

Epoch 23/30
 - 0s - loss: 0.9124 - val_loss: 0.5787
AUC: 0.8674

Epoch 24/30
 - 0s - loss: 0.9158 - val_loss: 0.5824
AUC: 0.8676

Epoch 25/30
 - 0s - loss: 0.9109 - val_loss: 0.5816
AUC: 0.8676

Epoch 26/30
 - 0s - loss: 0.9059 - val_loss: 0.5810
AUC: 0.8676

Epoch 27/30
 - 0s - loss: 0.9135 - val_loss: 0.5846
AUC: 0.8677

Epoch 28/30
 - 0s - loss: 0.9137 - val_loss: 0.5765
AUC: 0.8676

Epoch 29/30
 - 0s - loss: 0.9095 - val_loss: 0.5842
AUC: 0.8677

Epoch 30/30
 - 0s - loss: 0.9091 - val_loss: 0.5816
Using TensorFlow backend.
AUC: 0.8676

2019-03-08 09:13:02.312929: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:13:02.473983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:13:02.474026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:13:02.764035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:13:02.764085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:13:02.764094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:13:02.764354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1908
Epoch 2/80
 - 2s - loss: 0.3202
Epoch 3/80
 - 2s - loss: 0.2915
Epoch 4/80
 - 2s - loss: 0.2540
Epoch 5/80
 - 2s - loss: 0.2235
Epoch 6/80
 - 2s - loss: 0.2002
Epoch 7/80
 - 2s - loss: 0.1794
Epoch 8/80
 - 2s - loss: 0.1626
Epoch 9/80
 - 2s - loss: 0.1498
Epoch 10/80
 - 2s - loss: 0.1399
Epoch 11/80
 - 2s - loss: 0.1322
Epoch 12/80
 - 2s - loss: 0.1259
Epoch 13/80
 - 2s - loss: 0.1208
Epoch 14/80
 - 2s - loss: 0.1163
Epoch 15/80
 - 2s - loss: 0.1126
Epoch 16/80
 - 2s - loss: 0.1094
Epoch 17/80
 - 2s - loss: 0.1064
Epoch 18/80
 - 2s - loss: 0.1040
Epoch 19/80
 - 2s - loss: 0.1018
Epoch 20/80
 - 2s - loss: 0.0998
Epoch 21/80
 - 2s - loss: 0.0982
Epoch 22/80
 - 2s - loss: 0.0968
Epoch 23/80
 - 2s - loss: 0.0956
Epoch 24/80
 - 2s - loss: 0.0945
Epoch 25/80
 - 2s - loss: 0.0936
Epoch 26/80
 - 2s - loss: 0.0928
Epoch 27/80
 - 2s - loss: 0.0922
Epoch 28/80
 - 2s - loss: 0.0916
Epoch 29/80
 - 2s - loss: 0.0911
Epoch 30/80
 - 2s - loss: 0.0906
Epoch 31/80
 - 2s - loss: 0.0902
Epoch 32/80
 - 2s - loss: 0.0899
Epoch 33/80
 - 2s - loss: 0.0895
Epoch 34/80
 - 2s - loss: 0.0892
Epoch 35/80
 - 2s - loss: 0.0890
Epoch 36/80
 - 2s - loss: 0.0888
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:14:23.223771: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:14:23.385444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:14:23.385487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:14:23.676190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:14:23.676242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:14:23.676251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:14:23.676504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9798
Epoch 2/80
 - 2s - loss: 0.1814
Epoch 3/80
 - 2s - loss: 0.1574
Epoch 4/80
 - 2s - loss: 0.1388
Epoch 5/80
 - 2s - loss: 0.1225
Epoch 6/80
 - 2s - loss: 0.1077
Epoch 7/80
 - 2s - loss: 0.0953
Epoch 8/80
 - 2s - loss: 0.0852
Epoch 9/80
 - 2s - loss: 0.0773
Epoch 10/80
 - 2s - loss: 0.0708
Epoch 11/80
 - 2s - loss: 0.0655
Epoch 12/80
 - 2s - loss: 0.0612
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:15:01.819953: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:15:01.989940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:15:01.989982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:15:02.289761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:15:02.289811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:15:02.289820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:15:02.290075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9818
Epoch 2/80
 - 2s - loss: 0.1821
Epoch 3/80
 - 2s - loss: 0.1590
Epoch 4/80
 - 2s - loss: 0.1384
Epoch 5/80
 - 2s - loss: 0.1223
Epoch 6/80
 - 2s - loss: 0.1102
Epoch 7/80
 - 2s - loss: 0.0991
Epoch 8/80
 - 2s - loss: 0.0886
Epoch 9/80
 - 2s - loss: 0.0794
Epoch 10/80
 - 2s - loss: 0.0723
Epoch 11/80
 - 2s - loss: 0.0666
Epoch 12/80
 - 2s - loss: 0.0622
Epoch 13/80
 - 2s - loss: 0.0586
Epoch 14/80
 - 2s - loss: 0.0557
Epoch 15/80
 - 2s - loss: 0.0532
Epoch 16/80
 - 2s - loss: 0.0511
Epoch 17/80
 - 2s - loss: 0.0493
Epoch 18/80
 - 2s - loss: 0.0477
Epoch 19/80
 - 2s - loss: 0.0464
Epoch 20/80
 - 2s - loss: 0.0452
Epoch 21/80
 - 2s - loss: 0.0442
Epoch 22/80
 - 2s - loss: 0.0433
Epoch 23/80
 - 2s - loss: 0.0425
Epoch 24/80
 - 2s - loss: 0.0418
Epoch 25/80
 - 2s - loss: 0.0412
Epoch 26/80
 - 2s - loss: 0.0407
Epoch 27/80
 - 2s - loss: 0.0402
Epoch 28/80
 - 2s - loss: 0.0399
Epoch 29/80
 - 2s - loss: 0.0395
Epoch 30/80
 - 2s - loss: 0.0392
Epoch 31/80
 - 2s - loss: 0.0389
Epoch 32/80
 - 2s - loss: 0.0387
Epoch 33/80
 - 2s - loss: 0.0385
Epoch 34/80
 - 2s - loss: 0.0383
Epoch 35/80
 - 2s - loss: 0.0382
Epoch 36/80
 - 2s - loss: 0.0380
Epoch 37/80
 - 2s - loss: 0.0379
Epoch 38/80
 - 2s - loss: 0.0378
Epoch 39/80
 - 2s - loss: 0.0376
Epoch 40/80
 - 2s - loss: 0.0375
Epoch 41/80
 - 2s - loss: 0.0374
Epoch 42/80
 - 2s - loss: 0.0374
Epoch 43/80
 - 2s - loss: 0.0373
Epoch 44/80
 - 2s - loss: 0.0372
Epoch 45/80
 - 2s - loss: 0.0371
Epoch 46/80
 - 2s - loss: 0.0371
Epoch 47/80
 - 2s - loss: 0.0370
Epoch 48/80
 - 2s - loss: 0.0369
Epoch 49/80
 - 2s - loss: 0.0369
Epoch 50/80
 - 2s - loss: 0.0368
Epoch 51/80
 - 2s - loss: 0.0368
Epoch 52/80
 - 2s - loss: 0.0368
Epoch 53/80
 - 2s - loss: 0.0367
Epoch 54/80
 - 2s - loss: 0.0367
Epoch 55/80
 - 2s - loss: 0.0366
Epoch 56/80
 - 2s - loss: 0.0366
Epoch 57/80
 - 2s - loss: 0.0366
Epoch 58/80
 - 2s - loss: 0.0350
Epoch 59/80
 - 2s - loss: 0.0349
Epoch 60/80
 - 2s - loss: 0.0349
Epoch 61/80
 - 2s - loss: 0.0348
Epoch 62/80
 - 2s - loss: 0.0348
Epoch 63/80
 - 2s - loss: 0.0345
Epoch 64/80
 - 2s - loss: 0.0345
Epoch 65/80
 - 2s - loss: 0.0345
Epoch 66/80
 - 2s - loss: 0.0345
Epoch 67/80
 - 2s - loss: 0.0344
Epoch 68/80
 - 2s - loss: 0.0344
Epoch 69/80
 - 2s - loss: 0.0344
Epoch 70/80
 - 2s - loss: 0.0344
Epoch 71/80
 - 2s - loss: 0.0344
Epoch 72/80
 - 2s - loss: 0.0344
Epoch 73/80
 - 2s - loss: 0.0344
Epoch 74/80
 - 2s - loss: 0.0344
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2adf5d3911d0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 09:17:22.299761: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:17:22.461383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:17:22.461426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:17:22.754351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:17:22.754401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:17:22.754410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:17:22.754666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9876
Epoch 2/80
 - 2s - loss: 0.1801
Epoch 3/80
 - 2s - loss: 0.1487
Epoch 4/80
 - 2s - loss: 0.1247
Epoch 5/80
 - 2s - loss: 0.1093
Epoch 6/80
 - 2s - loss: 0.0979
Epoch 7/80
 - 2s - loss: 0.0888
Epoch 8/80
 - 2s - loss: 0.0812
Epoch 9/80
 - 2s - loss: 0.0748
Epoch 10/80
 - 2s - loss: 0.0693
Epoch 11/80
 - 2s - loss: 0.0647
Epoch 12/80
 - 2s - loss: 0.0608
Epoch 13/80
 - 2s - loss: 0.0576
Epoch 14/80
 - 2s - loss: 0.0548
Epoch 15/80
 - 2s - loss: 0.0525
Epoch 16/80
 - 2s - loss: 0.0504
Epoch 17/80
 - 2s - loss: 0.0487
Epoch 18/80
 - 2s - loss: 0.0471
Epoch 19/80
 - 2s - loss: 0.0458
Epoch 20/80
 - 2s - loss: 0.0447
Epoch 21/80
 - 2s - loss: 0.0437
Epoch 22/80
 - 2s - loss: 0.0428
Epoch 23/80
 - 2s - loss: 0.0420
Epoch 24/80
 - 2s - loss: 0.0414
Epoch 25/80
 - 2s - loss: 0.0408
Epoch 26/80
 - 2s - loss: 0.0403
Epoch 27/80
 - 2s - loss: 0.0399
Epoch 28/80
 - 2s - loss: 0.0395
Epoch 29/80
 - 2s - loss: 0.0392
Epoch 30/80
 - 2s - loss: 0.0389
Epoch 31/80
 - 2s - loss: 0.0386
Epoch 32/80
 - 2s - loss: 0.0384
Epoch 33/80
 - 2s - loss: 0.0382
Epoch 34/80
 - 2s - loss: 0.0380
Epoch 35/80
 - 2s - loss: 0.0378
Epoch 36/80
 - 1s - loss: 0.0377
Epoch 37/80
 - 2s - loss: 0.0376
Epoch 38/80
 - 2s - loss: 0.0374
Epoch 39/80
 - 2s - loss: 0.0373
Epoch 40/80
 - 2s - loss: 0.0372
Epoch 41/80
 - 2s - loss: 0.0371
Epoch 42/80
 - 2s - loss: 0.0371
Epoch 43/80
 - 2s - loss: 0.0370
Epoch 44/80
 - 2s - loss: 0.0369
Epoch 45/80
 - 2s - loss: 0.0368
Epoch 46/80
 - 2s - loss: 0.0368
Epoch 47/80
 - 2s - loss: 0.0367
Epoch 48/80
 - 2s - loss: 0.0366
Epoch 49/80
 - 2s - loss: 0.0366
Epoch 50/80
 - 1s - loss: 0.0366
Epoch 51/80
 - 2s - loss: 0.0365
Epoch 52/80
 - 1s - loss: 0.0364
Epoch 53/80
 - 2s - loss: 0.0364
Epoch 54/80
 - 1s - loss: 0.0364
Epoch 55/80
 - 1s - loss: 0.0363
Epoch 56/80
 - 1s - loss: 0.0363
Epoch 57/80
 - 1s - loss: 0.0363
Epoch 58/80
 - 1s - loss: 0.0362
Epoch 59/80
 - 1s - loss: 0.0362
Epoch 60/80
 - 2s - loss: 0.0362
Epoch 61/80
 - 1s - loss: 0.0346
Epoch 62/80
 - 1s - loss: 0.0345
Epoch 63/80
 - 2s - loss: 0.0345
Epoch 64/80
 - 2s - loss: 0.0345
Epoch 65/80
 - 1s - loss: 0.0345
Epoch 66/80
 - 2s - loss: 0.0341
Epoch 67/80
 - 2s - loss: 0.0341
Epoch 68/80
 - 2s - loss: 0.0341
Epoch 69/80
 - 1s - loss: 0.0341
Epoch 70/80
 - 2s - loss: 0.0340
Epoch 71/80
 - 1s - loss: 0.0340
Epoch 72/80
 - 2s - loss: 0.0340
Epoch 73/80
 - 2s - loss: 0.0340
Epoch 74/80
 - 2s - loss: 0.0340
Epoch 75/80
 - 2s - loss: 0.0340
Epoch 76/80
 - 2s - loss: 0.0340
Epoch 77/80
 - 2s - loss: 0.0340
Epoch 78/80
 - 1s - loss: 0.0340
Epoch 79/80
 - 1s - loss: 0.0340
Epoch 80/80
 - 2s - loss: 0.0340
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.8669 - val_loss: 1.9037
AUC: 0.7908

Epoch 2/80
 - 0s - loss: 2.4235 - val_loss: 0.9157
AUC: 0.8076

Epoch 3/80
 - 0s - loss: 1.5050 - val_loss: 0.7997
AUC: 0.8218

Epoch 4/80
 - 0s - loss: 1.2689 - val_loss: 0.6638
AUC: 0.8337

Epoch 5/80
 - 0s - loss: 1.2066 - val_loss: 0.6764
AUC: 0.8383

Epoch 6/80
 - 0s - loss: 1.1554 - val_loss: 0.6708
AUC: 0.8440

Epoch 7/80
 - 0s - loss: 1.1263 - val_loss: 0.6185
AUC: 0.8461

Epoch 8/80
 - 0s - loss: 1.1055 - val_loss: 0.7085
AUC: 0.8516

Epoch 9/80
 - 0s - loss: 1.0942 - val_loss: 0.6024
AUC: 0.8510

Epoch 10/80
 - 0s - loss: 1.0776 - val_loss: 0.6260
AUC: 0.8549

Epoch 11/80
 - 0s - loss: 1.0620 - val_loss: 0.6499
AUC: 0.8559

Epoch 12/80
 - 0s - loss: 1.0555 - val_loss: 0.6365
AUC: 0.8562

Epoch 13/80
 - 0s - loss: 1.0517 - val_loss: 0.6335
AUC: 0.8585

Epoch 14/80
 - 0s - loss: 1.0494 - val_loss: 0.6376
AUC: 0.8603

Epoch 15/80
 - 0s - loss: 1.0306 - val_loss: 0.5950
AUC: 0.8593

Epoch 16/80
 - 0s - loss: 1.0285 - val_loss: 0.6485
AUC: 0.8620

Epoch 17/80
 - 0s - loss: 1.0252 - val_loss: 0.6055
AUC: 0.8627

Epoch 18/80
 - 0s - loss: 1.0301 - val_loss: 0.5889
AUC: 0.8612

Epoch 19/80
 - 0s - loss: 1.0218 - val_loss: 0.6256
AUC: 0.8642

Epoch 20/80
 - 0s - loss: 1.0157 - val_loss: 0.6339
AUC: 0.8636

Epoch 21/80
 - 0s - loss: 1.0166 - val_loss: 0.6379
AUC: 0.8650

Epoch 22/80
 - 0s - loss: 1.0084 - val_loss: 0.6883
AUC: 0.8648

Epoch 23/80
 - 0s - loss: 1.0114 - val_loss: 0.6184
AUC: 0.8646

Epoch 24/80
 - 0s - loss: 1.0022 - val_loss: 0.5622
AUC: 0.8639

Epoch 25/80
 - 0s - loss: 0.9965 - val_loss: 0.5884
AUC: 0.8663

Epoch 26/80
 - 0s - loss: 0.9927 - val_loss: 0.6130
AUC: 0.8672

Epoch 27/80
 - 0s - loss: 0.9962 - val_loss: 0.5992
AUC: 0.8669

Epoch 28/80
 - 0s - loss: 0.9922 - val_loss: 0.5920
AUC: 0.8677

Epoch 29/80
 - 0s - loss: 0.9857 - val_loss: 0.6141
AUC: 0.8686

Epoch 30/80
 - 0s - loss: 0.9853 - val_loss: 0.6464
AUC: 0.8692

Epoch 31/80
 - 0s - loss: 0.9861 - val_loss: 0.6199
AUC: 0.8695

Epoch 32/80
 - 0s - loss: 0.9866 - val_loss: 0.6600
AUC: 0.8689

Epoch 33/80
 - 0s - loss: 0.9797 - val_loss: 0.6168
AUC: 0.8700

Epoch 34/80
 - 0s - loss: 0.9735 - val_loss: 0.5994
AUC: 0.8689

Epoch 35/80
 - 0s - loss: 0.9666 - val_loss: 0.5885
AUC: 0.8694

Epoch 36/80
 - 0s - loss: 0.9708 - val_loss: 0.6247
AUC: 0.8697

Epoch 37/80
 - 0s - loss: 0.9704 - val_loss: 0.5971
AUC: 0.8698

Epoch 38/80
 - 0s - loss: 0.9668 - val_loss: 0.5750
AUC: 0.8694

Epoch 39/80
 - 0s - loss: 0.9574 - val_loss: 0.5966
AUC: 0.8701

Epoch 40/80
 - 0s - loss: 0.9595 - val_loss: 0.5643
AUC: 0.8693

Epoch 41/80
 - 0s - loss: 0.9661 - val_loss: 0.5978
AUC: 0.8698

Epoch 42/80
 - 0s - loss: 0.9627 - val_loss: 0.6128
AUC: 0.8703

Epoch 43/80
 - 0s - loss: 0.9600 - val_loss: 0.5993
AUC: 0.8701

Epoch 44/80
 - 0s - loss: 0.9651 - val_loss: 0.5986
AUC: 0.8701

Epoch 45/80
 - 0s - loss: 0.9598 - val_loss: 0.5847
AUC: 0.8697

Epoch 46/80
 - 0s - loss: 0.9614 - val_loss: 0.5935
AUC: 0.8699

Epoch 47/80
 - 0s - loss: 0.9597 - val_loss: 0.5906
AUC: 0.8700

Epoch 48/80
 - 0s - loss: 0.9615 - val_loss: 0.6022
AUC: 0.8701

Epoch 49/80
 - 0s - loss: 0.9543 - val_loss: 0.5927
AUC: 0.8701

Epoch 50/80
 - 0s - loss: 0.9610 - val_loss: 0.5880
AUC: 0.8700

Epoch 51/80
 - 0s - loss: 0.9563 - val_loss: 0.5949
AUC: 0.8701

Epoch 52/80
 - 0s - loss: 0.9626 - val_loss: 0.6009
AUC: 0.8701

Epoch 53/80
 - 0s - loss: 0.9648 - val_loss: 0.5923
AUC: 0.8701

Epoch 54/80
 - 0s - loss: 0.9569 - val_loss: 0.5902
AUC: 0.8701

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9590 - val_loss: 0.5899
AUC: 0.8702

Epoch 2/30
 - 0s - loss: 0.9661 - val_loss: 0.5755
AUC: 0.8703

Epoch 3/30
 - 0s - loss: 0.9559 - val_loss: 0.5893
AUC: 0.8703

Epoch 4/30
 - 0s - loss: 0.9561 - val_loss: 0.5857
AUC: 0.8705

Epoch 5/30
 - 0s - loss: 0.9473 - val_loss: 0.5808
AUC: 0.8706

Epoch 6/30
 - 0s - loss: 0.9515 - val_loss: 0.5784
AUC: 0.8706

Epoch 7/30
 - 0s - loss: 0.9496 - val_loss: 0.5711
AUC: 0.8707

Epoch 8/30
 - 0s - loss: 0.9561 - val_loss: 0.5835
AUC: 0.8711

Epoch 9/30
 - 0s - loss: 0.9485 - val_loss: 0.5821
AUC: 0.8709

Epoch 10/30
 - 0s - loss: 0.9426 - val_loss: 0.5825
AUC: 0.8711

Epoch 11/30
 - 0s - loss: 0.9472 - val_loss: 0.5841
AUC: 0.8714

Epoch 12/30
 - 0s - loss: 0.9426 - val_loss: 0.5693
AUC: 0.8713

Epoch 13/30
 - 0s - loss: 0.9480 - val_loss: 0.5703
AUC: 0.8715

Epoch 14/30
 - 0s - loss: 0.9368 - val_loss: 0.5755
AUC: 0.8716

Epoch 15/30
 - 0s - loss: 0.9369 - val_loss: 0.5891
AUC: 0.8719

Epoch 16/30
 - 0s - loss: 0.9377 - val_loss: 0.5625
AUC: 0.8713

Epoch 17/30
 - 0s - loss: 0.9387 - val_loss: 0.5823
AUC: 0.8720

Epoch 18/30
 - 0s - loss: 0.9377 - val_loss: 0.5903
AUC: 0.8724

Epoch 19/30
 - 0s - loss: 0.9341 - val_loss: 0.5795
AUC: 0.8719

Epoch 20/30
 - 0s - loss: 0.9354 - val_loss: 0.5728
AUC: 0.8721

Epoch 21/30
 - 0s - loss: 0.9296 - val_loss: 0.5905
AUC: 0.8726

Epoch 22/30
 - 0s - loss: 0.9300 - val_loss: 0.5564
AUC: 0.8721

Epoch 23/30
 - 0s - loss: 0.9255 - val_loss: 0.5766
AUC: 0.8727

Epoch 24/30
 - 0s - loss: 0.9247 - val_loss: 0.5710
AUC: 0.8725

Epoch 25/30
 - 0s - loss: 0.9234 - val_loss: 0.5432
AUC: 0.8721

Epoch 26/30
 - 0s - loss: 0.9234 - val_loss: 0.5671
AUC: 0.8726

Epoch 27/30
 - 0s - loss: 0.9194 - val_loss: 0.5716
AUC: 0.8727

Epoch 28/30
 - 0s - loss: 0.9234 - val_loss: 0.5729
AUC: 0.8726

Epoch 29/30
 - 0s - loss: 0.9140 - val_loss: 0.5671
AUC: 0.8727

Epoch 30/30
 - 0s - loss: 0.9194 - val_loss: 0.5818
Using TensorFlow backend.
AUC: 0.8731

2019-03-08 09:20:43.840962: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:20:44.002487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:20:44.002531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:20:44.292551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:20:44.292602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:20:44.292611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:20:44.292863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6004
Epoch 2/80
 - 2s - loss: 0.0830
Epoch 3/80
 - 2s - loss: 0.0658
Epoch 4/80
 - 2s - loss: 0.0612
Epoch 5/80
 - 2s - loss: 0.0555
Epoch 6/80
 - 1s - loss: 0.0481
Epoch 7/80
 - 2s - loss: 0.0415
Epoch 8/80
 - 1s - loss: 0.0366
Epoch 9/80
 - 1s - loss: 0.0328
Epoch 10/80
 - 2s - loss: 0.0297
Epoch 11/80
 - 2s - loss: 0.0270
Epoch 12/80
 - 2s - loss: 0.0248
Epoch 13/80
 - 2s - loss: 0.0229
Epoch 14/80
 - 2s - loss: 0.0214
Epoch 15/80
 - 2s - loss: 0.0201
Epoch 16/80
 - 2s - loss: 0.0190
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0173
Epoch 19/80
 - 2s - loss: 0.0166
Epoch 20/80
 - 2s - loss: 0.0160
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0114
Epoch 48/80
 - 2s - loss: 0.0113
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0111
Epoch 55/80
 - 2s - loss: 0.0111
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.8939 - val_loss: 1.1992
AUC: 0.7699

Epoch 2/80
 - 0s - loss: 1.9050 - val_loss: 0.8190
AUC: 0.7921

Epoch 3/80
 - 0s - loss: 1.3535 - val_loss: 0.7720
AUC: 0.8163

Epoch 4/80
 - 0s - loss: 1.2319 - val_loss: 0.7312
AUC: 0.8284

Epoch 5/80
 - 0s - loss: 1.1880 - val_loss: 0.6978
AUC: 0.8346

Epoch 6/80
 - 0s - loss: 1.1389 - val_loss: 0.6728
AUC: 0.8416

Epoch 7/80
 - 0s - loss: 1.1243 - val_loss: 0.6470
AUC: 0.8454

Epoch 8/80
 - 0s - loss: 1.1041 - val_loss: 0.6453
AUC: 0.8485

Epoch 9/80
 - 0s - loss: 1.0918 - val_loss: 0.6551
AUC: 0.8504

Epoch 10/80
 - 0s - loss: 1.0761 - val_loss: 0.6400
AUC: 0.8506

Epoch 11/80
 - 0s - loss: 1.0716 - val_loss: 0.6276
AUC: 0.8523

Epoch 12/80
 - 0s - loss: 1.0628 - val_loss: 0.6983
AUC: 0.8539

Epoch 13/80
 - 0s - loss: 1.0547 - val_loss: 0.6277
AUC: 0.8522

Epoch 14/80
 - 0s - loss: 1.0488 - val_loss: 0.6461
AUC: 0.8525

Epoch 15/80
 - 0s - loss: 1.0435 - val_loss: 0.7136
AUC: 0.8561

Epoch 16/80
 - 0s - loss: 1.0436 - val_loss: 0.6508
AUC: 0.8554

Epoch 17/80
 - 0s - loss: 1.0344 - val_loss: 0.6103
AUC: 0.8543

Epoch 18/80
 - 0s - loss: 1.0260 - val_loss: 0.6230
AUC: 0.8540

Epoch 19/80
 - 0s - loss: 1.0253 - val_loss: 0.5956
AUC: 0.8557

Epoch 20/80
 - 0s - loss: 1.0163 - val_loss: 0.6522
AUC: 0.8577

Epoch 21/80
 - 0s - loss: 1.0234 - val_loss: 0.6357
AUC: 0.8571

Epoch 22/80
 - 0s - loss: 1.0103 - val_loss: 0.5956
AUC: 0.8576

Epoch 23/80
 - 0s - loss: 1.0146 - val_loss: 0.6134
AUC: 0.8566

Epoch 24/80
 - 0s - loss: 1.0027 - val_loss: 0.6689
AUC: 0.8586

Epoch 25/80
 - 0s - loss: 1.0063 - val_loss: 0.6508
AUC: 0.8594

Epoch 26/80
 - 0s - loss: 1.0028 - val_loss: 0.6134
AUC: 0.8580

Epoch 27/80
 - 0s - loss: 1.0011 - val_loss: 0.6887
AUC: 0.8593

Epoch 28/80
 - 0s - loss: 0.9962 - val_loss: 0.6440
AUC: 0.8589

Epoch 29/80
 - 0s - loss: 0.9909 - val_loss: 0.6378
AUC: 0.8603

Epoch 30/80
 - 0s - loss: 0.9891 - val_loss: 0.6088
AUC: 0.8593

Epoch 31/80
 - 0s - loss: 0.9803 - val_loss: 0.6165
AUC: 0.8596

Epoch 32/80
 - 0s - loss: 0.9796 - val_loss: 0.6219
AUC: 0.8602

Epoch 33/80
 - 0s - loss: 0.9799 - val_loss: 0.6263
AUC: 0.8600

Epoch 34/80
 - 0s - loss: 0.9779 - val_loss: 0.5948
AUC: 0.8597

Epoch 35/80
 - 0s - loss: 0.9780 - val_loss: 0.6247
AUC: 0.8600

Epoch 36/80
 - 0s - loss: 0.9808 - val_loss: 0.5931
AUC: 0.8600

Epoch 37/80
 - 0s - loss: 0.9795 - val_loss: 0.6137
AUC: 0.8603

Epoch 38/80
 - 0s - loss: 0.9818 - val_loss: 0.5990
AUC: 0.8599

Epoch 39/80
 - 0s - loss: 0.9795 - val_loss: 0.6270
AUC: 0.8608

Epoch 40/80
 - 0s - loss: 0.9758 - val_loss: 0.6221
AUC: 0.8602

Epoch 41/80
 - 0s - loss: 0.9749 - val_loss: 0.6284
AUC: 0.8607

Epoch 42/80
 - 0s - loss: 0.9736 - val_loss: 0.6087
AUC: 0.8603

Epoch 43/80
 - 0s - loss: 0.9801 - val_loss: 0.6153
AUC: 0.8604

Epoch 44/80
 - 0s - loss: 0.9741 - val_loss: 0.6112
AUC: 0.8609

Epoch 45/80
 - 0s - loss: 0.9775 - val_loss: 0.6377
AUC: 0.8613

Epoch 46/80
 - 0s - loss: 0.9795 - val_loss: 0.6199
AUC: 0.8607

Epoch 47/80
 - 0s - loss: 0.9750 - val_loss: 0.6027
AUC: 0.8606

Epoch 48/80
 - 0s - loss: 0.9724 - val_loss: 0.5976
AUC: 0.8604

Epoch 49/80
 - 0s - loss: 0.9669 - val_loss: 0.5988
AUC: 0.8605

Epoch 50/80
 - 0s - loss: 0.9736 - val_loss: 0.6008
AUC: 0.8605

Epoch 51/80
 - 0s - loss: 0.9744 - val_loss: 0.6019
AUC: 0.8606

Epoch 52/80
 - 0s - loss: 0.9707 - val_loss: 0.6050
AUC: 0.8606

Epoch 53/80
 - 0s - loss: 0.9674 - val_loss: 0.6061
AUC: 0.8607

Epoch 54/80
 - 0s - loss: 0.9737 - val_loss: 0.6080
AUC: 0.8609

Epoch 55/80
 - 0s - loss: 0.9710 - val_loss: 0.5996
AUC: 0.8605

Epoch 56/80
 - 0s - loss: 0.9691 - val_loss: 0.6101
AUC: 0.8608

Epoch 57/80
 - 0s - loss: 0.9727 - val_loss: 0.6087
AUC: 0.8608

Epoch 58/80
 - 0s - loss: 0.9663 - val_loss: 0.6053
AUC: 0.8607

Epoch 59/80
 - 0s - loss: 0.9741 - val_loss: 0.6063
AUC: 0.8608

Epoch 60/80
 - 0s - loss: 0.9694 - val_loss: 0.6051
AUC: 0.8608

Epoch 61/80
 - 0s - loss: 0.9729 - val_loss: 0.6057
AUC: 0.8608

Epoch 62/80
 - 0s - loss: 0.9718 - val_loss: 0.6051
AUC: 0.8608

Epoch 63/80
 - 0s - loss: 0.9664 - val_loss: 0.6056
AUC: 0.8608

Epoch 64/80
 - 0s - loss: 0.9738 - val_loss: 0.6062
AUC: 0.8608

Epoch 65/80
 - 0s - loss: 0.9692 - val_loss: 0.6058
AUC: 0.8608

Epoch 66/80
 - 0s - loss: 0.9689 - val_loss: 0.6034
AUC: 0.8608

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9774 - val_loss: 0.6011
AUC: 0.8608

Epoch 2/30
 - 0s - loss: 0.9755 - val_loss: 0.5866
AUC: 0.8607

Epoch 3/30
 - 0s - loss: 0.9632 - val_loss: 0.6041
AUC: 0.8611

Epoch 4/30
 - 0s - loss: 0.9659 - val_loss: 0.6179
AUC: 0.8613

Epoch 5/30
 - 0s - loss: 0.9642 - val_loss: 0.6012
AUC: 0.8613

Epoch 6/30
 - 0s - loss: 0.9660 - val_loss: 0.6087
AUC: 0.8613

Epoch 7/30
 - 0s - loss: 0.9627 - val_loss: 0.6075
AUC: 0.8615

Epoch 8/30
 - 0s - loss: 0.9562 - val_loss: 0.5956
AUC: 0.8612

Epoch 9/30
 - 0s - loss: 0.9638 - val_loss: 0.6184
AUC: 0.8618

Epoch 10/30
 - 0s - loss: 0.9610 - val_loss: 0.5908
AUC: 0.8616

Epoch 11/30
 - 0s - loss: 0.9540 - val_loss: 0.6059
AUC: 0.8618

Epoch 12/30
 - 0s - loss: 0.9487 - val_loss: 0.5982
AUC: 0.8616

Epoch 13/30
 - 0s - loss: 0.9549 - val_loss: 0.5994
AUC: 0.8617

Epoch 14/30
 - 0s - loss: 0.9580 - val_loss: 0.6004
AUC: 0.8618

Epoch 15/30
 - 0s - loss: 0.9508 - val_loss: 0.6014
AUC: 0.8619

Epoch 16/30
 - 0s - loss: 0.9452 - val_loss: 0.5932
AUC: 0.8617

Epoch 17/30
 - 0s - loss: 0.9498 - val_loss: 0.5978
AUC: 0.8618

Epoch 18/30
 - 0s - loss: 0.9468 - val_loss: 0.5933
AUC: 0.8617

Epoch 19/30
 - 0s - loss: 0.9469 - val_loss: 0.5972
AUC: 0.8618

Epoch 20/30
 - 0s - loss: 0.9478 - val_loss: 0.6007
AUC: 0.8619

Epoch 21/30
 - 0s - loss: 0.9485 - val_loss: 0.5956
AUC: 0.8618

Epoch 22/30
 - 0s - loss: 0.9434 - val_loss: 0.6018
AUC: 0.8621

Epoch 23/30
 - 0s - loss: 0.9532 - val_loss: 0.6008
AUC: 0.8620

Epoch 24/30
 - 0s - loss: 0.9477 - val_loss: 0.5982
AUC: 0.8620

Epoch 25/30
 - 0s - loss: 0.9476 - val_loss: 0.5969
AUC: 0.8619

Epoch 26/30
 - 0s - loss: 0.9462 - val_loss: 0.5974
AUC: 0.8620

Epoch 27/30
 - 0s - loss: 0.9482 - val_loss: 0.5972
AUC: 0.8620

Epoch 28/30
 - 0s - loss: 0.9456 - val_loss: 0.5972
AUC: 0.8620

Epoch 29/30
 - 0s - loss: 0.9448 - val_loss: 0.5962
AUC: 0.8619

Epoch 30/30
 - 0s - loss: 0.9430 - val_loss: 0.5964
Using TensorFlow backend.
AUC: 0.8620

2019-03-08 09:24:12.080215: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:24:12.244056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:24:12.244102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:24:12.535976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:24:12.536024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:24:12.536033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:24:12.536293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6003
Epoch 2/80
 - 2s - loss: 0.0831
Epoch 3/80
 - 2s - loss: 0.0628
Epoch 4/80
 - 2s - loss: 0.0547
Epoch 5/80
 - 2s - loss: 0.0483
Epoch 6/80
 - 2s - loss: 0.0432
Epoch 7/80
 - 2s - loss: 0.0388
Epoch 8/80
 - 2s - loss: 0.0350
Epoch 9/80
 - 2s - loss: 0.0316
Epoch 10/80
 - 2s - loss: 0.0287
Epoch 11/80
 - 2s - loss: 0.0262
Epoch 12/80
 - 2s - loss: 0.0241
Epoch 13/80
 - 2s - loss: 0.0224
Epoch 14/80
 - 2s - loss: 0.0210
Epoch 15/80
 - 2s - loss: 0.0198
Epoch 16/80
 - 2s - loss: 0.0187
Epoch 17/80
 - 2s - loss: 0.0179
Epoch 18/80
 - 2s - loss: 0.0171
Epoch 19/80
 - 2s - loss: 0.0164
Epoch 20/80
 - 2s - loss: 0.0158
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0149
Epoch 23/80
 - 2s - loss: 0.0145
Epoch 24/80
 - 2s - loss: 0.0142
Epoch 25/80
 - 2s - loss: 0.0139
Epoch 26/80
 - 2s - loss: 0.0136
Epoch 27/80
 - 2s - loss: 0.0134
Epoch 28/80
 - 2s - loss: 0.0132
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0129
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:25:23.446308: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:25:23.608676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:25:23.608720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:25:23.899211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:25:23.899263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:25:23.899273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:25:23.899560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6024
Epoch 2/80
 - 2s - loss: 0.0834
Epoch 3/80
 - 2s - loss: 0.0668
Epoch 4/80
 - 2s - loss: 0.0628
Epoch 5/80
 - 2s - loss: 0.0575
Epoch 6/80
 - 2s - loss: 0.0504
Epoch 7/80
 - 2s - loss: 0.0437
Epoch 8/80
 - 2s - loss: 0.0385
Epoch 9/80
 - 2s - loss: 0.0342
Epoch 10/80
 - 2s - loss: 0.0306
Epoch 11/80
 - 2s - loss: 0.0276
Epoch 12/80
 - 2s - loss: 0.0252
Epoch 13/80
 - 2s - loss: 0.0232
Epoch 14/80
 - 2s - loss: 0.0216
Epoch 15/80
 - 2s - loss: 0.0203
Epoch 16/80
 - 2s - loss: 0.0191
Epoch 17/80
 - 2s - loss: 0.0182
Epoch 18/80
 - 2s - loss: 0.0174
Epoch 19/80
 - 2s - loss: 0.0167
Epoch 20/80
 - 2s - loss: 0.0161
Epoch 21/80
 - 2s - loss: 0.0156
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0144
Epoch 25/80
 - 2s - loss: 0.0141
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0136
Epoch 28/80
 - 2s - loss: 0.0134
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0131
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0128
Epoch 33/80
 - 2s - loss: 0.0127
Epoch 34/80
 - 2s - loss: 0.0126
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0123
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0122
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0121
Epoch 43/80
 - 2s - loss: 0.0121
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0120
Epoch 46/80
 - 2s - loss: 0.0120
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0119
Epoch 49/80
 - 2s - loss: 0.0114
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0113
Epoch 52/80
 - 2s - loss: 0.0113
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0112
Epoch 56/80
 - 2s - loss: 0.0112
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.3120 - val_loss: 0.8929
AUC: 0.7997

Epoch 2/80
 - 0s - loss: 1.5811 - val_loss: 0.7526
AUC: 0.8178

Epoch 3/80
 - 0s - loss: 1.2737 - val_loss: 0.7538
AUC: 0.8325

Epoch 4/80
 - 0s - loss: 1.1993 - val_loss: 0.7028
AUC: 0.8387

Epoch 5/80
 - 0s - loss: 1.1591 - val_loss: 0.7399
AUC: 0.8460

Epoch 6/80
 - 0s - loss: 1.1408 - val_loss: 0.6876
AUC: 0.8467

Epoch 7/80
 - 0s - loss: 1.1286 - val_loss: 0.6692
AUC: 0.8518

Epoch 8/80
 - 0s - loss: 1.1015 - val_loss: 0.5954
AUC: 0.8521

Epoch 9/80
 - 0s - loss: 1.0902 - val_loss: 0.6489
AUC: 0.8550

Epoch 10/80
 - 0s - loss: 1.0859 - val_loss: 0.6565
AUC: 0.8555

Epoch 11/80
 - 0s - loss: 1.0659 - val_loss: 0.6040
AUC: 0.8570

Epoch 12/80
 - 0s - loss: 1.0628 - val_loss: 0.6780
AUC: 0.8588

Epoch 13/80
 - 0s - loss: 1.0561 - val_loss: 0.5874
AUC: 0.8572

Epoch 14/80
 - 0s - loss: 1.0559 - val_loss: 0.6426
AUC: 0.8605

Epoch 15/80
 - 0s - loss: 1.0457 - val_loss: 0.6563
AUC: 0.8600

Epoch 16/80
 - 0s - loss: 1.0350 - val_loss: 0.6603
AUC: 0.8611

Epoch 17/80
 - 0s - loss: 1.0326 - val_loss: 0.6844
AUC: 0.8618

Epoch 18/80
 - 0s - loss: 1.0273 - val_loss: 0.6022
AUC: 0.8598

Epoch 19/80
 - 0s - loss: 1.0250 - val_loss: 0.6671
AUC: 0.8627

Epoch 20/80
 - 0s - loss: 1.0246 - val_loss: 0.6011
AUC: 0.8626

Epoch 21/80
 - 0s - loss: 1.0206 - val_loss: 0.6292
AUC: 0.8631

Epoch 22/80
 - 0s - loss: 1.0137 - val_loss: 0.6379
AUC: 0.8628

Epoch 23/80
 - 0s - loss: 1.0062 - val_loss: 0.6358
AUC: 0.8629

Epoch 24/80
 - 0s - loss: 1.0073 - val_loss: 0.6134
AUC: 0.8632

Epoch 25/80
 - 0s - loss: 0.9992 - val_loss: 0.6634
AUC: 0.8638

Epoch 26/80
 - 0s - loss: 1.0004 - val_loss: 0.6109
AUC: 0.8636

Epoch 27/80
 - 0s - loss: 0.9977 - val_loss: 0.6123
AUC: 0.8635

Epoch 28/80
 - 0s - loss: 0.9974 - val_loss: 0.6384
AUC: 0.8641

Epoch 29/80
 - 0s - loss: 0.9964 - val_loss: 0.5903
AUC: 0.8632

Epoch 30/80
 - 0s - loss: 0.9896 - val_loss: 0.6325
AUC: 0.8635

Epoch 31/80
 - 0s - loss: 0.9985 - val_loss: 0.6247
AUC: 0.8637

Epoch 32/80
 - 0s - loss: 0.9992 - val_loss: 0.5855
AUC: 0.8633

Epoch 33/80
 - 0s - loss: 0.9945 - val_loss: 0.6376
AUC: 0.8640

Epoch 34/80
 - 0s - loss: 0.9935 - val_loss: 0.6082
AUC: 0.8638

Epoch 35/80
 - 0s - loss: 0.9919 - val_loss: 0.6341
AUC: 0.8639

Epoch 36/80
 - 0s - loss: 0.9949 - val_loss: 0.6044
AUC: 0.8637

Epoch 37/80
 - 0s - loss: 0.9930 - val_loss: 0.6103
AUC: 0.8638

Epoch 38/80
 - 0s - loss: 0.9902 - val_loss: 0.5962
AUC: 0.8637

Epoch 39/80
 - 0s - loss: 0.9986 - val_loss: 0.6085
AUC: 0.8639

Epoch 40/80
 - 0s - loss: 0.9933 - val_loss: 0.6105
AUC: 0.8638

Epoch 41/80
 - 0s - loss: 1.0024 - val_loss: 0.6083
AUC: 0.8641

Epoch 42/80
 - 0s - loss: 0.9927 - val_loss: 0.6059
AUC: 0.8641

Epoch 43/80
 - 0s - loss: 0.9887 - val_loss: 0.6031
AUC: 0.8640

Epoch 44/80
 - 0s - loss: 0.9915 - val_loss: 0.6058
AUC: 0.8640

Epoch 45/80
 - 0s - loss: 0.9912 - val_loss: 0.6077
AUC: 0.8639

Epoch 46/80
 - 0s - loss: 0.9878 - val_loss: 0.6094
AUC: 0.8640

Epoch 47/80
 - 0s - loss: 0.9871 - val_loss: 0.6139
AUC: 0.8641

Epoch 48/80
 - 0s - loss: 0.9869 - val_loss: 0.6151
AUC: 0.8642

Epoch 49/80
 - 0s - loss: 0.9840 - val_loss: 0.6077
AUC: 0.8640

Epoch 50/80
 - 0s - loss: 0.9858 - val_loss: 0.6065
AUC: 0.8640

Epoch 51/80
 - 0s - loss: 0.9837 - val_loss: 0.6030
AUC: 0.8640

Epoch 52/80
 - 0s - loss: 0.9863 - val_loss: 0.6111
AUC: 0.8642

Epoch 53/80
 - 0s - loss: 0.9882 - val_loss: 0.6095
AUC: 0.8641

Epoch 54/80
 - 0s - loss: 0.9868 - val_loss: 0.6099
AUC: 0.8641

Epoch 55/80
 - 0s - loss: 0.9826 - val_loss: 0.6079
AUC: 0.8641

Epoch 56/80
 - 0s - loss: 0.9836 - val_loss: 0.6074
AUC: 0.8641

Epoch 57/80
 - 0s - loss: 0.9868 - val_loss: 0.6058
AUC: 0.8641

Epoch 58/80
 - 0s - loss: 0.9870 - val_loss: 0.6084
AUC: 0.8641

Epoch 59/80
 - 0s - loss: 0.9893 - val_loss: 0.6064
AUC: 0.8641

Epoch 60/80
 - 0s - loss: 0.9826 - val_loss: 0.6065
AUC: 0.8641

Epoch 61/80
 - 0s - loss: 0.9871 - val_loss: 0.6076
AUC: 0.8641

Epoch 62/80
 - 0s - loss: 0.9887 - val_loss: 0.6072
AUC: 0.8641

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9872 - val_loss: 0.5951
AUC: 0.8642

Epoch 2/30
 - 0s - loss: 0.9917 - val_loss: 0.6097
AUC: 0.8644

Epoch 3/30
 - 0s - loss: 0.9841 - val_loss: 0.6257
AUC: 0.8648

Epoch 4/30
 - 0s - loss: 0.9836 - val_loss: 0.6125
AUC: 0.8649

Epoch 5/30
 - 0s - loss: 0.9798 - val_loss: 0.6038
AUC: 0.8649

Epoch 6/30
 - 0s - loss: 0.9728 - val_loss: 0.6137
AUC: 0.8652

Epoch 7/30
 - 0s - loss: 0.9789 - val_loss: 0.6088
AUC: 0.8653

Epoch 8/30
 - 0s - loss: 0.9743 - val_loss: 0.6046
AUC: 0.8652

Epoch 9/30
 - 0s - loss: 0.9790 - val_loss: 0.5947
AUC: 0.8654

Epoch 10/30
 - 0s - loss: 0.9781 - val_loss: 0.5989
AUC: 0.8655

Epoch 11/30
 - 0s - loss: 0.9675 - val_loss: 0.5860
AUC: 0.8656

Epoch 12/30
 - 0s - loss: 0.9648 - val_loss: 0.5822
AUC: 0.8657

Epoch 13/30
 - 0s - loss: 0.9701 - val_loss: 0.6020
AUC: 0.8658

Epoch 14/30
 - 0s - loss: 0.9667 - val_loss: 0.5969
AUC: 0.8659

Epoch 15/30
 - 0s - loss: 0.9675 - val_loss: 0.6092
AUC: 0.8660

Epoch 16/30
 - 0s - loss: 0.9637 - val_loss: 0.5882
AUC: 0.8660

Epoch 17/30
 - 0s - loss: 0.9660 - val_loss: 0.6187
AUC: 0.8663

Epoch 18/30
 - 0s - loss: 0.9616 - val_loss: 0.5901
AUC: 0.8663

Epoch 19/30
 - 0s - loss: 0.9599 - val_loss: 0.6086
AUC: 0.8662

Epoch 20/30
 - 0s - loss: 0.9598 - val_loss: 0.5878
AUC: 0.8664

Epoch 21/30
 - 0s - loss: 0.9523 - val_loss: 0.5839
AUC: 0.8664

Epoch 22/30
 - 0s - loss: 0.9550 - val_loss: 0.5961
AUC: 0.8667

Epoch 23/30
 - 0s - loss: 0.9519 - val_loss: 0.5887
AUC: 0.8666

Epoch 24/30
 - 0s - loss: 0.9585 - val_loss: 0.5915
AUC: 0.8666

Epoch 25/30
 - 0s - loss: 0.9546 - val_loss: 0.5978
AUC: 0.8666

Epoch 26/30
 - 0s - loss: 0.9511 - val_loss: 0.5916
AUC: 0.8666

Epoch 27/30
 - 0s - loss: 0.9577 - val_loss: 0.5914
AUC: 0.8666

Epoch 28/30
 - 0s - loss: 0.9474 - val_loss: 0.5936
AUC: 0.8666

Epoch 29/30
 - 0s - loss: 0.9530 - val_loss: 0.5964
AUC: 0.8667

Epoch 30/30
 - 0s - loss: 0.9526 - val_loss: 0.5939
Using TensorFlow backend.
AUC: 0.8667

2019-03-08 09:28:50.891211: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:28:51.056820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:28:51.056864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:28:51.350023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:28:51.350074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:28:51.350083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:28:51.350346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2008
Epoch 2/80
 - 2s - loss: 0.3171
Epoch 3/80
 - 2s - loss: 0.2816
Epoch 4/80
 - 2s - loss: 0.2419
Epoch 5/80
 - 2s - loss: 0.2100
Epoch 6/80
 - 2s - loss: 0.1891
Epoch 7/80
 - 2s - loss: 0.1727
Epoch 8/80
 - 2s - loss: 0.1587
Epoch 9/80
 - 2s - loss: 0.1471
Epoch 10/80
 - 2s - loss: 0.1379
Epoch 11/80
 - 2s - loss: 0.1307
Epoch 12/80
 - 2s - loss: 0.1249
Epoch 13/80
 - 2s - loss: 0.1200
Epoch 14/80
 - 2s - loss: 0.1157
Epoch 15/80
 - 2s - loss: 0.1119
Epoch 16/80
 - 2s - loss: 0.1085
Epoch 17/80
 - 2s - loss: 0.1055
Epoch 18/80
 - 2s - loss: 0.1031
Epoch 19/80
 - 2s - loss: 0.1009
Epoch 20/80
 - 2s - loss: 0.0991
Epoch 21/80
 - 2s - loss: 0.0975
Epoch 22/80
 - 2s - loss: 0.0960
Epoch 23/80
 - 2s - loss: 0.0949
Epoch 24/80
 - 2s - loss: 0.0938
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0921
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0909
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0899
Epoch 31/80
 - 2s - loss: 0.0895
Epoch 32/80
 - 2s - loss: 0.0892
Epoch 33/80
 - 2s - loss: 0.0889
Epoch 34/80
 - 2s - loss: 0.0885
Epoch 35/80
 - 2s - loss: 0.0883
Epoch 36/80
 - 2s - loss: 0.0881
Epoch 37/80
 - 2s - loss: 0.0878
Epoch 38/80
 - 2s - loss: 0.0876
Epoch 39/80
 - 2s - loss: 0.0874
Epoch 40/80
 - 2s - loss: 0.0873
Epoch 41/80
 - 2s - loss: 0.0871
Epoch 42/80
 - 2s - loss: 0.0869
Epoch 43/80
 - 2s - loss: 0.0868
Epoch 44/80
 - 2s - loss: 0.0867
Epoch 45/80
 - 2s - loss: 0.0866
Epoch 46/80
 - 2s - loss: 0.0865
Epoch 47/80
 - 2s - loss: 0.0863
Epoch 48/80
 - 2s - loss: 0.0862
Epoch 49/80
 - 2s - loss: 0.0861
Epoch 50/80
 - 2s - loss: 0.0860
Epoch 51/80
 - 2s - loss: 0.0860
Epoch 52/80
 - 2s - loss: 0.0859
Epoch 53/80
 - 2s - loss: 0.0858
Epoch 54/80
 - 2s - loss: 0.0857
Epoch 55/80
 - 2s - loss: 0.0857
Epoch 56/80
 - 2s - loss: 0.0856
Epoch 57/80
 - 2s - loss: 0.0856
Epoch 58/80
 - 2s - loss: 0.0855
Epoch 59/80
 - 2s - loss: 0.0854
Epoch 60/80
 - 2s - loss: 0.0854
Epoch 61/80
 - 2s - loss: 0.0853
Epoch 62/80
 - 2s - loss: 0.0853
Epoch 63/80
 - 2s - loss: 0.0852
Epoch 64/80
 - 2s - loss: 0.0852
Epoch 65/80
 - 2s - loss: 0.0851
Epoch 66/80
 - 2s - loss: 0.0851
Epoch 67/80
 - 2s - loss: 0.0851
Epoch 68/80
 - 2s - loss: 0.0850
Epoch 69/80
 - 2s - loss: 0.0850
Epoch 70/80
 - 2s - loss: 0.0849
Epoch 71/80
 - 2s - loss: 0.0849
Epoch 72/80
 - 2s - loss: 0.0849
Epoch 73/80
 - 2s - loss: 0.0848
Epoch 74/80
 - 2s - loss: 0.0815
Epoch 75/80
 - 2s - loss: 0.0812
Epoch 76/80
 - 2s - loss: 0.0812
Epoch 77/80
 - 2s - loss: 0.0812
Epoch 78/80
 - 2s - loss: 0.0812
Epoch 79/80
 - 2s - loss: 0.0804
Epoch 80/80
 - 2s - loss: 0.0804
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.2062 - val_loss: 1.4729
AUC: 0.7401

Epoch 2/80
 - 0s - loss: 2.1639 - val_loss: 0.8360
AUC: 0.8045

Epoch 3/80
 - 0s - loss: 1.4274 - val_loss: 0.7918
AUC: 0.8255

Epoch 4/80
 - 0s - loss: 1.2356 - val_loss: 0.7361
AUC: 0.8348

Epoch 5/80
 - 0s - loss: 1.1768 - val_loss: 0.7005
AUC: 0.8437

Epoch 6/80
 - 0s - loss: 1.1443 - val_loss: 0.7153
AUC: 0.8522

Epoch 7/80
 - 0s - loss: 1.1336 - val_loss: 0.6732
AUC: 0.8550

Epoch 8/80
 - 0s - loss: 1.1185 - val_loss: 0.6761
AUC: 0.8586

Epoch 9/80
 - 0s - loss: 1.1012 - val_loss: 0.6804
AUC: 0.8599

Epoch 10/80
 - 0s - loss: 1.0857 - val_loss: 0.6709
AUC: 0.8604

Epoch 11/80
 - 0s - loss: 1.0872 - val_loss: 0.7014
AUC: 0.8629

Epoch 12/80
 - 0s - loss: 1.0729 - val_loss: 0.6540
AUC: 0.8654

Epoch 13/80
 - 0s - loss: 1.0717 - val_loss: 0.6568
AUC: 0.8666

Epoch 14/80
 - 0s - loss: 1.0584 - val_loss: 0.6188
AUC: 0.8666

Epoch 15/80
 - 0s - loss: 1.0570 - val_loss: 0.5800
AUC: 0.8660

Epoch 16/80
 - 0s - loss: 1.0470 - val_loss: 0.6524
AUC: 0.8681

Epoch 17/80
 - 0s - loss: 1.0444 - val_loss: 0.5817
AUC: 0.8669

Epoch 18/80
 - 0s - loss: 1.0423 - val_loss: 0.6735
AUC: 0.8692

Epoch 19/80
 - 0s - loss: 1.0335 - val_loss: 0.6397
AUC: 0.8698

Epoch 20/80
 - 0s - loss: 1.0313 - val_loss: 0.6598
AUC: 0.8706

Epoch 21/80
 - 0s - loss: 1.0270 - val_loss: 0.5719
AUC: 0.8689

Epoch 22/80
 - 0s - loss: 1.0227 - val_loss: 0.6148
AUC: 0.8695

Epoch 23/80
 - 0s - loss: 1.0205 - val_loss: 0.6419
AUC: 0.8705

Epoch 24/80
 - 0s - loss: 1.0165 - val_loss: 0.5981
AUC: 0.8705

Epoch 25/80
 - 0s - loss: 1.0140 - val_loss: 0.6047
AUC: 0.8705

Epoch 26/80
 - 0s - loss: 1.0121 - val_loss: 0.6674
AUC: 0.8724

Epoch 27/80
 - 0s - loss: 1.0093 - val_loss: 0.5752
AUC: 0.8711

Epoch 28/80
 - 0s - loss: 1.0035 - val_loss: 0.6325
AUC: 0.8716

Epoch 29/80
 - 0s - loss: 1.0000 - val_loss: 0.6649
AUC: 0.8727

Epoch 30/80
 - 0s - loss: 0.9983 - val_loss: 0.6110
AUC: 0.8724

Epoch 31/80
 - 0s - loss: 0.9935 - val_loss: 0.5927
AUC: 0.8727

Epoch 32/80
 - 0s - loss: 0.9765 - val_loss: 0.6139
AUC: 0.8726

Epoch 33/80
 - 0s - loss: 0.9775 - val_loss: 0.5965
AUC: 0.8727

Epoch 34/80
 - 0s - loss: 0.9760 - val_loss: 0.6232
AUC: 0.8728

Epoch 35/80
 - 0s - loss: 0.9806 - val_loss: 0.6151
AUC: 0.8730

Epoch 36/80
 - 0s - loss: 0.9802 - val_loss: 0.6114
AUC: 0.8730

Epoch 37/80
 - 0s - loss: 0.9769 - val_loss: 0.6038
AUC: 0.8727

Epoch 38/80
 - 0s - loss: 0.9673 - val_loss: 0.6072
AUC: 0.8723

Epoch 39/80
 - 0s - loss: 0.9756 - val_loss: 0.6128
AUC: 0.8732

Epoch 40/80
 - 0s - loss: 0.9765 - val_loss: 0.5963
AUC: 0.8728

Epoch 41/80
 - 0s - loss: 0.9733 - val_loss: 0.6142
AUC: 0.8729

Epoch 42/80
 - 0s - loss: 0.9693 - val_loss: 0.6096
AUC: 0.8729

Epoch 43/80
 - 0s - loss: 0.9722 - val_loss: 0.5969
AUC: 0.8727

Epoch 44/80
 - 0s - loss: 0.9730 - val_loss: 0.6111
AUC: 0.8728

Epoch 45/80
 - 0s - loss: 0.9714 - val_loss: 0.6011
AUC: 0.8727

Epoch 46/80
 - 0s - loss: 0.9651 - val_loss: 0.5951
AUC: 0.8727

Epoch 47/80
 - 0s - loss: 0.9770 - val_loss: 0.5950
AUC: 0.8727

Epoch 48/80
 - 0s - loss: 0.9712 - val_loss: 0.6130
AUC: 0.8730

Epoch 49/80
 - 0s - loss: 0.9662 - val_loss: 0.6062
AUC: 0.8728

Epoch 50/80
 - 0s - loss: 0.9727 - val_loss: 0.6008
AUC: 0.8727

Epoch 51/80
 - 0s - loss: 0.9681 - val_loss: 0.5974
AUC: 0.8727

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9713 - val_loss: 0.5928
AUC: 0.8728

Epoch 2/30
 - 0s - loss: 0.9747 - val_loss: 0.5934
AUC: 0.8730

Epoch 3/30
 - 0s - loss: 0.9752 - val_loss: 0.5931
AUC: 0.8729

Epoch 4/30
 - 0s - loss: 0.9629 - val_loss: 0.5944
AUC: 0.8728

Epoch 5/30
 - 0s - loss: 0.9598 - val_loss: 0.5785
AUC: 0.8726

Epoch 6/30
 - 0s - loss: 0.9582 - val_loss: 0.6073
AUC: 0.8730

Epoch 7/30
 - 0s - loss: 0.9627 - val_loss: 0.5808
AUC: 0.8728

Epoch 8/30
 - 0s - loss: 0.9592 - val_loss: 0.5873
AUC: 0.8732

Epoch 9/30
 - 0s - loss: 0.9521 - val_loss: 0.6147
AUC: 0.8735

Epoch 10/30
 - 0s - loss: 0.9559 - val_loss: 0.5810
AUC: 0.8730

Epoch 11/30
 - 0s - loss: 0.9587 - val_loss: 0.5898
AUC: 0.8733

Epoch 12/30
 - 0s - loss: 0.9556 - val_loss: 0.6037
AUC: 0.8735

Epoch 13/30
 - 0s - loss: 0.9508 - val_loss: 0.6105
AUC: 0.8734

Epoch 14/30
 - 0s - loss: 0.9504 - val_loss: 0.5838
AUC: 0.8728

Epoch 15/30
 - 0s - loss: 0.9444 - val_loss: 0.5739
AUC: 0.8728

Epoch 16/30
 - 0s - loss: 0.9447 - val_loss: 0.5950
AUC: 0.8730

Epoch 17/30
 - 0s - loss: 0.9515 - val_loss: 0.5769
AUC: 0.8731

Epoch 18/30
 - 0s - loss: 0.9433 - val_loss: 0.5818
AUC: 0.8732

Epoch 19/30
 - 0s - loss: 0.9410 - val_loss: 0.6014
AUC: 0.8734

Epoch 20/30
 - 0s - loss: 0.9461 - val_loss: 0.5710
AUC: 0.8729

Epoch 21/30
 - 0s - loss: 0.9337 - val_loss: 0.5809
AUC: 0.8732

Epoch 22/30
 - 0s - loss: 0.9412 - val_loss: 0.5868
AUC: 0.8731

Epoch 23/30
 - 0s - loss: 0.9405 - val_loss: 0.5932
AUC: 0.8733

Epoch 24/30
 - 0s - loss: 0.9366 - val_loss: 0.5963
AUC: 0.8735

Epoch 25/30
 - 0s - loss: 0.9346 - val_loss: 0.5832
AUC: 0.8735

Epoch 26/30
 - 0s - loss: 0.9321 - val_loss: 0.5842
AUC: 0.8734

Epoch 27/30
 - 0s - loss: 0.9303 - val_loss: 0.5929
AUC: 0.8737

Epoch 28/30
 - 0s - loss: 0.9243 - val_loss: 0.5910
AUC: 0.8735

Epoch 29/30
 - 0s - loss: 0.9214 - val_loss: 0.5655
AUC: 0.8730

Epoch 30/30
 - 0s - loss: 0.9242 - val_loss: 0.5939
Using TensorFlow backend.
AUC: 0.8734

2019-03-08 09:32:18.162246: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:32:18.325113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:32:18.325157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:32:18.615045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:32:18.615109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:32:18.615118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:32:18.615381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2057
Epoch 2/80
 - 2s - loss: 0.3145
Epoch 3/80
 - 2s - loss: 0.2650
Epoch 4/80
 - 2s - loss: 0.2325
Epoch 5/80
 - 2s - loss: 0.2097
Epoch 6/80
 - 2s - loss: 0.1895
Epoch 7/80
 - 2s - loss: 0.1716
Epoch 8/80
 - 2s - loss: 0.1572
Epoch 9/80
 - 2s - loss: 0.1459
Epoch 10/80
 - 2s - loss: 0.1371
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:32:53.438908: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:32:53.600631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:32:53.600675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:32:53.890447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:32:53.890498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:32:53.890507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:32:53.890761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1983
Epoch 2/80
 - 2s - loss: 0.3154
Epoch 3/80
 - 2s - loss: 0.2648
Epoch 4/80
 - 2s - loss: 0.2272
Epoch 5/80
 - 2s - loss: 0.2017
Epoch 6/80
 - 2s - loss: 0.1836
Epoch 7/80
 - 2s - loss: 0.1688
Epoch 8/80
 - 2s - loss: 0.1564
Epoch 9/80
 - 2s - loss: 0.1461
Epoch 10/80
 - 2s - loss: 0.1376
Epoch 11/80
 - 2s - loss: 0.1306
Epoch 12/80
 - 2s - loss: 0.1247
Epoch 13/80
 - 2s - loss: 0.1197
Epoch 14/80
 - 2s - loss: 0.1156
Epoch 15/80
 - 2s - loss: 0.1119
Epoch 16/80
 - 2s - loss: 0.1088
Epoch 17/80
 - 2s - loss: 0.1060
Epoch 18/80
 - 2s - loss: 0.1036
Epoch 19/80
 - 2s - loss: 0.1014
Epoch 20/80
 - 2s - loss: 0.0996
Epoch 21/80
 - 2s - loss: 0.0979
Epoch 22/80
 - 2s - loss: 0.0965
Epoch 23/80
 - 2s - loss: 0.0953
Epoch 24/80
 - 2s - loss: 0.0942
Epoch 25/80
 - 2s - loss: 0.0933
Epoch 26/80
 - 2s - loss: 0.0924
Epoch 27/80
 - 2s - loss: 0.0918
Epoch 28/80
 - 2s - loss: 0.0912
Epoch 29/80
 - 2s - loss: 0.0906
Epoch 30/80
 - 2s - loss: 0.0902
Epoch 31/80
 - 2s - loss: 0.0898
Epoch 32/80
 - 2s - loss: 0.0894
Epoch 33/80
 - 2s - loss: 0.0891
Epoch 34/80
 - 2s - loss: 0.0888
Epoch 35/80
 - 2s - loss: 0.0885
Epoch 36/80
 - 2s - loss: 0.0883
Epoch 37/80
 - 2s - loss: 0.0881
Epoch 38/80
 - 2s - loss: 0.0878
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0875
Epoch 41/80
 - 2s - loss: 0.0874
Epoch 42/80
 - 2s - loss: 0.0872
Epoch 43/80
 - 2s - loss: 0.0870
Epoch 44/80
 - 2s - loss: 0.0870
Epoch 45/80
 - 2s - loss: 0.0868
Epoch 46/80
 - 2s - loss: 0.0867
Epoch 47/80
 - 2s - loss: 0.0866
Epoch 48/80
 - 2s - loss: 0.0865
Epoch 49/80
 - 2s - loss: 0.0864
Epoch 50/80
 - 2s - loss: 0.0863
Epoch 51/80
 - 2s - loss: 0.0862
Epoch 52/80
 - 2s - loss: 0.0862
Epoch 53/80
 - 2s - loss: 0.0861
Epoch 54/80
 - 2s - loss: 0.0860
Epoch 55/80
 - 2s - loss: 0.0860
Epoch 56/80
 - 2s - loss: 0.0859
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0858
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0857
Epoch 61/80
 - 2s - loss: 0.0856
Epoch 62/80
 - 2s - loss: 0.0856
Epoch 63/80
 - 2s - loss: 0.0855
Epoch 64/80
 - 2s - loss: 0.0854
Epoch 65/80
 - 2s - loss: 0.0855
Epoch 66/80
 - 2s - loss: 0.0854
Epoch 67/80
 - 2s - loss: 0.0853
Epoch 68/80
 - 2s - loss: 0.0853
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:35:04.230667: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:35:04.394184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:35:04.394218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:35:04.692184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:35:04.692229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:35:04.692238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:35:04.692491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2158
Epoch 2/80
 - 2s - loss: 0.3143
Epoch 3/80
 - 2s - loss: 0.2669
Epoch 4/80
 - 2s - loss: 0.2296
Epoch 5/80
 - 2s - loss: 0.2028
Epoch 6/80
 - 2s - loss: 0.1830
Epoch 7/80
 - 2s - loss: 0.1677
Epoch 8/80
 - 2s - loss: 0.1555
Epoch 9/80
 - 2s - loss: 0.1453
Epoch 10/80
 - 2s - loss: 0.1369
Epoch 11/80
 - 2s - loss: 0.1301
Epoch 12/80
 - 2s - loss: 0.1245
Epoch 13/80
 - 2s - loss: 0.1197
Epoch 14/80
 - 2s - loss: 0.1156
Epoch 15/80
 - 2s - loss: 0.1120
Epoch 16/80
 - 2s - loss: 0.1088
Epoch 17/80
 - 2s - loss: 0.1060
Epoch 18/80
 - 2s - loss: 0.1035
Epoch 19/80
 - 2s - loss: 0.1014
Epoch 20/80
 - 2s - loss: 0.0995
Epoch 21/80
 - 2s - loss: 0.0978
Epoch 22/80
 - 2s - loss: 0.0965
Epoch 23/80
 - 2s - loss: 0.0952
Epoch 24/80
 - 2s - loss: 0.0942
Epoch 25/80
 - 2s - loss: 0.0933
Epoch 26/80
 - 2s - loss: 0.0925
Epoch 27/80
 - 2s - loss: 0.0919
Epoch 28/80
 - 2s - loss: 0.0913
Epoch 29/80
 - 2s - loss: 0.0908
Epoch 30/80
 - 2s - loss: 0.0903
Epoch 31/80
 - 2s - loss: 0.0899
Epoch 32/80
 - 2s - loss: 0.0896
Epoch 33/80
 - 2s - loss: 0.0893
Epoch 34/80
 - 2s - loss: 0.0890
Epoch 35/80
 - 2s - loss: 0.0887
Epoch 36/80
 - 2s - loss: 0.0885
Epoch 37/80
 - 2s - loss: 0.0883
Epoch 38/80
 - 2s - loss: 0.0881
Epoch 39/80
 - 2s - loss: 0.0879
Epoch 40/80
 - 2s - loss: 0.0878
Epoch 41/80
 - 2s - loss: 0.0876
Epoch 42/80
 - 2s - loss: 0.0874
Epoch 43/80
 - 2s - loss: 0.0873
Epoch 44/80
 - 2s - loss: 0.0872
Epoch 45/80
 - 2s - loss: 0.0871
Epoch 46/80
 - 2s - loss: 0.0870
Epoch 47/80
 - 2s - loss: 0.0869
Epoch 48/80
 - 2s - loss: 0.0868
Epoch 49/80
 - 2s - loss: 0.0867
Epoch 50/80
 - 2s - loss: 0.0866
Epoch 51/80
 - 2s - loss: 0.0865
Epoch 52/80
 - 2s - loss: 0.0865
Epoch 53/80
 - 2s - loss: 0.0864
Epoch 54/80
 - 2s - loss: 0.0863
Epoch 55/80
 - 2s - loss: 0.0862
Epoch 56/80
 - 2s - loss: 0.0862
Epoch 57/80
 - 2s - loss: 0.0861
Epoch 58/80
 - 2s - loss: 0.0861
Epoch 59/80
 - 2s - loss: 0.0860
Epoch 60/80
 - 2s - loss: 0.0859
Epoch 61/80
 - 2s - loss: 0.0859
Epoch 62/80
 - 2s - loss: 0.0859
Epoch 63/80
 - 2s - loss: 0.0859
Epoch 64/80
 - 2s - loss: 0.0825
Epoch 65/80
 - 2s - loss: 0.0822
Epoch 66/80
 - 2s - loss: 0.0821
Epoch 67/80
 - 2s - loss: 0.0821
Epoch 68/80
 - 2s - loss: 0.0821
Epoch 69/80
 - 2s - loss: 0.0813
Epoch 70/80
 - 2s - loss: 0.0813
Epoch 71/80
 - 2s - loss: 0.0813
Epoch 72/80
 - 2s - loss: 0.0813
Epoch 73/80
 - 2s - loss: 0.0811
Epoch 74/80
 - 2s - loss: 0.0811
Epoch 75/80
 - 2s - loss: 0.0811
Epoch 76/80
 - 2s - loss: 0.0811
Epoch 77/80
 - 2s - loss: 0.0811
Epoch 78/80
 - 2s - loss: 0.0811
Epoch 79/80
 - 2s - loss: 0.0811
Epoch 80/80
 - 2s - loss: 0.0810
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.6688 - val_loss: 0.9941
AUC: 0.7919

Epoch 2/80
 - 0s - loss: 1.3744 - val_loss: 0.7138
AUC: 0.8169

Epoch 3/80
 - 0s - loss: 1.1883 - val_loss: 0.6936
AUC: 0.8384

Epoch 4/80
 - 0s - loss: 1.1513 - val_loss: 0.6926
AUC: 0.8474

Epoch 5/80
 - 0s - loss: 1.1142 - val_loss: 0.6645
AUC: 0.8507

Epoch 6/80
 - 0s - loss: 1.0860 - val_loss: 0.7002
AUC: 0.8552

Epoch 7/80
 - 0s - loss: 1.0819 - val_loss: 0.6445
AUC: 0.8578

Epoch 8/80
 - 0s - loss: 1.0650 - val_loss: 0.6660
AUC: 0.8583

Epoch 9/80
 - 0s - loss: 1.0467 - val_loss: 0.6494
AUC: 0.8608

Epoch 10/80
 - 0s - loss: 1.0437 - val_loss: 0.5753
AUC: 0.8603

Epoch 11/80
 - 0s - loss: 1.0274 - val_loss: 0.6006
AUC: 0.8613

Epoch 12/80
 - 0s - loss: 1.0303 - val_loss: 0.6777
AUC: 0.8641

Epoch 13/80
 - 0s - loss: 1.0266 - val_loss: 0.5990
AUC: 0.8602

Epoch 14/80
 - 0s - loss: 1.0255 - val_loss: 0.6533
AUC: 0.8642

Epoch 15/80
 - 0s - loss: 1.0203 - val_loss: 0.5973
AUC: 0.8651

Epoch 16/80
 - 0s - loss: 1.0172 - val_loss: 0.5972
AUC: 0.8648

Epoch 17/80
 - 0s - loss: 1.0173 - val_loss: 0.6281
AUC: 0.8650

Epoch 18/80
 - 0s - loss: 1.0000 - val_loss: 0.7069
AUC: 0.8658

Epoch 19/80
 - 0s - loss: 1.0045 - val_loss: 0.5667
AUC: 0.8649

Epoch 20/80
 - 0s - loss: 1.0051 - val_loss: 0.6464
AUC: 0.8681

Epoch 21/80
 - 0s - loss: 0.9957 - val_loss: 0.5720
AUC: 0.8670

Epoch 22/80
 - 0s - loss: 0.9876 - val_loss: 0.6371
AUC: 0.8676

Epoch 23/80
 - 0s - loss: 0.9885 - val_loss: 0.6452
AUC: 0.8679

Epoch 24/80
 - 0s - loss: 0.9895 - val_loss: 0.6542
AUC: 0.8672

Epoch 25/80
 - 0s - loss: 0.9817 - val_loss: 0.5797
AUC: 0.8657

Epoch 26/80
 - 0s - loss: 0.9805 - val_loss: 0.6173
AUC: 0.8682

Epoch 27/80
 - 0s - loss: 0.9782 - val_loss: 0.6159
AUC: 0.8681

Epoch 28/80
 - 0s - loss: 0.9740 - val_loss: 0.5689
AUC: 0.8686

Epoch 29/80
 - 0s - loss: 0.9661 - val_loss: 0.5957
AUC: 0.8678

Epoch 30/80
 - 0s - loss: 0.9603 - val_loss: 0.6034
AUC: 0.8685

Epoch 31/80
 - 0s - loss: 0.9503 - val_loss: 0.5718
AUC: 0.8680

Epoch 32/80
 - 0s - loss: 0.9474 - val_loss: 0.6230
AUC: 0.8689

Epoch 33/80
 - 0s - loss: 0.9548 - val_loss: 0.6035
AUC: 0.8685

Epoch 34/80
 - 0s - loss: 0.9488 - val_loss: 0.6095
AUC: 0.8688

Epoch 35/80
 - 0s - loss: 0.9531 - val_loss: 0.5995
AUC: 0.8686

Epoch 36/80
 - 0s - loss: 0.9471 - val_loss: 0.5998
AUC: 0.8691

Epoch 37/80
 - 0s - loss: 0.9504 - val_loss: 0.5980
AUC: 0.8692

Epoch 38/80
 - 0s - loss: 0.9475 - val_loss: 0.5976
AUC: 0.8687

Epoch 39/80
 - 0s - loss: 0.9498 - val_loss: 0.6132
AUC: 0.8690

Epoch 40/80
 - 0s - loss: 0.9447 - val_loss: 0.6021
AUC: 0.8689

Epoch 41/80
 - 0s - loss: 0.9465 - val_loss: 0.5923
AUC: 0.8688

Epoch 42/80
 - 0s - loss: 0.9457 - val_loss: 0.5900
AUC: 0.8688

Epoch 43/80
 - 0s - loss: 0.9418 - val_loss: 0.5926
AUC: 0.8689

Epoch 44/80
 - 0s - loss: 0.9423 - val_loss: 0.5794
AUC: 0.8689

Epoch 45/80
 - 0s - loss: 0.9488 - val_loss: 0.5973
AUC: 0.8691

Epoch 46/80
 - 0s - loss: 0.9469 - val_loss: 0.5864
AUC: 0.8689

Epoch 47/80
 - 0s - loss: 0.9437 - val_loss: 0.6038
AUC: 0.8691

Epoch 48/80
 - 0s - loss: 0.9410 - val_loss: 0.5871
AUC: 0.8690

Epoch 49/80
 - 0s - loss: 0.9398 - val_loss: 0.5867
AUC: 0.8690

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9514 - val_loss: 0.5710
AUC: 0.8688

Epoch 2/30
 - 0s - loss: 0.9425 - val_loss: 0.5744
AUC: 0.8688

Epoch 3/30
 - 0s - loss: 0.9436 - val_loss: 0.6202
AUC: 0.8692

Epoch 4/30
 - 0s - loss: 0.9408 - val_loss: 0.6181
AUC: 0.8693

Epoch 5/30
 - 0s - loss: 0.9454 - val_loss: 0.6178
AUC: 0.8693

Epoch 6/30
 - 0s - loss: 0.9363 - val_loss: 0.5816
AUC: 0.8692

Epoch 7/30
 - 0s - loss: 0.9365 - val_loss: 0.5864
AUC: 0.8693

Epoch 8/30
 - 0s - loss: 0.9325 - val_loss: 0.5756
AUC: 0.8691

Epoch 9/30
 - 0s - loss: 0.9421 - val_loss: 0.6069
AUC: 0.8693

Epoch 10/30
 - 0s - loss: 0.9303 - val_loss: 0.5887
AUC: 0.8694

Epoch 11/30
 - 0s - loss: 0.9303 - val_loss: 0.5912
AUC: 0.8693

Epoch 12/30
 - 0s - loss: 0.9260 - val_loss: 0.5864
AUC: 0.8693

Epoch 13/30
 - 0s - loss: 0.9267 - val_loss: 0.5830
AUC: 0.8693

Epoch 14/30
 - 0s - loss: 0.9296 - val_loss: 0.5879
AUC: 0.8694

Epoch 15/30
 - 0s - loss: 0.9239 - val_loss: 0.5843
AUC: 0.8694

Epoch 16/30
 - 0s - loss: 0.9277 - val_loss: 0.5850
AUC: 0.8694

Epoch 17/30
 - 0s - loss: 0.9271 - val_loss: 0.5810
AUC: 0.8693

Epoch 18/30
 - 0s - loss: 0.9280 - val_loss: 0.5829
AUC: 0.8693

Epoch 19/30
 - 0s - loss: 0.9279 - val_loss: 0.5859
AUC: 0.8694

Epoch 20/30
 - 0s - loss: 0.9278 - val_loss: 0.5795
AUC: 0.8694

Epoch 21/30
 - 0s - loss: 0.9293 - val_loss: 0.5865
AUC: 0.8694

Epoch 22/30
 - 0s - loss: 0.9241 - val_loss: 0.5856
AUC: 0.8694

Epoch 23/30
 - 0s - loss: 0.9243 - val_loss: 0.5857
AUC: 0.8694

Epoch 24/30
 - 0s - loss: 0.9231 - val_loss: 0.5847
AUC: 0.8694

Epoch 25/30
 - 0s - loss: 0.9208 - val_loss: 0.5840
AUC: 0.8693

Epoch 26/30
 - 0s - loss: 0.9237 - val_loss: 0.5830
AUC: 0.8694

Epoch 27/30
 - 0s - loss: 0.9142 - val_loss: 0.5832
AUC: 0.8693

Epoch 28/30
 - 0s - loss: 0.9260 - val_loss: 0.5837
AUC: 0.8694

Epoch 29/30
 - 0s - loss: 0.9213 - val_loss: 0.5836
AUC: 0.8694

Epoch 30/30
 - 0s - loss: 0.9181 - val_loss: 0.5822
Using TensorFlow backend.
AUC: 0.8693

2019-03-08 09:38:29.205091: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:38:29.370461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:38:29.370504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:38:29.662948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:38:29.662998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:38:29.663007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:38:29.663268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0099
Epoch 2/80
 - 2s - loss: 0.1834
Epoch 3/80
 - 2s - loss: 0.1608
Epoch 4/80
 - 2s - loss: 0.1409
Epoch 5/80
 - 2s - loss: 0.1228
Epoch 6/80
 - 2s - loss: 0.1087
Epoch 7/80
 - 2s - loss: 0.0964
Epoch 8/80
 - 2s - loss: 0.0860
Epoch 9/80
 - 2s - loss: 0.0776
Epoch 10/80
 - 2s - loss: 0.0708
Epoch 11/80
 - 2s - loss: 0.0655
Epoch 12/80
 - 2s - loss: 0.0614
Epoch 13/80
 - 2s - loss: 0.0580
Epoch 14/80
 - 2s - loss: 0.0553
Epoch 15/80
 - 2s - loss: 0.0529
Epoch 16/80
 - 2s - loss: 0.0508
Epoch 17/80
 - 2s - loss: 0.0491
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0461
Epoch 20/80
 - 2s - loss: 0.0450
Epoch 21/80
 - 2s - loss: 0.0439
Epoch 22/80
 - 2s - loss: 0.0430
Epoch 23/80
 - 2s - loss: 0.0422
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0405
Epoch 27/80
 - 2s - loss: 0.0400
Epoch 28/80
 - 2s - loss: 0.0396
Epoch 29/80
 - 2s - loss: 0.0393
Epoch 30/80
 - 2s - loss: 0.0390
Epoch 31/80
 - 2s - loss: 0.0387
Epoch 32/80
 - 2s - loss: 0.0385
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0381
Epoch 35/80
 - 2s - loss: 0.0380
Epoch 36/80
 - 2s - loss: 0.0378
Epoch 37/80
 - 2s - loss: 0.0377
Epoch 38/80
 - 2s - loss: 0.0375
Epoch 39/80
 - 2s - loss: 0.0374
Epoch 40/80
 - 2s - loss: 0.0373
Epoch 41/80
 - 2s - loss: 0.0372
Epoch 42/80
 - 2s - loss: 0.0371
Epoch 43/80
 - 2s - loss: 0.0371
Epoch 44/80
 - 2s - loss: 0.0370
Epoch 45/80
 - 2s - loss: 0.0369
Epoch 46/80
 - 2s - loss: 0.0368
Epoch 47/80
 - 2s - loss: 0.0368
Epoch 48/80
 - 2s - loss: 0.0367
Epoch 49/80
 - 2s - loss: 0.0367
Epoch 50/80
 - 2s - loss: 0.0366
Epoch 51/80
 - 2s - loss: 0.0366
Epoch 52/80
 - 2s - loss: 0.0365
Epoch 53/80
 - 2s - loss: 0.0365
Epoch 54/80
 - 2s - loss: 0.0364
Epoch 55/80
 - 2s - loss: 0.0364
Epoch 56/80
 - 2s - loss: 0.0364
Epoch 57/80
 - 2s - loss: 0.0364
Epoch 58/80
 - 2s - loss: 0.0363
Epoch 59/80
 - 2s - loss: 0.0348
Epoch 60/80
 - 2s - loss: 0.0346
Epoch 61/80
 - 2s - loss: 0.0346
Epoch 62/80
 - 2s - loss: 0.0346
Epoch 63/80
 - 2s - loss: 0.0346
Epoch 64/80
 - 2s - loss: 0.0343
Epoch 65/80
 - 2s - loss: 0.0342
Epoch 66/80
 - 2s - loss: 0.0342
Epoch 67/80
 - 2s - loss: 0.0342
Epoch 68/80
 - 2s - loss: 0.0341
Epoch 69/80
 - 2s - loss: 0.0341
Epoch 70/80
 - 2s - loss: 0.0341
Epoch 71/80
 - 2s - loss: 0.0341
Epoch 72/80
 - 2s - loss: 0.0341
Epoch 73/80
 - 2s - loss: 0.0341
Epoch 74/80
 - 2s - loss: 0.0341
Epoch 75/80
 - 2s - loss: 0.0341
Epoch 76/80
 - 2s - loss: 0.0341
Epoch 77/80
 - 2s - loss: 0.0341
Epoch 78/80
 - 2s - loss: 0.0341
Epoch 79/80
 - 2s - loss: 0.0341
Epoch 80/80
 - 2s - loss: 0.0341
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.9581 - val_loss: 0.8067
AUC: 0.8018

Epoch 2/80
 - 0s - loss: 1.3547 - val_loss: 0.7416
AUC: 0.8288

Epoch 3/80
 - 0s - loss: 1.1564 - val_loss: 0.6958
AUC: 0.8421

Epoch 4/80
 - 0s - loss: 1.1266 - val_loss: 0.6771
AUC: 0.8469

Epoch 5/80
 - 0s - loss: 1.0857 - val_loss: 0.6700
AUC: 0.8543

Epoch 6/80
 - 0s - loss: 1.0768 - val_loss: 0.6157
AUC: 0.8554

Epoch 7/80
 - 0s - loss: 1.0570 - val_loss: 0.6555
AUC: 0.8581

Epoch 8/80
 - 0s - loss: 1.0642 - val_loss: 0.6753
AUC: 0.8599

Epoch 9/80
 - 0s - loss: 1.0379 - val_loss: 0.5702
AUC: 0.8581

Epoch 10/80
 - 0s - loss: 1.0319 - val_loss: 0.6274
AUC: 0.8614

Epoch 11/80
 - 0s - loss: 1.0275 - val_loss: 0.5959
AUC: 0.8625

Epoch 12/80
 - 0s - loss: 1.0196 - val_loss: 0.6154
AUC: 0.8613

Epoch 13/80
 - 0s - loss: 1.0100 - val_loss: 0.6522
AUC: 0.8624

Epoch 14/80
 - 0s - loss: 1.0068 - val_loss: 0.5972
AUC: 0.8634

Epoch 15/80
 - 0s - loss: 1.0088 - val_loss: 0.6167
AUC: 0.8638

Epoch 16/80
 - 0s - loss: 0.9991 - val_loss: 0.6679
AUC: 0.8647

Epoch 17/80
 - 0s - loss: 0.9895 - val_loss: 0.6770
AUC: 0.8657

Epoch 18/80
 - 0s - loss: 0.9941 - val_loss: 0.6138
AUC: 0.8640

Epoch 19/80
 - 0s - loss: 0.9896 - val_loss: 0.5960
AUC: 0.8640

Epoch 20/80
 - 0s - loss: 0.9723 - val_loss: 0.6021
AUC: 0.8653

Epoch 21/80
 - 0s - loss: 0.9749 - val_loss: 0.6212
AUC: 0.8662

Epoch 22/80
 - 0s - loss: 0.9651 - val_loss: 0.5903
AUC: 0.8651

Epoch 23/80
 - 0s - loss: 0.9714 - val_loss: 0.5969
AUC: 0.8661

Epoch 24/80
 - 0s - loss: 0.9672 - val_loss: 0.6047
AUC: 0.8660

Epoch 25/80
 - 0s - loss: 0.9643 - val_loss: 0.5956
AUC: 0.8660

Epoch 26/80
 - 0s - loss: 0.9638 - val_loss: 0.6102
AUC: 0.8660

Epoch 27/80
 - 0s - loss: 0.9620 - val_loss: 0.5999
AUC: 0.8665

Epoch 28/80
 - 0s - loss: 0.9600 - val_loss: 0.5798
AUC: 0.8657

Epoch 29/80
 - 0s - loss: 0.9556 - val_loss: 0.5522
AUC: 0.8645

Epoch 30/80
 - 0s - loss: 0.9610 - val_loss: 0.6091
AUC: 0.8665

Epoch 31/80
 - 0s - loss: 0.9560 - val_loss: 0.6202
AUC: 0.8665

Epoch 32/80
 - 0s - loss: 0.9544 - val_loss: 0.5750
AUC: 0.8653

Epoch 33/80
 - 0s - loss: 0.9550 - val_loss: 0.5976
AUC: 0.8661

Epoch 34/80
 - 0s - loss: 0.9566 - val_loss: 0.5876
AUC: 0.8662

Epoch 35/80
 - 0s - loss: 0.9529 - val_loss: 0.6045
AUC: 0.8667

Epoch 36/80
 - 0s - loss: 0.9564 - val_loss: 0.5864
AUC: 0.8659

Epoch 37/80
 - 0s - loss: 0.9477 - val_loss: 0.6130
AUC: 0.8665

Epoch 38/80
 - 0s - loss: 0.9496 - val_loss: 0.5853
AUC: 0.8656

Epoch 39/80
 - 0s - loss: 0.9550 - val_loss: 0.5677
AUC: 0.8653

Epoch 40/80
 - 0s - loss: 0.9390 - val_loss: 0.6046
AUC: 0.8662

Epoch 41/80
 - 0s - loss: 0.9438 - val_loss: 0.5952
AUC: 0.8659

Epoch 42/80
 - 0s - loss: 0.9480 - val_loss: 0.6041
AUC: 0.8664

Epoch 43/80
 - 0s - loss: 0.9475 - val_loss: 0.6022
AUC: 0.8663

Epoch 44/80
 - 0s - loss: 0.9481 - val_loss: 0.6001
AUC: 0.8661

Epoch 45/80
 - 0s - loss: 0.9412 - val_loss: 0.6081
AUC: 0.8665

Epoch 46/80
 - 0s - loss: 0.9442 - val_loss: 0.6005
AUC: 0.8662

Epoch 47/80
 - 0s - loss: 0.9482 - val_loss: 0.6142
AUC: 0.8664

Epoch 48/80
 - 0s - loss: 0.9449 - val_loss: 0.5869
AUC: 0.8657

Epoch 49/80
 - 0s - loss: 0.9437 - val_loss: 0.5923
AUC: 0.8659

Epoch 50/80
 - 0s - loss: 0.9387 - val_loss: 0.5977
AUC: 0.8660

Epoch 51/80
 - 0s - loss: 0.9432 - val_loss: 0.5973
AUC: 0.8661

Epoch 52/80
 - 0s - loss: 0.9474 - val_loss: 0.5951
AUC: 0.8660

Epoch 53/80
 - 0s - loss: 0.9455 - val_loss: 0.5951
AUC: 0.8660

Epoch 54/80
 - 0s - loss: 0.9426 - val_loss: 0.5958
AUC: 0.8660

Epoch 55/80
 - 0s - loss: 0.9399 - val_loss: 0.5951
AUC: 0.8660

Epoch 56/80
 - 0s - loss: 0.9426 - val_loss: 0.5958
AUC: 0.8660

Epoch 57/80
 - 0s - loss: 0.9393 - val_loss: 0.5957
AUC: 0.8660

Epoch 58/80
 - 0s - loss: 0.9434 - val_loss: 0.5952
AUC: 0.8660

Epoch 59/80
 - 0s - loss: 0.9440 - val_loss: 0.5990
AUC: 0.8661

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9479 - val_loss: 0.5967
AUC: 0.8663

Epoch 2/30
 - 0s - loss: 0.9517 - val_loss: 0.6212
AUC: 0.8671

Epoch 3/30
 - 0s - loss: 0.9484 - val_loss: 0.5881
AUC: 0.8661

Epoch 4/30
 - 0s - loss: 0.9442 - val_loss: 0.6076
AUC: 0.8665

Epoch 5/30
 - 0s - loss: 0.9454 - val_loss: 0.5718
AUC: 0.8653

Epoch 6/30
 - 0s - loss: 0.9445 - val_loss: 0.5873
AUC: 0.8660

Epoch 7/30
 - 0s - loss: 0.9394 - val_loss: 0.5895
AUC: 0.8660

Epoch 8/30
 - 0s - loss: 0.9360 - val_loss: 0.6260
AUC: 0.8671

Epoch 9/30
 - 0s - loss: 0.9360 - val_loss: 0.6020
AUC: 0.8664

Epoch 10/30
 - 0s - loss: 0.9388 - val_loss: 0.6102
AUC: 0.8670

Epoch 11/30
 - 0s - loss: 0.9340 - val_loss: 0.6137
AUC: 0.8673

Epoch 12/30
 - 0s - loss: 0.9303 - val_loss: 0.5940
AUC: 0.8667

Epoch 13/30
 - 0s - loss: 0.9316 - val_loss: 0.5895
AUC: 0.8665

Epoch 14/30
 - 0s - loss: 0.9253 - val_loss: 0.5814
AUC: 0.8664

Epoch 15/30
 - 0s - loss: 0.9344 - val_loss: 0.5740
AUC: 0.8661

Epoch 16/30
 - 0s - loss: 0.9221 - val_loss: 0.5867
AUC: 0.8665

Epoch 17/30
 - 0s - loss: 0.9212 - val_loss: 0.5934
AUC: 0.8667

Epoch 18/30
 - 0s - loss: 0.9253 - val_loss: 0.5894
AUC: 0.8665

Epoch 19/30
 - 0s - loss: 0.9271 - val_loss: 0.5848
AUC: 0.8663

Epoch 20/30
 - 0s - loss: 0.9250 - val_loss: 0.5933
AUC: 0.8666

Epoch 21/30
 - 0s - loss: 0.9201 - val_loss: 0.5893
AUC: 0.8666

Epoch 22/30
 - 0s - loss: 0.9272 - val_loss: 0.5881
AUC: 0.8665

Epoch 23/30
 - 0s - loss: 0.9227 - val_loss: 0.5854
AUC: 0.8664

Epoch 24/30
 - 0s - loss: 0.9234 - val_loss: 0.5867
AUC: 0.8665

Epoch 25/30
 - 0s - loss: 0.9213 - val_loss: 0.5920
AUC: 0.8666

Epoch 26/30
 - 0s - loss: 0.9201 - val_loss: 0.5903
AUC: 0.8666

Epoch 27/30
 - 0s - loss: 0.9225 - val_loss: 0.5901
AUC: 0.8666

Epoch 28/30
 - 0s - loss: 0.9210 - val_loss: 0.5901
AUC: 0.8666

Epoch 29/30
 - 0s - loss: 0.9163 - val_loss: 0.5883
AUC: 0.8665

Epoch 30/30
 - 0s - loss: 0.9246 - val_loss: 0.5890
Using TensorFlow backend.
AUC: 0.8665

2019-03-08 09:42:00.157125: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:42:00.319124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:42:00.319188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:42:00.611468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:42:00.611519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:42:00.611528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:42:00.611793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0079
Epoch 2/80
 - 2s - loss: 0.1832
Epoch 3/80
 - 2s - loss: 0.1524
Epoch 4/80
 - 2s - loss: 0.1279
Epoch 5/80
 - 2s - loss: 0.1114
Epoch 6/80
 - 2s - loss: 0.0994
Epoch 7/80
 - 2s - loss: 0.0898
Epoch 8/80
 - 2s - loss: 0.0819
Epoch 9/80
 - 2s - loss: 0.0752
Epoch 10/80
 - 2s - loss: 0.0697
Epoch 11/80
 - 2s - loss: 0.0651
Epoch 12/80
 - 2s - loss: 0.0611
Epoch 13/80
 - 2s - loss: 0.0578
Epoch 14/80
 - 2s - loss: 0.0550
Epoch 15/80
 - 2s - loss: 0.0527
Epoch 16/80
 - 2s - loss: 0.0507
Epoch 17/80
 - 2s - loss: 0.0490
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0462
Epoch 20/80
 - 2s - loss: 0.0450
Epoch 21/80
 - 2s - loss: 0.0441
Epoch 22/80
 - 2s - loss: 0.0432
Epoch 23/80
 - 2s - loss: 0.0425
Epoch 24/80
 - 2s - loss: 0.0418
Epoch 25/80
 - 2s - loss: 0.0412
Epoch 26/80
 - 2s - loss: 0.0407
Epoch 27/80
 - 2s - loss: 0.0403
Epoch 28/80
 - 2s - loss: 0.0399
Epoch 29/80
 - 2s - loss: 0.0395
Epoch 30/80
 - 2s - loss: 0.0392
Epoch 31/80
 - 2s - loss: 0.0389
Epoch 32/80
 - 2s - loss: 0.0387
Epoch 33/80
 - 2s - loss: 0.0385
Epoch 34/80
 - 2s - loss: 0.0383
Epoch 35/80
 - 2s - loss: 0.0381
Epoch 36/80
 - 2s - loss: 0.0380
Epoch 37/80
 - 2s - loss: 0.0378
Epoch 38/80
 - 2s - loss: 0.0377
Epoch 39/80
 - 2s - loss: 0.0376
Epoch 40/80
 - 2s - loss: 0.0375
Epoch 41/80
 - 2s - loss: 0.0374
Epoch 42/80
 - 2s - loss: 0.0373
Epoch 43/80
 - 2s - loss: 0.0372
Epoch 44/80
 - 2s - loss: 0.0371
Epoch 45/80
 - 2s - loss: 0.0371
Epoch 46/80
 - 2s - loss: 0.0370
Epoch 47/80
 - 2s - loss: 0.0369
Epoch 48/80
 - 2s - loss: 0.0369
Epoch 49/80
 - 2s - loss: 0.0368
Epoch 50/80
 - 2s - loss: 0.0368
Epoch 51/80
 - 2s - loss: 0.0367
Epoch 52/80
 - 2s - loss: 0.0367
Epoch 53/80
 - 2s - loss: 0.0366
Epoch 54/80
 - 2s - loss: 0.0366
Epoch 55/80
 - 2s - loss: 0.0366
Epoch 56/80
 - 2s - loss: 0.0365
Epoch 57/80
 - 2s - loss: 0.0365
Epoch 58/80
 - 2s - loss: 0.0365
Epoch 59/80
 - 2s - loss: 0.0349
Epoch 60/80
 - 2s - loss: 0.0348
Epoch 61/80
 - 2s - loss: 0.0348
Epoch 62/80
 - 2s - loss: 0.0348
Epoch 63/80
 - 2s - loss: 0.0348
Epoch 64/80
 - 2s - loss: 0.0344
Epoch 65/80
 - 2s - loss: 0.0344
Epoch 66/80
 - 2s - loss: 0.0344
Epoch 67/80
 - 2s - loss: 0.0344
Epoch 68/80
 - 2s - loss: 0.0343
Epoch 69/80
 - 2s - loss: 0.0343
Epoch 70/80
 - 2s - loss: 0.0343
Epoch 71/80
 - 2s - loss: 0.0343
Epoch 72/80
 - 2s - loss: 0.0343
Epoch 73/80
 - 2s - loss: 0.0343
Epoch 74/80
 - 2s - loss: 0.0343
Epoch 75/80
 - 2s - loss: 0.0343
Epoch 76/80
 - 2s - loss: 0.0343
Epoch 77/80
 - 2s - loss: 0.0343
Epoch 78/80
 - 2s - loss: 0.0343
Epoch 79/80
 - 2s - loss: 0.0343
Epoch 80/80
 - 2s - loss: 0.0343
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 1.8773 - val_loss: 0.7498
AUC: 0.8226

Epoch 2/80
 - 0s - loss: 1.2314 - val_loss: 0.6712
AUC: 0.8395

Epoch 3/80
 - 0s - loss: 1.1485 - val_loss: 0.6779
AUC: 0.8567

Epoch 4/80
 - 0s - loss: 1.1119 - val_loss: 0.6639
AUC: 0.8613

Epoch 5/80
 - 0s - loss: 1.0866 - val_loss: 0.6401
AUC: 0.8641

Epoch 6/80
 - 0s - loss: 1.0713 - val_loss: 0.6264
AUC: 0.8667

Epoch 7/80
 - 0s - loss: 1.0606 - val_loss: 0.6713
AUC: 0.8701

Epoch 8/80
 - 0s - loss: 1.0473 - val_loss: 0.6266
AUC: 0.8699

Epoch 9/80
 - 0s - loss: 1.0373 - val_loss: 0.6222
AUC: 0.8713

Epoch 10/80
 - 0s - loss: 1.0310 - val_loss: 0.5826
AUC: 0.8708

Epoch 11/80
 - 0s - loss: 1.0215 - val_loss: 0.5838
AUC: 0.8724

Epoch 12/80
 - 0s - loss: 1.0262 - val_loss: 0.7011
AUC: 0.8752

Epoch 13/80
 - 0s - loss: 1.0149 - val_loss: 0.5979
AUC: 0.8748

Epoch 14/80
 - 0s - loss: 1.0152 - val_loss: 0.6659
AUC: 0.8761

Epoch 15/80
 - 0s - loss: 1.0079 - val_loss: 0.6490
AUC: 0.8752

Epoch 16/80
 - 0s - loss: 1.0043 - val_loss: 0.6235
AUC: 0.8766

Epoch 17/80
 - 0s - loss: 0.9944 - val_loss: 0.5938
AUC: 0.8760

Epoch 18/80
 - 0s - loss: 0.9890 - val_loss: 0.6112
AUC: 0.8769

Epoch 19/80
 - 0s - loss: 0.9932 - val_loss: 0.6201
AUC: 0.8780

Epoch 20/80
 - 0s - loss: 0.9898 - val_loss: 0.5936
AUC: 0.8777

Epoch 21/80
 - 0s - loss: 0.9757 - val_loss: 0.5736
AUC: 0.8778

Epoch 22/80
 - 0s - loss: 0.9691 - val_loss: 0.5964
AUC: 0.8783

Epoch 23/80
 - 0s - loss: 0.9755 - val_loss: 0.5767
AUC: 0.8779

Epoch 24/80
 - 0s - loss: 0.9734 - val_loss: 0.6032
AUC: 0.8783

Epoch 25/80
 - 0s - loss: 0.9726 - val_loss: 0.6060
AUC: 0.8788

Epoch 26/80
 - 0s - loss: 0.9696 - val_loss: 0.6367
AUC: 0.8789

Epoch 27/80
 - 0s - loss: 0.9715 - val_loss: 0.6156
AUC: 0.8789

Epoch 28/80
 - 0s - loss: 0.9660 - val_loss: 0.5862
AUC: 0.8786

Epoch 29/80
 - 0s - loss: 0.9672 - val_loss: 0.5922
AUC: 0.8786

Epoch 30/80
 - 0s - loss: 0.9615 - val_loss: 0.5839
AUC: 0.8787

Epoch 31/80
 - 0s - loss: 0.9629 - val_loss: 0.6199
AUC: 0.8788

Epoch 32/80
 - 0s - loss: 0.9605 - val_loss: 0.5896
AUC: 0.8786

Epoch 33/80
 - 0s - loss: 0.9657 - val_loss: 0.5946
AUC: 0.8786

Epoch 34/80
 - 0s - loss: 0.9635 - val_loss: 0.5879
AUC: 0.8786

Epoch 35/80
 - 0s - loss: 0.9618 - val_loss: 0.5849
AUC: 0.8786

Epoch 36/80
 - 0s - loss: 0.9585 - val_loss: 0.5892
AUC: 0.8788

Epoch 37/80
 - 0s - loss: 0.9581 - val_loss: 0.5888
AUC: 0.8788

Epoch 38/80
 - 0s - loss: 0.9582 - val_loss: 0.5879
AUC: 0.8788

Epoch 39/80
 - 0s - loss: 0.9620 - val_loss: 0.5964
AUC: 0.8789

Epoch 40/80
 - 0s - loss: 0.9578 - val_loss: 0.5918
AUC: 0.8789

Epoch 41/80
 - 0s - loss: 0.9599 - val_loss: 0.5938
AUC: 0.8789

Epoch 42/80
 - 0s - loss: 0.9586 - val_loss: 0.5924
AUC: 0.8789

Epoch 43/80
 - 0s - loss: 0.9601 - val_loss: 0.5911
AUC: 0.8789

Epoch 44/80
 - 0s - loss: 0.9642 - val_loss: 0.5907
AUC: 0.8789

Epoch 45/80
 - 0s - loss: 0.9543 - val_loss: 0.5914
AUC: 0.8789

Epoch 46/80
 - 0s - loss: 0.9565 - val_loss: 0.5904
AUC: 0.8789

Epoch 47/80
 - 0s - loss: 0.9616 - val_loss: 0.5901
AUC: 0.8789

Epoch 48/80
 - 0s - loss: 0.9572 - val_loss: 0.5931
AUC: 0.8789

Epoch 49/80
 - 0s - loss: 0.9640 - val_loss: 0.5932
AUC: 0.8790

Epoch 50/80
 - 0s - loss: 0.9603 - val_loss: 0.5919
AUC: 0.8790

Epoch 51/80
 - 0s - loss: 0.9551 - val_loss: 0.5905
AUC: 0.8789

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9613 - val_loss: 0.5676
AUC: 0.8787

Epoch 2/30
 - 0s - loss: 0.9568 - val_loss: 0.5826
AUC: 0.8792

Epoch 3/30
 - 0s - loss: 0.9590 - val_loss: 0.5957
AUC: 0.8792

Epoch 4/30
 - 0s - loss: 0.9552 - val_loss: 0.5917
AUC: 0.8795

Epoch 5/30
 - 0s - loss: 0.9568 - val_loss: 0.6000
AUC: 0.8795

Epoch 6/30
 - 0s - loss: 0.9528 - val_loss: 0.5673
AUC: 0.8791

Epoch 7/30
 - 0s - loss: 0.9446 - val_loss: 0.5870
AUC: 0.8794

Epoch 8/30
 - 0s - loss: 0.9521 - val_loss: 0.5778
AUC: 0.8794

Epoch 9/30
 - 0s - loss: 0.9462 - val_loss: 0.5766
AUC: 0.8796

Epoch 10/30
 - 0s - loss: 0.9440 - val_loss: 0.5776
AUC: 0.8796

Epoch 11/30
 - 0s - loss: 0.9455 - val_loss: 0.5795
AUC: 0.8795

Epoch 12/30
 - 0s - loss: 0.9391 - val_loss: 0.5855
AUC: 0.8798

Epoch 13/30
 - 0s - loss: 0.9402 - val_loss: 0.5686
AUC: 0.8794

Epoch 14/30
 - 0s - loss: 0.9405 - val_loss: 0.5920
AUC: 0.8799

Epoch 15/30
 - 0s - loss: 0.9376 - val_loss: 0.5951
AUC: 0.8800

Epoch 16/30
 - 0s - loss: 0.9398 - val_loss: 0.5948
AUC: 0.8802

Epoch 17/30
 - 0s - loss: 0.9333 - val_loss: 0.5787
AUC: 0.8799

Epoch 18/30
 - 0s - loss: 0.9331 - val_loss: 0.5768
AUC: 0.8799

Epoch 19/30
 - 0s - loss: 0.9290 - val_loss: 0.5774
AUC: 0.8799

Epoch 20/30
 - 0s - loss: 0.9345 - val_loss: 0.5792
AUC: 0.8800

Epoch 21/30
 - 0s - loss: 0.9292 - val_loss: 0.5768
AUC: 0.8799

Epoch 22/30
 - 0s - loss: 0.9356 - val_loss: 0.5841
AUC: 0.8801

Epoch 23/30
 - 0s - loss: 0.9303 - val_loss: 0.5816
AUC: 0.8801

Epoch 24/30
 - 0s - loss: 0.9296 - val_loss: 0.5810
AUC: 0.8801

Epoch 25/30
 - 0s - loss: 0.9322 - val_loss: 0.5777
AUC: 0.8801

Epoch 26/30
 - 0s - loss: 0.9275 - val_loss: 0.5823
AUC: 0.8801

Epoch 27/30
 - 0s - loss: 0.9274 - val_loss: 0.5817
AUC: 0.8801

Epoch 28/30
 - 0s - loss: 0.9281 - val_loss: 0.5810
AUC: 0.8801

Epoch 29/30
 - 0s - loss: 0.9281 - val_loss: 0.5793
AUC: 0.8801

Epoch 30/30
 - 0s - loss: 0.9287 - val_loss: 0.5794
Using TensorFlow backend.
AUC: 0.8801

2019-03-08 09:45:26.791704: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:45:26.953867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:45:26.953910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:45:27.247328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:45:27.247378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:45:27.247387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:45:27.247641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0033
Epoch 2/80
 - 2s - loss: 0.1809
Epoch 3/80
 - 2s - loss: 0.1526
Epoch 4/80
 - 2s - loss: 0.1311
Epoch 5/80
 - 2s - loss: 0.1151
Epoch 6/80
 - 2s - loss: 0.1022
Epoch 7/80
 - 2s - loss: 0.0915
Epoch 8/80
 - 2s - loss: 0.0830
Epoch 9/80
 - 2s - loss: 0.0759
Epoch 10/80
 - 2s - loss: 0.0701
Epoch 11/80
 - 2s - loss: 0.0652
Epoch 12/80
 - 2s - loss: 0.0612
Epoch 13/80
 - 2s - loss: 0.0579
Epoch 14/80
 - 2s - loss: 0.0551
Epoch 15/80
 - 2s - loss: 0.0527
Epoch 16/80
 - 2s - loss: 0.0506
Epoch 17/80
 - 2s - loss: 0.0488
Epoch 18/80
 - 2s - loss: 0.0473
Epoch 19/80
 - 2s - loss: 0.0460
Epoch 20/80
 - 2s - loss: 0.0448
Epoch 21/80
 - 2s - loss: 0.0438
Epoch 22/80
 - 2s - loss: 0.0429
Epoch 23/80
 - 2s - loss: 0.0422
Epoch 24/80
 - 2s - loss: 0.0415
Epoch 25/80
 - 2s - loss: 0.0409
Epoch 26/80
 - 2s - loss: 0.0404
Epoch 27/80
 - 2s - loss: 0.0400
Epoch 28/80
 - 2s - loss: 0.0396
Epoch 29/80
 - 2s - loss: 0.0392
Epoch 30/80
 - 2s - loss: 0.0389
Epoch 31/80
 - 2s - loss: 0.0387
Epoch 32/80
 - 2s - loss: 0.0384
Epoch 33/80
 - 2s - loss: 0.0382
Epoch 34/80
 - 2s - loss: 0.0380
Epoch 35/80
 - 2s - loss: 0.0378
Epoch 36/80
 - 2s - loss: 0.0377
Epoch 37/80
 - 2s - loss: 0.0376
Epoch 38/80
 - 2s - loss: 0.0374
Epoch 39/80
 - 2s - loss: 0.0373
Epoch 40/80
 - 2s - loss: 0.0372
Epoch 41/80
 - 2s - loss: 0.0371
Epoch 42/80
 - 2s - loss: 0.0370
Epoch 43/80
 - 2s - loss: 0.0369
Epoch 44/80
 - 2s - loss: 0.0369
Epoch 45/80
 - 2s - loss: 0.0368
Epoch 46/80
 - 2s - loss: 0.0367
Epoch 47/80
 - 2s - loss: 0.0367
Epoch 48/80
 - 2s - loss: 0.0366
Epoch 49/80
 - 2s - loss: 0.0366
Epoch 50/80
 - 2s - loss: 0.0365
Epoch 51/80
 - 2s - loss: 0.0365
Epoch 52/80
 - 2s - loss: 0.0364
Epoch 53/80
 - 2s - loss: 0.0364
Epoch 54/80
 - 2s - loss: 0.0363
Epoch 55/80
 - 2s - loss: 0.0363
Epoch 56/80
 - 2s - loss: 0.0363
Epoch 57/80
 - 2s - loss: 0.0362
Epoch 58/80
 - 2s - loss: 0.0362
Epoch 59/80
 - 2s - loss: 0.0362
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:47:24.086808: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:47:24.250184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:47:24.250228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:47:24.542617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:47:24.542668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:47:24.542677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:47:24.542933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6014
Epoch 2/80
 - 2s - loss: 0.0831
Epoch 3/80
 - 2s - loss: 0.0640
Epoch 4/80
 - 2s - loss: 0.0570
Epoch 5/80
 - 2s - loss: 0.0506
Epoch 6/80
 - 2s - loss: 0.0449
Epoch 7/80
 - 2s - loss: 0.0398
Epoch 8/80
 - 2s - loss: 0.0354
Epoch 9/80
 - 2s - loss: 0.0317
Epoch 10/80
 - 2s - loss: 0.0286
Epoch 11/80
 - 2s - loss: 0.0260
Epoch 12/80
 - 2s - loss: 0.0239
Epoch 13/80
 - 2s - loss: 0.0222
Epoch 14/80
 - 2s - loss: 0.0208
Epoch 15/80
 - 2s - loss: 0.0196
Epoch 16/80
 - 2s - loss: 0.0186
Epoch 17/80
 - 2s - loss: 0.0177
Epoch 18/80
 - 2s - loss: 0.0169
Epoch 19/80
 - 2s - loss: 0.0163
Epoch 20/80
 - 2s - loss: 0.0157
Epoch 21/80
 - 2s - loss: 0.0153
Epoch 22/80
 - 2s - loss: 0.0149
Epoch 23/80
 - 2s - loss: 0.0145
Epoch 24/80
 - 2s - loss: 0.0142
Epoch 25/80
 - 2s - loss: 0.0139
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0134
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0129
Epoch 31/80
 - 2s - loss: 0.0128
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 1s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0123
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0118
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0111
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:49:12.220361: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:49:12.382949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:49:12.382993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:49:12.676587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:49:12.676639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:49:12.676648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:49:12.676902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6059
Epoch 2/80
 - 2s - loss: 0.0843
Epoch 3/80
 - 2s - loss: 0.0639
Epoch 4/80
 - 2s - loss: 0.0564
Epoch 5/80
 - 2s - loss: 0.0500
Epoch 6/80
 - 2s - loss: 0.0443
Epoch 7/80
 - 2s - loss: 0.0396
Epoch 8/80
 - 2s - loss: 0.0356
Epoch 9/80
 - 2s - loss: 0.0320
Epoch 10/80
 - 2s - loss: 0.0290
Epoch 11/80
 - 2s - loss: 0.0264
Epoch 12/80
 - 2s - loss: 0.0243
Epoch 13/80
 - 2s - loss: 0.0226
Epoch 14/80
 - 2s - loss: 0.0211
Epoch 15/80
 - 2s - loss: 0.0199
Epoch 16/80
 - 2s - loss: 0.0188
Epoch 17/80
 - 2s - loss: 0.0179
Epoch 18/80
 - 2s - loss: 0.0172
Epoch 19/80
 - 2s - loss: 0.0165
Epoch 20/80
 - 2s - loss: 0.0159
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0146
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0128
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0118
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0111
Epoch 54/80
 - 2s - loss: 0.0111
Epoch 55/80
 - 2s - loss: 0.0111
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.9598 - val_loss: 0.7537
AUC: 0.8150

Epoch 2/80
 - 0s - loss: 1.3750 - val_loss: 0.7935
AUC: 0.8304

Epoch 3/80
 - 0s - loss: 1.2043 - val_loss: 0.7331
AUC: 0.8479

Epoch 4/80
 - 0s - loss: 1.1488 - val_loss: 0.7207
AUC: 0.8534

Epoch 5/80
 - 0s - loss: 1.1160 - val_loss: 0.6140
AUC: 0.8548

Epoch 6/80
 - 0s - loss: 1.1016 - val_loss: 0.6352
AUC: 0.8590

Epoch 7/80
 - 0s - loss: 1.0693 - val_loss: 0.6679
AUC: 0.8611

Epoch 8/80
 - 0s - loss: 1.0673 - val_loss: 0.5961
AUC: 0.8603

Epoch 9/80
 - 0s - loss: 1.0587 - val_loss: 0.6199
AUC: 0.8626

Epoch 10/80
 - 0s - loss: 1.0492 - val_loss: 0.6907
AUC: 0.8653

Epoch 11/80
 - 0s - loss: 1.0418 - val_loss: 0.5849
AUC: 0.8637

Epoch 12/80
 - 0s - loss: 1.0365 - val_loss: 0.5593
AUC: 0.8651

Epoch 13/80
 - 0s - loss: 1.0354 - val_loss: 0.6729
AUC: 0.8679

Epoch 14/80
 - 0s - loss: 1.0271 - val_loss: 0.6387
AUC: 0.8675

Epoch 15/80
 - 0s - loss: 1.0238 - val_loss: 0.5894
AUC: 0.8674

Epoch 16/80
 - 0s - loss: 1.0166 - val_loss: 0.5875
AUC: 0.8674

Epoch 17/80
 - 0s - loss: 1.0043 - val_loss: 0.5784
AUC: 0.8683

Epoch 18/80
 - 0s - loss: 1.0103 - val_loss: 0.6067
AUC: 0.8696

Epoch 19/80
 - 0s - loss: 1.0028 - val_loss: 0.6250
AUC: 0.8697

Epoch 20/80
 - 0s - loss: 1.0019 - val_loss: 0.6054
AUC: 0.8694

Epoch 21/80
 - 0s - loss: 0.9997 - val_loss: 0.6531
AUC: 0.8712

Epoch 22/80
 - 0s - loss: 0.9989 - val_loss: 0.5846
AUC: 0.8705

Epoch 23/80
 - 0s - loss: 0.9818 - val_loss: 0.5989
AUC: 0.8714

Epoch 24/80
 - 0s - loss: 0.9725 - val_loss: 0.6050
AUC: 0.8717

Epoch 25/80
 - 0s - loss: 0.9768 - val_loss: 0.5900
AUC: 0.8717

Epoch 26/80
 - 0s - loss: 0.9751 - val_loss: 0.5867
AUC: 0.8714

Epoch 27/80
 - 0s - loss: 0.9712 - val_loss: 0.5706
AUC: 0.8716

Epoch 28/80
 - 0s - loss: 0.9717 - val_loss: 0.6346
AUC: 0.8719

Epoch 29/80
 - 0s - loss: 0.9746 - val_loss: 0.5968
AUC: 0.8721

Epoch 30/80
 - 0s - loss: 0.9719 - val_loss: 0.5986
AUC: 0.8721

Epoch 31/80
 - 0s - loss: 0.9706 - val_loss: 0.5977
AUC: 0.8719

Epoch 32/80
 - 0s - loss: 0.9714 - val_loss: 0.5995
AUC: 0.8724

Epoch 33/80
 - 0s - loss: 0.9704 - val_loss: 0.5949
AUC: 0.8723

Epoch 34/80
 - 0s - loss: 0.9641 - val_loss: 0.5979
AUC: 0.8723

Epoch 35/80
 - 0s - loss: 0.9669 - val_loss: 0.5928
AUC: 0.8723

Epoch 36/80
 - 0s - loss: 0.9659 - val_loss: 0.6019
AUC: 0.8724

Epoch 37/80
 - 0s - loss: 0.9693 - val_loss: 0.5992
AUC: 0.8724

Epoch 38/80
 - 0s - loss: 0.9743 - val_loss: 0.6006
AUC: 0.8724

Epoch 39/80
 - 0s - loss: 0.9622 - val_loss: 0.5940
AUC: 0.8724

Epoch 40/80
 - 0s - loss: 0.9671 - val_loss: 0.6044
AUC: 0.8724

Epoch 41/80
 - 0s - loss: 0.9644 - val_loss: 0.5960
AUC: 0.8724

Epoch 42/80
 - 0s - loss: 0.9642 - val_loss: 0.5985
AUC: 0.8724

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9732 - val_loss: 0.5944
AUC: 0.8725

Epoch 2/30
 - 0s - loss: 0.9680 - val_loss: 0.5947
AUC: 0.8724

Epoch 3/30
 - 0s - loss: 0.9634 - val_loss: 0.6017
AUC: 0.8727

Epoch 4/30
 - 0s - loss: 0.9549 - val_loss: 0.5607
AUC: 0.8725

Epoch 5/30
 - 0s - loss: 0.9608 - val_loss: 0.6069
AUC: 0.8730

Epoch 6/30
 - 0s - loss: 0.9665 - val_loss: 0.6002
AUC: 0.8729

Epoch 7/30
 - 0s - loss: 0.9537 - val_loss: 0.6122
AUC: 0.8730

Epoch 8/30
 - 1s - loss: 0.9599 - val_loss: 0.5906
AUC: 0.8731

Epoch 9/30
 - 1s - loss: 0.9574 - val_loss: 0.5936
AUC: 0.8732

Epoch 10/30
 - 0s - loss: 0.9517 - val_loss: 0.5924
AUC: 0.8733

Epoch 11/30
 - 0s - loss: 0.9531 - val_loss: 0.5821
AUC: 0.8734

Epoch 12/30
 - 0s - loss: 0.9533 - val_loss: 0.5868
AUC: 0.8736

Epoch 13/30
 - 0s - loss: 0.9503 - val_loss: 0.6143
AUC: 0.8737

Epoch 14/30
 - 0s - loss: 0.9504 - val_loss: 0.5874
AUC: 0.8735

Epoch 15/30
 - 0s - loss: 0.9408 - val_loss: 0.5901
AUC: 0.8735

Epoch 16/30
 - 0s - loss: 0.9422 - val_loss: 0.5799
AUC: 0.8735

Epoch 17/30
 - 0s - loss: 0.9412 - val_loss: 0.5808
AUC: 0.8735

Epoch 18/30
 - 0s - loss: 0.9403 - val_loss: 0.5835
AUC: 0.8736

Epoch 19/30
 - 0s - loss: 0.9373 - val_loss: 0.5775
AUC: 0.8736

Epoch 20/30
 - 0s - loss: 0.9407 - val_loss: 0.5827
AUC: 0.8737

Epoch 21/30
 - 0s - loss: 0.9429 - val_loss: 0.5839
AUC: 0.8737

Epoch 22/30
 - 0s - loss: 0.9356 - val_loss: 0.5856
AUC: 0.8737

Epoch 23/30
 - 0s - loss: 0.9409 - val_loss: 0.5852
AUC: 0.8736

Epoch 24/30
 - 0s - loss: 0.9385 - val_loss: 0.5826
AUC: 0.8737

Epoch 25/30
 - 0s - loss: 0.9330 - val_loss: 0.5820
AUC: 0.8737

Epoch 26/30
 - 0s - loss: 0.9435 - val_loss: 0.5828
AUC: 0.8737

Epoch 27/30
 - 0s - loss: 0.9370 - val_loss: 0.5828
AUC: 0.8737

Epoch 28/30
 - 0s - loss: 0.9385 - val_loss: 0.5836
AUC: 0.8737

Epoch 29/30
 - 0s - loss: 0.9379 - val_loss: 0.5839
AUC: 0.8737

Epoch 30/30
 - 0s - loss: 0.9436 - val_loss: 0.5833
Using TensorFlow backend.
AUC: 0.8737

2019-03-08 09:52:32.984761: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:52:33.146932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:52:33.146975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:52:33.439302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:52:33.439353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:52:33.439362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:52:33.439618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5845
Epoch 2/80
 - 2s - loss: 0.0820
Epoch 3/80
 - 2s - loss: 0.0657
Epoch 4/80
 - 2s - loss: 0.0611
Epoch 5/80
 - 2s - loss: 0.0556
Epoch 6/80
 - 2s - loss: 0.0491
Epoch 7/80
 - 2s - loss: 0.0430
Epoch 8/80
 - 2s - loss: 0.0380
Epoch 9/80
 - 2s - loss: 0.0340
Epoch 10/80
 - 2s - loss: 0.0306
Epoch 11/80
 - 2s - loss: 0.0276
Epoch 12/80
 - 2s - loss: 0.0252
Epoch 13/80
 - 2s - loss: 0.0233
Epoch 14/80
 - 2s - loss: 0.0216
Epoch 15/80
 - 2s - loss: 0.0203
Epoch 16/80
 - 2s - loss: 0.0191
Epoch 17/80
 - 2s - loss: 0.0182
Epoch 18/80
 - 2s - loss: 0.0174
Epoch 19/80
 - 2s - loss: 0.0167
Epoch 20/80
 - 2s - loss: 0.0161
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 1s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0144
Epoch 25/80
 - 2s - loss: 0.0141
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0136
Epoch 28/80
 - 2s - loss: 0.0134
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0128
Epoch 33/80
 - 2s - loss: 0.0127
Epoch 34/80
 - 2s - loss: 0.0126
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0123
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0122
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0121
Epoch 43/80
 - 2s - loss: 0.0121
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 1s - loss: 0.0120
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0119
Epoch 49/80
 - 1s - loss: 0.0114
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:54:13.283585: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:54:13.446259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:54:13.446303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:54:13.739992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:54:13.740043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:54:13.740052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:54:13.740321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2086
Epoch 2/80
 - 2s - loss: 0.3117
Epoch 3/80
 - 2s - loss: 0.2606
Epoch 4/80
 - 2s - loss: 0.2262
Epoch 5/80
 - 2s - loss: 0.2031
Epoch 6/80
 - 1s - loss: 0.1847
Epoch 7/80
 - 2s - loss: 0.1697
Epoch 8/80
 - 1s - loss: 0.1568
Epoch 9/80
 - 2s - loss: 0.1458
Epoch 10/80
 - 2s - loss: 0.1367
Epoch 11/80
 - 2s - loss: 0.1295
Epoch 12/80
 - 2s - loss: 0.1237
Epoch 13/80
 - 2s - loss: 0.1190
Epoch 14/80
 - 2s - loss: 0.1149
Epoch 15/80
 - 2s - loss: 0.1112
Epoch 16/80
 - 2s - loss: 0.1081
Epoch 17/80
 - 1s - loss: 0.1053
Epoch 18/80
 - 1s - loss: 0.1029
Epoch 19/80
 - 2s - loss: 0.1007
Epoch 20/80
 - 2s - loss: 0.0988
Epoch 21/80
 - 1s - loss: 0.0972
Epoch 22/80
 - 1s - loss: 0.0958
Epoch 23/80
 - 1s - loss: 0.0946
Epoch 24/80
 - 1s - loss: 0.0936
Epoch 25/80
 - 1s - loss: 0.0927
Epoch 26/80
 - 1s - loss: 0.0919
Epoch 27/80
 - 2s - loss: 0.0912
Epoch 28/80
 - 1s - loss: 0.0907
Epoch 29/80
 - 1s - loss: 0.0901
Epoch 30/80
 - 1s - loss: 0.0896
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 09:55:24.111395: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:55:24.272961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:55:24.273004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:55:24.566159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:55:24.566216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:55:24.566226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:55:24.566482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2065
Epoch 2/80
 - 2s - loss: 0.3131
Epoch 3/80
 - 2s - loss: 0.2649
Epoch 4/80
 - 2s - loss: 0.2253
Epoch 5/80
 - 2s - loss: 0.2028
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b30712fd668>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 09:55:50.690198: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:55:50.851865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:55:50.851918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:55:51.145318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:55:51.145362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:55:51.145373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:55:51.145683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1808
Epoch 2/80
 - 2s - loss: 0.3184
Epoch 3/80
 - 2s - loss: 0.2782
Epoch 4/80
 - 2s - loss: 0.2342
Epoch 5/80
 - 2s - loss: 0.2067
Epoch 6/80
 - 2s - loss: 0.1877
Epoch 7/80
 - 2s - loss: 0.1728
Epoch 8/80
 - 2s - loss: 0.1598
Epoch 9/80
 - 2s - loss: 0.1488
Epoch 10/80
 - 2s - loss: 0.1395
Epoch 11/80
 - 2s - loss: 0.1317
Epoch 12/80
 - 2s - loss: 0.1254
Epoch 13/80
 - 2s - loss: 0.1204
Epoch 14/80
 - 2s - loss: 0.1159
Epoch 15/80
 - 2s - loss: 0.1121
Epoch 16/80
 - 2s - loss: 0.1088
Epoch 17/80
 - 2s - loss: 0.1058
Epoch 18/80
 - 2s - loss: 0.1034
Epoch 19/80
 - 2s - loss: 0.1011
Epoch 20/80
 - 2s - loss: 0.0992
Epoch 21/80
 - 2s - loss: 0.0976
Epoch 22/80
 - 2s - loss: 0.0962
Epoch 23/80
 - 2s - loss: 0.0950
Epoch 24/80
 - 2s - loss: 0.0939
Epoch 25/80
 - 2s - loss: 0.0930
Epoch 26/80
 - 2s - loss: 0.0922
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0909
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0900
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0892
Epoch 33/80
 - 2s - loss: 0.0889
Epoch 34/80
 - 2s - loss: 0.0886
Epoch 35/80
 - 2s - loss: 0.0884
Epoch 36/80
 - 2s - loss: 0.0881
Epoch 37/80
 - 2s - loss: 0.0879
Epoch 38/80
 - 2s - loss: 0.0877
Epoch 39/80
 - 2s - loss: 0.0875
Epoch 40/80
 - 2s - loss: 0.0874
Epoch 41/80
 - 2s - loss: 0.0872
Epoch 42/80
 - 2s - loss: 0.0871
Epoch 43/80
 - 2s - loss: 0.0870
Epoch 44/80
 - 2s - loss: 0.0868
Epoch 45/80
 - 2s - loss: 0.0867
Epoch 46/80
 - 2s - loss: 0.0866
Epoch 47/80
 - 2s - loss: 0.0865
Epoch 48/80
 - 2s - loss: 0.0864
Epoch 49/80
 - 2s - loss: 0.0863
Epoch 50/80
 - 2s - loss: 0.0862
Epoch 51/80
 - 2s - loss: 0.0861
Epoch 52/80
 - 2s - loss: 0.0861
Epoch 53/80
 - 2s - loss: 0.0860
Epoch 54/80
 - 2s - loss: 0.0859
Epoch 55/80
 - 2s - loss: 0.0858
Epoch 56/80
 - 2s - loss: 0.0858
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0857
Epoch 59/80
 - 2s - loss: 0.0856
Epoch 60/80
 - 2s - loss: 0.0856
Epoch 61/80
 - 2s - loss: 0.0855
Epoch 62/80
 - 2s - loss: 0.0855
Epoch 63/80
 - 2s - loss: 0.0855
Epoch 64/80
 - 2s - loss: 0.0854
Epoch 65/80
 - 2s - loss: 0.0853
Epoch 66/80
 - 2s - loss: 0.0853
Epoch 67/80
 - 2s - loss: 0.0853
Epoch 68/80
 - 2s - loss: 0.0853
Epoch 69/80
 - 2s - loss: 0.0819
Epoch 70/80
 - 2s - loss: 0.0816
Epoch 71/80
 - 2s - loss: 0.0816
Epoch 72/80
 - 2s - loss: 0.0816
Epoch 73/80
 - 2s - loss: 0.0815
Epoch 74/80
 - 2s - loss: 0.0807
Epoch 75/80
 - 2s - loss: 0.0807
Epoch 76/80
 - 2s - loss: 0.0807
Epoch 77/80
 - 2s - loss: 0.0807
Epoch 78/80
 - 2s - loss: 0.0805
Epoch 79/80
 - 2s - loss: 0.0805
Epoch 80/80
 - 2s - loss: 0.0805
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.1752 - val_loss: 1.3781
AUC: 0.7981

Epoch 2/80
 - 0s - loss: 2.4796 - val_loss: 1.1130
AUC: 0.8157

Epoch 3/80
 - 0s - loss: 1.6497 - val_loss: 0.8314
AUC: 0.8230

Epoch 4/80
 - 0s - loss: 1.3183 - val_loss: 0.8725
AUC: 0.8369

Epoch 5/80
 - 0s - loss: 1.2428 - val_loss: 0.6851
AUC: 0.8415

Epoch 6/80
 - 0s - loss: 1.1701 - val_loss: 0.6666
AUC: 0.8452

Epoch 7/80
 - 0s - loss: 1.1445 - val_loss: 0.7383
AUC: 0.8505

Epoch 8/80
 - 0s - loss: 1.1169 - val_loss: 0.6037
AUC: 0.8531

Epoch 9/80
 - 0s - loss: 1.0981 - val_loss: 0.6234
AUC: 0.8549

Epoch 10/80
 - 0s - loss: 1.0835 - val_loss: 0.6788
AUC: 0.8586

Epoch 11/80
 - 0s - loss: 1.0713 - val_loss: 0.6459
AUC: 0.8590

Epoch 12/80
 - 0s - loss: 1.0675 - val_loss: 0.6301
AUC: 0.8609

Epoch 13/80
 - 0s - loss: 1.0537 - val_loss: 0.6249
AUC: 0.8607

Epoch 14/80
 - 0s - loss: 1.0462 - val_loss: 0.6864
AUC: 0.8631

Epoch 15/80
 - 0s - loss: 1.0348 - val_loss: 0.6599
AUC: 0.8637

Epoch 16/80
 - 0s - loss: 1.0299 - val_loss: 0.6941
AUC: 0.8644

Epoch 17/80
 - 0s - loss: 1.0316 - val_loss: 0.5667
AUC: 0.8634

Epoch 18/80
 - 0s - loss: 1.0241 - val_loss: 0.6283
AUC: 0.8642

Epoch 19/80
 - 0s - loss: 1.0218 - val_loss: 0.5970
AUC: 0.8646

Epoch 20/80
 - 0s - loss: 1.0140 - val_loss: 0.6487
AUC: 0.8660

Epoch 21/80
 - 0s - loss: 1.0159 - val_loss: 0.6585
AUC: 0.8670

Epoch 22/80
 - 0s - loss: 1.0127 - val_loss: 0.5881
AUC: 0.8662

Epoch 23/80
 - 0s - loss: 1.0063 - val_loss: 0.6614
AUC: 0.8666

Epoch 24/80
 - 0s - loss: 0.9984 - val_loss: 0.6753
AUC: 0.8668

Epoch 25/80
 - 0s - loss: 0.9982 - val_loss: 0.6707
AUC: 0.8662

Epoch 26/80
 - 0s - loss: 1.0003 - val_loss: 0.5886
AUC: 0.8657

Epoch 27/80
 - 0s - loss: 0.9902 - val_loss: 0.6262
AUC: 0.8674

Epoch 28/80
 - 0s - loss: 0.9865 - val_loss: 0.6269
AUC: 0.8677

Epoch 29/80
 - 0s - loss: 0.9851 - val_loss: 0.6112
AUC: 0.8674

Epoch 30/80
 - 0s - loss: 0.9834 - val_loss: 0.6234
AUC: 0.8680

Epoch 31/80
 - 0s - loss: 0.9782 - val_loss: 0.5924
AUC: 0.8676

Epoch 32/80
 - 0s - loss: 0.9801 - val_loss: 0.6097
AUC: 0.8678

Epoch 33/80
 - 0s - loss: 0.9782 - val_loss: 0.6110
AUC: 0.8680

Epoch 34/80
 - 0s - loss: 0.9805 - val_loss: 0.6019
AUC: 0.8679

Epoch 35/80
 - 0s - loss: 0.9837 - val_loss: 0.6316
AUC: 0.8684

Epoch 36/80
 - 0s - loss: 0.9778 - val_loss: 0.6158
AUC: 0.8684

Epoch 37/80
 - 0s - loss: 0.9755 - val_loss: 0.5874
AUC: 0.8679

Epoch 38/80
 - 0s - loss: 0.9769 - val_loss: 0.6118
AUC: 0.8682

Epoch 39/80
 - 0s - loss: 0.9773 - val_loss: 0.6016
AUC: 0.8681

Epoch 40/80
 - 0s - loss: 0.9777 - val_loss: 0.6157
AUC: 0.8684

Epoch 41/80
 - 0s - loss: 0.9742 - val_loss: 0.6005
AUC: 0.8682

Epoch 42/80
 - 0s - loss: 0.9734 - val_loss: 0.6026
AUC: 0.8682

Epoch 43/80
 - 0s - loss: 0.9725 - val_loss: 0.6092
AUC: 0.8683

Epoch 44/80
 - 0s - loss: 0.9734 - val_loss: 0.6070
AUC: 0.8683

Epoch 45/80
 - 0s - loss: 0.9799 - val_loss: 0.6026
AUC: 0.8682

Epoch 46/80
 - 0s - loss: 0.9757 - val_loss: 0.6106
AUC: 0.8683

Epoch 47/80
 - 0s - loss: 0.9758 - val_loss: 0.6010
AUC: 0.8682

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9777 - val_loss: 0.6046
AUC: 0.8682

Epoch 2/30
 - 0s - loss: 0.9770 - val_loss: 0.6008
AUC: 0.8682

Epoch 3/30
 - 0s - loss: 0.9729 - val_loss: 0.6160
AUC: 0.8685

Epoch 4/30
 - 0s - loss: 0.9683 - val_loss: 0.6097
AUC: 0.8686

Epoch 5/30
 - 0s - loss: 0.9701 - val_loss: 0.6188
AUC: 0.8689

Epoch 6/30
 - 0s - loss: 0.9686 - val_loss: 0.5917
AUC: 0.8687

Epoch 7/30
 - 0s - loss: 0.9681 - val_loss: 0.6265
AUC: 0.8691

Epoch 8/30
 - 0s - loss: 0.9691 - val_loss: 0.6047
AUC: 0.8690

Epoch 9/30
 - 0s - loss: 0.9654 - val_loss: 0.6012
AUC: 0.8692

Epoch 10/30
 - 0s - loss: 0.9640 - val_loss: 0.5983
AUC: 0.8692

Epoch 11/30
 - 0s - loss: 0.9587 - val_loss: 0.6005
AUC: 0.8693

Epoch 12/30
 - 0s - loss: 0.9624 - val_loss: 0.6113
AUC: 0.8696

Epoch 13/30
 - 0s - loss: 0.9574 - val_loss: 0.6123
AUC: 0.8696

Epoch 14/30
 - 0s - loss: 0.9588 - val_loss: 0.6170
AUC: 0.8698

Epoch 15/30
 - 0s - loss: 0.9513 - val_loss: 0.6031
AUC: 0.8697

Epoch 16/30
 - 0s - loss: 0.9491 - val_loss: 0.5950
AUC: 0.8696

Epoch 17/30
 - 0s - loss: 0.9494 - val_loss: 0.5989
AUC: 0.8697

Epoch 18/30
 - 0s - loss: 0.9467 - val_loss: 0.5947
AUC: 0.8696

Epoch 19/30
 - 0s - loss: 0.9491 - val_loss: 0.5988
AUC: 0.8697

Epoch 20/30
 - 0s - loss: 0.9480 - val_loss: 0.6013
AUC: 0.8698

Epoch 21/30
 - 0s - loss: 0.9481 - val_loss: 0.5985
AUC: 0.8698

Epoch 22/30
 - 0s - loss: 0.9474 - val_loss: 0.5983
AUC: 0.8698

Epoch 23/30
 - 0s - loss: 0.9524 - val_loss: 0.6023
AUC: 0.8698

Epoch 24/30
 - 0s - loss: 0.9480 - val_loss: 0.5940
AUC: 0.8697

Epoch 25/30
 - 0s - loss: 0.9472 - val_loss: 0.5957
AUC: 0.8698

Epoch 26/30
 - 0s - loss: 0.9488 - val_loss: 0.5993
AUC: 0.8698

Epoch 27/30
 - 0s - loss: 0.9432 - val_loss: 0.5991
AUC: 0.8698

Epoch 28/30
 - 0s - loss: 0.9474 - val_loss: 0.5975
AUC: 0.8698

Epoch 29/30
 - 0s - loss: 0.9478 - val_loss: 0.5974
AUC: 0.8698

Epoch 30/30
 - 0s - loss: 0.9480 - val_loss: 0.5972
Using TensorFlow backend.
AUC: 0.8698

2019-03-08 09:59:11.215591: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 09:59:11.396047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 09:59:11.396091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 09:59:11.691234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 09:59:11.691287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 09:59:11.691296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 09:59:11.691575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2088
Epoch 2/80
 - 2s - loss: 0.3162
Epoch 3/80
 - 2s - loss: 0.2683
Epoch 4/80
 - 2s - loss: 0.2307
Epoch 5/80
 - 2s - loss: 0.2061
Epoch 6/80
 - 2s - loss: 0.1868
Epoch 7/80
 - 2s - loss: 0.1710
Epoch 8/80
 - 2s - loss: 0.1580
Epoch 9/80
 - 2s - loss: 0.1469
Epoch 10/80
 - 2s - loss: 0.1380
Epoch 11/80
 - 2s - loss: 0.1308
Epoch 12/80
 - 2s - loss: 0.1248
Epoch 13/80
 - 2s - loss: 0.1197
Epoch 14/80
 - 2s - loss: 0.1155
Epoch 15/80
 - 2s - loss: 0.1117
Epoch 16/80
 - 2s - loss: 0.1085
Epoch 17/80
 - 2s - loss: 0.1057
Epoch 18/80
 - 2s - loss: 0.1033
Epoch 19/80
 - 2s - loss: 0.1011
Epoch 20/80
 - 2s - loss: 0.0992
Epoch 21/80
 - 2s - loss: 0.0977
Epoch 22/80
 - 2s - loss: 0.0963
Epoch 23/80
 - 2s - loss: 0.0951
Epoch 24/80
 - 2s - loss: 0.0941
Epoch 25/80
 - 2s - loss: 0.0932
Epoch 26/80
 - 2s - loss: 0.0925
Epoch 27/80
 - 2s - loss: 0.0918
Epoch 28/80
 - 2s - loss: 0.0913
Epoch 29/80
 - 2s - loss: 0.0907
Epoch 30/80
 - 2s - loss: 0.0903
Epoch 31/80
 - 2s - loss: 0.0899
Epoch 32/80
 - 2s - loss: 0.0896
Epoch 33/80
 - 2s - loss: 0.0892
Epoch 34/80
 - 2s - loss: 0.0889
Epoch 35/80
 - 2s - loss: 0.0887
Epoch 36/80
 - 2s - loss: 0.0885
Epoch 37/80
 - 2s - loss: 0.0883
Epoch 38/80
 - 2s - loss: 0.0881
Epoch 39/80
 - 2s - loss: 0.0879
Epoch 40/80
 - 2s - loss: 0.0877
Epoch 41/80
 - 2s - loss: 0.0876
Epoch 42/80
 - 2s - loss: 0.0874
Epoch 43/80
 - 2s - loss: 0.0873
Epoch 44/80
 - 2s - loss: 0.0872
Epoch 45/80
 - 2s - loss: 0.0870
Epoch 46/80
 - 2s - loss: 0.0869
Epoch 47/80
 - 2s - loss: 0.0868
Epoch 48/80
 - 2s - loss: 0.0868
Epoch 49/80
 - 2s - loss: 0.0867
Epoch 50/80
 - 2s - loss: 0.0866
Epoch 51/80
 - 2s - loss: 0.0865
Epoch 52/80
 - 2s - loss: 0.0864
Epoch 53/80
 - 2s - loss: 0.0863
Epoch 54/80
 - 2s - loss: 0.0863
Epoch 55/80
 - 2s - loss: 0.0862
Epoch 56/80
 - 2s - loss: 0.0861
Epoch 57/80
 - 2s - loss: 0.0861
Epoch 58/80
 - 2s - loss: 0.0860
Epoch 59/80
 - 2s - loss: 0.0860
Epoch 60/80
 - 2s - loss: 0.0859
Epoch 61/80
 - 2s - loss: 0.0859
Epoch 62/80
 - 2s - loss: 0.0858
Epoch 63/80
 - 2s - loss: 0.0858
Epoch 64/80
 - 2s - loss: 0.0857
Epoch 65/80
 - 2s - loss: 0.0857
Epoch 66/80
 - 2s - loss: 0.0856
Epoch 67/80
 - 2s - loss: 0.0856
Epoch 68/80
 - 2s - loss: 0.0856
Epoch 69/80
 - 2s - loss: 0.0856
Epoch 70/80
 - 2s - loss: 0.0855
Epoch 71/80
 - 2s - loss: 0.0855
Epoch 72/80
 - 2s - loss: 0.0855
Epoch 73/80
 - 2s - loss: 0.0854
Epoch 74/80
 - 2s - loss: 0.0854
Epoch 75/80
 - 2s - loss: 0.0820
Epoch 76/80
 - 2s - loss: 0.0818
Epoch 77/80
 - 2s - loss: 0.0817
Epoch 78/80
 - 2s - loss: 0.0817
Epoch 79/80
 - 2s - loss: 0.0817
Epoch 80/80
 - 2s - loss: 0.0809
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.5808 - val_loss: 1.4708
AUC: 0.7337

Epoch 2/80
 - 0s - loss: 3.0130 - val_loss: 1.1824
AUC: 0.7789

Epoch 3/80
 - 0s - loss: 2.1813 - val_loss: 1.0186
AUC: 0.7972

Epoch 4/80
 - 0s - loss: 1.7062 - val_loss: 0.8771
AUC: 0.8136

Epoch 5/80
 - 0s - loss: 1.4424 - val_loss: 0.7874
AUC: 0.8261

Epoch 6/80
 - 0s - loss: 1.2899 - val_loss: 0.7414
AUC: 0.8344

Epoch 7/80
 - 0s - loss: 1.2230 - val_loss: 0.7560
AUC: 0.8388

Epoch 8/80
 - 0s - loss: 1.1816 - val_loss: 0.7411
AUC: 0.8443

Epoch 9/80
 - 0s - loss: 1.1436 - val_loss: 0.6616
AUC: 0.8449

Epoch 10/80
 - 0s - loss: 1.1231 - val_loss: 0.6722
AUC: 0.8482

Epoch 11/80
 - 0s - loss: 1.1001 - val_loss: 0.7114
AUC: 0.8510

Epoch 12/80
 - 0s - loss: 1.0966 - val_loss: 0.6530
AUC: 0.8527

Epoch 13/80
 - 0s - loss: 1.0852 - val_loss: 0.6996
AUC: 0.8537

Epoch 14/80
 - 0s - loss: 1.0760 - val_loss: 0.6791
AUC: 0.8542

Epoch 15/80
 - 0s - loss: 1.0649 - val_loss: 0.6367
AUC: 0.8563

Epoch 16/80
 - 0s - loss: 1.0625 - val_loss: 0.6495
AUC: 0.8570

Epoch 17/80
 - 0s - loss: 1.0561 - val_loss: 0.5768
AUC: 0.8565

Epoch 18/80
 - 0s - loss: 1.0370 - val_loss: 0.6221
AUC: 0.8587

Epoch 19/80
 - 0s - loss: 1.0400 - val_loss: 0.6101
AUC: 0.8594

Epoch 20/80
 - 0s - loss: 1.0398 - val_loss: 0.7020
AUC: 0.8593

Epoch 21/80
 - 0s - loss: 1.0355 - val_loss: 0.6633
AUC: 0.8588

Epoch 22/80
 - 0s - loss: 1.0302 - val_loss: 0.6896
AUC: 0.8610

Epoch 23/80
 - 0s - loss: 1.0304 - val_loss: 0.5759
AUC: 0.8586

Epoch 24/80
 - 0s - loss: 1.0311 - val_loss: 0.5930
AUC: 0.8607

Epoch 25/80
 - 0s - loss: 1.0182 - val_loss: 0.6580
AUC: 0.8617

Epoch 26/80
 - 0s - loss: 1.0244 - val_loss: 0.6626
AUC: 0.8612

Epoch 27/80
 - 0s - loss: 1.0142 - val_loss: 0.6266
AUC: 0.8615

Epoch 28/80
 - 0s - loss: 1.0196 - val_loss: 0.6490
AUC: 0.8629

Epoch 29/80
 - 0s - loss: 1.0119 - val_loss: 0.6927
AUC: 0.8640

Epoch 30/80
 - 0s - loss: 1.0084 - val_loss: 0.6084
AUC: 0.8638

Epoch 31/80
 - 0s - loss: 1.0043 - val_loss: 0.6241
AUC: 0.8644

Epoch 32/80
 - 0s - loss: 1.0081 - val_loss: 0.6203
AUC: 0.8636

Epoch 33/80
 - 0s - loss: 0.9976 - val_loss: 0.6585
AUC: 0.8637

Epoch 34/80
 - 0s - loss: 0.9948 - val_loss: 0.6426
AUC: 0.8641

Epoch 35/80
 - 0s - loss: 0.9930 - val_loss: 0.6196
AUC: 0.8639

Epoch 36/80
 - 0s - loss: 0.9983 - val_loss: 0.6102
AUC: 0.8640

Epoch 37/80
 - 0s - loss: 0.9887 - val_loss: 0.6380
AUC: 0.8643

Epoch 38/80
 - 0s - loss: 0.9875 - val_loss: 0.6246
AUC: 0.8645

Epoch 39/80
 - 0s - loss: 0.9885 - val_loss: 0.6211
AUC: 0.8647

Epoch 40/80
 - 0s - loss: 0.9915 - val_loss: 0.6017
AUC: 0.8646

Epoch 41/80
 - 0s - loss: 0.9861 - val_loss: 0.6225
AUC: 0.8648

Epoch 42/80
 - 0s - loss: 0.9861 - val_loss: 0.6080
AUC: 0.8647

Epoch 43/80
 - 0s - loss: 0.9932 - val_loss: 0.6072
AUC: 0.8648

Epoch 44/80
 - 0s - loss: 0.9837 - val_loss: 0.6102
AUC: 0.8647

Epoch 45/80
 - 0s - loss: 0.9830 - val_loss: 0.6152
AUC: 0.8649

Epoch 46/80
 - 0s - loss: 0.9869 - val_loss: 0.6194
AUC: 0.8649

Epoch 47/80
 - 0s - loss: 0.9822 - val_loss: 0.6098
AUC: 0.8647

Epoch 48/80
 - 0s - loss: 0.9825 - val_loss: 0.6197
AUC: 0.8649

Epoch 49/80
 - 0s - loss: 0.9879 - val_loss: 0.6161
AUC: 0.8649

Epoch 50/80
 - 0s - loss: 0.9811 - val_loss: 0.6162
AUC: 0.8649

Epoch 51/80
 - 0s - loss: 0.9827 - val_loss: 0.6179
AUC: 0.8648

Epoch 52/80
 - 0s - loss: 0.9860 - val_loss: 0.6212
AUC: 0.8648

Epoch 53/80
 - 0s - loss: 0.9881 - val_loss: 0.6188
AUC: 0.8649

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9850 - val_loss: 0.6064
AUC: 0.8649

Epoch 2/30
 - 0s - loss: 0.9818 - val_loss: 0.6258
AUC: 0.8652

Epoch 3/30
 - 0s - loss: 0.9830 - val_loss: 0.6309
AUC: 0.8653

Epoch 4/30
 - 0s - loss: 0.9782 - val_loss: 0.6143
AUC: 0.8654

Epoch 5/30
 - 0s - loss: 0.9758 - val_loss: 0.6225
AUC: 0.8657

Epoch 6/30
 - 0s - loss: 0.9755 - val_loss: 0.6176
AUC: 0.8656

Epoch 7/30
 - 0s - loss: 0.9725 - val_loss: 0.6168
AUC: 0.8658

Epoch 8/30
 - 0s - loss: 0.9664 - val_loss: 0.6295
AUC: 0.8658

Epoch 9/30
 - 0s - loss: 0.9711 - val_loss: 0.6021
AUC: 0.8655

Epoch 10/30
 - 0s - loss: 0.9668 - val_loss: 0.6096
AUC: 0.8660

Epoch 11/30
 - 0s - loss: 0.9703 - val_loss: 0.5988
AUC: 0.8660

Epoch 12/30
 - 0s - loss: 0.9669 - val_loss: 0.6009
AUC: 0.8661

Epoch 13/30
 - 0s - loss: 0.9613 - val_loss: 0.6142
AUC: 0.8662

Epoch 14/30
 - 0s - loss: 0.9604 - val_loss: 0.6054
AUC: 0.8664

Epoch 15/30
 - 0s - loss: 0.9614 - val_loss: 0.6085
AUC: 0.8665

Epoch 16/30
 - 0s - loss: 0.9616 - val_loss: 0.6109
AUC: 0.8667

Epoch 17/30
 - 0s - loss: 0.9552 - val_loss: 0.6215
AUC: 0.8669

Epoch 18/30
 - 0s - loss: 0.9554 - val_loss: 0.5970
AUC: 0.8667

Epoch 19/30
 - 0s - loss: 0.9506 - val_loss: 0.5977
AUC: 0.8671

Epoch 20/30
 - 0s - loss: 0.9526 - val_loss: 0.6151
AUC: 0.8672

Epoch 21/30
 - 0s - loss: 0.9498 - val_loss: 0.5968
AUC: 0.8670

Epoch 22/30
 - 0s - loss: 0.9515 - val_loss: 0.6067
AUC: 0.8671

Epoch 23/30
 - 0s - loss: 0.9451 - val_loss: 0.5908
AUC: 0.8671

Epoch 24/30
 - 0s - loss: 0.9374 - val_loss: 0.5817
AUC: 0.8671

Epoch 25/30
 - 0s - loss: 0.9429 - val_loss: 0.6010
AUC: 0.8672

Epoch 26/30
 - 0s - loss: 0.9405 - val_loss: 0.6004
AUC: 0.8674

Epoch 27/30
 - 0s - loss: 0.9418 - val_loss: 0.5901
AUC: 0.8673

Epoch 28/30
 - 0s - loss: 0.9354 - val_loss: 0.5961
AUC: 0.8674

Epoch 29/30
 - 0s - loss: 0.9343 - val_loss: 0.6096
AUC: 0.8677

Epoch 30/30
 - 0s - loss: 0.9323 - val_loss: 0.6028
Using TensorFlow backend.
AUC: 0.8677

2019-03-08 10:02:35.682230: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:02:35.850097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:02:35.850140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:02:36.147080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:02:36.147131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:02:36.147140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:02:36.147428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9931
Epoch 2/80
 - 2s - loss: 0.1805
Epoch 3/80
 - 2s - loss: 0.1551
Epoch 4/80
 - 2s - loss: 0.1342
Epoch 5/80
 - 2s - loss: 0.1172
Epoch 6/80
 - 2s - loss: 0.1030
Epoch 7/80
 - 2s - loss: 0.0915
Epoch 8/80
 - 2s - loss: 0.0824
Epoch 9/80
 - 2s - loss: 0.0754
Epoch 10/80
 - 2s - loss: 0.0697
Epoch 11/80
 - 2s - loss: 0.0650
Epoch 12/80
 - 2s - loss: 0.0612
Epoch 13/80
 - 2s - loss: 0.0580
Epoch 14/80
 - 2s - loss: 0.0553
Epoch 15/80
 - 2s - loss: 0.0530
Epoch 16/80
 - 2s - loss: 0.0509
Epoch 17/80
 - 2s - loss: 0.0491
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0461
Epoch 20/80
 - 2s - loss: 0.0449
Epoch 21/80
 - 2s - loss: 0.0439
Epoch 22/80
 - 2s - loss: 0.0430
Epoch 23/80
 - 2s - loss: 0.0422
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0404
Epoch 27/80
 - 2s - loss: 0.0400
Epoch 28/80
 - 2s - loss: 0.0396
Epoch 29/80
 - 2s - loss: 0.0393
Epoch 30/80
 - 2s - loss: 0.0390
Epoch 31/80
 - 2s - loss: 0.0387
Epoch 32/80
 - 2s - loss: 0.0385
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0381
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:03:53.808199: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:03:53.973425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:03:53.973469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:03:54.270335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:03:54.270387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:03:54.270396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:03:54.270649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0048
Epoch 2/80
 - 2s - loss: 0.1806
Epoch 3/80
 - 2s - loss: 0.1548
Epoch 4/80
 - 2s - loss: 0.1309
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:04:18.628498: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:04:18.792088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:04:18.792132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:04:19.089369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:04:19.089420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:04:19.089429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:04:19.089699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9771
Epoch 2/80
 - 2s - loss: 0.1809
Epoch 3/80
 - 2s - loss: 0.1572
Epoch 4/80
 - 2s - loss: 0.1379
Epoch 5/80
 - 2s - loss: 0.1210
Epoch 6/80
 - 2s - loss: 0.1075
Epoch 7/80
 - 2s - loss: 0.0961
Epoch 8/80
 - 2s - loss: 0.0862
Epoch 9/80
 - 2s - loss: 0.0782
Epoch 10/80
 - 2s - loss: 0.0717
Epoch 11/80
 - 2s - loss: 0.0663
Epoch 12/80
 - 2s - loss: 0.0618
Epoch 13/80
 - 2s - loss: 0.0581
Epoch 14/80
 - 2s - loss: 0.0552
Epoch 15/80
 - 2s - loss: 0.0527
Epoch 16/80
 - 2s - loss: 0.0506
Epoch 17/80
 - 2s - loss: 0.0488
Epoch 18/80
 - 2s - loss: 0.0473
Epoch 19/80
 - 2s - loss: 0.0459
Epoch 20/80
 - 2s - loss: 0.0448
Epoch 21/80
 - 2s - loss: 0.0437
Epoch 22/80
 - 2s - loss: 0.0429
Epoch 23/80
 - 2s - loss: 0.0421
Epoch 24/80
 - 2s - loss: 0.0414
Epoch 25/80
 - 2s - loss: 0.0408
Epoch 26/80
 - 2s - loss: 0.0403
Epoch 27/80
 - 2s - loss: 0.0399
Epoch 28/80
 - 2s - loss: 0.0395
Epoch 29/80
 - 2s - loss: 0.0392
Epoch 30/80
 - 2s - loss: 0.0389
Epoch 31/80
 - 2s - loss: 0.0386
Epoch 32/80
 - 2s - loss: 0.0384
Epoch 33/80
 - 2s - loss: 0.0382
Epoch 34/80
 - 2s - loss: 0.0380
Epoch 35/80
 - 2s - loss: 0.0378
Epoch 36/80
 - 2s - loss: 0.0377
Epoch 37/80
 - 2s - loss: 0.0375
Epoch 38/80
 - 2s - loss: 0.0374
Epoch 39/80
 - 2s - loss: 0.0373
Epoch 40/80
 - 2s - loss: 0.0372
Epoch 41/80
 - 2s - loss: 0.0371
Epoch 42/80
 - 2s - loss: 0.0370
Epoch 43/80
 - 2s - loss: 0.0369
Epoch 44/80
 - 2s - loss: 0.0368
Epoch 45/80
 - 2s - loss: 0.0368
Epoch 46/80
 - 2s - loss: 0.0367
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:05:55.039407: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:05:55.210052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:05:55.210098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:05:55.505538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:05:55.505592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:05:55.505601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:05:55.505881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6017
Epoch 2/80
 - 2s - loss: 0.0825
Epoch 3/80
 - 2s - loss: 0.0650
Epoch 4/80
 - 2s - loss: 0.0591
Epoch 5/80
 - 2s - loss: 0.0526
Epoch 6/80
 - 2s - loss: 0.0465
Epoch 7/80
 - 2s - loss: 0.0412
Epoch 8/80
 - 2s - loss: 0.0366
Epoch 9/80
 - 2s - loss: 0.0326
Epoch 10/80
 - 2s - loss: 0.0293
Epoch 11/80
 - 2s - loss: 0.0267
Epoch 12/80
 - 2s - loss: 0.0245
Epoch 13/80
 - 2s - loss: 0.0227
Epoch 14/80
 - 2s - loss: 0.0212
Epoch 15/80
 - 2s - loss: 0.0199
Epoch 16/80
 - 2s - loss: 0.0188
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:06:39.325296: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:06:39.492805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:06:39.492850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:06:39.791528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:06:39.791580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:06:39.791590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:06:39.791844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6018
Epoch 2/80
 - 2s - loss: 0.0827
Epoch 3/80
 - 2s - loss: 0.0635
Epoch 4/80
 - 2s - loss: 0.0557
Epoch 5/80
 - 2s - loss: 0.0491
Epoch 6/80
 - 2s - loss: 0.0442
Epoch 7/80
 - 2s - loss: 0.0400
Epoch 8/80
 - 2s - loss: 0.0363
Epoch 9/80
 - 2s - loss: 0.0329
Epoch 10/80
 - 2s - loss: 0.0297
Epoch 11/80
 - 2s - loss: 0.0270
Epoch 12/80
 - 2s - loss: 0.0247
Epoch 13/80
 - 2s - loss: 0.0228
Epoch 14/80
 - 2s - loss: 0.0212
Epoch 15/80
 - 2s - loss: 0.0199
Epoch 16/80
 - 2s - loss: 0.0188
Epoch 17/80
 - 2s - loss: 0.0179
Epoch 18/80
 - 2s - loss: 0.0171
Epoch 19/80
 - 2s - loss: 0.0165
Epoch 20/80
 - 2s - loss: 0.0159
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0146
Epoch 24/80
 - 2s - loss: 0.0142
Epoch 25/80
 - 2s - loss: 0.0139
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0128
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0123
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0121
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0118
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0112
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0111
Epoch 54/80
 - 2s - loss: 0.0111
Epoch 55/80
 - 2s - loss: 0.0111
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:08:43.942609: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:08:44.108057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:08:44.108102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:08:44.411237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:08:44.411301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:08:44.411311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:08:44.411589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6155
Epoch 2/80
 - 2s - loss: 0.0839
Epoch 3/80
 - 2s - loss: 0.0611
Epoch 4/80
 - 2s - loss: 0.0517
Epoch 5/80
 - 2s - loss: 0.0452
Epoch 6/80
 - 2s - loss: 0.0404
Epoch 7/80
 - 2s - loss: 0.0366
Epoch 8/80
 - 2s - loss: 0.0333
Epoch 9/80
 - 2s - loss: 0.0305
Epoch 10/80
 - 2s - loss: 0.0280
Epoch 11/80
 - 2s - loss: 0.0258
Epoch 12/80
 - 2s - loss: 0.0239
Epoch 13/80
 - 2s - loss: 0.0223
Epoch 14/80
 - 2s - loss: 0.0210
Epoch 15/80
 - 2s - loss: 0.0198
Epoch 16/80
 - 2s - loss: 0.0188
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0172
Epoch 19/80
 - 2s - loss: 0.0166
Epoch 20/80
 - 2s - loss: 0.0160
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0144
Epoch 25/80
 - 2s - loss: 0.0141
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0136
Epoch 28/80
 - 2s - loss: 0.0134
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0128
Epoch 33/80
 - 2s - loss: 0.0127
Epoch 34/80
 - 2s - loss: 0.0126
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0124
Epoch 38/80
 - 2s - loss: 0.0123
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0122
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0121
Epoch 43/80
 - 2s - loss: 0.0121
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0120
Epoch 46/80
 - 2s - loss: 0.0120
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0114
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0113
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0112
Epoch 56/80
 - 2s - loss: 0.0112
Epoch 57/80
 - 2s - loss: 0.0112
Epoch 58/80
 - 2s - loss: 0.0112
Epoch 59/80
 - 2s - loss: 0.0112
Epoch 60/80
 - 2s - loss: 0.0112
Epoch 61/80
 - 2s - loss: 0.0112
Epoch 62/80
 - 2s - loss: 0.0112
Epoch 63/80
 - 2s - loss: 0.0112
Epoch 64/80
 - 2s - loss: 0.0112
Epoch 65/80
 - 2s - loss: 0.0112
Epoch 66/80
 - 2s - loss: 0.0112
Epoch 67/80
 - 2s - loss: 0.0112
Epoch 68/80
 - 2s - loss: 0.0112
Epoch 69/80
 - 2s - loss: 0.0112
Epoch 70/80
 - 2s - loss: 0.0112
Epoch 71/80
 - 2s - loss: 0.0112
Epoch 72/80
 - 2s - loss: 0.0112
Epoch 73/80
 - 2s - loss: 0.0112
Epoch 74/80
 - 2s - loss: 0.0112
Epoch 75/80
 - 2s - loss: 0.0112
Epoch 76/80
 - 2s - loss: 0.0112
Epoch 77/80
 - 2s - loss: 0.0112
Epoch 78/80
 - 2s - loss: 0.0112
Epoch 79/80
 - 2s - loss: 0.0112
Epoch 80/80
 - 2s - loss: 0.0112
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 9.8349 - val_loss: 1.4682
AUC: 0.6819

Epoch 2/80
 - 0s - loss: 3.4876 - val_loss: 1.3071
AUC: 0.7928

Epoch 3/80
 - 0s - loss: 2.6485 - val_loss: 1.2273
AUC: 0.8109

Epoch 4/80
 - 0s - loss: 2.0326 - val_loss: 1.0265
AUC: 0.8267

Epoch 5/80
 - 0s - loss: 1.5877 - val_loss: 0.7016
AUC: 0.8346

Epoch 6/80
 - 0s - loss: 1.3415 - val_loss: 0.8003
AUC: 0.8398

Epoch 7/80
 - 0s - loss: 1.2435 - val_loss: 0.6883
AUC: 0.8407

Epoch 8/80
 - 0s - loss: 1.1803 - val_loss: 0.7032
AUC: 0.8451

Epoch 9/80
 - 0s - loss: 1.1477 - val_loss: 0.6899
AUC: 0.8472

Epoch 10/80
 - 0s - loss: 1.1196 - val_loss: 0.6806
AUC: 0.8494

Epoch 11/80
 - 0s - loss: 1.1124 - val_loss: 0.6564
AUC: 0.8524

Epoch 12/80
 - 0s - loss: 1.1011 - val_loss: 0.6744
AUC: 0.8543

Epoch 13/80
 - 0s - loss: 1.0837 - val_loss: 0.6483
AUC: 0.8543

Epoch 14/80
 - 0s - loss: 1.0871 - val_loss: 0.7218
AUC: 0.8578

Epoch 15/80
 - 0s - loss: 1.0681 - val_loss: 0.6526
AUC: 0.8584

Epoch 16/80
 - 0s - loss: 1.0592 - val_loss: 0.5995
AUC: 0.8554

Epoch 17/80
 - 0s - loss: 1.0639 - val_loss: 0.6753
AUC: 0.8596

Epoch 18/80
 - 0s - loss: 1.0521 - val_loss: 0.6363
AUC: 0.8594

Epoch 19/80
 - 0s - loss: 1.0468 - val_loss: 0.6387
AUC: 0.8599

Epoch 20/80
 - 0s - loss: 1.0435 - val_loss: 0.6480
AUC: 0.8608

Epoch 21/80
 - 0s - loss: 1.0363 - val_loss: 0.6282
AUC: 0.8609

Epoch 22/80
 - 0s - loss: 1.0410 - val_loss: 0.6732
AUC: 0.8613

Epoch 23/80
 - 0s - loss: 1.0360 - val_loss: 0.6062
AUC: 0.8606

Epoch 24/80
 - 0s - loss: 1.0261 - val_loss: 0.6058
AUC: 0.8620

Epoch 25/80
 - 0s - loss: 1.0250 - val_loss: 0.6224
AUC: 0.8623

Epoch 26/80
 - 0s - loss: 1.0224 - val_loss: 0.5891
AUC: 0.8616

Epoch 27/80
 - 0s - loss: 1.0192 - val_loss: 0.6058
AUC: 0.8628

Epoch 28/80
 - 0s - loss: 1.0151 - val_loss: 0.5370
AUC: 0.8612

Epoch 29/80
 - 0s - loss: 1.0170 - val_loss: 0.6149
AUC: 0.8631

Epoch 30/80
 - 0s - loss: 1.0085 - val_loss: 0.6238
AUC: 0.8636

Epoch 31/80
 - 0s - loss: 1.0070 - val_loss: 0.6723
AUC: 0.8646

Epoch 32/80
 - 0s - loss: 1.0043 - val_loss: 0.6285
AUC: 0.8644

Epoch 33/80
 - 0s - loss: 1.0052 - val_loss: 0.5999
AUC: 0.8637

Epoch 34/80
 - 0s - loss: 0.9959 - val_loss: 0.6449
AUC: 0.8645

Epoch 35/80
 - 0s - loss: 0.9958 - val_loss: 0.6152
AUC: 0.8648

Epoch 36/80
 - 0s - loss: 0.9954 - val_loss: 0.6196
AUC: 0.8646

Epoch 37/80
 - 0s - loss: 0.9899 - val_loss: 0.5551
AUC: 0.8639

Epoch 38/80
 - 0s - loss: 0.9901 - val_loss: 0.5837
AUC: 0.8642

Epoch 39/80
 - 0s - loss: 0.9799 - val_loss: 0.6187
AUC: 0.8649

Epoch 40/80
 - 0s - loss: 0.9867 - val_loss: 0.6140
AUC: 0.8652

Epoch 41/80
 - 0s - loss: 0.9778 - val_loss: 0.6115
AUC: 0.8651

Epoch 42/80
 - 0s - loss: 0.9817 - val_loss: 0.6217
AUC: 0.8655

Epoch 43/80
 - 0s - loss: 0.9781 - val_loss: 0.6288
AUC: 0.8655

Epoch 44/80
 - 0s - loss: 0.9787 - val_loss: 0.6008
AUC: 0.8652

Epoch 45/80
 - 0s - loss: 0.9798 - val_loss: 0.5943
AUC: 0.8648

Epoch 46/80
 - 0s - loss: 0.9723 - val_loss: 0.5918
AUC: 0.8651

Epoch 47/80
 - 0s - loss: 0.9769 - val_loss: 0.6101
AUC: 0.8656

Epoch 48/80
 - 0s - loss: 0.9735 - val_loss: 0.6273
AUC: 0.8657

Epoch 49/80
 - 0s - loss: 0.9732 - val_loss: 0.6033
AUC: 0.8655

Epoch 50/80
 - 0s - loss: 0.9711 - val_loss: 0.6066
AUC: 0.8655

Epoch 51/80
 - 0s - loss: 0.9755 - val_loss: 0.6046
AUC: 0.8654

Epoch 52/80
 - 0s - loss: 0.9774 - val_loss: 0.6013
AUC: 0.8654

Epoch 53/80
 - 0s - loss: 0.9751 - val_loss: 0.6082
AUC: 0.8655

Epoch 54/80
 - 0s - loss: 0.9724 - val_loss: 0.6106
AUC: 0.8655

Epoch 55/80
 - 0s - loss: 0.9711 - val_loss: 0.6089
AUC: 0.8655

Epoch 56/80
 - 0s - loss: 0.9708 - val_loss: 0.6087
AUC: 0.8655

Epoch 57/80
 - 0s - loss: 0.9750 - val_loss: 0.6023
AUC: 0.8655

Epoch 58/80
 - 0s - loss: 0.9795 - val_loss: 0.6097
AUC: 0.8656

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9792 - val_loss: 0.6093
AUC: 0.8660

Epoch 2/30
 - 0s - loss: 0.9713 - val_loss: 0.6065
AUC: 0.8659

Epoch 3/30
 - 0s - loss: 0.9781 - val_loss: 0.5903
AUC: 0.8656

Epoch 4/30
 - 0s - loss: 0.9667 - val_loss: 0.6215
AUC: 0.8661

Epoch 5/30
 - 0s - loss: 0.9701 - val_loss: 0.6100
AUC: 0.8663

Epoch 6/30
 - 0s - loss: 0.9658 - val_loss: 0.6098
AUC: 0.8664

Epoch 7/30
 - 0s - loss: 0.9618 - val_loss: 0.6192
AUC: 0.8667

Epoch 8/30
 - 0s - loss: 0.9621 - val_loss: 0.6008
AUC: 0.8667

Epoch 9/30
 - 0s - loss: 0.9611 - val_loss: 0.5929
AUC: 0.8666

Epoch 10/30
 - 0s - loss: 0.9600 - val_loss: 0.6126
AUC: 0.8668

Epoch 11/30
 - 0s - loss: 0.9548 - val_loss: 0.5975
AUC: 0.8670

Epoch 12/30
 - 0s - loss: 0.9577 - val_loss: 0.6060
AUC: 0.8670

Epoch 13/30
 - 0s - loss: 0.9547 - val_loss: 0.5807
AUC: 0.8669

Epoch 14/30
 - 0s - loss: 0.9518 - val_loss: 0.6105
AUC: 0.8671

Epoch 15/30
 - 0s - loss: 0.9535 - val_loss: 0.6044
AUC: 0.8672

Epoch 16/30
 - 0s - loss: 0.9510 - val_loss: 0.5994
AUC: 0.8674

Epoch 17/30
 - 0s - loss: 0.9480 - val_loss: 0.6001
AUC: 0.8675

Epoch 18/30
 - 0s - loss: 0.9459 - val_loss: 0.5905
AUC: 0.8675

Epoch 19/30
 - 0s - loss: 0.9446 - val_loss: 0.6003
AUC: 0.8674

Epoch 20/30
 - 0s - loss: 0.9413 - val_loss: 0.5943
AUC: 0.8677

Epoch 21/30
 - 0s - loss: 0.9396 - val_loss: 0.5749
AUC: 0.8675

Epoch 22/30
 - 0s - loss: 0.9428 - val_loss: 0.6016
AUC: 0.8680

Epoch 23/30
 - 0s - loss: 0.9415 - val_loss: 0.5886
AUC: 0.8678

Epoch 24/30
 - 0s - loss: 0.9338 - val_loss: 0.6033
AUC: 0.8681

Epoch 25/30
 - 0s - loss: 0.9346 - val_loss: 0.5884
AUC: 0.8680

Epoch 26/30
 - 0s - loss: 0.9370 - val_loss: 0.5828
AUC: 0.8680

Epoch 27/30
 - 0s - loss: 0.9356 - val_loss: 0.5864
AUC: 0.8682

Epoch 28/30
 - 0s - loss: 0.9343 - val_loss: 0.5800
AUC: 0.8684

Epoch 29/30
 - 0s - loss: 0.9322 - val_loss: 0.5905
AUC: 0.8685

Epoch 30/30
 - 0s - loss: 0.9281 - val_loss: 0.5832
Using TensorFlow backend.
AUC: 0.8683

2019-03-08 10:12:08.394965: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:12:08.560314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:12:08.560358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:12:08.857755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:12:08.857807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:12:08.857816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:12:08.858075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1904
Epoch 2/80
 - 2s - loss: 0.3152
Epoch 3/80
 - 2s - loss: 0.2719
Epoch 4/80
 - 2s - loss: 0.2344
Epoch 5/80
 - 2s - loss: 0.2103
Epoch 6/80
 - 2s - loss: 0.1896
Epoch 7/80
 - 2s - loss: 0.1721
Epoch 8/80
 - 2s - loss: 0.1581
Epoch 9/80
 - 2s - loss: 0.1466
Epoch 10/80
 - 2s - loss: 0.1371
Epoch 11/80
 - 2s - loss: 0.1297
Epoch 12/80
 - 2s - loss: 0.1236
Epoch 13/80
 - 2s - loss: 0.1186
Epoch 14/80
 - 2s - loss: 0.1144
Epoch 15/80
 - 2s - loss: 0.1107
Epoch 16/80
 - 2s - loss: 0.1075
Epoch 17/80
 - 2s - loss: 0.1047
Epoch 18/80
 - 2s - loss: 0.1023
Epoch 19/80
 - 2s - loss: 0.1002
Epoch 20/80
 - 2s - loss: 0.0984
Epoch 21/80
 - 2s - loss: 0.0969
Epoch 22/80
 - 2s - loss: 0.0955
Epoch 23/80
 - 2s - loss: 0.0943
Epoch 24/80
 - 2s - loss: 0.0933
Epoch 25/80
 - 2s - loss: 0.0925
Epoch 26/80
 - 2s - loss: 0.0918
Epoch 27/80
 - 2s - loss: 0.0911
Epoch 28/80
 - 2s - loss: 0.0906
Epoch 29/80
 - 2s - loss: 0.0901
Epoch 30/80
 - 2s - loss: 0.0897
Epoch 31/80
 - 2s - loss: 0.0893
Epoch 32/80
 - 2s - loss: 0.0890
Epoch 33/80
 - 2s - loss: 0.0886
Epoch 34/80
 - 2s - loss: 0.0884
Epoch 35/80
 - 2s - loss: 0.0881
Epoch 36/80
 - 2s - loss: 0.0879
Epoch 37/80
 - 2s - loss: 0.0877
Epoch 38/80
 - 2s - loss: 0.0874
Epoch 39/80
 - 2s - loss: 0.0873
Epoch 40/80
 - 2s - loss: 0.0871
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:13:34.754801: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:13:34.919406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:13:34.919451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:13:35.221971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:13:35.222022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:13:35.222031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:13:35.222320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1883
Epoch 2/80
 - 2s - loss: 0.3174
Epoch 3/80
 - 2s - loss: 0.2740
Epoch 4/80
 - 2s - loss: 0.2344
Epoch 5/80
 - 2s - loss: 0.2074
Epoch 6/80
 - 2s - loss: 0.1872
Epoch 7/80
 - 2s - loss: 0.1712
Epoch 8/80
 - 2s - loss: 0.1583
Epoch 9/80
 - 2s - loss: 0.1476
Epoch 10/80
 - 2s - loss: 0.1386
Epoch 11/80
 - 2s - loss: 0.1310
Epoch 12/80
 - 2s - loss: 0.1248
Epoch 13/80
 - 2s - loss: 0.1197
Epoch 14/80
 - 2s - loss: 0.1153
Epoch 15/80
 - 2s - loss: 0.1115
Epoch 16/80
 - 2s - loss: 0.1083
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:14:18.732516: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:14:18.900404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:14:18.900453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:14:19.200995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:14:19.201048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:14:19.201057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:14:19.201341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1968
Epoch 2/80
 - 2s - loss: 0.3154
Epoch 3/80
 - 2s - loss: 0.2715
Epoch 4/80
 - 2s - loss: 0.2340
Epoch 5/80
 - 2s - loss: 0.2090
Epoch 6/80
 - 2s - loss: 0.1889
Epoch 7/80
 - 2s - loss: 0.1724
Epoch 8/80
 - 2s - loss: 0.1590
Epoch 9/80
 - 2s - loss: 0.1479
Epoch 10/80
 - 2s - loss: 0.1386
Epoch 11/80
 - 2s - loss: 0.1309
Epoch 12/80
 - 2s - loss: 0.1247
Epoch 13/80
 - 2s - loss: 0.1194
Epoch 14/80
 - 2s - loss: 0.1151
Epoch 15/80
 - 2s - loss: 0.1114
Epoch 16/80
 - 2s - loss: 0.1082
Epoch 17/80
 - 2s - loss: 0.1054
Epoch 18/80
 - 2s - loss: 0.1029
Epoch 19/80
 - 2s - loss: 0.1009
Epoch 20/80
 - 2s - loss: 0.0990
Epoch 21/80
 - 2s - loss: 0.0974
Epoch 22/80
 - 2s - loss: 0.0960
Epoch 23/80
 - 2s - loss: 0.0948
Epoch 24/80
 - 2s - loss: 0.0938
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0921
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0909
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0900
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0892
Epoch 33/80
 - 2s - loss: 0.0889
Epoch 34/80
 - 2s - loss: 0.0886
Epoch 35/80
 - 2s - loss: 0.0884
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0879
Epoch 38/80
 - 2s - loss: 0.0877
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0874
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:15:44.591050: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:15:44.756059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:15:44.756102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:15:45.050396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:15:45.050466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:15:45.050490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:15:45.050744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2168
Epoch 2/80
 - 2s - loss: 0.3187
Epoch 3/80
 - 2s - loss: 0.2831
Epoch 4/80
 - 2s - loss: 0.2414
Epoch 5/80
 - 2s - loss: 0.2104
Epoch 6/80
 - 2s - loss: 0.1886
Epoch 7/80
 - 2s - loss: 0.1714
Epoch 8/80
 - 2s - loss: 0.1575
Epoch 9/80
 - 2s - loss: 0.1464
Epoch 10/80
 - 2s - loss: 0.1374
Epoch 11/80
 - 2s - loss: 0.1303
Epoch 12/80
 - 2s - loss: 0.1245
Epoch 13/80
 - 2s - loss: 0.1195
Epoch 14/80
 - 2s - loss: 0.1154
Epoch 15/80
 - 2s - loss: 0.1117
Epoch 16/80
 - 2s - loss: 0.1085
Epoch 17/80
 - 2s - loss: 0.1057
Epoch 18/80
 - 2s - loss: 0.1032
Epoch 19/80
 - 2s - loss: 0.1011
Epoch 20/80
 - 2s - loss: 0.0993
Epoch 21/80
 - 2s - loss: 0.0977
Epoch 22/80
 - 2s - loss: 0.0963
Epoch 23/80
 - 2s - loss: 0.0951
Epoch 24/80
 - 2s - loss: 0.0941
Epoch 25/80
 - 2s - loss: 0.0932
Epoch 26/80
 - 2s - loss: 0.0924
Epoch 27/80
 - 2s - loss: 0.0918
Epoch 28/80
 - 2s - loss: 0.0912
Epoch 29/80
 - 2s - loss: 0.0907
Epoch 30/80
 - 2s - loss: 0.0903
Epoch 31/80
 - 2s - loss: 0.0899
Epoch 32/80
 - 2s - loss: 0.0895
Epoch 33/80
 - 2s - loss: 0.0892
Epoch 34/80
 - 2s - loss: 0.0889
Epoch 35/80
 - 2s - loss: 0.0886
Epoch 36/80
 - 2s - loss: 0.0884
Epoch 37/80
 - 2s - loss: 0.0882
Epoch 38/80
 - 2s - loss: 0.0880
Epoch 39/80
 - 2s - loss: 0.0878
Epoch 40/80
 - 2s - loss: 0.0877
Epoch 41/80
 - 2s - loss: 0.0875
Epoch 42/80
 - 2s - loss: 0.0873
Epoch 43/80
 - 2s - loss: 0.0872
Epoch 44/80
 - 2s - loss: 0.0871
Epoch 45/80
 - 2s - loss: 0.0870
Epoch 46/80
 - 2s - loss: 0.0869
Epoch 47/80
 - 2s - loss: 0.0868
Epoch 48/80
 - 2s - loss: 0.0867
Epoch 49/80
 - 2s - loss: 0.0865
Epoch 50/80
 - 2s - loss: 0.0865
Epoch 51/80
 - 2s - loss: 0.0864
Epoch 52/80
 - 2s - loss: 0.0863
Epoch 53/80
 - 2s - loss: 0.0863
Epoch 54/80
 - 2s - loss: 0.0862
Epoch 55/80
 - 2s - loss: 0.0861
Epoch 56/80
 - 2s - loss: 0.0860
Epoch 57/80
 - 2s - loss: 0.0860
Epoch 58/80
 - 2s - loss: 0.0859
Epoch 59/80
 - 2s - loss: 0.0859
Epoch 60/80
 - 2s - loss: 0.0858
Epoch 61/80
 - 2s - loss: 0.0858
Epoch 62/80
 - 2s - loss: 0.0857
Epoch 63/80
 - 2s - loss: 0.0857
Epoch 64/80
 - 2s - loss: 0.0857
Epoch 65/80
 - 2s - loss: 0.0856
Epoch 66/80
 - 2s - loss: 0.0856
Epoch 67/80
 - 2s - loss: 0.0855
Epoch 68/80
 - 2s - loss: 0.0855
Epoch 69/80
 - 2s - loss: 0.0854
Epoch 70/80
 - 2s - loss: 0.0854
Epoch 71/80
 - 2s - loss: 0.0854
Epoch 72/80
 - 2s - loss: 0.0854
Epoch 73/80
 - 2s - loss: 0.0820
Epoch 74/80
 - 2s - loss: 0.0817
Epoch 75/80
 - 2s - loss: 0.0817
Epoch 76/80
 - 2s - loss: 0.0817
Epoch 77/80
 - 2s - loss: 0.0817
Epoch 78/80
 - 2s - loss: 0.0809
Epoch 79/80
 - 2s - loss: 0.0809
Epoch 80/80
 - 2s - loss: 0.0809
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4254 - val_loss: 1.0040
AUC: 0.8128

Epoch 2/80
 - 0s - loss: 1.8358 - val_loss: 0.8283
AUC: 0.8345

Epoch 3/80
 - 0s - loss: 1.3180 - val_loss: 0.7060
AUC: 0.8449

Epoch 4/80
 - 0s - loss: 1.1881 - val_loss: 0.7246
AUC: 0.8539

Epoch 5/80
 - 0s - loss: 1.1187 - val_loss: 0.6229
AUC: 0.8551

Epoch 6/80
 - 0s - loss: 1.0968 - val_loss: 0.6220
AUC: 0.8574

Epoch 7/80
 - 0s - loss: 1.0794 - val_loss: 0.7275
AUC: 0.8611

Epoch 8/80
 - 0s - loss: 1.0606 - val_loss: 0.6228
AUC: 0.8596

Epoch 9/80
 - 0s - loss: 1.0552 - val_loss: 0.6093
AUC: 0.8603

Epoch 10/80
 - 0s - loss: 1.0526 - val_loss: 0.5691
AUC: 0.8620

Epoch 11/80
 - 0s - loss: 1.0453 - val_loss: 0.6165
AUC: 0.8628

Epoch 12/80
 - 0s - loss: 1.0305 - val_loss: 0.6778
AUC: 0.8651

Epoch 13/80
 - 0s - loss: 1.0220 - val_loss: 0.5783
AUC: 0.8647

Epoch 14/80
 - 0s - loss: 1.0203 - val_loss: 0.6121
AUC: 0.8649

Epoch 15/80
 - 0s - loss: 1.0120 - val_loss: 0.5961
AUC: 0.8654

Epoch 16/80
 - 0s - loss: 1.0053 - val_loss: 0.6649
AUC: 0.8670

Epoch 17/80
 - 0s - loss: 1.0030 - val_loss: 0.5833
AUC: 0.8670

Epoch 18/80
 - 0s - loss: 0.9979 - val_loss: 0.6740
AUC: 0.8670

Epoch 19/80
 - 0s - loss: 0.9977 - val_loss: 0.6269
AUC: 0.8673

Epoch 20/80
 - 0s - loss: 0.9818 - val_loss: 0.6027
AUC: 0.8651

Epoch 21/80
 - 0s - loss: 0.9830 - val_loss: 0.6529
AUC: 0.8684

Epoch 22/80
 - 0s - loss: 0.9790 - val_loss: 0.6097
AUC: 0.8676

Epoch 23/80
 - 0s - loss: 0.9720 - val_loss: 0.6164
AUC: 0.8685

Epoch 24/80
 - 0s - loss: 0.9730 - val_loss: 0.6229
AUC: 0.8687

Epoch 25/80
 - 0s - loss: 0.9718 - val_loss: 0.6150
AUC: 0.8684

Epoch 26/80
 - 0s - loss: 0.9709 - val_loss: 0.5624
AUC: 0.8679

Epoch 27/80
 - 0s - loss: 0.9771 - val_loss: 0.6397
AUC: 0.8687

Epoch 28/80
 - 0s - loss: 0.9711 - val_loss: 0.6112
AUC: 0.8685

Epoch 29/80
 - 0s - loss: 0.9683 - val_loss: 0.6019
AUC: 0.8682

Epoch 30/80
 - 0s - loss: 0.9659 - val_loss: 0.6146
AUC: 0.8684

Epoch 31/80
 - 0s - loss: 0.9648 - val_loss: 0.6001
AUC: 0.8686

Epoch 32/80
 - 0s - loss: 0.9669 - val_loss: 0.6030
AUC: 0.8688

Epoch 33/80
 - 0s - loss: 0.9649 - val_loss: 0.6012
AUC: 0.8686

Epoch 34/80
 - 0s - loss: 0.9650 - val_loss: 0.5995
AUC: 0.8685

Epoch 35/80
 - 0s - loss: 0.9636 - val_loss: 0.5911
AUC: 0.8689

Epoch 36/80
 - 0s - loss: 0.9604 - val_loss: 0.5945
AUC: 0.8689

Epoch 37/80
 - 0s - loss: 0.9569 - val_loss: 0.6071
AUC: 0.8689

Epoch 38/80
 - 0s - loss: 0.9586 - val_loss: 0.5926
AUC: 0.8689

Epoch 39/80
 - 0s - loss: 0.9547 - val_loss: 0.6041
AUC: 0.8689

Epoch 40/80
 - 0s - loss: 0.9601 - val_loss: 0.6048
AUC: 0.8688

Epoch 41/80
 - 0s - loss: 0.9640 - val_loss: 0.6033
AUC: 0.8689

Epoch 42/80
 - 0s - loss: 0.9581 - val_loss: 0.6056
AUC: 0.8689

Epoch 43/80
 - 0s - loss: 0.9563 - val_loss: 0.6052
AUC: 0.8689

Epoch 44/80
 - 0s - loss: 0.9576 - val_loss: 0.5925
AUC: 0.8688

Epoch 45/80
 - 0s - loss: 0.9542 - val_loss: 0.6029
AUC: 0.8688

Epoch 46/80
 - 0s - loss: 0.9522 - val_loss: 0.5972
AUC: 0.8689

Epoch 47/80
 - 0s - loss: 0.9538 - val_loss: 0.5997
AUC: 0.8689

Epoch 48/80
 - 0s - loss: 0.9539 - val_loss: 0.6012
AUC: 0.8689

Epoch 49/80
 - 0s - loss: 0.9584 - val_loss: 0.5994
AUC: 0.8689

Epoch 50/80
 - 0s - loss: 0.9575 - val_loss: 0.6012
AUC: 0.8689

Epoch 51/80
 - 0s - loss: 0.9537 - val_loss: 0.6031
AUC: 0.8690

Epoch 52/80
 - 0s - loss: 0.9514 - val_loss: 0.6003
AUC: 0.8689

Epoch 53/80
 - 0s - loss: 0.9493 - val_loss: 0.6009
AUC: 0.8689

Epoch 54/80
 - 0s - loss: 0.9525 - val_loss: 0.6009
AUC: 0.8689

Epoch 55/80
 - 0s - loss: 0.9548 - val_loss: 0.6028
AUC: 0.8689

Epoch 56/80
 - 0s - loss: 0.9560 - val_loss: 0.6008
AUC: 0.8690

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9629 - val_loss: 0.6032
AUC: 0.8692

Epoch 2/30
 - 0s - loss: 0.9519 - val_loss: 0.6018
AUC: 0.8692

Epoch 3/30
 - 0s - loss: 0.9546 - val_loss: 0.6085
AUC: 0.8693

Epoch 4/30
 - 0s - loss: 0.9492 - val_loss: 0.5909
AUC: 0.8694

Epoch 5/30
 - 0s - loss: 0.9468 - val_loss: 0.6128
AUC: 0.8696

Epoch 6/30
 - 0s - loss: 0.9483 - val_loss: 0.6089
AUC: 0.8697

Epoch 7/30
 - 0s - loss: 0.9461 - val_loss: 0.6092
AUC: 0.8698

Epoch 8/30
 - 0s - loss: 0.9416 - val_loss: 0.5934
AUC: 0.8695

Epoch 9/30
 - 0s - loss: 0.9409 - val_loss: 0.5932
AUC: 0.8695

Epoch 10/30
 - 0s - loss: 0.9368 - val_loss: 0.5802
AUC: 0.8696

Epoch 11/30
 - 0s - loss: 0.9387 - val_loss: 0.6130
AUC: 0.8703

Epoch 12/30
 - 0s - loss: 0.9394 - val_loss: 0.5981
AUC: 0.8703

Epoch 13/30
 - 0s - loss: 0.9385 - val_loss: 0.6175
AUC: 0.8704

Epoch 14/30
 - 0s - loss: 0.9350 - val_loss: 0.5952
AUC: 0.8702

Epoch 15/30
 - 0s - loss: 0.9246 - val_loss: 0.5676
AUC: 0.8700

Epoch 16/30
 - 0s - loss: 0.9271 - val_loss: 0.6001
AUC: 0.8704

Epoch 17/30
 - 0s - loss: 0.9217 - val_loss: 0.5906
AUC: 0.8701

Epoch 18/30
 - 0s - loss: 0.9261 - val_loss: 0.5989
AUC: 0.8705

Epoch 19/30
 - 0s - loss: 0.9264 - val_loss: 0.5895
AUC: 0.8702

Epoch 20/30
 - 0s - loss: 0.9199 - val_loss: 0.5960
AUC: 0.8706

Epoch 21/30
 - 0s - loss: 0.9208 - val_loss: 0.5758
AUC: 0.8703

Epoch 22/30
 - 0s - loss: 0.9191 - val_loss: 0.5870
AUC: 0.8707

Epoch 23/30
 - 0s - loss: 0.9171 - val_loss: 0.5847
AUC: 0.8707

Epoch 24/30
 - 0s - loss: 0.9078 - val_loss: 0.5516
AUC: 0.8701

Epoch 25/30
 - 0s - loss: 0.9141 - val_loss: 0.5833
AUC: 0.8707

Epoch 26/30
 - 0s - loss: 0.9064 - val_loss: 0.5798
AUC: 0.8705

Epoch 27/30
 - 0s - loss: 0.9041 - val_loss: 0.5856
AUC: 0.8706

Epoch 28/30
 - 0s - loss: 0.9065 - val_loss: 0.5858
AUC: 0.8703

Epoch 29/30
 - 0s - loss: 0.9073 - val_loss: 0.5861
AUC: 0.8705

Epoch 30/30
 - 0s - loss: 0.9062 - val_loss: 0.5804
Using TensorFlow backend.
AUC: 0.8708

2019-03-08 10:19:10.502119: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:19:10.668680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:19:10.668791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:19:10.964297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:19:10.964360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:19:10.964369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:19:10.964644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0035
Epoch 2/80
 - 2s - loss: 0.1792
Epoch 3/80
 - 2s - loss: 0.1485
Epoch 4/80
 - 2s - loss: 0.1277
Epoch 5/80
 - 2s - loss: 0.1123
Epoch 6/80
 - 2s - loss: 0.1002
Epoch 7/80
 - 2s - loss: 0.0906
Epoch 8/80
 - 2s - loss: 0.0827
Epoch 9/80
 - 2s - loss: 0.0759
Epoch 10/80
 - 2s - loss: 0.0701
Epoch 11/80
 - 2s - loss: 0.0653
Epoch 12/80
 - 2s - loss: 0.0614
Epoch 13/80
 - 2s - loss: 0.0580
Epoch 14/80
 - 2s - loss: 0.0553
Epoch 15/80
 - 2s - loss: 0.0529
Epoch 16/80
 - 2s - loss: 0.0508
Epoch 17/80
 - 2s - loss: 0.0490
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0461
Epoch 20/80
 - 2s - loss: 0.0450
Epoch 21/80
 - 2s - loss: 0.0440
Epoch 22/80
 - 2s - loss: 0.0431
Epoch 23/80
 - 2s - loss: 0.0423
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0405
Epoch 27/80
 - 2s - loss: 0.0401
Epoch 28/80
 - 2s - loss: 0.0397
Epoch 29/80
 - 2s - loss: 0.0393
Epoch 30/80
 - 2s - loss: 0.0391
Epoch 31/80
 - 2s - loss: 0.0388
Epoch 32/80
 - 2s - loss: 0.0386
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0382
Epoch 35/80
 - 2s - loss: 0.0380
Epoch 36/80
 - 2s - loss: 0.0378
Epoch 37/80
 - 2s - loss: 0.0377
Epoch 38/80
 - 2s - loss: 0.0376
Epoch 39/80
 - 2s - loss: 0.0375
Epoch 40/80
 - 2s - loss: 0.0373
Epoch 41/80
 - 2s - loss: 0.0372
Epoch 42/80
 - 2s - loss: 0.0372
Epoch 43/80
 - 2s - loss: 0.0371
Epoch 44/80
 - 2s - loss: 0.0370
Epoch 45/80
 - 2s - loss: 0.0369
Epoch 46/80
 - 2s - loss: 0.0369
Epoch 47/80
 - 2s - loss: 0.0368
Epoch 48/80
 - 2s - loss: 0.0368
Epoch 49/80
 - 2s - loss: 0.0367
Epoch 50/80
 - 2s - loss: 0.0367
Epoch 51/80
 - 2s - loss: 0.0366
Epoch 52/80
 - 2s - loss: 0.0366
Epoch 53/80
 - 2s - loss: 0.0365
Epoch 54/80
 - 2s - loss: 0.0365
Epoch 55/80
 - 2s - loss: 0.0364
Epoch 56/80
 - 2s - loss: 0.0364
Epoch 57/80
 - 2s - loss: 0.0364
Epoch 58/80
 - 2s - loss: 0.0364
Epoch 59/80
 - 2s - loss: 0.0363
Epoch 60/80
 - 2s - loss: 0.0363
Epoch 61/80
 - 2s - loss: 0.0348
Epoch 62/80
 - 2s - loss: 0.0346
Epoch 63/80
 - 2s - loss: 0.0346
Epoch 64/80
 - 2s - loss: 0.0346
Epoch 65/80
 - 2s - loss: 0.0346
Epoch 66/80
 - 2s - loss: 0.0342
Epoch 67/80
 - 2s - loss: 0.0342
Epoch 68/80
 - 2s - loss: 0.0342
Epoch 69/80
 - 2s - loss: 0.0342
Epoch 70/80
 - 2s - loss: 0.0341
Epoch 71/80
 - 2s - loss: 0.0341
Epoch 72/80
 - 2s - loss: 0.0341
Epoch 73/80
 - 2s - loss: 0.0341
Epoch 74/80
 - 2s - loss: 0.0341
Epoch 75/80
 - 2s - loss: 0.0341
Epoch 76/80
 - 2s - loss: 0.0341
Epoch 77/80
 - 2s - loss: 0.0341
Epoch 78/80
 - 2s - loss: 0.0341
Epoch 79/80
 - 2s - loss: 0.0341
Epoch 80/80
 - 2s - loss: 0.0341
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0781 - val_loss: 1.1735
AUC: 0.8125

Epoch 2/80
 - 0s - loss: 1.7098 - val_loss: 0.7508
AUC: 0.8320

Epoch 3/80
 - 0s - loss: 1.2601 - val_loss: 0.6455
AUC: 0.8392

Epoch 4/80
 - 0s - loss: 1.1528 - val_loss: 0.6702
AUC: 0.8432

Epoch 5/80
 - 0s - loss: 1.1086 - val_loss: 0.6208
AUC: 0.8460

Epoch 6/80
 - 0s - loss: 1.0848 - val_loss: 0.7042
AUC: 0.8507

Epoch 7/80
 - 0s - loss: 1.0662 - val_loss: 0.6374
AUC: 0.8534

Epoch 8/80
 - 0s - loss: 1.0602 - val_loss: 0.6352
AUC: 0.8524

Epoch 9/80
 - 0s - loss: 1.0415 - val_loss: 0.6206
AUC: 0.8561

Epoch 10/80
 - 0s - loss: 1.0343 - val_loss: 0.6368
AUC: 0.8565

Epoch 11/80
 - 0s - loss: 1.0259 - val_loss: 0.6195
AUC: 0.8572

Epoch 12/80
 - 0s - loss: 1.0257 - val_loss: 0.5884
AUC: 0.8587

Epoch 13/80
 - 0s - loss: 1.0151 - val_loss: 0.6427
AUC: 0.8602

Epoch 14/80
 - 0s - loss: 1.0090 - val_loss: 0.6430
AUC: 0.8604

Epoch 15/80
 - 0s - loss: 1.0077 - val_loss: 0.6357
AUC: 0.8613

Epoch 16/80
 - 0s - loss: 0.9913 - val_loss: 0.6352
AUC: 0.8615

Epoch 17/80
 - 0s - loss: 0.9937 - val_loss: 0.6429
AUC: 0.8617

Epoch 18/80
 - 0s - loss: 0.9824 - val_loss: 0.6421
AUC: 0.8630

Epoch 19/80
 - 0s - loss: 0.9823 - val_loss: 0.6367
AUC: 0.8631

Epoch 20/80
 - 0s - loss: 0.9792 - val_loss: 0.5774
AUC: 0.8623

Epoch 21/80
 - 0s - loss: 0.9791 - val_loss: 0.6069
AUC: 0.8627

Epoch 22/80
 - 0s - loss: 0.9678 - val_loss: 0.5422
AUC: 0.8616

Epoch 23/80
 - 0s - loss: 0.9677 - val_loss: 0.6017
AUC: 0.8636

Epoch 24/80
 - 0s - loss: 0.9666 - val_loss: 0.6439
AUC: 0.8654

Epoch 25/80
 - 0s - loss: 0.9638 - val_loss: 0.5884
AUC: 0.8645

Epoch 26/80
 - 0s - loss: 0.9632 - val_loss: 0.6700
AUC: 0.8655

Epoch 27/80
 - 0s - loss: 0.9595 - val_loss: 0.6196
AUC: 0.8651

Epoch 28/80
 - 0s - loss: 0.9490 - val_loss: 0.6379
AUC: 0.8656

Epoch 29/80
 - 0s - loss: 0.9522 - val_loss: 0.6258
AUC: 0.8651

Epoch 30/80
 - 0s - loss: 0.9496 - val_loss: 0.5871
AUC: 0.8662

Epoch 31/80
 - 0s - loss: 0.9522 - val_loss: 0.5984
AUC: 0.8662

Epoch 32/80
 - 0s - loss: 0.9406 - val_loss: 0.5923
AUC: 0.8657

Epoch 33/80
 - 0s - loss: 0.9288 - val_loss: 0.5886
AUC: 0.8674

Epoch 34/80
 - 0s - loss: 0.9268 - val_loss: 0.5891
AUC: 0.8678

Epoch 35/80
 - 0s - loss: 0.9237 - val_loss: 0.6195
AUC: 0.8678

Epoch 36/80
 - 0s - loss: 0.9235 - val_loss: 0.5831
AUC: 0.8674

Epoch 37/80
 - 0s - loss: 0.9238 - val_loss: 0.5741
AUC: 0.8669

Epoch 38/80
 - 0s - loss: 0.9246 - val_loss: 0.5912
AUC: 0.8676

Epoch 39/80
 - 0s - loss: 0.9215 - val_loss: 0.5989
AUC: 0.8674

Epoch 40/80
 - 0s - loss: 0.9195 - val_loss: 0.5802
AUC: 0.8672

Epoch 41/80
 - 0s - loss: 0.9152 - val_loss: 0.5603
AUC: 0.8668

Epoch 42/80
 - 0s - loss: 0.9179 - val_loss: 0.5844
AUC: 0.8673

Epoch 43/80
 - 0s - loss: 0.9175 - val_loss: 0.5951
AUC: 0.8676

Epoch 44/80
 - 0s - loss: 0.9183 - val_loss: 0.5836
AUC: 0.8674

Epoch 45/80
 - 0s - loss: 0.9180 - val_loss: 0.5756
AUC: 0.8673

Epoch 46/80
 - 0s - loss: 0.9156 - val_loss: 0.5882
AUC: 0.8676

Epoch 47/80
 - 0s - loss: 0.9220 - val_loss: 0.5821
AUC: 0.8675

Epoch 48/80
 - 0s - loss: 0.9139 - val_loss: 0.5780
AUC: 0.8674

Epoch 49/80
 - 0s - loss: 0.9190 - val_loss: 0.5944
AUC: 0.8677

Epoch 50/80
 - 0s - loss: 0.9205 - val_loss: 0.5962
AUC: 0.8677

Epoch 51/80
 - 0s - loss: 0.9120 - val_loss: 0.5858
AUC: 0.8677

Epoch 52/80
 - 0s - loss: 0.9138 - val_loss: 0.5904
AUC: 0.8677

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9199 - val_loss: 0.5888
AUC: 0.8674

Epoch 2/30
 - 0s - loss: 0.9201 - val_loss: 0.5619
AUC: 0.8669

Epoch 3/30
 - 0s - loss: 0.9177 - val_loss: 0.5851
AUC: 0.8675

Epoch 4/30
 - 0s - loss: 0.9159 - val_loss: 0.5846
AUC: 0.8676

Epoch 5/30
 - 0s - loss: 0.9168 - val_loss: 0.5675
AUC: 0.8674

Epoch 6/30
 - 0s - loss: 0.9101 - val_loss: 0.5888
AUC: 0.8678

Epoch 7/30
 - 0s - loss: 0.9130 - val_loss: 0.5704
AUC: 0.8675

Epoch 8/30
 - 0s - loss: 0.9116 - val_loss: 0.5770
AUC: 0.8678

Epoch 9/30
 - 0s - loss: 0.9145 - val_loss: 0.5845
AUC: 0.8680

Epoch 10/30
 - 0s - loss: 0.9071 - val_loss: 0.5768
AUC: 0.8679

Epoch 11/30
 - 0s - loss: 0.9115 - val_loss: 0.5778
AUC: 0.8678

Epoch 12/30
 - 0s - loss: 0.9043 - val_loss: 0.5965
AUC: 0.8684

Epoch 13/30
 - 0s - loss: 0.8973 - val_loss: 0.5793
AUC: 0.8680

Epoch 14/30
 - 0s - loss: 0.8992 - val_loss: 0.5760
AUC: 0.8679

Epoch 15/30
 - 0s - loss: 0.8982 - val_loss: 0.5815
AUC: 0.8681

Epoch 16/30
 - 0s - loss: 0.8971 - val_loss: 0.5781
AUC: 0.8680

Epoch 17/30
 - 0s - loss: 0.8989 - val_loss: 0.5771
AUC: 0.8680

Epoch 18/30
 - 0s - loss: 0.9009 - val_loss: 0.5833
AUC: 0.8682

Epoch 19/30
 - 0s - loss: 0.8982 - val_loss: 0.5826
AUC: 0.8682

Epoch 20/30
 - 0s - loss: 0.8958 - val_loss: 0.5770
AUC: 0.8681

Epoch 21/30
 - 0s - loss: 0.8972 - val_loss: 0.5755
AUC: 0.8681

Epoch 22/30
 - 0s - loss: 0.8976 - val_loss: 0.5823
AUC: 0.8682

Epoch 23/30
 - 0s - loss: 0.9002 - val_loss: 0.5809
AUC: 0.8682

Epoch 24/30
 - 0s - loss: 0.9008 - val_loss: 0.5807
AUC: 0.8682

Epoch 25/30
 - 0s - loss: 0.8944 - val_loss: 0.5784
AUC: 0.8681

Epoch 26/30
 - 0s - loss: 0.8999 - val_loss: 0.5790
AUC: 0.8681

Epoch 27/30
 - 0s - loss: 0.8995 - val_loss: 0.5784
AUC: 0.8681

Epoch 28/30
 - 0s - loss: 0.8945 - val_loss: 0.5787
AUC: 0.8681

Epoch 29/30
 - 0s - loss: 0.8994 - val_loss: 0.5785
AUC: 0.8681

Epoch 30/30
 - 0s - loss: 0.8940 - val_loss: 0.5783
Using TensorFlow backend.
AUC: 0.8681

2019-03-08 10:22:33.787666: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:22:33.965214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:22:33.965260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:22:34.259484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:22:34.259536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:22:34.259545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:22:34.259800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9996
Epoch 2/80
 - 2s - loss: 0.1804
Epoch 3/80
 - 2s - loss: 0.1514
Epoch 4/80
 - 2s - loss: 0.1314
Epoch 5/80
 - 2s - loss: 0.1161
Epoch 6/80
 - 2s - loss: 0.1039
Epoch 7/80
 - 2s - loss: 0.0932
Epoch 8/80
 - 2s - loss: 0.0841
Epoch 9/80
 - 2s - loss: 0.0767
Epoch 10/80
 - 2s - loss: 0.0706
Epoch 11/80
 - 2s - loss: 0.0656
Epoch 12/80
 - 2s - loss: 0.0615
Epoch 13/80
 - 2s - loss: 0.0581
Epoch 14/80
 - 2s - loss: 0.0553
Epoch 15/80
 - 2s - loss: 0.0530
Epoch 16/80
 - 2s - loss: 0.0509
Epoch 17/80
 - 2s - loss: 0.0491
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0462
Epoch 20/80
 - 2s - loss: 0.0450
Epoch 21/80
 - 2s - loss: 0.0440
Epoch 22/80
 - 2s - loss: 0.0431
Epoch 23/80
 - 2s - loss: 0.0423
Epoch 24/80
 - 2s - loss: 0.0417
Epoch 25/80
 - 2s - loss: 0.0411
Epoch 26/80
 - 2s - loss: 0.0406
Epoch 27/80
 - 2s - loss: 0.0402
Epoch 28/80
 - 2s - loss: 0.0398
Epoch 29/80
 - 2s - loss: 0.0394
Epoch 30/80
 - 2s - loss: 0.0392
Epoch 31/80
 - 2s - loss: 0.0389
Epoch 32/80
 - 2s - loss: 0.0387
Epoch 33/80
 - 2s - loss: 0.0385
Epoch 34/80
 - 2s - loss: 0.0383
Epoch 35/80
 - 2s - loss: 0.0381
Epoch 36/80
 - 2s - loss: 0.0380
Epoch 37/80
 - 2s - loss: 0.0379
Epoch 38/80
 - 2s - loss: 0.0377
Epoch 39/80
 - 2s - loss: 0.0376
Epoch 40/80
 - 2s - loss: 0.0375
Epoch 41/80
 - 2s - loss: 0.0374
Epoch 42/80
 - 2s - loss: 0.0373
Epoch 43/80
 - 2s - loss: 0.0372
Epoch 44/80
 - 2s - loss: 0.0372
Epoch 45/80
 - 2s - loss: 0.0371
Epoch 46/80
 - 2s - loss: 0.0371
Epoch 47/80
 - 2s - loss: 0.0370
Epoch 48/80
 - 2s - loss: 0.0369
Epoch 49/80
 - 2s - loss: 0.0369
Epoch 50/80
 - 2s - loss: 0.0368
Epoch 51/80
 - 2s - loss: 0.0368
Epoch 52/80
 - 2s - loss: 0.0367
Epoch 53/80
 - 2s - loss: 0.0367
Epoch 54/80
 - 2s - loss: 0.0367
Epoch 55/80
 - 2s - loss: 0.0366
Epoch 56/80
 - 2s - loss: 0.0366
Epoch 57/80
 - 2s - loss: 0.0365
Epoch 58/80
 - 2s - loss: 0.0365
Epoch 59/80
 - 2s - loss: 0.0350
Epoch 60/80
 - 2s - loss: 0.0348
Epoch 61/80
 - 2s - loss: 0.0348
Epoch 62/80
 - 2s - loss: 0.0348
Epoch 63/80
 - 2s - loss: 0.0348
Epoch 64/80
 - 2s - loss: 0.0345
Epoch 65/80
 - 2s - loss: 0.0344
Epoch 66/80
 - 2s - loss: 0.0344
Epoch 67/80
 - 2s - loss: 0.0344
Epoch 68/80
 - 2s - loss: 0.0343
Epoch 69/80
 - 2s - loss: 0.0343
Epoch 70/80
 - 2s - loss: 0.0343
Epoch 71/80
 - 2s - loss: 0.0343
Epoch 72/80
 - 2s - loss: 0.0343
Epoch 73/80
 - 2s - loss: 0.0343
Epoch 74/80
 - 2s - loss: 0.0343
Epoch 75/80
 - 2s - loss: 0.0343
Epoch 76/80
 - 2s - loss: 0.0343
Epoch 77/80
 - 2s - loss: 0.0343
Epoch 78/80
 - 2s - loss: 0.0343
Epoch 79/80
 - 2s - loss: 0.0343
Epoch 80/80
 - 2s - loss: 0.0343
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.5907 - val_loss: 1.5886
AUC: 0.7827

Epoch 2/80
 - 0s - loss: 2.9504 - val_loss: 1.0187
AUC: 0.8121

Epoch 3/80
 - 0s - loss: 2.0398 - val_loss: 0.9450
AUC: 0.8378

Epoch 4/80
 - 0s - loss: 1.5551 - val_loss: 0.7509
AUC: 0.8423

Epoch 5/80
 - 0s - loss: 1.3254 - val_loss: 0.6509
AUC: 0.8462

Epoch 6/80
 - 0s - loss: 1.2188 - val_loss: 0.7068
AUC: 0.8534

Epoch 7/80
 - 0s - loss: 1.1875 - val_loss: 0.7256
AUC: 0.8543

Epoch 8/80
 - 0s - loss: 1.1609 - val_loss: 0.7073
AUC: 0.8568

Epoch 9/80
 - 0s - loss: 1.1112 - val_loss: 0.6902
AUC: 0.8616

Epoch 10/80
 - 0s - loss: 1.1145 - val_loss: 0.6926
AUC: 0.8620

Epoch 11/80
 - 0s - loss: 1.0979 - val_loss: 0.6981
AUC: 0.8625

Epoch 12/80
 - 0s - loss: 1.0733 - val_loss: 0.6310
AUC: 0.8638

Epoch 13/80
 - 0s - loss: 1.0705 - val_loss: 0.6085
AUC: 0.8638

Epoch 14/80
 - 0s - loss: 1.0672 - val_loss: 0.6957
AUC: 0.8683

Epoch 15/80
 - 0s - loss: 1.0600 - val_loss: 0.6312
AUC: 0.8673

Epoch 16/80
 - 0s - loss: 1.0452 - val_loss: 0.6033
AUC: 0.8686

Epoch 17/80
 - 0s - loss: 1.0426 - val_loss: 0.6760
AUC: 0.8696

Epoch 18/80
 - 0s - loss: 1.0427 - val_loss: 0.6639
AUC: 0.8699

Epoch 19/80
 - 0s - loss: 1.0347 - val_loss: 0.6734
AUC: 0.8704

Epoch 20/80
 - 0s - loss: 1.0292 - val_loss: 0.6673
AUC: 0.8711

Epoch 21/80
 - 0s - loss: 1.0247 - val_loss: 0.6232
AUC: 0.8711

Epoch 22/80
 - 0s - loss: 1.0201 - val_loss: 0.6712
AUC: 0.8722

Epoch 23/80
 - 0s - loss: 1.0110 - val_loss: 0.6110
AUC: 0.8718

Epoch 24/80
 - 0s - loss: 1.0103 - val_loss: 0.6416
AUC: 0.8713

Epoch 25/80
 - 0s - loss: 1.0079 - val_loss: 0.6914
AUC: 0.8730

Epoch 26/80
 - 0s - loss: 1.0044 - val_loss: 0.6195
AUC: 0.8719

Epoch 27/80
 - 0s - loss: 1.0003 - val_loss: 0.6179
AUC: 0.8724

Epoch 28/80
 - 0s - loss: 0.9935 - val_loss: 0.6293
AUC: 0.8728

Epoch 29/80
 - 0s - loss: 0.9942 - val_loss: 0.6216
AUC: 0.8728

Epoch 30/80
 - 0s - loss: 0.9906 - val_loss: 0.6341
AUC: 0.8734

Epoch 31/80
 - 0s - loss: 0.9868 - val_loss: 0.6121
AUC: 0.8729

Epoch 32/80
 - 0s - loss: 0.9923 - val_loss: 0.6258
AUC: 0.8729

Epoch 33/80
 - 0s - loss: 0.9912 - val_loss: 0.6327
AUC: 0.8733

Epoch 34/80
 - 0s - loss: 0.9875 - val_loss: 0.6055
AUC: 0.8730

Epoch 35/80
 - 0s - loss: 0.9802 - val_loss: 0.6086
AUC: 0.8731

Epoch 36/80
 - 0s - loss: 0.9872 - val_loss: 0.5967
AUC: 0.8728

Epoch 37/80
 - 0s - loss: 0.9917 - val_loss: 0.6175
AUC: 0.8732

Epoch 38/80
 - 0s - loss: 0.9843 - val_loss: 0.6386
AUC: 0.8739

Epoch 39/80
 - 0s - loss: 0.9865 - val_loss: 0.6081
AUC: 0.8734

Epoch 40/80
 - 0s - loss: 0.9832 - val_loss: 0.6359
AUC: 0.8738

Epoch 41/80
 - 0s - loss: 0.9842 - val_loss: 0.6131
AUC: 0.8734

Epoch 42/80
 - 0s - loss: 0.9824 - val_loss: 0.5932
AUC: 0.8732

Epoch 43/80
 - 0s - loss: 0.9789 - val_loss: 0.5909
AUC: 0.8735

Epoch 44/80
 - 0s - loss: 0.9821 - val_loss: 0.5684
AUC: 0.8728

Epoch 45/80
 - 0s - loss: 0.9875 - val_loss: 0.6224
AUC: 0.8737

Epoch 46/80
 - 0s - loss: 0.9870 - val_loss: 0.5962
AUC: 0.8735

Epoch 47/80
 - 0s - loss: 0.9786 - val_loss: 0.6443
AUC: 0.8743

Epoch 48/80
 - 0s - loss: 0.9787 - val_loss: 0.5842
AUC: 0.8737

Epoch 49/80
 - 0s - loss: 0.9809 - val_loss: 0.6144
AUC: 0.8737

Epoch 50/80
 - 0s - loss: 0.9769 - val_loss: 0.5862
AUC: 0.8735

Epoch 51/80
 - 0s - loss: 0.9734 - val_loss: 0.6060
AUC: 0.8741

Epoch 52/80
 - 0s - loss: 0.9682 - val_loss: 0.5869
AUC: 0.8736

Epoch 53/80
 - 0s - loss: 0.9708 - val_loss: 0.5965
AUC: 0.8743

Epoch 54/80
 - 0s - loss: 0.9746 - val_loss: 0.6119
AUC: 0.8744

Epoch 55/80
 - 0s - loss: 0.9717 - val_loss: 0.6080
AUC: 0.8744

Epoch 56/80
 - 0s - loss: 0.9701 - val_loss: 0.6046
AUC: 0.8743

Epoch 57/80
 - 0s - loss: 0.9643 - val_loss: 0.6001
AUC: 0.8742

Epoch 58/80
 - 0s - loss: 0.9693 - val_loss: 0.5996
AUC: 0.8741

Epoch 59/80
 - 0s - loss: 0.9682 - val_loss: 0.5939
AUC: 0.8739

Epoch 60/80
 - 0s - loss: 0.9729 - val_loss: 0.5960
AUC: 0.8740

Epoch 61/80
 - 0s - loss: 0.9680 - val_loss: 0.6008
AUC: 0.8742

Epoch 62/80
 - 0s - loss: 0.9691 - val_loss: 0.5990
AUC: 0.8741

Epoch 63/80
 - 0s - loss: 0.9713 - val_loss: 0.6021
AUC: 0.8742

Epoch 64/80
 - 0s - loss: 0.9662 - val_loss: 0.5978
AUC: 0.8742

Epoch 65/80
 - 0s - loss: 0.9707 - val_loss: 0.5990
AUC: 0.8742

Epoch 66/80
 - 0s - loss: 0.9706 - val_loss: 0.6003
AUC: 0.8742

Epoch 67/80
 - 0s - loss: 0.9642 - val_loss: 0.5985
AUC: 0.8742

Epoch 68/80
 - 0s - loss: 0.9642 - val_loss: 0.5986
AUC: 0.8742

Epoch 69/80
 - 0s - loss: 0.9716 - val_loss: 0.6013
AUC: 0.8743

Epoch 70/80
 - 0s - loss: 0.9674 - val_loss: 0.5994
AUC: 0.8742

Epoch 71/80
 - 0s - loss: 0.9713 - val_loss: 0.5984
AUC: 0.8742

Epoch 72/80
 - 0s - loss: 0.9678 - val_loss: 0.5982
AUC: 0.8742

Epoch 73/80
 - 0s - loss: 0.9682 - val_loss: 0.5981
AUC: 0.8742

Epoch 74/80
 - 0s - loss: 0.9681 - val_loss: 0.6004
AUC: 0.8743

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9766 - val_loss: 0.6036
AUC: 0.8743

Epoch 2/30
 - 0s - loss: 0.9704 - val_loss: 0.6034
AUC: 0.8745

Epoch 3/30
 - 0s - loss: 0.9689 - val_loss: 0.5980
AUC: 0.8745

Epoch 4/30
 - 0s - loss: 0.9721 - val_loss: 0.5957
AUC: 0.8745

Epoch 5/30
 - 0s - loss: 0.9695 - val_loss: 0.5736
AUC: 0.8742

Epoch 6/30
 - 0s - loss: 0.9585 - val_loss: 0.5880
AUC: 0.8749

Epoch 7/30
 - 0s - loss: 0.9561 - val_loss: 0.5918
AUC: 0.8752

Epoch 8/30
 - 0s - loss: 0.9614 - val_loss: 0.5827
AUC: 0.8749

Epoch 9/30
 - 0s - loss: 0.9586 - val_loss: 0.5949
AUC: 0.8754

Epoch 10/30
 - 0s - loss: 0.9509 - val_loss: 0.6031
AUC: 0.8756

Epoch 11/30
 - 0s - loss: 0.9519 - val_loss: 0.5895
AUC: 0.8754

Epoch 12/30
 - 0s - loss: 0.9490 - val_loss: 0.5857
AUC: 0.8758

Epoch 13/30
 - 0s - loss: 0.9515 - val_loss: 0.5983
AUC: 0.8757

Epoch 14/30
 - 0s - loss: 0.9434 - val_loss: 0.6038
AUC: 0.8760

Epoch 15/30
 - 0s - loss: 0.9461 - val_loss: 0.6107
AUC: 0.8762

Epoch 16/30
 - 0s - loss: 0.9458 - val_loss: 0.5871
AUC: 0.8759

Epoch 17/30
 - 0s - loss: 0.9422 - val_loss: 0.5906
AUC: 0.8760

Epoch 18/30
 - 0s - loss: 0.9413 - val_loss: 0.5914
AUC: 0.8760

Epoch 19/30
 - 0s - loss: 0.9442 - val_loss: 0.5894
AUC: 0.8759

Epoch 20/30
 - 0s - loss: 0.9470 - val_loss: 0.5876
AUC: 0.8759

Epoch 21/30
 - 0s - loss: 0.9381 - val_loss: 0.5887
AUC: 0.8759

Epoch 22/30
 - 0s - loss: 0.9387 - val_loss: 0.5899
AUC: 0.8759

Epoch 23/30
 - 0s - loss: 0.9428 - val_loss: 0.5853
AUC: 0.8758

Epoch 24/30
 - 0s - loss: 0.9400 - val_loss: 0.5877
AUC: 0.8758

Epoch 25/30
 - 0s - loss: 0.9402 - val_loss: 0.5859
AUC: 0.8758

Epoch 26/30
 - 0s - loss: 0.9407 - val_loss: 0.5869
AUC: 0.8758

Epoch 27/30
 - 0s - loss: 0.9396 - val_loss: 0.5869
AUC: 0.8758

Epoch 28/30
 - 0s - loss: 0.9354 - val_loss: 0.5881
AUC: 0.8759

Epoch 29/30
 - 0s - loss: 0.9393 - val_loss: 0.5880
AUC: 0.8759

Epoch 30/30
 - 0s - loss: 0.9439 - val_loss: 0.5883
Using TensorFlow backend.
AUC: 0.8759

2019-03-08 10:26:11.507965: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:26:11.672370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:26:11.672415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:26:11.972403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:26:11.972464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:26:11.972474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:26:11.972732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9888
Epoch 2/80
 - 2s - loss: 0.1815
Epoch 3/80
 - 2s - loss: 0.1591
Epoch 4/80
 - 2s - loss: 0.1382
Epoch 5/80
 - 2s - loss: 0.1200
Epoch 6/80
 - 2s - loss: 0.1060
Epoch 7/80
 - 2s - loss: 0.0947
Epoch 8/80
 - 2s - loss: 0.0855
Epoch 9/80
 - 2s - loss: 0.0779
Epoch 10/80
 - 2s - loss: 0.0716
Epoch 11/80
 - 2s - loss: 0.0663
Epoch 12/80
 - 2s - loss: 0.0619
Epoch 13/80
 - 2s - loss: 0.0583
Epoch 14/80
 - 2s - loss: 0.0554
Epoch 15/80
 - 2s - loss: 0.0528
Epoch 16/80
 - 2s - loss: 0.0507
Epoch 17/80
 - 2s - loss: 0.0489
Epoch 18/80
 - 2s - loss: 0.0473
Epoch 19/80
 - 2s - loss: 0.0460
Epoch 20/80
 - 2s - loss: 0.0448
Epoch 21/80
 - 2s - loss: 0.0438
Epoch 22/80
 - 2s - loss: 0.0429
Epoch 23/80
 - 2s - loss: 0.0422
Epoch 24/80
 - 2s - loss: 0.0415
Epoch 25/80
 - 2s - loss: 0.0409
Epoch 26/80
 - 2s - loss: 0.0404
Epoch 27/80
 - 2s - loss: 0.0400
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:27:18.169419: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:27:18.331297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:27:18.331342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:27:18.630039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:27:18.630098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:27:18.630107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:27:18.630366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5893
Epoch 2/80
 - 2s - loss: 0.0838
Epoch 3/80
 - 2s - loss: 0.0663
Epoch 4/80
 - 2s - loss: 0.0614
Epoch 5/80
 - 2s - loss: 0.0559
Epoch 6/80
 - 2s - loss: 0.0497
Epoch 7/80
 - 2s - loss: 0.0436
Epoch 8/80
 - 2s - loss: 0.0381
Epoch 9/80
 - 2s - loss: 0.0338
Epoch 10/80
 - 2s - loss: 0.0302
Epoch 11/80
 - 2s - loss: 0.0274
Epoch 12/80
 - 2s - loss: 0.0250
Epoch 13/80
 - 2s - loss: 0.0231
Epoch 14/80
 - 2s - loss: 0.0214
Epoch 15/80
 - 2s - loss: 0.0201
Epoch 16/80
 - 2s - loss: 0.0190
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0172
Epoch 19/80
 - 2s - loss: 0.0165
Epoch 20/80
 - 2s - loss: 0.0159
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0146
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0128
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0114
Epoch 47/80
 - 2s - loss: 0.0113
Epoch 48/80
 - 2s - loss: 0.0113
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0112
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0112
Epoch 56/80
 - 2s - loss: 0.0112
Epoch 57/80
 - 2s - loss: 0.0112
Epoch 58/80
 - 2s - loss: 0.0112
Epoch 59/80
 - 2s - loss: 0.0112
Epoch 60/80
 - 2s - loss: 0.0112
Epoch 61/80
 - 2s - loss: 0.0112
Epoch 62/80
 - 2s - loss: 0.0112
Epoch 63/80
 - 2s - loss: 0.0112
Epoch 64/80
 - 2s - loss: 0.0112
Epoch 65/80
 - 2s - loss: 0.0112
Epoch 66/80
 - 2s - loss: 0.0112
Epoch 67/80
 - 2s - loss: 0.0112
Epoch 68/80
 - 2s - loss: 0.0112
Epoch 69/80
 - 2s - loss: 0.0112
Epoch 70/80
 - 2s - loss: 0.0112
Epoch 71/80
 - 2s - loss: 0.0112
Epoch 72/80
 - 2s - loss: 0.0112
Epoch 73/80
 - 2s - loss: 0.0112
Epoch 74/80
 - 2s - loss: 0.0112
Epoch 75/80
 - 2s - loss: 0.0112
Epoch 76/80
 - 2s - loss: 0.0112
Epoch 77/80
 - 2s - loss: 0.0112
Epoch 78/80
 - 2s - loss: 0.0112
Epoch 79/80
 - 2s - loss: 0.0112
Epoch 80/80
 - 2s - loss: 0.0112
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.7392 - val_loss: 1.2399
AUC: 0.7672

Epoch 2/80
 - 0s - loss: 2.7265 - val_loss: 0.9580
AUC: 0.8118

Epoch 3/80
 - 0s - loss: 1.7586 - val_loss: 0.8793
AUC: 0.8325

Epoch 4/80
 - 0s - loss: 1.3222 - val_loss: 0.7246
AUC: 0.8368

Epoch 5/80
 - 0s - loss: 1.2087 - val_loss: 0.7439
AUC: 0.8410

Epoch 6/80
 - 0s - loss: 1.1490 - val_loss: 0.6387
AUC: 0.8427

Epoch 7/80
 - 0s - loss: 1.1169 - val_loss: 0.6928
AUC: 0.8472

Epoch 8/80
 - 0s - loss: 1.1072 - val_loss: 0.7138
AUC: 0.8509

Epoch 9/80
 - 0s - loss: 1.0926 - val_loss: 0.6306
AUC: 0.8517

Epoch 10/80
 - 0s - loss: 1.0747 - val_loss: 0.6075
AUC: 0.8526

Epoch 11/80
 - 0s - loss: 1.0587 - val_loss: 0.6829
AUC: 0.8557

Epoch 12/80
 - 0s - loss: 1.0504 - val_loss: 0.6125
AUC: 0.8550

Epoch 13/80
 - 0s - loss: 1.0437 - val_loss: 0.6150
AUC: 0.8568

Epoch 14/80
 - 0s - loss: 1.0375 - val_loss: 0.6192
AUC: 0.8556

Epoch 15/80
 - 0s - loss: 1.0342 - val_loss: 0.6490
AUC: 0.8589

Epoch 16/80
 - 0s - loss: 1.0206 - val_loss: 0.6738
AUC: 0.8604

Epoch 17/80
 - 0s - loss: 1.0229 - val_loss: 0.6610
AUC: 0.8606

Epoch 18/80
 - 0s - loss: 1.0125 - val_loss: 0.6528
AUC: 0.8612

Epoch 19/80
 - 0s - loss: 1.0088 - val_loss: 0.6505
AUC: 0.8610

Epoch 20/80
 - 0s - loss: 1.0136 - val_loss: 0.6127
AUC: 0.8613

Epoch 21/80
 - 0s - loss: 0.9945 - val_loss: 0.6172
AUC: 0.8620

Epoch 22/80
 - 0s - loss: 0.9981 - val_loss: 0.6092
AUC: 0.8618

Epoch 23/80
 - 0s - loss: 0.9944 - val_loss: 0.5849
AUC: 0.8614

Epoch 24/80
 - 0s - loss: 0.9908 - val_loss: 0.6300
AUC: 0.8625

Epoch 25/80
 - 0s - loss: 0.9917 - val_loss: 0.6089
AUC: 0.8624

Epoch 26/80
 - 0s - loss: 0.9914 - val_loss: 0.5998
AUC: 0.8622

Epoch 27/80
 - 0s - loss: 0.9934 - val_loss: 0.6231
AUC: 0.8629

Epoch 28/80
 - 0s - loss: 0.9844 - val_loss: 0.6119
AUC: 0.8627

Epoch 29/80
 - 0s - loss: 0.9857 - val_loss: 0.6276
AUC: 0.8630

Epoch 30/80
 - 0s - loss: 0.9880 - val_loss: 0.6011
AUC: 0.8625

Epoch 31/80
 - 0s - loss: 0.9846 - val_loss: 0.6077
AUC: 0.8631

Epoch 32/80
 - 0s - loss: 0.9810 - val_loss: 0.5938
AUC: 0.8628

Epoch 33/80
 - 0s - loss: 0.9784 - val_loss: 0.6065
AUC: 0.8628

Epoch 34/80
 - 0s - loss: 0.9786 - val_loss: 0.6040
AUC: 0.8628

Epoch 35/80
 - 0s - loss: 0.9799 - val_loss: 0.6088
AUC: 0.8629

Epoch 36/80
 - 0s - loss: 0.9787 - val_loss: 0.6068
AUC: 0.8630

Epoch 37/80
 - 0s - loss: 0.9719 - val_loss: 0.6095
AUC: 0.8631

Epoch 38/80
 - 0s - loss: 0.9780 - val_loss: 0.6068
AUC: 0.8631

Epoch 39/80
 - 0s - loss: 0.9761 - val_loss: 0.6007
AUC: 0.8629

Epoch 40/80
 - 0s - loss: 0.9782 - val_loss: 0.6059
AUC: 0.8632

Epoch 41/80
 - 0s - loss: 0.9752 - val_loss: 0.6112
AUC: 0.8632

Epoch 42/80
 - 0s - loss: 0.9776 - val_loss: 0.6099
AUC: 0.8633

Epoch 43/80
 - 0s - loss: 0.9840 - val_loss: 0.6121
AUC: 0.8634

Epoch 44/80
 - 0s - loss: 0.9792 - val_loss: 0.6093
AUC: 0.8633

Epoch 45/80
 - 0s - loss: 0.9779 - val_loss: 0.6068
AUC: 0.8633

Epoch 46/80
 - 0s - loss: 0.9788 - val_loss: 0.6073
AUC: 0.8633

Epoch 47/80
 - 0s - loss: 0.9729 - val_loss: 0.6067
AUC: 0.8633

Epoch 48/80
 - 0s - loss: 0.9770 - val_loss: 0.6059
AUC: 0.8633

Epoch 49/80
 - 0s - loss: 0.9763 - val_loss: 0.6079
AUC: 0.8633

Epoch 50/80
 - 0s - loss: 0.9762 - val_loss: 0.6062
AUC: 0.8633

Epoch 51/80
 - 0s - loss: 0.9771 - val_loss: 0.6064
AUC: 0.8633

Epoch 52/80
 - 0s - loss: 0.9830 - val_loss: 0.6077
AUC: 0.8633

Epoch 53/80
 - 0s - loss: 0.9780 - val_loss: 0.6082
AUC: 0.8634

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9757 - val_loss: 0.5903
AUC: 0.8630

Epoch 2/30
 - 0s - loss: 0.9834 - val_loss: 0.6205
AUC: 0.8637

Epoch 3/30
 - 0s - loss: 0.9751 - val_loss: 0.6072
AUC: 0.8639

Epoch 4/30
 - 0s - loss: 0.9634 - val_loss: 0.6026
AUC: 0.8639

Epoch 5/30
 - 0s - loss: 0.9736 - val_loss: 0.6101
AUC: 0.8643

Epoch 6/30
 - 0s - loss: 0.9667 - val_loss: 0.5952
AUC: 0.8640

Epoch 7/30
 - 0s - loss: 0.9679 - val_loss: 0.5954
AUC: 0.8638

Epoch 8/30
 - 0s - loss: 0.9613 - val_loss: 0.5909
AUC: 0.8638

Epoch 9/30
 - 0s - loss: 0.9682 - val_loss: 0.6087
AUC: 0.8644

Epoch 10/30
 - 0s - loss: 0.9593 - val_loss: 0.5920
AUC: 0.8641

Epoch 11/30
 - 0s - loss: 0.9594 - val_loss: 0.5884
AUC: 0.8643

Epoch 12/30
 - 0s - loss: 0.9587 - val_loss: 0.6179
AUC: 0.8650

Epoch 13/30
 - 0s - loss: 0.9553 - val_loss: 0.6055
AUC: 0.8644

Epoch 14/30
 - 0s - loss: 0.9476 - val_loss: 0.6137
AUC: 0.8649

Epoch 15/30
 - 0s - loss: 0.9503 - val_loss: 0.6014
AUC: 0.8648

Epoch 16/30
 - 0s - loss: 0.9478 - val_loss: 0.6048
AUC: 0.8651

Epoch 17/30
 - 0s - loss: 0.9503 - val_loss: 0.5939
AUC: 0.8648

Epoch 18/30
 - 0s - loss: 0.9464 - val_loss: 0.5854
AUC: 0.8647

Epoch 19/30
 - 0s - loss: 0.9450 - val_loss: 0.5883
AUC: 0.8650

Epoch 20/30
 - 0s - loss: 0.9385 - val_loss: 0.5813
AUC: 0.8649

Epoch 21/30
 - 0s - loss: 0.9338 - val_loss: 0.5997
AUC: 0.8653

Epoch 22/30
 - 0s - loss: 0.9404 - val_loss: 0.6049
AUC: 0.8654

Epoch 23/30
 - 0s - loss: 0.9356 - val_loss: 0.6131
AUC: 0.8655

Epoch 24/30
 - 0s - loss: 0.9325 - val_loss: 0.5818
AUC: 0.8651

Epoch 25/30
 - 0s - loss: 0.9229 - val_loss: 0.5617
AUC: 0.8646

Epoch 26/30
 - 0s - loss: 0.9316 - val_loss: 0.6028
AUC: 0.8656

Epoch 27/30
 - 0s - loss: 0.9326 - val_loss: 0.5869
AUC: 0.8653

Epoch 28/30
 - 0s - loss: 0.9245 - val_loss: 0.5958
AUC: 0.8654

Epoch 29/30
 - 0s - loss: 0.9258 - val_loss: 0.5794
AUC: 0.8652

Epoch 30/30
 - 0s - loss: 0.9249 - val_loss: 0.5822
Using TensorFlow backend.
AUC: 0.8652

2019-03-08 10:30:39.494561: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:30:39.659906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:30:39.659950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:30:39.961207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:30:39.961258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:30:39.961268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:30:39.961548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5940
Epoch 2/80
 - 2s - loss: 0.0819
Epoch 3/80
 - 2s - loss: 0.0647
Epoch 4/80
 - 2s - loss: 0.0586
Epoch 5/80
 - 2s - loss: 0.0529
Epoch 6/80
 - 2s - loss: 0.0473
Epoch 7/80
 - 2s - loss: 0.0420
Epoch 8/80
 - 2s - loss: 0.0374
Epoch 9/80
 - 2s - loss: 0.0334
Epoch 10/80
 - 2s - loss: 0.0300
Epoch 11/80
 - 2s - loss: 0.0272
Epoch 12/80
 - 2s - loss: 0.0249
Epoch 13/80
 - 2s - loss: 0.0229
Epoch 14/80
 - 2s - loss: 0.0213
Epoch 15/80
 - 2s - loss: 0.0200
Epoch 16/80
 - 2s - loss: 0.0189
Epoch 17/80
 - 2s - loss: 0.0179
Epoch 18/80
 - 2s - loss: 0.0171
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:31:25.943665: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:31:26.109094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:31:26.109131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:31:26.411877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:31:26.411928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:31:26.411937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:31:26.412257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6074
Epoch 2/80
 - 2s - loss: 0.0833
Epoch 3/80
 - 2s - loss: 0.0653
Epoch 4/80
 - 2s - loss: 0.0597
Epoch 5/80
 - 2s - loss: 0.0534
Epoch 6/80
 - 2s - loss: 0.0471
Epoch 7/80
 - 2s - loss: 0.0418
Epoch 8/80
 - 2s - loss: 0.0374
Epoch 9/80
 - 2s - loss: 0.0335
Epoch 10/80
 - 2s - loss: 0.0301
Epoch 11/80
 - 2s - loss: 0.0272
Epoch 12/80
 - 2s - loss: 0.0249
Epoch 13/80
 - 2s - loss: 0.0229
Epoch 14/80
 - 2s - loss: 0.0214
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b9ec9bc36a0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 10:32:10.337801: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:32:10.503772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:32:10.503815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:32:10.802629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:32:10.802681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:32:10.802690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:32:10.802944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2099
Epoch 2/80
 - 2s - loss: 0.3153
Epoch 3/80
 - 2s - loss: 0.2760
Epoch 4/80
 - 2s - loss: 0.2395
Epoch 5/80
 - 2s - loss: 0.2104
Epoch 6/80
 - 2s - loss: 0.1892
Epoch 7/80
 - 2s - loss: 0.1721
Epoch 8/80
 - 2s - loss: 0.1583
Epoch 9/80
 - 2s - loss: 0.1471
Epoch 10/80
 - 2s - loss: 0.1381
Epoch 11/80
 - 2s - loss: 0.1308
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 10:32:45.624346: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:32:45.788517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:32:45.788562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:32:46.087750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:32:46.087802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:32:46.087811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:32:46.088065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1984
Epoch 2/80
 - 2s - loss: 0.3096
Epoch 3/80
 - 2s - loss: 0.2623
Epoch 4/80
 - 2s - loss: 0.2318
Epoch 5/80
 - 2s - loss: 0.2076
Epoch 6/80
 - 2s - loss: 0.1877
Epoch 7/80
 - 2s - loss: 0.1711
Epoch 8/80
 - 2s - loss: 0.1578
Epoch 9/80
 - 2s - loss: 0.1468
Epoch 10/80
 - 2s - loss: 0.1377
Epoch 11/80
 - 2s - loss: 0.1303
Epoch 12/80
 - 2s - loss: 0.1243
Epoch 13/80
 - 2s - loss: 0.1192
Epoch 14/80
 - 2s - loss: 0.1149
Epoch 15/80
 - 2s - loss: 0.1111
Epoch 16/80
 - 2s - loss: 0.1079
Epoch 17/80
 - 2s - loss: 0.1050
Epoch 18/80
 - 2s - loss: 0.1025
Epoch 19/80
 - 2s - loss: 0.1004
Epoch 20/80
 - 2s - loss: 0.0986
Epoch 21/80
 - 2s - loss: 0.0970
Epoch 22/80
 - 2s - loss: 0.0957
Epoch 23/80
 - 2s - loss: 0.0944
Epoch 24/80
 - 2s - loss: 0.0935
Epoch 25/80
 - 2s - loss: 0.0926
Epoch 26/80
 - 2s - loss: 0.0920
Epoch 27/80
 - 2s - loss: 0.0913
Epoch 28/80
 - 2s - loss: 0.0908
Epoch 29/80
 - 2s - loss: 0.0903
Epoch 30/80
 - 2s - loss: 0.0899
Epoch 31/80
 - 2s - loss: 0.0895
Epoch 32/80
 - 2s - loss: 0.0892
Epoch 33/80
 - 2s - loss: 0.0888
Epoch 34/80
 - 2s - loss: 0.0886
Epoch 35/80
 - 2s - loss: 0.0883
Epoch 36/80
 - 2s - loss: 0.0881
Epoch 37/80
 - 2s - loss: 0.0879
Epoch 38/80
 - 2s - loss: 0.0877
Epoch 39/80
 - 2s - loss: 0.0875
Epoch 40/80
 - 2s - loss: 0.0874
Epoch 41/80
 - 2s - loss: 0.0872
Epoch 42/80
 - 2s - loss: 0.0871
Epoch 43/80
 - 2s - loss: 0.0869
Epoch 44/80
 - 2s - loss: 0.0869
Epoch 45/80
 - 2s - loss: 0.0868
Epoch 46/80
 - 2s - loss: 0.0866
Epoch 47/80
 - 2s - loss: 0.0865
Epoch 48/80
 - 2s - loss: 0.0864
Epoch 49/80
 - 2s - loss: 0.0864
Epoch 50/80
 - 2s - loss: 0.0863
Epoch 51/80
 - 2s - loss: 0.0862
Epoch 52/80
 - 2s - loss: 0.0862
Epoch 53/80
 - 2s - loss: 0.0861
Epoch 54/80
 - 2s - loss: 0.0860
Epoch 55/80
 - 2s - loss: 0.0859
Epoch 56/80
 - 2s - loss: 0.0859
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0858
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0857
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:34:42.337391: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:34:42.502996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:34:42.503039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:34:42.800807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:34:42.800858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:34:42.800867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:34:42.801120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2109
Epoch 2/80
 - 2s - loss: 0.3171
Epoch 3/80
 - 2s - loss: 0.2770
Epoch 4/80
 - 2s - loss: 0.2353
Epoch 5/80
 - 2s - loss: 0.2074
Epoch 6/80
 - 2s - loss: 0.1874
Epoch 7/80
 - 2s - loss: 0.1711
Epoch 8/80
 - 2s - loss: 0.1579
Epoch 9/80
 - 2s - loss: 0.1469
Epoch 10/80
 - 2s - loss: 0.1381
Epoch 11/80
 - 2s - loss: 0.1308
Epoch 12/80
 - 2s - loss: 0.1248
Epoch 13/80
 - 2s - loss: 0.1198
Epoch 14/80
 - 2s - loss: 0.1155
Epoch 15/80
 - 2s - loss: 0.1119
Epoch 16/80
 - 2s - loss: 0.1087
Epoch 17/80
 - 2s - loss: 0.1059
Epoch 18/80
 - 2s - loss: 0.1035
Epoch 19/80
 - 2s - loss: 0.1014
Epoch 20/80
 - 2s - loss: 0.0995
Epoch 21/80
 - 2s - loss: 0.0979
Epoch 22/80
 - 2s - loss: 0.0965
Epoch 23/80
 - 2s - loss: 0.0953
Epoch 24/80
 - 2s - loss: 0.0942
Epoch 25/80
 - 2s - loss: 0.0933
Epoch 26/80
 - 2s - loss: 0.0925
Epoch 27/80
 - 2s - loss: 0.0918
Epoch 28/80
 - 2s - loss: 0.0913
Epoch 29/80
 - 2s - loss: 0.0908
Epoch 30/80
 - 2s - loss: 0.0903
Epoch 31/80
 - 2s - loss: 0.0899
Epoch 32/80
 - 2s - loss: 0.0895
Epoch 33/80
 - 2s - loss: 0.0892
Epoch 34/80
 - 2s - loss: 0.0889
Epoch 35/80
 - 2s - loss: 0.0886
Epoch 36/80
 - 2s - loss: 0.0884
Epoch 37/80
 - 2s - loss: 0.0881
Epoch 38/80
 - 2s - loss: 0.0880
Epoch 39/80
 - 2s - loss: 0.0877
Epoch 40/80
 - 2s - loss: 0.0876
Epoch 41/80
 - 2s - loss: 0.0874
Epoch 42/80
 - 2s - loss: 0.0873
Epoch 43/80
 - 2s - loss: 0.0871
Epoch 44/80
 - 2s - loss: 0.0870
Epoch 45/80
 - 2s - loss: 0.0869
Epoch 46/80
 - 2s - loss: 0.0868
Epoch 47/80
 - 2s - loss: 0.0866
Epoch 48/80
 - 2s - loss: 0.0865
Epoch 49/80
 - 2s - loss: 0.0865
Epoch 50/80
 - 2s - loss: 0.0864
Epoch 51/80
 - 2s - loss: 0.0863
Epoch 52/80
 - 2s - loss: 0.0862
Epoch 53/80
 - 2s - loss: 0.0861
Epoch 54/80
 - 2s - loss: 0.0861
Epoch 55/80
 - 2s - loss: 0.0860
Epoch 56/80
 - 2s - loss: 0.0859
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0858
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0857
Epoch 61/80
 - 2s - loss: 0.0857
Epoch 62/80
 - 2s - loss: 0.0856
Epoch 63/80
 - 2s - loss: 0.0856
Epoch 64/80
 - 2s - loss: 0.0855
Epoch 65/80
 - 2s - loss: 0.0855
Epoch 66/80
 - 2s - loss: 0.0854
Epoch 67/80
 - 2s - loss: 0.0854
Epoch 68/80
 - 2s - loss: 0.0854
Epoch 69/80
 - 2s - loss: 0.0853
Epoch 70/80
 - 2s - loss: 0.0853
Epoch 71/80
 - 2s - loss: 0.0852
Epoch 72/80
 - 2s - loss: 0.0852
Epoch 73/80
 - 2s - loss: 0.0819
Epoch 74/80
 - 2s - loss: 0.0816
Epoch 75/80
 - 2s - loss: 0.0815
Epoch 76/80
 - 2s - loss: 0.0815
Epoch 77/80
 - 2s - loss: 0.0815
Epoch 78/80
 - 2s - loss: 0.0807
Epoch 79/80
 - 2s - loss: 0.0807
Epoch 80/80
 - 2s - loss: 0.0807
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.2995 - val_loss: 0.8477
AUC: 0.8255

Epoch 2/80
 - 0s - loss: 1.3004 - val_loss: 0.7040
AUC: 0.8439

Epoch 3/80
 - 0s - loss: 1.1773 - val_loss: 0.6489
AUC: 0.8503

Epoch 4/80
 - 0s - loss: 1.1130 - val_loss: 0.6205
AUC: 0.8544

Epoch 5/80
 - 0s - loss: 1.0888 - val_loss: 0.6931
AUC: 0.8586

Epoch 6/80
 - 0s - loss: 1.0571 - val_loss: 0.6382
AUC: 0.8585

Epoch 7/80
 - 0s - loss: 1.0470 - val_loss: 0.6338
AUC: 0.8612

Epoch 8/80
 - 0s - loss: 1.0396 - val_loss: 0.6396
AUC: 0.8621

Epoch 9/80
 - 0s - loss: 1.0267 - val_loss: 0.7205
AUC: 0.8651

Epoch 10/80
 - 0s - loss: 1.0275 - val_loss: 0.7077
AUC: 0.8651

Epoch 11/80
 - 0s - loss: 1.0183 - val_loss: 0.6058
AUC: 0.8649

Epoch 12/80
 - 0s - loss: 1.0127 - val_loss: 0.6122
AUC: 0.8640

Epoch 13/80
 - 0s - loss: 1.0034 - val_loss: 0.6647
AUC: 0.8653

Epoch 14/80
 - 0s - loss: 0.9993 - val_loss: 0.6559
AUC: 0.8681

Epoch 15/80
 - 0s - loss: 0.9928 - val_loss: 0.5555
AUC: 0.8648

Epoch 16/80
 - 0s - loss: 0.9890 - val_loss: 0.6790
AUC: 0.8668

Epoch 17/80
 - 0s - loss: 0.9875 - val_loss: 0.6304
AUC: 0.8682

Epoch 18/80
 - 0s - loss: 0.9777 - val_loss: 0.6610
AUC: 0.8678

Epoch 19/80
 - 0s - loss: 0.9807 - val_loss: 0.5804
AUC: 0.8674

Epoch 20/80
 - 0s - loss: 0.9718 - val_loss: 0.6467
AUC: 0.8681

Epoch 21/80
 - 0s - loss: 0.9750 - val_loss: 0.6368
AUC: 0.8684

Epoch 22/80
 - 0s - loss: 0.9704 - val_loss: 0.6211
AUC: 0.8671

Epoch 23/80
 - 0s - loss: 0.9671 - val_loss: 0.7098
AUC: 0.8688

Epoch 24/80
 - 0s - loss: 0.9646 - val_loss: 0.5405
AUC: 0.8679

Epoch 25/80
 - 0s - loss: 0.9517 - val_loss: 0.5962
AUC: 0.8671

Epoch 26/80
 - 0s - loss: 0.9599 - val_loss: 0.5825
AUC: 0.8682

Epoch 27/80
 - 0s - loss: 0.9575 - val_loss: 0.6522
AUC: 0.8696

Epoch 28/80
 - 0s - loss: 0.9472 - val_loss: 0.6095
AUC: 0.8679

Epoch 29/80
 - 0s - loss: 0.9420 - val_loss: 0.6939
AUC: 0.8709

Epoch 30/80
 - 0s - loss: 0.9458 - val_loss: 0.5343
AUC: 0.8667

Epoch 31/80
 - 0s - loss: 0.9341 - val_loss: 0.6298
AUC: 0.8691

Epoch 32/80
 - 0s - loss: 0.9365 - val_loss: 0.5073
AUC: 0.8666

Epoch 33/80
 - 0s - loss: 0.9332 - val_loss: 0.6649
AUC: 0.8709

Epoch 34/80
 - 0s - loss: 0.9301 - val_loss: 0.5720
AUC: 0.8681

Epoch 35/80
 - 0s - loss: 0.9290 - val_loss: 0.6022
AUC: 0.8701

Epoch 36/80
 - 0s - loss: 0.9257 - val_loss: 0.6389
AUC: 0.8697

Epoch 37/80
 - 0s - loss: 0.9224 - val_loss: 0.5614
AUC: 0.8684

Epoch 38/80
 - 0s - loss: 0.9146 - val_loss: 0.6665
AUC: 0.8693

Epoch 39/80
 - 0s - loss: 0.9130 - val_loss: 0.5984
AUC: 0.8694

Epoch 40/80
 - 0s - loss: 0.9198 - val_loss: 0.5088
AUC: 0.8674

Epoch 41/80
 - 0s - loss: 0.9050 - val_loss: 0.5388
AUC: 0.8684

Epoch 42/80
 - 0s - loss: 0.9071 - val_loss: 0.5948
AUC: 0.8689

Epoch 43/80
 - 0s - loss: 0.8870 - val_loss: 0.5600
AUC: 0.8688

Epoch 44/80
 - 0s - loss: 0.8834 - val_loss: 0.5563
AUC: 0.8688

Epoch 45/80
 - 0s - loss: 0.8829 - val_loss: 0.5737
AUC: 0.8694

Epoch 46/80
 - 0s - loss: 0.8849 - val_loss: 0.5595
AUC: 0.8691

Epoch 47/80
 - 0s - loss: 0.8826 - val_loss: 0.5491
AUC: 0.8686

Epoch 48/80
 - 0s - loss: 0.8793 - val_loss: 0.5601
AUC: 0.8686

Epoch 49/80
 - 0s - loss: 0.8786 - val_loss: 0.5479
AUC: 0.8687

Epoch 50/80
 - 0s - loss: 0.8720 - val_loss: 0.5972
AUC: 0.8695

Epoch 51/80
 - 0s - loss: 0.8802 - val_loss: 0.5650
AUC: 0.8693

Epoch 52/80
 - 0s - loss: 0.8716 - val_loss: 0.6117
AUC: 0.8697

Epoch 53/80
 - 0s - loss: 0.8755 - val_loss: 0.5675
AUC: 0.8692

Epoch 54/80
 - 0s - loss: 0.8704 - val_loss: 0.5674
AUC: 0.8691

Epoch 55/80
 - 0s - loss: 0.8731 - val_loss: 0.5683
AUC: 0.8692

Epoch 56/80
 - 0s - loss: 0.8720 - val_loss: 0.5696
AUC: 0.8692

Epoch 57/80
 - 0s - loss: 0.8731 - val_loss: 0.5611
AUC: 0.8690

Epoch 58/80
 - 0s - loss: 0.8716 - val_loss: 0.5624
AUC: 0.8689

Epoch 59/80
 - 0s - loss: 0.8717 - val_loss: 0.5913
AUC: 0.8693

Epoch 60/80
 - 0s - loss: 0.8741 - val_loss: 0.5649
AUC: 0.8691

Epoch 61/80
 - 0s - loss: 0.8726 - val_loss: 0.5583
AUC: 0.8689

Epoch 62/80
 - 0s - loss: 0.8706 - val_loss: 0.5698
AUC: 0.8691

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9341 - val_loss: 0.5745
AUC: 0.8697

Epoch 2/30
 - 0s - loss: 0.9315 - val_loss: 0.5987
AUC: 0.8699

Epoch 3/30
 - 1s - loss: 0.9236 - val_loss: 0.5904
AUC: 0.8697

Epoch 4/30
 - 0s - loss: 0.9270 - val_loss: 0.5683
AUC: 0.8693

Epoch 5/30
 - 1s - loss: 0.9137 - val_loss: 0.5771
AUC: 0.8694

Epoch 6/30
 - 1s - loss: 0.9210 - val_loss: 0.5871
AUC: 0.8693

Epoch 7/30
 - 1s - loss: 0.9156 - val_loss: 0.5527
AUC: 0.8690

Epoch 8/30
 - 0s - loss: 0.9140 - val_loss: 0.5949
AUC: 0.8697

Epoch 9/30
 - 1s - loss: 0.9116 - val_loss: 0.5843
AUC: 0.8696

Epoch 10/30
 - 0s - loss: 0.9102 - val_loss: 0.5907
AUC: 0.8700

Epoch 11/30
 - 0s - loss: 0.9079 - val_loss: 0.5496
AUC: 0.8692

Epoch 12/30
 - 0s - loss: 0.9113 - val_loss: 0.5792
AUC: 0.8699

Epoch 13/30
 - 0s - loss: 0.9084 - val_loss: 0.5768
AUC: 0.8700

Epoch 14/30
 - 0s - loss: 0.9032 - val_loss: 0.5852
AUC: 0.8701

Epoch 15/30
 - 0s - loss: 0.9038 - val_loss: 0.5701
AUC: 0.8697

Epoch 16/30
 - 0s - loss: 0.9012 - val_loss: 0.5721
AUC: 0.8695

Epoch 17/30
 - 1s - loss: 0.8964 - val_loss: 0.5768
AUC: 0.8699

Epoch 18/30
 - 0s - loss: 0.8982 - val_loss: 0.5762
AUC: 0.8699

Epoch 19/30
 - 1s - loss: 0.8978 - val_loss: 0.5579
AUC: 0.8697

Epoch 20/30
 - 1s - loss: 0.8922 - val_loss: 0.5588
AUC: 0.8698

Epoch 21/30
 - 1s - loss: 0.8921 - val_loss: 0.5751
AUC: 0.8702

Epoch 22/30
 - 1s - loss: 0.8884 - val_loss: 0.5674
AUC: 0.8700

Epoch 23/30
 - 1s - loss: 0.8899 - val_loss: 0.5723
AUC: 0.8701

Epoch 24/30
 - 0s - loss: 0.8879 - val_loss: 0.5693
AUC: 0.8700

Epoch 25/30
 - 1s - loss: 0.8839 - val_loss: 0.5747
AUC: 0.8700

Epoch 26/30
 - 0s - loss: 0.8895 - val_loss: 0.5695
AUC: 0.8699

Epoch 27/30
 - 0s - loss: 0.8899 - val_loss: 0.5708
AUC: 0.8699

Epoch 28/30
 - 0s - loss: 0.8923 - val_loss: 0.5752
AUC: 0.8700

Epoch 29/30
 - 0s - loss: 0.8882 - val_loss: 0.5780
AUC: 0.8700

Epoch 30/30
 - 0s - loss: 0.8867 - val_loss: 0.5699
Using TensorFlow backend.
AUC: 0.8699

2019-03-08 10:38:15.869909: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:38:16.035509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:38:16.035553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:38:16.334745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:38:16.334796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:38:16.334805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:38:16.335057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2288
Epoch 2/80
 - 2s - loss: 0.3121
Epoch 3/80
 - 2s - loss: 0.2586
Epoch 4/80
 - 2s - loss: 0.2238
Epoch 5/80
 - 2s - loss: 0.2013
Epoch 6/80
 - 2s - loss: 0.1832
Epoch 7/80
 - 2s - loss: 0.1683
Epoch 8/80
 - 2s - loss: 0.1557
Epoch 9/80
 - 2s - loss: 0.1451
Epoch 10/80
 - 2s - loss: 0.1364
Epoch 11/80
 - 2s - loss: 0.1294
Epoch 12/80
 - 2s - loss: 0.1236
Epoch 13/80
 - 2s - loss: 0.1187
Epoch 14/80
 - 2s - loss: 0.1145
Epoch 15/80
 - 2s - loss: 0.1109
Epoch 16/80
 - 2s - loss: 0.1077
Epoch 17/80
 - 2s - loss: 0.1050
Epoch 18/80
 - 2s - loss: 0.1026
Epoch 19/80
 - 2s - loss: 0.1005
Epoch 20/80
 - 2s - loss: 0.0988
Epoch 21/80
 - 2s - loss: 0.0972
Epoch 22/80
 - 2s - loss: 0.0959
Epoch 23/80
 - 2s - loss: 0.0948
Epoch 24/80
 - 2s - loss: 0.0937
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0922
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0910
Epoch 29/80
 - 2s - loss: 0.0905
Epoch 30/80
 - 2s - loss: 0.0901
Epoch 31/80
 - 2s - loss: 0.0897
Epoch 32/80
 - 2s - loss: 0.0893
Epoch 33/80
 - 2s - loss: 0.0891
Epoch 34/80
 - 2s - loss: 0.0888
Epoch 35/80
 - 2s - loss: 0.0885
Epoch 36/80
 - 2s - loss: 0.0884
Epoch 37/80
 - 2s - loss: 0.0881
Epoch 38/80
 - 2s - loss: 0.0879
Epoch 39/80
 - 2s - loss: 0.0878
Epoch 40/80
 - 2s - loss: 0.0876
Epoch 41/80
 - 2s - loss: 0.0875
Epoch 42/80
 - 2s - loss: 0.0873
Epoch 43/80
 - 2s - loss: 0.0872
Epoch 44/80
 - 2s - loss: 0.0871
Epoch 45/80
 - 2s - loss: 0.0870
Epoch 46/80
 - 2s - loss: 0.0869
Epoch 47/80
 - 2s - loss: 0.0868
Epoch 48/80
 - 2s - loss: 0.0867
Epoch 49/80
 - 2s - loss: 0.0866
Epoch 50/80
 - 2s - loss: 0.0865
Epoch 51/80
 - 2s - loss: 0.0864
Epoch 52/80
 - 2s - loss: 0.0863
Epoch 53/80
 - 2s - loss: 0.0863
Epoch 54/80
 - 2s - loss: 0.0862
Epoch 55/80
 - 2s - loss: 0.0862
Epoch 56/80
 - 2s - loss: 0.0861
Epoch 57/80
 - 2s - loss: 0.0860
Epoch 58/80
 - 2s - loss: 0.0860
Epoch 59/80
 - 2s - loss: 0.0860
Epoch 60/80
 - 2s - loss: 0.0859
Epoch 61/80
 - 2s - loss: 0.0859
Epoch 62/80
 - 2s - loss: 0.0858
Epoch 63/80
 - 2s - loss: 0.0857
Epoch 64/80
 - 2s - loss: 0.0857
Epoch 65/80
 - 2s - loss: 0.0857
Epoch 66/80
 - 2s - loss: 0.0857
Epoch 67/80
 - 2s - loss: 0.0823
Epoch 68/80
 - 2s - loss: 0.0820
Epoch 69/80
 - 2s - loss: 0.0820
Epoch 70/80
 - 2s - loss: 0.0820
Epoch 71/80
 - 2s - loss: 0.0820
Epoch 72/80
 - 2s - loss: 0.0812
Epoch 73/80
 - 2s - loss: 0.0811
Epoch 74/80
 - 2s - loss: 0.0811
Epoch 75/80
 - 2s - loss: 0.0811
Epoch 76/80
 - 2s - loss: 0.0809
Epoch 77/80
 - 2s - loss: 0.0809
Epoch 78/80
 - 2s - loss: 0.0809
Epoch 79/80
 - 2s - loss: 0.0809
Epoch 80/80
 - 2s - loss: 0.0809
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.7378 - val_loss: 0.7916
AUC: 0.8206

Epoch 2/80
 - 0s - loss: 1.4005 - val_loss: 0.7748
AUC: 0.8404

Epoch 3/80
 - 0s - loss: 1.1748 - val_loss: 0.7227
AUC: 0.8478

Epoch 4/80
 - 0s - loss: 1.1067 - val_loss: 0.6570
AUC: 0.8539

Epoch 5/80
 - 0s - loss: 1.0985 - val_loss: 0.6502
AUC: 0.8567

Epoch 6/80
 - 0s - loss: 1.0655 - val_loss: 0.6180
AUC: 0.8591

Epoch 7/80
 - 0s - loss: 1.0577 - val_loss: 0.6431
AUC: 0.8606

Epoch 8/80
 - 0s - loss: 1.0509 - val_loss: 0.6872
AUC: 0.8624

Epoch 9/80
 - 0s - loss: 1.0342 - val_loss: 0.6200
AUC: 0.8635

Epoch 10/80
 - 0s - loss: 1.0256 - val_loss: 0.6437
AUC: 0.8646

Epoch 11/80
 - 0s - loss: 1.0344 - val_loss: 0.6767
AUC: 0.8666

Epoch 12/80
 - 0s - loss: 1.0061 - val_loss: 0.6536
AUC: 0.8663

Epoch 13/80
 - 0s - loss: 1.0017 - val_loss: 0.5606
AUC: 0.8661

Epoch 14/80
 - 0s - loss: 0.9990 - val_loss: 0.6445
AUC: 0.8682

Epoch 15/80
 - 0s - loss: 0.9921 - val_loss: 0.6150
AUC: 0.8667

Epoch 16/80
 - 0s - loss: 0.9991 - val_loss: 0.6130
AUC: 0.8671

Epoch 17/80
 - 0s - loss: 0.9904 - val_loss: 0.5686
AUC: 0.8677

Epoch 18/80
 - 0s - loss: 0.9798 - val_loss: 0.6896
AUC: 0.8680

Epoch 19/80
 - 0s - loss: 0.9758 - val_loss: 0.6336
AUC: 0.8691

Epoch 20/80
 - 0s - loss: 0.9712 - val_loss: 0.5984
AUC: 0.8692

Epoch 21/80
 - 0s - loss: 0.9688 - val_loss: 0.6547
AUC: 0.8674

Epoch 22/80
 - 0s - loss: 0.9686 - val_loss: 0.6215
AUC: 0.8683

Epoch 23/80
 - 0s - loss: 0.9624 - val_loss: 0.5988
AUC: 0.8679

Epoch 24/80
 - 0s - loss: 0.9497 - val_loss: 0.5783
AUC: 0.8692

Epoch 25/80
 - 0s - loss: 0.9443 - val_loss: 0.5925
AUC: 0.8692

Epoch 26/80
 - 0s - loss: 0.9459 - val_loss: 0.5972
AUC: 0.8695

Epoch 27/80
 - 0s - loss: 0.9422 - val_loss: 0.5812
AUC: 0.8695

Epoch 28/80
 - 0s - loss: 0.9364 - val_loss: 0.6095
AUC: 0.8691

Epoch 29/80
 - 0s - loss: 0.9420 - val_loss: 0.5915
AUC: 0.8699

Epoch 30/80
 - 0s - loss: 0.9328 - val_loss: 0.6043
AUC: 0.8694

Epoch 31/80
 - 0s - loss: 0.9335 - val_loss: 0.5937
AUC: 0.8699

Epoch 32/80
 - 0s - loss: 0.9365 - val_loss: 0.5974
AUC: 0.8701

Epoch 33/80
 - 0s - loss: 0.9412 - val_loss: 0.5635
AUC: 0.8694

Epoch 34/80
 - 0s - loss: 0.9303 - val_loss: 0.5871
AUC: 0.8698

Epoch 35/80
 - 0s - loss: 0.9280 - val_loss: 0.5877
AUC: 0.8699

Epoch 36/80
 - 0s - loss: 0.9233 - val_loss: 0.5859
AUC: 0.8698

Epoch 37/80
 - 0s - loss: 0.9281 - val_loss: 0.6053
AUC: 0.8700

Epoch 38/80
 - 0s - loss: 0.9273 - val_loss: 0.5870
AUC: 0.8700

Epoch 39/80
 - 0s - loss: 0.9225 - val_loss: 0.5982
AUC: 0.8701

Epoch 40/80
 - 0s - loss: 0.9271 - val_loss: 0.5979
AUC: 0.8702

Epoch 41/80
 - 0s - loss: 0.9269 - val_loss: 0.5889
AUC: 0.8701

Epoch 42/80
 - 0s - loss: 0.9243 - val_loss: 0.5880
AUC: 0.8701

Epoch 43/80
 - 0s - loss: 0.9211 - val_loss: 0.5925
AUC: 0.8702

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9290 - val_loss: 0.6041
AUC: 0.8704

Epoch 2/30
 - 1s - loss: 0.9289 - val_loss: 0.5949
AUC: 0.8701

Epoch 3/30
 - 1s - loss: 0.9285 - val_loss: 0.5830
AUC: 0.8700

Epoch 4/30
 - 1s - loss: 0.9227 - val_loss: 0.5861
AUC: 0.8701

Epoch 5/30
 - 1s - loss: 0.9240 - val_loss: 0.6017
AUC: 0.8699

Epoch 6/30
 - 1s - loss: 0.9182 - val_loss: 0.5614
AUC: 0.8698

Epoch 7/30
 - 0s - loss: 0.9179 - val_loss: 0.5928
AUC: 0.8706

Epoch 8/30
 - 0s - loss: 0.9169 - val_loss: 0.5969
AUC: 0.8705

Epoch 9/30
 - 0s - loss: 0.9083 - val_loss: 0.5930
AUC: 0.8701

Epoch 10/30
 - 0s - loss: 0.9147 - val_loss: 0.5982
AUC: 0.8703

Epoch 11/30
 - 0s - loss: 0.9109 - val_loss: 0.5948
AUC: 0.8705

Epoch 12/30
 - 0s - loss: 0.9070 - val_loss: 0.5765
AUC: 0.8703

Epoch 13/30
 - 0s - loss: 0.9037 - val_loss: 0.5877
AUC: 0.8708

Epoch 14/30
 - 0s - loss: 0.9060 - val_loss: 0.5871
AUC: 0.8706

Epoch 15/30
 - 0s - loss: 0.9024 - val_loss: 0.5782
AUC: 0.8704

Epoch 16/30
 - 0s - loss: 0.9062 - val_loss: 0.5886
AUC: 0.8706

Epoch 17/30
 - 0s - loss: 0.8988 - val_loss: 0.5694
AUC: 0.8704

Epoch 18/30
 - 0s - loss: 0.9036 - val_loss: 0.5800
AUC: 0.8706

Epoch 19/30
 - 0s - loss: 0.9011 - val_loss: 0.5849
AUC: 0.8707

Epoch 20/30
 - 0s - loss: 0.9005 - val_loss: 0.5778
AUC: 0.8706

Epoch 21/30
 - 0s - loss: 0.8963 - val_loss: 0.5756
AUC: 0.8705

Epoch 22/30
 - 0s - loss: 0.9000 - val_loss: 0.5822
AUC: 0.8706

Epoch 23/30
 - 0s - loss: 0.8920 - val_loss: 0.5684
AUC: 0.8705

Epoch 24/30
 - 0s - loss: 0.8952 - val_loss: 0.5752
AUC: 0.8705

Epoch 25/30
 - 0s - loss: 0.9008 - val_loss: 0.5857
AUC: 0.8706

Epoch 26/30
 - 0s - loss: 0.8976 - val_loss: 0.5733
AUC: 0.8706

Epoch 27/30
 - 0s - loss: 0.8886 - val_loss: 0.5735
AUC: 0.8706

Epoch 28/30
 - 0s - loss: 0.8972 - val_loss: 0.5764
AUC: 0.8706

Epoch 29/30
 - 0s - loss: 0.8943 - val_loss: 0.5778
AUC: 0.8706

Epoch 30/30
 - 0s - loss: 0.8952 - val_loss: 0.5773
Using TensorFlow backend.
AUC: 0.8706

2019-03-08 10:41:37.594356: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:41:37.759574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:41:37.759618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:41:38.055559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:41:38.055610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:41:38.055618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:41:38.055875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0001
Epoch 2/80
 - 2s - loss: 0.1818
Epoch 3/80
 - 2s - loss: 0.1584
Epoch 4/80
 - 2s - loss: 0.1372
Epoch 5/80
 - 2s - loss: 0.1187
Epoch 6/80
 - 2s - loss: 0.1050
Epoch 7/80
 - 2s - loss: 0.0941
Epoch 8/80
 - 2s - loss: 0.0852
Epoch 9/80
 - 2s - loss: 0.0779
Epoch 10/80
 - 2s - loss: 0.0717
Epoch 11/80
 - 2s - loss: 0.0664
Epoch 12/80
 - 2s - loss: 0.0621
Epoch 13/80
 - 2s - loss: 0.0585
Epoch 14/80
 - 2s - loss: 0.0556
Epoch 15/80
 - 2s - loss: 0.0531
Epoch 16/80
 - 2s - loss: 0.0509
Epoch 17/80
 - 2s - loss: 0.0491
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0460
Epoch 20/80
 - 2s - loss: 0.0449
Epoch 21/80
 - 2s - loss: 0.0438
Epoch 22/80
 - 2s - loss: 0.0429
Epoch 23/80
 - 2s - loss: 0.0421
Epoch 24/80
 - 2s - loss: 0.0414
Epoch 25/80
 - 2s - loss: 0.0408
Epoch 26/80
 - 2s - loss: 0.0403
Epoch 27/80
 - 2s - loss: 0.0398
Epoch 28/80
 - 2s - loss: 0.0395
Epoch 29/80
 - 2s - loss: 0.0391
Epoch 30/80
 - 2s - loss: 0.0388
Epoch 31/80
 - 2s - loss: 0.0386
Epoch 32/80
 - 2s - loss: 0.0383
Epoch 33/80
 - 2s - loss: 0.0381
Epoch 34/80
 - 2s - loss: 0.0379
Epoch 35/80
 - 2s - loss: 0.0378
Epoch 36/80
 - 2s - loss: 0.0376
Epoch 37/80
 - 2s - loss: 0.0375
Epoch 38/80
 - 2s - loss: 0.0374
Epoch 39/80
 - 2s - loss: 0.0373
Epoch 40/80
 - 2s - loss: 0.0372
Epoch 41/80
 - 2s - loss: 0.0371
Epoch 42/80
 - 2s - loss: 0.0370
Epoch 43/80
 - 2s - loss: 0.0369
Epoch 44/80
 - 2s - loss: 0.0369
Epoch 45/80
 - 2s - loss: 0.0368
Epoch 46/80
 - 2s - loss: 0.0368
Epoch 47/80
 - 2s - loss: 0.0367
Epoch 48/80
 - 2s - loss: 0.0366
Epoch 49/80
 - 2s - loss: 0.0366
Epoch 50/80
 - 2s - loss: 0.0365
Epoch 51/80
 - 2s - loss: 0.0365
Epoch 52/80
 - 2s - loss: 0.0364
Epoch 53/80
 - 2s - loss: 0.0364
Epoch 54/80
 - 2s - loss: 0.0364
Epoch 55/80
 - 2s - loss: 0.0363
Epoch 56/80
 - 2s - loss: 0.0363
Epoch 57/80
 - 2s - loss: 0.0363
Epoch 58/80
 - 2s - loss: 0.0363
Epoch 59/80
 - 2s - loss: 0.0362
Epoch 60/80
 - 2s - loss: 0.0362
Epoch 61/80
 - 2s - loss: 0.0347
Epoch 62/80
 - 2s - loss: 0.0345
Epoch 63/80
 - 2s - loss: 0.0345
Epoch 64/80
 - 2s - loss: 0.0345
Epoch 65/80
 - 2s - loss: 0.0345
Epoch 66/80
 - 2s - loss: 0.0341
Epoch 67/80
 - 2s - loss: 0.0341
Epoch 68/80
 - 2s - loss: 0.0341
Epoch 69/80
 - 2s - loss: 0.0341
Epoch 70/80
 - 2s - loss: 0.0340
Epoch 71/80
 - 2s - loss: 0.0340
Epoch 72/80
 - 2s - loss: 0.0340
Epoch 73/80
 - 2s - loss: 0.0340
Epoch 74/80
 - 2s - loss: 0.0340
Epoch 75/80
 - 2s - loss: 0.0340
Epoch 76/80
 - 2s - loss: 0.0340
Epoch 77/80
 - 2s - loss: 0.0340
Epoch 78/80
 - 2s - loss: 0.0340
Epoch 79/80
 - 2s - loss: 0.0340
Epoch 80/80
 - 2s - loss: 0.0340
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.2121 - val_loss: 1.0224
AUC: 0.8023

Epoch 2/80
 - 0s - loss: 1.5646 - val_loss: 0.7304
AUC: 0.8364

Epoch 3/80
 - 0s - loss: 1.2211 - val_loss: 0.6685
AUC: 0.8396

Epoch 4/80
 - 0s - loss: 1.1304 - val_loss: 0.6468
AUC: 0.8442

Epoch 5/80
 - 0s - loss: 1.0914 - val_loss: 0.5950
AUC: 0.8472

Epoch 6/80
 - 0s - loss: 1.0720 - val_loss: 0.6427
AUC: 0.8512

Epoch 7/80
 - 0s - loss: 1.0574 - val_loss: 0.6934
AUC: 0.8567

Epoch 8/80
 - 0s - loss: 1.0397 - val_loss: 0.5924
AUC: 0.8552

Epoch 9/80
 - 0s - loss: 1.0290 - val_loss: 0.6106
AUC: 0.8576

Epoch 10/80
 - 0s - loss: 1.0237 - val_loss: 0.6141
AUC: 0.8583

Epoch 11/80
 - 0s - loss: 1.0221 - val_loss: 0.7377
AUC: 0.8627

Epoch 12/80
 - 0s - loss: 1.0135 - val_loss: 0.5951
AUC: 0.8597

Epoch 13/80
 - 0s - loss: 1.0034 - val_loss: 0.6692
AUC: 0.8624

Epoch 14/80
 - 0s - loss: 1.0007 - val_loss: 0.5823
AUC: 0.8617

Epoch 15/80
 - 0s - loss: 0.9975 - val_loss: 0.6097
AUC: 0.8614

Epoch 16/80
 - 0s - loss: 0.9843 - val_loss: 0.5913
AUC: 0.8600

Epoch 17/80
 - 0s - loss: 0.9869 - val_loss: 0.6126
AUC: 0.8635

Epoch 18/80
 - 0s - loss: 0.9826 - val_loss: 0.6115
AUC: 0.8627

Epoch 19/80
 - 0s - loss: 0.9741 - val_loss: 0.6660
AUC: 0.8653

Epoch 20/80
 - 0s - loss: 0.9724 - val_loss: 0.6421
AUC: 0.8639

Epoch 21/80
 - 0s - loss: 0.9684 - val_loss: 0.6710
AUC: 0.8651

Epoch 22/80
 - 0s - loss: 0.9664 - val_loss: 0.6841
AUC: 0.8656

Epoch 23/80
 - 0s - loss: 0.9722 - val_loss: 0.6439
AUC: 0.8648

Epoch 24/80
 - 0s - loss: 0.9599 - val_loss: 0.5889
AUC: 0.8626

Epoch 25/80
 - 0s - loss: 0.9481 - val_loss: 0.6022
AUC: 0.8647

Epoch 26/80
 - 0s - loss: 0.9399 - val_loss: 0.6023
AUC: 0.8649

Epoch 27/80
 - 0s - loss: 0.9415 - val_loss: 0.5938
AUC: 0.8647

Epoch 28/80
 - 0s - loss: 0.9403 - val_loss: 0.6166
AUC: 0.8656

Epoch 29/80
 - 0s - loss: 0.9407 - val_loss: 0.6039
AUC: 0.8651

Epoch 30/80
 - 0s - loss: 0.9361 - val_loss: 0.5765
AUC: 0.8646

Epoch 31/80
 - 0s - loss: 0.9335 - val_loss: 0.6346
AUC: 0.8656

Epoch 32/80
 - 0s - loss: 0.9388 - val_loss: 0.6126
AUC: 0.8655

Epoch 33/80
 - 0s - loss: 0.9312 - val_loss: 0.6157
AUC: 0.8656

Epoch 34/80
 - 0s - loss: 0.9296 - val_loss: 0.5963
AUC: 0.8653

Epoch 35/80
 - 0s - loss: 0.9329 - val_loss: 0.6145
AUC: 0.8656

Epoch 36/80
 - 0s - loss: 0.9352 - val_loss: 0.5945
AUC: 0.8651

Epoch 37/80
 - 0s - loss: 0.9274 - val_loss: 0.5572
AUC: 0.8645

Epoch 38/80
 - 0s - loss: 0.9277 - val_loss: 0.5892
AUC: 0.8655

Epoch 39/80
 - 0s - loss: 0.9282 - val_loss: 0.5940
AUC: 0.8657

Epoch 40/80
 - 0s - loss: 0.9283 - val_loss: 0.5861
AUC: 0.8655

Epoch 41/80
 - 0s - loss: 0.9258 - val_loss: 0.6356
AUC: 0.8666

Epoch 42/80
 - 0s - loss: 0.9243 - val_loss: 0.5905
AUC: 0.8655

Epoch 43/80
 - 0s - loss: 0.9244 - val_loss: 0.5872
AUC: 0.8655

Epoch 44/80
 - 0s - loss: 0.9200 - val_loss: 0.5996
AUC: 0.8661

Epoch 45/80
 - 0s - loss: 0.9246 - val_loss: 0.5968
AUC: 0.8659

Epoch 46/80
 - 0s - loss: 0.9176 - val_loss: 0.6014
AUC: 0.8658

Epoch 47/80
 - 0s - loss: 0.9216 - val_loss: 0.5985
AUC: 0.8660

Epoch 48/80
 - 0s - loss: 0.9179 - val_loss: 0.5796
AUC: 0.8658

Epoch 49/80
 - 0s - loss: 0.9151 - val_loss: 0.5792
AUC: 0.8656

Epoch 50/80
 - 0s - loss: 0.9130 - val_loss: 0.5761
AUC: 0.8655

Epoch 51/80
 - 0s - loss: 0.9140 - val_loss: 0.5805
AUC: 0.8655

Epoch 52/80
 - 0s - loss: 0.9134 - val_loss: 0.5843
AUC: 0.8656

Epoch 53/80
 - 0s - loss: 0.9136 - val_loss: 0.6024
AUC: 0.8660

Epoch 54/80
 - 0s - loss: 0.9134 - val_loss: 0.5813
AUC: 0.8656

Epoch 55/80
 - 0s - loss: 0.9122 - val_loss: 0.5761
AUC: 0.8656

Epoch 56/80
 - 0s - loss: 0.9186 - val_loss: 0.5876
AUC: 0.8657

Epoch 57/80
 - 0s - loss: 0.9127 - val_loss: 0.5811
AUC: 0.8655

Epoch 58/80
 - 0s - loss: 0.9063 - val_loss: 0.5853
AUC: 0.8656

Epoch 59/80
 - 0s - loss: 0.9109 - val_loss: 0.5834
AUC: 0.8656

Epoch 60/80
 - 0s - loss: 0.9153 - val_loss: 0.5861
AUC: 0.8657

Epoch 61/80
 - 0s - loss: 0.9124 - val_loss: 0.5852
AUC: 0.8657

Epoch 62/80
 - 0s - loss: 0.9125 - val_loss: 0.5855
AUC: 0.8657

Epoch 63/80
 - 0s - loss: 0.9104 - val_loss: 0.5856
AUC: 0.8657

Epoch 64/80
 - 0s - loss: 0.9117 - val_loss: 0.5845
AUC: 0.8657

Epoch 65/80
 - 0s - loss: 0.9104 - val_loss: 0.5874
AUC: 0.8657

Epoch 66/80
 - 0s - loss: 0.9096 - val_loss: 0.5864
AUC: 0.8657

Epoch 67/80
 - 0s - loss: 0.9137 - val_loss: 0.5858
AUC: 0.8657

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9196 - val_loss: 0.6023
AUC: 0.8663

Epoch 2/30
 - 0s - loss: 0.9222 - val_loss: 0.5775
AUC: 0.8655

Epoch 3/30
 - 0s - loss: 0.9149 - val_loss: 0.5722
AUC: 0.8656

Epoch 4/30
 - 0s - loss: 0.9165 - val_loss: 0.5882
AUC: 0.8655

Epoch 5/30
 - 0s - loss: 0.9158 - val_loss: 0.5876
AUC: 0.8656

Epoch 6/30
 - 0s - loss: 0.9131 - val_loss: 0.5848
AUC: 0.8657

Epoch 7/30
 - 0s - loss: 0.9107 - val_loss: 0.5870
AUC: 0.8660

Epoch 8/30
 - 0s - loss: 0.9106 - val_loss: 0.5692
AUC: 0.8655

Epoch 9/30
 - 0s - loss: 0.9092 - val_loss: 0.5802
AUC: 0.8660

Epoch 10/30
 - 0s - loss: 0.9040 - val_loss: 0.5478
AUC: 0.8653

Epoch 11/30
 - 0s - loss: 0.9050 - val_loss: 0.5753
AUC: 0.8660

Epoch 12/30
 - 0s - loss: 0.9015 - val_loss: 0.6043
AUC: 0.8667

Epoch 13/30
 - 0s - loss: 0.8995 - val_loss: 0.5993
AUC: 0.8665

Epoch 14/30
 - 0s - loss: 0.8998 - val_loss: 0.6046
AUC: 0.8665

Epoch 15/30
 - 0s - loss: 0.8935 - val_loss: 0.5624
AUC: 0.8658

Epoch 16/30
 - 0s - loss: 0.8979 - val_loss: 0.5934
AUC: 0.8667

Epoch 17/30
 - 0s - loss: 0.8989 - val_loss: 0.6070
AUC: 0.8667

Epoch 18/30
 - 0s - loss: 0.8980 - val_loss: 0.6006
AUC: 0.8668

Epoch 19/30
 - 0s - loss: 0.8886 - val_loss: 0.5739
AUC: 0.8664

Epoch 20/30
 - 0s - loss: 0.8905 - val_loss: 0.5745
AUC: 0.8667

Epoch 21/30
 - 0s - loss: 0.8835 - val_loss: 0.5762
AUC: 0.8667

Epoch 22/30
 - 0s - loss: 0.8832 - val_loss: 0.5761
AUC: 0.8665

Epoch 23/30
 - 0s - loss: 0.8879 - val_loss: 0.5763
AUC: 0.8665

Epoch 24/30
 - 0s - loss: 0.8877 - val_loss: 0.5773
AUC: 0.8665

Epoch 25/30
 - 0s - loss: 0.8853 - val_loss: 0.5775
AUC: 0.8665

Epoch 26/30
 - 0s - loss: 0.8840 - val_loss: 0.5805
AUC: 0.8666

Epoch 27/30
 - 0s - loss: 0.8848 - val_loss: 0.5726
AUC: 0.8665

Epoch 28/30
 - 0s - loss: 0.8865 - val_loss: 0.5774
AUC: 0.8666

Epoch 29/30
 - 0s - loss: 0.8861 - val_loss: 0.5723
AUC: 0.8664

Epoch 30/30
 - 0s - loss: 0.8819 - val_loss: 0.5795
Using TensorFlow backend.
AUC: 0.8666

2019-03-08 10:45:15.033074: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:45:15.200154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:45:15.200222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:45:15.495348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:45:15.495399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:45:15.495409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:45:15.495683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9739
Epoch 2/80
 - 2s - loss: 0.1815
Epoch 3/80
 - 2s - loss: 0.1589
Epoch 4/80
 - 2s - loss: 0.1370
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:45:39.566724: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:45:39.730775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:45:39.730819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:45:40.026152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:45:40.026208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:45:40.026217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:45:40.026472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0052
Epoch 2/80
 - 2s - loss: 0.1818
Epoch 3/80
 - 2s - loss: 0.1512
Epoch 4/80
 - 2s - loss: 0.1282
Epoch 5/80
 - 2s - loss: 0.1121
Epoch 6/80
 - 2s - loss: 0.0995
Epoch 7/80
 - 2s - loss: 0.0896
Epoch 8/80
 - 2s - loss: 0.0816
Epoch 9/80
 - 2s - loss: 0.0750
Epoch 10/80
 - 2s - loss: 0.0695
Epoch 11/80
 - 2s - loss: 0.0649
Epoch 12/80
 - 2s - loss: 0.0610
Epoch 13/80
 - 2s - loss: 0.0576
Epoch 14/80
 - 2s - loss: 0.0548
Epoch 15/80
 - 2s - loss: 0.0523
Epoch 16/80
 - 2s - loss: 0.0503
Epoch 17/80
 - 2s - loss: 0.0485
Epoch 18/80
 - 2s - loss: 0.0470
Epoch 19/80
 - 2s - loss: 0.0457
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:46:31.698614: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:46:31.861110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:46:31.861155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:46:32.157780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:46:32.157833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:46:32.157842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:46:32.158098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6002
Epoch 2/80
 - 2s - loss: 0.0840
Epoch 3/80
 - 2s - loss: 0.0652
Epoch 4/80
 - 2s - loss: 0.0587
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:46:56.466675: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:46:56.630712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:46:56.630754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:46:56.924842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:46:56.924893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:46:56.924902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:46:56.925158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6133
Epoch 2/80
 - 2s - loss: 0.0834
Epoch 3/80
 - 2s - loss: 0.0655
Epoch 4/80
 - 2s - loss: 0.0600
Epoch 5/80
 - 2s - loss: 0.0536
Epoch 6/80
 - 2s - loss: 0.0472
Epoch 7/80
 - 2s - loss: 0.0415
Epoch 8/80
 - 2s - loss: 0.0365
Epoch 9/80
 - 2s - loss: 0.0324
Epoch 10/80
 - 2s - loss: 0.0291
Epoch 11/80
 - 2s - loss: 0.0264
Epoch 12/80
 - 2s - loss: 0.0243
Epoch 13/80
 - 2s - loss: 0.0225
Epoch 14/80
 - 2s - loss: 0.0211
Epoch 15/80
 - 2s - loss: 0.0199
Epoch 16/80
 - 2s - loss: 0.0188
Epoch 17/80
 - 2s - loss: 0.0179
Epoch 18/80
 - 2s - loss: 0.0171
Epoch 19/80
 - 2s - loss: 0.0165
Epoch 20/80
 - 2s - loss: 0.0159
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0146
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0128
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0124
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 10:48:15.489304: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:48:15.649050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:48:15.649093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:48:15.942586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:48:15.942637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:48:15.942646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:48:15.942900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6123
Epoch 2/80
 - 2s - loss: 0.0833
Epoch 3/80
 - 2s - loss: 0.0650
Epoch 4/80
 - 2s - loss: 0.0591
Epoch 5/80
 - 2s - loss: 0.0525
Epoch 6/80
 - 2s - loss: 0.0459
Epoch 7/80
 - 2s - loss: 0.0401
Epoch 8/80
 - 2s - loss: 0.0354
Epoch 9/80
 - 2s - loss: 0.0318
Epoch 10/80
 - 2s - loss: 0.0288
Epoch 11/80
 - 2s - loss: 0.0264
Epoch 12/80
 - 2s - loss: 0.0243
Epoch 13/80
 - 2s - loss: 0.0226
Epoch 14/80
 - 2s - loss: 0.0211
Epoch 15/80
 - 2s - loss: 0.0199
Epoch 16/80
 - 2s - loss: 0.0189
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0173
Epoch 19/80
 - 2s - loss: 0.0166
Epoch 20/80
 - 2s - loss: 0.0160
Epoch 21/80
 - 2s - loss: 0.0156
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0144
Epoch 25/80
 - 2s - loss: 0.0141
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0136
Epoch 28/80
 - 2s - loss: 0.0134
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0131
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0128
Epoch 33/80
 - 2s - loss: 0.0127
Epoch 34/80
 - 2s - loss: 0.0126
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0123
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0122
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0121
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0120
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0119
Epoch 49/80
 - 2s - loss: 0.0119
Epoch 50/80
 - 2s - loss: 0.0118
Epoch 51/80
 - 2s - loss: 0.0113
Epoch 52/80
 - 2s - loss: 0.0113
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0111
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.3756 - val_loss: 1.4669
AUC: 0.7993

Epoch 2/80
 - 0s - loss: 1.8245 - val_loss: 0.6950
AUC: 0.8293

Epoch 3/80
 - 0s - loss: 1.3169 - val_loss: 0.7730
AUC: 0.8427

Epoch 4/80
 - 0s - loss: 1.1815 - val_loss: 0.6422
AUC: 0.8466

Epoch 5/80
 - 0s - loss: 1.1353 - val_loss: 0.6761
AUC: 0.8509

Epoch 6/80
 - 0s - loss: 1.1070 - val_loss: 0.6456
AUC: 0.8521

Epoch 7/80
 - 0s - loss: 1.0949 - val_loss: 0.6662
AUC: 0.8556

Epoch 8/80
 - 0s - loss: 1.0662 - val_loss: 0.6756
AUC: 0.8576

Epoch 9/80
 - 0s - loss: 1.0518 - val_loss: 0.6513
AUC: 0.8577

Epoch 10/80
 - 0s - loss: 1.0440 - val_loss: 0.6378
AUC: 0.8583

Epoch 11/80
 - 0s - loss: 1.0357 - val_loss: 0.6775
AUC: 0.8609

Epoch 12/80
 - 0s - loss: 1.0321 - val_loss: 0.6977
AUC: 0.8598

Epoch 13/80
 - 0s - loss: 1.0273 - val_loss: 0.6176
AUC: 0.8596

Epoch 14/80
 - 0s - loss: 1.0255 - val_loss: 0.6023
AUC: 0.8613

Epoch 15/80
 - 0s - loss: 1.0131 - val_loss: 0.5793
AUC: 0.8616

Epoch 16/80
 - 0s - loss: 1.0111 - val_loss: 0.5428
AUC: 0.8619

Epoch 17/80
 - 0s - loss: 1.0087 - val_loss: 0.7033
AUC: 0.8637

Epoch 18/80
 - 0s - loss: 1.0047 - val_loss: 0.6106
AUC: 0.8629

Epoch 19/80
 - 0s - loss: 0.9973 - val_loss: 0.6222
AUC: 0.8636

Epoch 20/80
 - 0s - loss: 0.9922 - val_loss: 0.6270
AUC: 0.8638

Epoch 21/80
 - 0s - loss: 0.9808 - val_loss: 0.6027
AUC: 0.8632

Epoch 22/80
 - 0s - loss: 0.9908 - val_loss: 0.6658
AUC: 0.8651

Epoch 23/80
 - 0s - loss: 0.9876 - val_loss: 0.6629
AUC: 0.8652

Epoch 24/80
 - 0s - loss: 0.9712 - val_loss: 0.5953
AUC: 0.8645

Epoch 25/80
 - 0s - loss: 0.9759 - val_loss: 0.5938
AUC: 0.8657

Epoch 26/80
 - 0s - loss: 0.9660 - val_loss: 0.5682
AUC: 0.8642

Epoch 27/80
 - 0s - loss: 0.9583 - val_loss: 0.5936
AUC: 0.8660

Epoch 28/80
 - 0s - loss: 0.9530 - val_loss: 0.5843
AUC: 0.8661

Epoch 29/80
 - 0s - loss: 0.9485 - val_loss: 0.5879
AUC: 0.8660

Epoch 30/80
 - 0s - loss: 0.9532 - val_loss: 0.5955
AUC: 0.8667

Epoch 31/80
 - 0s - loss: 0.9508 - val_loss: 0.6089
AUC: 0.8664

Epoch 32/80
 - 0s - loss: 0.9503 - val_loss: 0.6026
AUC: 0.8667

Epoch 33/80
 - 0s - loss: 0.9473 - val_loss: 0.6017
AUC: 0.8663

Epoch 34/80
 - 0s - loss: 0.9455 - val_loss: 0.6134
AUC: 0.8665

Epoch 35/80
 - 0s - loss: 0.9456 - val_loss: 0.5720
AUC: 0.8662

Epoch 36/80
 - 0s - loss: 0.9429 - val_loss: 0.6206
AUC: 0.8667

Epoch 37/80
 - 0s - loss: 0.9394 - val_loss: 0.5848
AUC: 0.8664

Epoch 38/80
 - 0s - loss: 0.9380 - val_loss: 0.5943
AUC: 0.8664

Epoch 39/80
 - 0s - loss: 0.9341 - val_loss: 0.5894
AUC: 0.8663

Epoch 40/80
 - 0s - loss: 0.9406 - val_loss: 0.5862
AUC: 0.8663

Epoch 41/80
 - 0s - loss: 0.9378 - val_loss: 0.5901
AUC: 0.8664

Epoch 42/80
 - 0s - loss: 0.9439 - val_loss: 0.5940
AUC: 0.8665

Epoch 43/80
 - 0s - loss: 0.9372 - val_loss: 0.5917
AUC: 0.8665

Epoch 44/80
 - 0s - loss: 0.9418 - val_loss: 0.5930
AUC: 0.8665

Epoch 45/80
 - 0s - loss: 0.9406 - val_loss: 0.6026
AUC: 0.8667

Epoch 46/80
 - 0s - loss: 0.9385 - val_loss: 0.5931
AUC: 0.8665

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9470 - val_loss: 0.6298
AUC: 0.8667

Epoch 2/30
 - 0s - loss: 0.9469 - val_loss: 0.6008
AUC: 0.8667

Epoch 3/30
 - 0s - loss: 0.9457 - val_loss: 0.6030
AUC: 0.8667

Epoch 4/30
 - 0s - loss: 0.9399 - val_loss: 0.5687
AUC: 0.8665

Epoch 5/30
 - 0s - loss: 0.9415 - val_loss: 0.6113
AUC: 0.8670

Epoch 6/30
 - 0s - loss: 0.9391 - val_loss: 0.5785
AUC: 0.8670

Epoch 7/30
 - 0s - loss: 0.9390 - val_loss: 0.6008
AUC: 0.8675

Epoch 8/30
 - 0s - loss: 0.9314 - val_loss: 0.5945
AUC: 0.8671

Epoch 9/30
 - 0s - loss: 0.9312 - val_loss: 0.6064
AUC: 0.8674

Epoch 10/30
 - 0s - loss: 0.9327 - val_loss: 0.5854
AUC: 0.8670

Epoch 11/30
 - 0s - loss: 0.9283 - val_loss: 0.5946
AUC: 0.8672

Epoch 12/30
 - 0s - loss: 0.9317 - val_loss: 0.5753
AUC: 0.8670

Epoch 13/30
 - 0s - loss: 0.9305 - val_loss: 0.5933
AUC: 0.8674

Epoch 14/30
 - 0s - loss: 0.9246 - val_loss: 0.6065
AUC: 0.8675

Epoch 15/30
 - 1s - loss: 0.9185 - val_loss: 0.5834
AUC: 0.8673

Epoch 16/30
 - 0s - loss: 0.9221 - val_loss: 0.5848
AUC: 0.8673

Epoch 17/30
 - 1s - loss: 0.9175 - val_loss: 0.5805
AUC: 0.8673

Epoch 18/30
 - 1s - loss: 0.9164 - val_loss: 0.5851
AUC: 0.8673

Epoch 19/30
 - 1s - loss: 0.9170 - val_loss: 0.5841
AUC: 0.8674

Epoch 20/30
 - 1s - loss: 0.9172 - val_loss: 0.5839
AUC: 0.8673

Epoch 21/30
 - 1s - loss: 0.9196 - val_loss: 0.5862
AUC: 0.8674

Epoch 22/30
 - 1s - loss: 0.9152 - val_loss: 0.5858
AUC: 0.8674

Epoch 23/30
 - 0s - loss: 0.9158 - val_loss: 0.5856
AUC: 0.8674

Epoch 24/30
 - 0s - loss: 0.9164 - val_loss: 0.5805
AUC: 0.8673

Epoch 25/30
 - 0s - loss: 0.9208 - val_loss: 0.5812
AUC: 0.8673

Epoch 26/30
 - 0s - loss: 0.9157 - val_loss: 0.5810
AUC: 0.8673

Epoch 27/30
 - 0s - loss: 0.9188 - val_loss: 0.5818
AUC: 0.8674

Epoch 28/30
 - 0s - loss: 0.9192 - val_loss: 0.5828
AUC: 0.8674

Epoch 29/30
 - 0s - loss: 0.9151 - val_loss: 0.5826
AUC: 0.8674

Epoch 30/30
 - 0s - loss: 0.9192 - val_loss: 0.5819
Using TensorFlow backend.
AUC: 0.8673

2019-03-08 10:51:38.601100: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:51:38.767741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:51:38.767785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:51:39.061233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:51:39.061275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:51:39.061285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:51:39.061585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2178
Epoch 2/80
 - 2s - loss: 0.3144
Epoch 3/80
 - 2s - loss: 0.2658
Epoch 4/80
 - 2s - loss: 0.2283
Epoch 5/80
 - 2s - loss: 0.2053
Epoch 6/80
 - 2s - loss: 0.1869
Epoch 7/80
 - 2s - loss: 0.1706
Epoch 8/80
 - 2s - loss: 0.1569
Epoch 9/80
 - 2s - loss: 0.1455
Epoch 10/80
 - 2s - loss: 0.1364
Epoch 11/80
 - 2s - loss: 0.1293
Epoch 12/80
 - 2s - loss: 0.1236
Epoch 13/80
 - 2s - loss: 0.1189
Epoch 14/80
 - 2s - loss: 0.1149
Epoch 15/80
 - 2s - loss: 0.1114
Epoch 16/80
 - 2s - loss: 0.1083
Epoch 17/80
 - 2s - loss: 0.1055
Epoch 18/80
 - 2s - loss: 0.1029
Epoch 19/80
 - 2s - loss: 0.1008
Epoch 20/80
 - 2s - loss: 0.0989
Epoch 21/80
 - 2s - loss: 0.0973
Epoch 22/80
 - 2s - loss: 0.0959
Epoch 23/80
 - 2s - loss: 0.0947
Epoch 24/80
 - 2s - loss: 0.0937
Epoch 25/80
 - 2s - loss: 0.0928
Epoch 26/80
 - 2s - loss: 0.0920
Epoch 27/80
 - 2s - loss: 0.0913
Epoch 28/80
 - 2s - loss: 0.0908
Epoch 29/80
 - 2s - loss: 0.0903
Epoch 30/80
 - 2s - loss: 0.0898
Epoch 31/80
 - 2s - loss: 0.0894
Epoch 32/80
 - 2s - loss: 0.0891
Epoch 33/80
 - 2s - loss: 0.0888
Epoch 34/80
 - 2s - loss: 0.0884
Epoch 35/80
 - 2s - loss: 0.0882
Epoch 36/80
 - 2s - loss: 0.0880
Epoch 37/80
 - 2s - loss: 0.0878
Epoch 38/80
 - 2s - loss: 0.0875
Epoch 39/80
 - 2s - loss: 0.0874
Epoch 40/80
 - 2s - loss: 0.0872
Epoch 41/80
 - 2s - loss: 0.0870
Epoch 42/80
 - 2s - loss: 0.0869
Epoch 43/80
 - 2s - loss: 0.0868
Epoch 44/80
 - 2s - loss: 0.0866
Epoch 45/80
 - 2s - loss: 0.0865
Epoch 46/80
 - 2s - loss: 0.0864
Epoch 47/80
 - 2s - loss: 0.0863
Epoch 48/80
 - 2s - loss: 0.0862
Epoch 49/80
 - 2s - loss: 0.0861
Epoch 50/80
 - 2s - loss: 0.0860
Epoch 51/80
 - 2s - loss: 0.0860
Epoch 52/80
 - 2s - loss: 0.0859
Epoch 53/80
 - 2s - loss: 0.0858
Epoch 54/80
 - 2s - loss: 0.0857
Epoch 55/80
 - 2s - loss: 0.0856
Epoch 56/80
 - 2s - loss: 0.0856
Epoch 57/80
 - 2s - loss: 0.0856
Epoch 58/80
 - 2s - loss: 0.0855
Epoch 59/80
 - 2s - loss: 0.0854
Epoch 60/80
 - 2s - loss: 0.0854
Epoch 61/80
 - 2s - loss: 0.0853
Epoch 62/80
 - 2s - loss: 0.0853
Epoch 63/80
 - 2s - loss: 0.0852
Epoch 64/80
 - 2s - loss: 0.0852
Epoch 65/80
 - 2s - loss: 0.0851
Epoch 66/80
 - 2s - loss: 0.0851
Epoch 67/80
 - 2s - loss: 0.0851
Epoch 68/80
 - 2s - loss: 0.0850
Epoch 69/80
 - 2s - loss: 0.0850
Epoch 70/80
 - 2s - loss: 0.0850
Epoch 71/80
 - 2s - loss: 0.0849
Epoch 72/80
 - 2s - loss: 0.0849
Epoch 73/80
 - 2s - loss: 0.0815
Epoch 74/80
 - 2s - loss: 0.0813
Epoch 75/80
 - 2s - loss: 0.0812
Epoch 76/80
 - 2s - loss: 0.0812
Epoch 77/80
 - 2s - loss: 0.0812
Epoch 78/80
 - 2s - loss: 0.0804
Epoch 79/80
 - 2s - loss: 0.0804
Epoch 80/80
 - 2s - loss: 0.0804
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.6813 - val_loss: 1.4005
AUC: 0.8069

Epoch 2/80
 - 0s - loss: 2.4946 - val_loss: 0.7852
AUC: 0.8390

Epoch 3/80
 - 0s - loss: 1.7357 - val_loss: 0.7912
AUC: 0.8443

Epoch 4/80
 - 0s - loss: 1.3459 - val_loss: 0.8336
AUC: 0.8532

Epoch 5/80
 - 0s - loss: 1.1947 - val_loss: 0.6216
AUC: 0.8555

Epoch 6/80
 - 0s - loss: 1.1552 - val_loss: 0.6787
AUC: 0.8580

Epoch 7/80
 - 0s - loss: 1.1303 - val_loss: 0.7072
AUC: 0.8615

Epoch 8/80
 - 0s - loss: 1.1011 - val_loss: 0.7023
AUC: 0.8614

Epoch 9/80
 - 0s - loss: 1.0864 - val_loss: 0.6601
AUC: 0.8647

Epoch 10/80
 - 0s - loss: 1.0665 - val_loss: 0.6427
AUC: 0.8655

Epoch 11/80
 - 0s - loss: 1.0586 - val_loss: 0.6569
AUC: 0.8666

Epoch 12/80
 - 0s - loss: 1.0551 - val_loss: 0.7161
AUC: 0.8681

Epoch 13/80
 - 0s - loss: 1.0570 - val_loss: 0.6979
AUC: 0.8674

Epoch 14/80
 - 0s - loss: 1.0428 - val_loss: 0.6132
AUC: 0.8693

Epoch 15/80
 - 0s - loss: 1.0329 - val_loss: 0.6101
AUC: 0.8694

Epoch 16/80
 - 0s - loss: 1.0365 - val_loss: 0.6373
AUC: 0.8707

Epoch 17/80
 - 0s - loss: 1.0257 - val_loss: 0.5415
AUC: 0.8694

Epoch 18/80
 - 0s - loss: 1.0317 - val_loss: 0.5942
AUC: 0.8726

Epoch 19/80
 - 0s - loss: 1.0207 - val_loss: 0.6210
AUC: 0.8724

Epoch 20/80
 - 0s - loss: 1.0117 - val_loss: 0.6328
AUC: 0.8718

Epoch 21/80
 - 0s - loss: 1.0096 - val_loss: 0.6273
AUC: 0.8723

Epoch 22/80
 - 0s - loss: 1.0096 - val_loss: 0.5345
AUC: 0.8719

Epoch 23/80
 - 0s - loss: 1.0054 - val_loss: 0.5753
AUC: 0.8729

Epoch 24/80
 - 0s - loss: 1.0077 - val_loss: 0.6053
AUC: 0.8739

Epoch 25/80
 - 0s - loss: 0.9970 - val_loss: 0.5766
AUC: 0.8736

Epoch 26/80
 - 0s - loss: 0.9977 - val_loss: 0.6002
AUC: 0.8743

Epoch 27/80
 - 0s - loss: 0.9844 - val_loss: 0.5892
AUC: 0.8731

Epoch 28/80
 - 0s - loss: 0.9937 - val_loss: 0.6240
AUC: 0.8728

Epoch 29/80
 - 0s - loss: 0.9920 - val_loss: 0.6032
AUC: 0.8734

Epoch 30/80
 - 0s - loss: 0.9859 - val_loss: 0.6380
AUC: 0.8753

Epoch 31/80
 - 0s - loss: 0.9840 - val_loss: 0.6131
AUC: 0.8747

Epoch 32/80
 - 0s - loss: 0.9730 - val_loss: 0.6102
AUC: 0.8751

Epoch 33/80
 - 0s - loss: 0.9722 - val_loss: 0.6035
AUC: 0.8750

Epoch 34/80
 - 0s - loss: 0.9704 - val_loss: 0.6110
AUC: 0.8752

Epoch 35/80
 - 0s - loss: 0.9628 - val_loss: 0.5827
AUC: 0.8747

Epoch 36/80
 - 0s - loss: 0.9658 - val_loss: 0.6116
AUC: 0.8753

Epoch 37/80
 - 0s - loss: 0.9670 - val_loss: 0.5836
AUC: 0.8751

Epoch 38/80
 - 0s - loss: 0.9645 - val_loss: 0.6116
AUC: 0.8754

Epoch 39/80
 - 0s - loss: 0.9645 - val_loss: 0.6019
AUC: 0.8752

Epoch 40/80
 - 0s - loss: 0.9566 - val_loss: 0.5700
AUC: 0.8751

Epoch 41/80
 - 0s - loss: 0.9619 - val_loss: 0.5976
AUC: 0.8754

Epoch 42/80
 - 0s - loss: 0.9597 - val_loss: 0.6042
AUC: 0.8752

Epoch 43/80
 - 0s - loss: 0.9594 - val_loss: 0.6011
AUC: 0.8753

Epoch 44/80
 - 0s - loss: 0.9613 - val_loss: 0.5971
AUC: 0.8753

Epoch 45/80
 - 0s - loss: 0.9575 - val_loss: 0.5921
AUC: 0.8751

Epoch 46/80
 - 0s - loss: 0.9516 - val_loss: 0.5946
AUC: 0.8752

Epoch 47/80
 - 0s - loss: 0.9600 - val_loss: 0.5961
AUC: 0.8752

Epoch 48/80
 - 0s - loss: 0.9558 - val_loss: 0.6012
AUC: 0.8752

Epoch 49/80
 - 0s - loss: 0.9577 - val_loss: 0.6040
AUC: 0.8752

Epoch 50/80
 - 0s - loss: 0.9584 - val_loss: 0.5905
AUC: 0.8751

Epoch 51/80
 - 0s - loss: 0.9594 - val_loss: 0.6008
AUC: 0.8753

Epoch 52/80
 - 0s - loss: 0.9529 - val_loss: 0.5846
AUC: 0.8752

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9634 - val_loss: 0.5977
AUC: 0.8753

Epoch 2/30
 - 0s - loss: 0.9553 - val_loss: 0.5964
AUC: 0.8753

Epoch 3/30
 - 0s - loss: 0.9544 - val_loss: 0.5708
AUC: 0.8751

Epoch 4/30
 - 0s - loss: 0.9498 - val_loss: 0.5896
AUC: 0.8755

Epoch 5/30
 - 0s - loss: 0.9524 - val_loss: 0.6021
AUC: 0.8757

Epoch 6/30
 - 0s - loss: 0.9468 - val_loss: 0.5687
AUC: 0.8752

Epoch 7/30
 - 0s - loss: 0.9449 - val_loss: 0.5780
AUC: 0.8756

Epoch 8/30
 - 0s - loss: 0.9461 - val_loss: 0.6037
AUC: 0.8760

Epoch 9/30
 - 0s - loss: 0.9415 - val_loss: 0.5756
AUC: 0.8759

Epoch 10/30
 - 0s - loss: 0.9380 - val_loss: 0.5710
AUC: 0.8755

Epoch 11/30
 - 0s - loss: 0.9429 - val_loss: 0.6139
AUC: 0.8762

Epoch 12/30
 - 0s - loss: 0.9382 - val_loss: 0.5769
AUC: 0.8760

Epoch 13/30
 - 0s - loss: 0.9374 - val_loss: 0.5731
AUC: 0.8760

Epoch 14/30
 - 0s - loss: 0.9366 - val_loss: 0.5752
AUC: 0.8760

Epoch 15/30
 - 0s - loss: 0.9324 - val_loss: 0.5901
AUC: 0.8763

Epoch 16/30
 - 0s - loss: 0.9319 - val_loss: 0.5795
AUC: 0.8762

Epoch 17/30
 - 0s - loss: 0.9259 - val_loss: 0.5848
AUC: 0.8762

Epoch 18/30
 - 0s - loss: 0.9274 - val_loss: 0.5810
AUC: 0.8763

Epoch 19/30
 - 0s - loss: 0.9261 - val_loss: 0.5793
AUC: 0.8763

Epoch 20/30
 - 0s - loss: 0.9269 - val_loss: 0.5832
AUC: 0.8764

Epoch 21/30
 - 0s - loss: 0.9281 - val_loss: 0.5808
AUC: 0.8763

Epoch 22/30
 - 0s - loss: 0.9278 - val_loss: 0.5810
AUC: 0.8764

Epoch 23/30
 - 0s - loss: 0.9344 - val_loss: 0.5801
AUC: 0.8764

Epoch 24/30
 - 0s - loss: 0.9261 - val_loss: 0.5849
AUC: 0.8764

Epoch 25/30
 - 0s - loss: 0.9242 - val_loss: 0.5854
AUC: 0.8765

Epoch 26/30
 - 0s - loss: 0.9277 - val_loss: 0.5811
AUC: 0.8764

Epoch 27/30
 - 0s - loss: 0.9208 - val_loss: 0.5819
AUC: 0.8764

Epoch 28/30
 - 0s - loss: 0.9236 - val_loss: 0.5816
AUC: 0.8764

Epoch 29/30
 - 0s - loss: 0.9233 - val_loss: 0.5825
AUC: 0.8764

Epoch 30/30
 - 0s - loss: 0.9304 - val_loss: 0.5822
Using TensorFlow backend.
AUC: 0.8765

2019-03-08 10:54:57.254444: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:54:57.421407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:54:57.421453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:54:57.716478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:54:57.716528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:54:57.716537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:54:57.716804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1921
Epoch 2/80
 - 2s - loss: 0.3187
Epoch 3/80
 - 2s - loss: 0.2859
Epoch 4/80
 - 2s - loss: 0.2466
Epoch 5/80
 - 2s - loss: 0.2143
Epoch 6/80
 - 2s - loss: 0.1918
Epoch 7/80
 - 2s - loss: 0.1744
Epoch 8/80
 - 2s - loss: 0.1603
Epoch 9/80
 - 2s - loss: 0.1488
Epoch 10/80
 - 2s - loss: 0.1394
Epoch 11/80
 - 2s - loss: 0.1316
Epoch 12/80
 - 2s - loss: 0.1254
Epoch 13/80
 - 2s - loss: 0.1202
Epoch 14/80
 - 2s - loss: 0.1157
Epoch 15/80
 - 2s - loss: 0.1118
Epoch 16/80
 - 2s - loss: 0.1085
Epoch 17/80
 - 2s - loss: 0.1056
Epoch 18/80
 - 2s - loss: 0.1030
Epoch 19/80
 - 2s - loss: 0.1009
Epoch 20/80
 - 2s - loss: 0.0990
Epoch 21/80
 - 2s - loss: 0.0974
Epoch 22/80
 - 2s - loss: 0.0960
Epoch 23/80
 - 2s - loss: 0.0948
Epoch 24/80
 - 2s - loss: 0.0938
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0922
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0909
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0900
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0893
Epoch 33/80
 - 2s - loss: 0.0890
Epoch 34/80
 - 2s - loss: 0.0887
Epoch 35/80
 - 2s - loss: 0.0884
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0880
Epoch 38/80
 - 2s - loss: 0.0878
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0875
Epoch 41/80
 - 2s - loss: 0.0873
Epoch 42/80
 - 2s - loss: 0.0871
Epoch 43/80
 - 2s - loss: 0.0871
Epoch 44/80
 - 2s - loss: 0.0869
Epoch 45/80
 - 2s - loss: 0.0868
Epoch 46/80
 - 2s - loss: 0.0867
Epoch 47/80
 - 2s - loss: 0.0866
Epoch 48/80
 - 2s - loss: 0.0865
Epoch 49/80
 - 2s - loss: 0.0864
Epoch 50/80
 - 2s - loss: 0.0863
Epoch 51/80
 - 2s - loss: 0.0862
Epoch 52/80
 - 2s - loss: 0.0861
Epoch 53/80
 - 2s - loss: 0.0861
Epoch 54/80
 - 2s - loss: 0.0860
Epoch 55/80
 - 2s - loss: 0.0860
Epoch 56/80
 - 2s - loss: 0.0859
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0858
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0857
Epoch 61/80
 - 2s - loss: 0.0856
Epoch 62/80
 - 2s - loss: 0.0856
Epoch 63/80
 - 2s - loss: 0.0855
Epoch 64/80
 - 2s - loss: 0.0855
Epoch 65/80
 - 2s - loss: 0.0854
Epoch 66/80
 - 2s - loss: 0.0854
Epoch 67/80
 - 2s - loss: 0.0854
Epoch 68/80
 - 2s - loss: 0.0853
Epoch 69/80
 - 2s - loss: 0.0853
Epoch 70/80
 - 2s - loss: 0.0819
Epoch 71/80
 - 2s - loss: 0.0816
Epoch 72/80
 - 2s - loss: 0.0816
Epoch 73/80
 - 2s - loss: 0.0816
Epoch 74/80
 - 2s - loss: 0.0816
Epoch 75/80
 - 2s - loss: 0.0808
Epoch 76/80
 - 2s - loss: 0.0808
Epoch 77/80
 - 2s - loss: 0.0808
Epoch 78/80
 - 2s - loss: 0.0808
Epoch 79/80
 - 2s - loss: 0.0806
Epoch 80/80
 - 2s - loss: 0.0806
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0810 - val_loss: 1.1943
AUC: 0.8202

Epoch 2/80
 - 0s - loss: 2.0307 - val_loss: 0.8602
AUC: 0.8429

Epoch 3/80
 - 0s - loss: 1.4905 - val_loss: 0.8444
AUC: 0.8569

Epoch 4/80
 - 0s - loss: 1.2574 - val_loss: 0.6644
AUC: 0.8583

Epoch 5/80
 - 0s - loss: 1.1531 - val_loss: 0.6226
AUC: 0.8596

Epoch 6/80
 - 0s - loss: 1.1156 - val_loss: 0.6078
AUC: 0.8618

Epoch 7/80
 - 0s - loss: 1.0819 - val_loss: 0.6702
AUC: 0.8640

Epoch 8/80
 - 0s - loss: 1.0714 - val_loss: 0.6772
AUC: 0.8667

Epoch 9/80
 - 0s - loss: 1.0577 - val_loss: 0.6125
AUC: 0.8686

Epoch 10/80
 - 0s - loss: 1.0433 - val_loss: 0.6220
AUC: 0.8664

Epoch 11/80
 - 0s - loss: 1.0395 - val_loss: 0.6254
AUC: 0.8686

Epoch 12/80
 - 0s - loss: 1.0310 - val_loss: 0.6324
AUC: 0.8703

Epoch 13/80
 - 0s - loss: 1.0237 - val_loss: 0.5971
AUC: 0.8691

Epoch 14/80
 - 0s - loss: 1.0153 - val_loss: 0.5980
AUC: 0.8704

Epoch 15/80
 - 0s - loss: 1.0106 - val_loss: 0.5269
AUC: 0.8688

Epoch 16/80
 - 0s - loss: 1.0140 - val_loss: 0.6949
AUC: 0.8719

Epoch 17/80
 - 0s - loss: 1.0081 - val_loss: 0.6308
AUC: 0.8711

Epoch 18/80
 - 0s - loss: 0.9999 - val_loss: 0.5265
AUC: 0.8690

Epoch 19/80
 - 0s - loss: 1.0010 - val_loss: 0.6107
AUC: 0.8729

Epoch 20/80
 - 0s - loss: 0.9943 - val_loss: 0.6500
AUC: 0.8726

Epoch 21/80
 - 0s - loss: 0.9996 - val_loss: 0.5715
AUC: 0.8731

Epoch 22/80
 - 0s - loss: 0.9838 - val_loss: 0.6080
AUC: 0.8738

Epoch 23/80
 - 0s - loss: 0.9864 - val_loss: 0.6244
AUC: 0.8733

Epoch 24/80
 - 0s - loss: 0.9908 - val_loss: 0.5622
AUC: 0.8731

Epoch 25/80
 - 0s - loss: 0.9822 - val_loss: 0.6167
AUC: 0.8729

Epoch 26/80
 - 0s - loss: 0.9800 - val_loss: 0.5458
AUC: 0.8719

Epoch 27/80
 - 0s - loss: 0.9786 - val_loss: 0.4862
AUC: 0.8726

Epoch 28/80
 - 0s - loss: 0.9665 - val_loss: 0.5931
AUC: 0.8744

Epoch 29/80
 - 0s - loss: 0.9638 - val_loss: 0.5748
AUC: 0.8718

Epoch 30/80
 - 0s - loss: 0.9720 - val_loss: 0.5064
AUC: 0.8733

Epoch 31/80
 - 0s - loss: 0.9613 - val_loss: 0.5781
AUC: 0.8744

Epoch 32/80
 - 0s - loss: 0.9653 - val_loss: 0.5899
AUC: 0.8748

Epoch 33/80
 - 0s - loss: 0.9577 - val_loss: 0.5605
AUC: 0.8732

Epoch 34/80
 - 0s - loss: 0.9541 - val_loss: 0.5919
AUC: 0.8750

Epoch 35/80
 - 0s - loss: 0.9549 - val_loss: 0.5394
AUC: 0.8736

Epoch 36/80
 - 0s - loss: 0.9492 - val_loss: 0.5878
AUC: 0.8745

Epoch 37/80
 - 0s - loss: 0.9540 - val_loss: 0.6380
AUC: 0.8744

Epoch 38/80
 - 0s - loss: 0.9353 - val_loss: 0.5747
AUC: 0.8751

Epoch 39/80
 - 0s - loss: 0.9363 - val_loss: 0.5578
AUC: 0.8752

Epoch 40/80
 - 0s - loss: 0.9351 - val_loss: 0.5751
AUC: 0.8756

Epoch 41/80
 - 0s - loss: 0.9314 - val_loss: 0.5693
AUC: 0.8754

Epoch 42/80
 - 0s - loss: 0.9333 - val_loss: 0.5764
AUC: 0.8756

Epoch 43/80
 - 0s - loss: 0.9337 - val_loss: 0.5682
AUC: 0.8753

Epoch 44/80
 - 0s - loss: 0.9278 - val_loss: 0.5839
AUC: 0.8755

Epoch 45/80
 - 0s - loss: 0.9328 - val_loss: 0.5511
AUC: 0.8754

Epoch 46/80
 - 0s - loss: 0.9348 - val_loss: 0.5532
AUC: 0.8751

Epoch 47/80
 - 0s - loss: 0.9334 - val_loss: 0.5768
AUC: 0.8756

Epoch 48/80
 - 0s - loss: 0.9325 - val_loss: 0.5711
AUC: 0.8755

Epoch 49/80
 - 0s - loss: 0.9286 - val_loss: 0.5685
AUC: 0.8755

Epoch 50/80
 - 0s - loss: 0.9255 - val_loss: 0.5652
AUC: 0.8755

Epoch 51/80
 - 0s - loss: 0.9292 - val_loss: 0.5684
AUC: 0.8755

Epoch 52/80
 - 0s - loss: 0.9304 - val_loss: 0.5701
AUC: 0.8755

Epoch 53/80
 - 0s - loss: 0.9252 - val_loss: 0.5789
AUC: 0.8755

Epoch 54/80
 - 0s - loss: 0.9265 - val_loss: 0.5736
AUC: 0.8755

Epoch 55/80
 - 0s - loss: 0.9237 - val_loss: 0.5722
AUC: 0.8755

Epoch 56/80
 - 0s - loss: 0.9260 - val_loss: 0.5706
AUC: 0.8754

Epoch 57/80
 - 0s - loss: 0.9240 - val_loss: 0.5653
AUC: 0.8754

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9326 - val_loss: 0.5760
AUC: 0.8756

Epoch 2/30
 - 0s - loss: 0.9312 - val_loss: 0.5545
AUC: 0.8754

Epoch 3/30
 - 0s - loss: 0.9305 - val_loss: 0.5812
AUC: 0.8757

Epoch 4/30
 - 0s - loss: 0.9266 - val_loss: 0.5658
AUC: 0.8757

Epoch 5/30
 - 0s - loss: 0.9252 - val_loss: 0.5705
AUC: 0.8759

Epoch 6/30
 - 0s - loss: 0.9201 - val_loss: 0.5859
AUC: 0.8760

Epoch 7/30
 - 0s - loss: 0.9263 - val_loss: 0.5763
AUC: 0.8760

Epoch 8/30
 - 0s - loss: 0.9208 - val_loss: 0.5776
AUC: 0.8759

Epoch 9/30
 - 0s - loss: 0.9156 - val_loss: 0.5367
AUC: 0.8758

Epoch 10/30
 - 0s - loss: 0.9146 - val_loss: 0.5782
AUC: 0.8762

Epoch 11/30
 - 0s - loss: 0.9144 - val_loss: 0.5714
AUC: 0.8762

Epoch 12/30
 - 0s - loss: 0.9151 - val_loss: 0.5762
AUC: 0.8763

Epoch 13/30
 - 0s - loss: 0.9149 - val_loss: 0.5732
AUC: 0.8762

Epoch 14/30
 - 0s - loss: 0.9074 - val_loss: 0.5639
AUC: 0.8762

Epoch 15/30
 - 0s - loss: 0.9056 - val_loss: 0.5644
AUC: 0.8762

Epoch 16/30
 - 0s - loss: 0.9053 - val_loss: 0.5836
AUC: 0.8762

Epoch 17/30
 - 0s - loss: 0.9075 - val_loss: 0.5499
AUC: 0.8760

Epoch 18/30
 - 0s - loss: 0.9049 - val_loss: 0.5799
AUC: 0.8763

Epoch 19/30
 - 0s - loss: 0.8990 - val_loss: 0.5635
AUC: 0.8762

Epoch 20/30
 - 0s - loss: 0.9002 - val_loss: 0.5602
AUC: 0.8762

Epoch 21/30
 - 0s - loss: 0.8966 - val_loss: 0.5574
AUC: 0.8762

Epoch 22/30
 - 0s - loss: 0.8988 - val_loss: 0.5613
AUC: 0.8763

Epoch 23/30
 - 0s - loss: 0.9013 - val_loss: 0.5602
AUC: 0.8763

Epoch 24/30
 - 0s - loss: 0.8969 - val_loss: 0.5549
AUC: 0.8762

Epoch 25/30
 - 0s - loss: 0.8976 - val_loss: 0.5662
AUC: 0.8763

Epoch 26/30
 - 0s - loss: 0.8979 - val_loss: 0.5567
AUC: 0.8762

Epoch 27/30
 - 0s - loss: 0.8936 - val_loss: 0.5609
AUC: 0.8763

Epoch 28/30
 - 0s - loss: 0.8946 - val_loss: 0.5611
AUC: 0.8763

Epoch 29/30
 - 0s - loss: 0.8937 - val_loss: 0.5580
AUC: 0.8762

Epoch 30/30
 - 0s - loss: 0.8936 - val_loss: 0.5593
Using TensorFlow backend.
AUC: 0.8762

2019-03-08 10:58:17.933618: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 10:58:18.109022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 10:58:18.109066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 10:58:18.404312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 10:58:18.404365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 10:58:18.404374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 10:58:18.404626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2052
Epoch 2/80
 - 2s - loss: 0.3178
Epoch 3/80
 - 2s - loss: 0.2832
Epoch 4/80
 - 2s - loss: 0.2457
Epoch 5/80
 - 2s - loss: 0.2142
Epoch 6/80
 - 2s - loss: 0.1911
Epoch 7/80
 - 2s - loss: 0.1728
Epoch 8/80
 - 2s - loss: 0.1584
Epoch 9/80
 - 2s - loss: 0.1469
Epoch 10/80
 - 2s - loss: 0.1376
Epoch 11/80
 - 2s - loss: 0.1303
Epoch 12/80
 - 2s - loss: 0.1243
Epoch 13/80
 - 2s - loss: 0.1195
Epoch 14/80
 - 2s - loss: 0.1154
Epoch 15/80
 - 2s - loss: 0.1119
Epoch 16/80
 - 2s - loss: 0.1088
Epoch 17/80
 - 2s - loss: 0.1061
Epoch 18/80
 - 2s - loss: 0.1036
Epoch 19/80
 - 2s - loss: 0.1015
Epoch 20/80
 - 2s - loss: 0.0996
Epoch 21/80
 - 2s - loss: 0.0979
Epoch 22/80
 - 2s - loss: 0.0965
Epoch 23/80
 - 2s - loss: 0.0953
Epoch 24/80
 - 2s - loss: 0.0943
Epoch 25/80
 - 2s - loss: 0.0933
Epoch 26/80
 - 2s - loss: 0.0926
Epoch 27/80
 - 2s - loss: 0.0919
Epoch 28/80
 - 2s - loss: 0.0912
Epoch 29/80
 - 2s - loss: 0.0907
Epoch 30/80
 - 2s - loss: 0.0903
Epoch 31/80
 - 2s - loss: 0.0899
Epoch 32/80
 - 2s - loss: 0.0895
Epoch 33/80
 - 2s - loss: 0.0892
Epoch 34/80
 - 2s - loss: 0.0889
Epoch 35/80
 - 2s - loss: 0.0886
Epoch 36/80
 - 2s - loss: 0.0883
Epoch 37/80
 - 2s - loss: 0.0881
Epoch 38/80
 - 2s - loss: 0.0880
Epoch 39/80
 - 2s - loss: 0.0877
Epoch 40/80
 - 2s - loss: 0.0876
Epoch 41/80
 - 2s - loss: 0.0874
Epoch 42/80
 - 2s - loss: 0.0873
Epoch 43/80
 - 2s - loss: 0.0871
Epoch 44/80
 - 2s - loss: 0.0870
Epoch 45/80
 - 2s - loss: 0.0868
Epoch 46/80
 - 2s - loss: 0.0868
Epoch 47/80
 - 2s - loss: 0.0866
Epoch 48/80
 - 2s - loss: 0.0865
Epoch 49/80
 - 2s - loss: 0.0864
Epoch 50/80
 - 2s - loss: 0.0863
Epoch 51/80
 - 2s - loss: 0.0863
Epoch 52/80
 - 2s - loss: 0.0862
Epoch 53/80
 - 2s - loss: 0.0861
Epoch 54/80
 - 2s - loss: 0.0860
Epoch 55/80
 - 2s - loss: 0.0859
Epoch 56/80
 - 2s - loss: 0.0859
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0858
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0857
Epoch 61/80
 - 2s - loss: 0.0856
Epoch 62/80
 - 2s - loss: 0.0855
Epoch 63/80
 - 2s - loss: 0.0855
Epoch 64/80
 - 2s - loss: 0.0855
Epoch 65/80
 - 2s - loss: 0.0854
Epoch 66/80
 - 2s - loss: 0.0854
Epoch 67/80
 - 2s - loss: 0.0853
Epoch 68/80
 - 2s - loss: 0.0853
Epoch 69/80
 - 2s - loss: 0.0852
Epoch 70/80
 - 2s - loss: 0.0852
Epoch 71/80
 - 2s - loss: 0.0852
Epoch 72/80
 - 2s - loss: 0.0852
Epoch 73/80
 - 2s - loss: 0.0818
Epoch 74/80
 - 2s - loss: 0.0815
Epoch 75/80
 - 2s - loss: 0.0815
Epoch 76/80
 - 2s - loss: 0.0815
Epoch 77/80
 - 2s - loss: 0.0815
Epoch 78/80
 - 2s - loss: 0.0807
Epoch 79/80
 - 2s - loss: 0.0806
Epoch 80/80
 - 2s - loss: 0.0806
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.2153 - val_loss: 1.2239
AUC: 0.7964

Epoch 2/80
 - 0s - loss: 2.7831 - val_loss: 1.0715
AUC: 0.8282

Epoch 3/80
 - 0s - loss: 2.1355 - val_loss: 0.9529
AUC: 0.8388

Epoch 4/80
 - 0s - loss: 1.6601 - val_loss: 0.7350
AUC: 0.8450

Epoch 5/80
 - 0s - loss: 1.4182 - val_loss: 0.7777
AUC: 0.8501

Epoch 6/80
 - 0s - loss: 1.2420 - val_loss: 0.6607
AUC: 0.8513

Epoch 7/80
 - 0s - loss: 1.1665 - val_loss: 0.6505
AUC: 0.8546

Epoch 8/80
 - 0s - loss: 1.1203 - val_loss: 0.5902
AUC: 0.8546

Epoch 9/80
 - 0s - loss: 1.1017 - val_loss: 0.6559
AUC: 0.8581

Epoch 10/80
 - 0s - loss: 1.0816 - val_loss: 0.6861
AUC: 0.8592

Epoch 11/80
 - 0s - loss: 1.0672 - val_loss: 0.6629
AUC: 0.8584

Epoch 12/80
 - 0s - loss: 1.0558 - val_loss: 0.6333
AUC: 0.8605

Epoch 13/80
 - 0s - loss: 1.0530 - val_loss: 0.6458
AUC: 0.8609

Epoch 14/80
 - 0s - loss: 1.0425 - val_loss: 0.6110
AUC: 0.8579

Epoch 15/80
 - 0s - loss: 1.0437 - val_loss: 0.6645
AUC: 0.8623

Epoch 16/80
 - 0s - loss: 1.0280 - val_loss: 0.6264
AUC: 0.8623

Epoch 17/80
 - 0s - loss: 1.0253 - val_loss: 0.5575
AUC: 0.8616

Epoch 18/80
 - 0s - loss: 1.0232 - val_loss: 0.6013
AUC: 0.8624

Epoch 19/80
 - 0s - loss: 1.0131 - val_loss: 0.6035
AUC: 0.8616

Epoch 20/80
 - 0s - loss: 1.0104 - val_loss: 0.5651
AUC: 0.8635

Epoch 21/80
 - 0s - loss: 0.9969 - val_loss: 0.6145
AUC: 0.8643

Epoch 22/80
 - 0s - loss: 0.9989 - val_loss: 0.5788
AUC: 0.8633

Epoch 23/80
 - 0s - loss: 0.9926 - val_loss: 0.6974
AUC: 0.8664

Epoch 24/80
 - 0s - loss: 0.9917 - val_loss: 0.6288
AUC: 0.8645

Epoch 25/80
 - 0s - loss: 0.9894 - val_loss: 0.6049
AUC: 0.8649

Epoch 26/80
 - 0s - loss: 0.9821 - val_loss: 0.5679
AUC: 0.8650

Epoch 27/80
 - 0s - loss: 0.9844 - val_loss: 0.6823
AUC: 0.8655

Epoch 28/80
 - 0s - loss: 0.9761 - val_loss: 0.6014
AUC: 0.8663

Epoch 29/80
 - 0s - loss: 0.9680 - val_loss: 0.6096
AUC: 0.8662

Epoch 30/80
 - 0s - loss: 0.9683 - val_loss: 0.5723
AUC: 0.8657

Epoch 31/80
 - 0s - loss: 0.9660 - val_loss: 0.6063
AUC: 0.8659

Epoch 32/80
 - 0s - loss: 0.9742 - val_loss: 0.6041
AUC: 0.8663

Epoch 33/80
 - 0s - loss: 0.9648 - val_loss: 0.6148
AUC: 0.8665

Epoch 34/80
 - 0s - loss: 0.9647 - val_loss: 0.6006
AUC: 0.8663

Epoch 35/80
 - 0s - loss: 0.9699 - val_loss: 0.6194
AUC: 0.8666

Epoch 36/80
 - 0s - loss: 0.9636 - val_loss: 0.6105
AUC: 0.8665

Epoch 37/80
 - 0s - loss: 0.9608 - val_loss: 0.6016
AUC: 0.8663

Epoch 38/80
 - 0s - loss: 0.9580 - val_loss: 0.5977
AUC: 0.8664

Epoch 39/80
 - 0s - loss: 0.9551 - val_loss: 0.6008
AUC: 0.8664

Epoch 40/80
 - 0s - loss: 0.9591 - val_loss: 0.6042
AUC: 0.8664

Epoch 41/80
 - 0s - loss: 0.9580 - val_loss: 0.5949
AUC: 0.8663

Epoch 42/80
 - 0s - loss: 0.9598 - val_loss: 0.6023
AUC: 0.8664

Epoch 43/80
 - 0s - loss: 0.9635 - val_loss: 0.5942
AUC: 0.8663

Epoch 44/80
 - 0s - loss: 0.9595 - val_loss: 0.6038
AUC: 0.8664

Epoch 45/80
 - 0s - loss: 0.9649 - val_loss: 0.5999
AUC: 0.8664

Epoch 46/80
 - 0s - loss: 0.9576 - val_loss: 0.5979
AUC: 0.8665

Epoch 47/80
 - 0s - loss: 0.9602 - val_loss: 0.5954
AUC: 0.8665

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9649 - val_loss: 0.5958
AUC: 0.8665

Epoch 2/30
 - 0s - loss: 0.9658 - val_loss: 0.6214
AUC: 0.8670

Epoch 3/30
 - 0s - loss: 0.9605 - val_loss: 0.5939
AUC: 0.8667

Epoch 4/30
 - 0s - loss: 0.9538 - val_loss: 0.5881
AUC: 0.8667

Epoch 5/30
 - 0s - loss: 0.9543 - val_loss: 0.6131
AUC: 0.8672

Epoch 6/30
 - 0s - loss: 0.9543 - val_loss: 0.6050
AUC: 0.8672

Epoch 7/30
 - 0s - loss: 0.9473 - val_loss: 0.5708
AUC: 0.8668

Epoch 8/30
 - 0s - loss: 0.9474 - val_loss: 0.5871
AUC: 0.8673

Epoch 9/30
 - 0s - loss: 0.9478 - val_loss: 0.6278
AUC: 0.8678

Epoch 10/30
 - 0s - loss: 0.9418 - val_loss: 0.5896
AUC: 0.8676

Epoch 11/30
 - 0s - loss: 0.9436 - val_loss: 0.5994
AUC: 0.8678

Epoch 12/30
 - 0s - loss: 0.9440 - val_loss: 0.5928
AUC: 0.8678

Epoch 13/30
 - 0s - loss: 0.9433 - val_loss: 0.5880
AUC: 0.8678

Epoch 14/30
 - 0s - loss: 0.9340 - val_loss: 0.5812
AUC: 0.8678

Epoch 15/30
 - 0s - loss: 0.9356 - val_loss: 0.5870
AUC: 0.8681

Epoch 16/30
 - 0s - loss: 0.9382 - val_loss: 0.5802
AUC: 0.8679

Epoch 17/30
 - 0s - loss: 0.9317 - val_loss: 0.5875
AUC: 0.8683

Epoch 18/30
 - 0s - loss: 0.9289 - val_loss: 0.5909
AUC: 0.8683

Epoch 19/30
 - 0s - loss: 0.9242 - val_loss: 0.5822
AUC: 0.8681

Epoch 20/30
 - 0s - loss: 0.9248 - val_loss: 0.5869
AUC: 0.8682

Epoch 21/30
 - 0s - loss: 0.9312 - val_loss: 0.5917
AUC: 0.8683

Epoch 22/30
 - 0s - loss: 0.9303 - val_loss: 0.5920
AUC: 0.8684

Epoch 23/30
 - 0s - loss: 0.9272 - val_loss: 0.5912
AUC: 0.8683

Epoch 24/30
 - 0s - loss: 0.9284 - val_loss: 0.5825
AUC: 0.8682

Epoch 25/30
 - 0s - loss: 0.9284 - val_loss: 0.5884
AUC: 0.8683

Epoch 26/30
 - 0s - loss: 0.9243 - val_loss: 0.5860
AUC: 0.8683

Epoch 27/30
 - 0s - loss: 0.9274 - val_loss: 0.5852
AUC: 0.8683

Epoch 28/30
 - 0s - loss: 0.9258 - val_loss: 0.5853
AUC: 0.8683

Epoch 29/30
 - 0s - loss: 0.9256 - val_loss: 0.5866
AUC: 0.8683

Epoch 30/30
 - 0s - loss: 0.9214 - val_loss: 0.5858
Using TensorFlow backend.
AUC: 0.8683

2019-03-08 11:01:35.146275: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:01:35.316577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:01:35.316621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:01:35.625850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:01:35.625899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:01:35.625908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:01:35.626201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2002
Epoch 2/80
 - 2s - loss: 0.3148
Epoch 3/80
 - 2s - loss: 0.2695
Epoch 4/80
 - 2s - loss: 0.2353
Epoch 5/80
 - 2s - loss: 0.2113
Epoch 6/80
 - 2s - loss: 0.1912
Epoch 7/80
 - 2s - loss: 0.1735
Epoch 8/80
 - 2s - loss: 0.1591
Epoch 9/80
 - 2s - loss: 0.1474
Epoch 10/80
 - 2s - loss: 0.1377
Epoch 11/80
 - 2s - loss: 0.1300
Epoch 12/80
 - 2s - loss: 0.1239
Epoch 13/80
 - 2s - loss: 0.1190
Epoch 14/80
 - 2s - loss: 0.1149
Epoch 15/80
 - 2s - loss: 0.1114
Epoch 16/80
 - 2s - loss: 0.1084
Epoch 17/80
 - 2s - loss: 0.1057
Epoch 18/80
 - 2s - loss: 0.1034
Epoch 19/80
 - 2s - loss: 0.1013
Epoch 20/80
 - 2s - loss: 0.0995
Epoch 21/80
 - 2s - loss: 0.0979
Epoch 22/80
 - 2s - loss: 0.0966
Epoch 23/80
 - 2s - loss: 0.0954
Epoch 24/80
 - 2s - loss: 0.0944
Epoch 25/80
 - 2s - loss: 0.0935
Epoch 26/80
 - 2s - loss: 0.0927
Epoch 27/80
 - 2s - loss: 0.0920
Epoch 28/80
 - 2s - loss: 0.0915
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:02:41.522021: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:02:41.683155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:02:41.683218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:02:41.975682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:02:41.975735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:02:41.975744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:02:41.976001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9902
Epoch 2/80
 - 2s - loss: 0.1806
Epoch 3/80
 - 2s - loss: 0.1534
Epoch 4/80
 - 2s - loss: 0.1341
Epoch 5/80
 - 2s - loss: 0.1187
Epoch 6/80
 - 2s - loss: 0.1054
Epoch 7/80
 - 2s - loss: 0.0942
Epoch 8/80
 - 2s - loss: 0.0848
Epoch 9/80
 - 2s - loss: 0.0769
Epoch 10/80
 - 2s - loss: 0.0705
Epoch 11/80
 - 2s - loss: 0.0654
Epoch 12/80
 - 2s - loss: 0.0614
Epoch 13/80
 - 2s - loss: 0.0581
Epoch 14/80
 - 2s - loss: 0.0553
Epoch 15/80
 - 2s - loss: 0.0529
Epoch 16/80
 - 2s - loss: 0.0508
Epoch 17/80
 - 2s - loss: 0.0490
Epoch 18/80
 - 2s - loss: 0.0475
Epoch 19/80
 - 2s - loss: 0.0461
Epoch 20/80
 - 2s - loss: 0.0449
Epoch 21/80
 - 2s - loss: 0.0439
Epoch 22/80
 - 2s - loss: 0.0430
Epoch 23/80
 - 2s - loss: 0.0423
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0405
Epoch 27/80
 - 2s - loss: 0.0401
Epoch 28/80
 - 2s - loss: 0.0397
Epoch 29/80
 - 2s - loss: 0.0393
Epoch 30/80
 - 2s - loss: 0.0390
Epoch 31/80
 - 2s - loss: 0.0387
Epoch 32/80
 - 2s - loss: 0.0385
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0381
Epoch 35/80
 - 2s - loss: 0.0379
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 11:03:59.988226: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:04:00.152685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:04:00.152728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:04:00.448035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:04:00.448085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:04:00.448094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:04:00.448380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9964
Epoch 2/80
 - 2s - loss: 0.1823
Epoch 3/80
 - 2s - loss: 0.1580
Epoch 4/80
 - 2s - loss: 0.1349
Epoch 5/80
 - 2s - loss: 0.1182
Epoch 6/80
 - 2s - loss: 0.1061
Epoch 7/80
 - 2s - loss: 0.0952
Epoch 8/80
 - 2s - loss: 0.0856
Epoch 9/80
 - 2s - loss: 0.0777
Epoch 10/80
 - 2s - loss: 0.0713
Epoch 11/80
 - 2s - loss: 0.0661
Epoch 12/80
 - 2s - loss: 0.0619
Epoch 13/80
 - 2s - loss: 0.0584
Epoch 14/80
 - 2s - loss: 0.0555
Epoch 15/80
 - 2s - loss: 0.0531
Epoch 16/80
 - 2s - loss: 0.0510
Epoch 17/80
 - 2s - loss: 0.0492
Epoch 18/80
 - 2s - loss: 0.0477
Epoch 19/80
 - 2s - loss: 0.0464
Epoch 20/80
 - 2s - loss: 0.0452
Epoch 21/80
 - 2s - loss: 0.0442
Epoch 22/80
 - 2s - loss: 0.0433
Epoch 23/80
 - 2s - loss: 0.0425
Epoch 24/80
 - 2s - loss: 0.0418
Epoch 25/80
 - 2s - loss: 0.0413
Epoch 26/80
 - 2s - loss: 0.0407
Epoch 27/80
 - 2s - loss: 0.0403
Epoch 28/80
 - 2s - loss: 0.0399
Epoch 29/80
 - 2s - loss: 0.0395
Epoch 30/80
 - 2s - loss: 0.0392
Epoch 31/80
 - 2s - loss: 0.0389
Epoch 32/80
 - 2s - loss: 0.0387
Epoch 33/80
 - 2s - loss: 0.0385
Epoch 34/80
 - 2s - loss: 0.0383
Epoch 35/80
 - 2s - loss: 0.0381
Epoch 36/80
 - 2s - loss: 0.0380
Epoch 37/80
 - 2s - loss: 0.0378
Epoch 38/80
 - 2s - loss: 0.0377
Epoch 39/80
 - 2s - loss: 0.0376
Epoch 40/80
 - 2s - loss: 0.0375
Epoch 41/80
 - 2s - loss: 0.0374
Epoch 42/80
 - 2s - loss: 0.0373
Epoch 43/80
 - 2s - loss: 0.0372
Epoch 44/80
 - 2s - loss: 0.0371
Epoch 45/80
 - 2s - loss: 0.0370
Epoch 46/80
 - 2s - loss: 0.0370
Epoch 47/80
 - 2s - loss: 0.0369
Epoch 48/80
 - 2s - loss: 0.0369
Epoch 49/80
 - 2s - loss: 0.0368
Epoch 50/80
 - 2s - loss: 0.0368
Epoch 51/80
 - 2s - loss: 0.0367
Epoch 52/80
 - 2s - loss: 0.0367
Epoch 53/80
 - 2s - loss: 0.0366
Epoch 54/80
 - 2s - loss: 0.0366
Epoch 55/80
 - 2s - loss: 0.0366
Epoch 56/80
 - 2s - loss: 0.0365
Epoch 57/80
 - 2s - loss: 0.0350
Epoch 58/80
 - 2s - loss: 0.0348
Epoch 59/80
 - 2s - loss: 0.0348
Epoch 60/80
 - 2s - loss: 0.0348
Epoch 61/80
 - 2s - loss: 0.0348
Epoch 62/80
 - 2s - loss: 0.0344
Epoch 63/80
 - 2s - loss: 0.0344
Epoch 64/80
 - 2s - loss: 0.0344
Epoch 65/80
 - 2s - loss: 0.0344
Epoch 66/80
 - 2s - loss: 0.0343
Epoch 67/80
 - 2s - loss: 0.0343
Epoch 68/80
 - 2s - loss: 0.0343
Epoch 69/80
 - 2s - loss: 0.0343
Epoch 70/80
 - 2s - loss: 0.0343
Epoch 71/80
 - 2s - loss: 0.0343
Epoch 72/80
 - 2s - loss: 0.0343
Epoch 73/80
 - 2s - loss: 0.0343
Epoch 74/80
 - 2s - loss: 0.0343
Epoch 75/80
 - 2s - loss: 0.0343
Epoch 76/80
 - 2s - loss: 0.0343
Epoch 77/80
 - 2s - loss: 0.0343
Epoch 78/80
 - 2s - loss: 0.0343
Epoch 79/80
 - 2s - loss: 0.0343
Epoch 80/80
 - 2s - loss: 0.0343
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.9804 - val_loss: 1.6789
AUC: 0.8051

Epoch 2/80
 - 0s - loss: 2.9329 - val_loss: 1.1278
AUC: 0.8306

Epoch 3/80
 - 0s - loss: 2.2272 - val_loss: 1.0128
AUC: 0.8478

Epoch 4/80
 - 0s - loss: 1.7258 - val_loss: 0.8200
AUC: 0.8510

Epoch 5/80
 - 0s - loss: 1.3627 - val_loss: 0.6470
AUC: 0.8527

Epoch 6/80
 - 0s - loss: 1.2161 - val_loss: 0.6225
AUC: 0.8564

Epoch 7/80
 - 0s - loss: 1.1564 - val_loss: 0.6349
AUC: 0.8597

Epoch 8/80
 - 0s - loss: 1.1135 - val_loss: 0.6067
AUC: 0.8614

Epoch 9/80
 - 0s - loss: 1.0925 - val_loss: 0.6211
AUC: 0.8635

Epoch 10/80
 - 0s - loss: 1.0771 - val_loss: 0.7467
AUC: 0.8674

Epoch 11/80
 - 0s - loss: 1.0687 - val_loss: 0.6206
AUC: 0.8669

Epoch 12/80
 - 0s - loss: 1.0570 - val_loss: 0.6558
AUC: 0.8680

Epoch 13/80
 - 0s - loss: 1.0484 - val_loss: 0.7338
AUC: 0.8706

Epoch 14/80
 - 0s - loss: 1.0398 - val_loss: 0.6417
AUC: 0.8687

Epoch 15/80
 - 0s - loss: 1.0347 - val_loss: 0.6458
AUC: 0.8710

Epoch 16/80
 - 0s - loss: 1.0287 - val_loss: 0.6058
AUC: 0.8711

Epoch 17/80
 - 0s - loss: 1.0231 - val_loss: 0.6659
AUC: 0.8712

Epoch 18/80
 - 0s - loss: 1.0176 - val_loss: 0.6813
AUC: 0.8723

Epoch 19/80
 - 0s - loss: 1.0186 - val_loss: 0.5786
AUC: 0.8718

Epoch 20/80
 - 0s - loss: 1.0139 - val_loss: 0.5918
AUC: 0.8707

Epoch 21/80
 - 0s - loss: 0.9998 - val_loss: 0.6656
AUC: 0.8723

Epoch 22/80
 - 0s - loss: 0.9963 - val_loss: 0.5917
AUC: 0.8737

Epoch 23/80
 - 0s - loss: 0.9992 - val_loss: 0.6850
AUC: 0.8746

Epoch 24/80
 - 0s - loss: 0.9966 - val_loss: 0.5692
AUC: 0.8742

Epoch 25/80
 - 0s - loss: 0.9937 - val_loss: 0.6025
AUC: 0.8744

Epoch 26/80
 - 0s - loss: 0.9877 - val_loss: 0.6156
AUC: 0.8747

Epoch 27/80
 - 0s - loss: 0.9848 - val_loss: 0.5469
AUC: 0.8739

Epoch 28/80
 - 0s - loss: 0.9844 - val_loss: 0.6140
AUC: 0.8756

Epoch 29/80
 - 0s - loss: 0.9805 - val_loss: 0.5999
AUC: 0.8741

Epoch 30/80
 - 0s - loss: 0.9713 - val_loss: 0.6192
AUC: 0.8749

Epoch 31/80
 - 0s - loss: 0.9737 - val_loss: 0.5838
AUC: 0.8758

Epoch 32/80
 - 0s - loss: 0.9693 - val_loss: 0.5690
AUC: 0.8755

Epoch 33/80
 - 0s - loss: 0.9616 - val_loss: 0.5422
AUC: 0.8750

Epoch 34/80
 - 0s - loss: 0.9647 - val_loss: 0.6534
AUC: 0.8763

Epoch 35/80
 - 0s - loss: 0.9654 - val_loss: 0.6731
AUC: 0.8768

Epoch 36/80
 - 0s - loss: 0.9706 - val_loss: 0.5568
AUC: 0.8758

Epoch 37/80
 - 0s - loss: 0.9615 - val_loss: 0.6910
AUC: 0.8772

Epoch 38/80
 - 0s - loss: 0.9665 - val_loss: 0.5767
AUC: 0.8754

Epoch 39/80
 - 0s - loss: 0.9599 - val_loss: 0.6095
AUC: 0.8768

Epoch 40/80
 - 0s - loss: 0.9542 - val_loss: 0.5219
AUC: 0.8760

Epoch 41/80
 - 0s - loss: 0.9475 - val_loss: 0.6256
AUC: 0.8776

Epoch 42/80
 - 0s - loss: 0.9458 - val_loss: 0.6185
AUC: 0.8779

Epoch 43/80
 - 0s - loss: 0.9448 - val_loss: 0.6033
AUC: 0.8782

Epoch 44/80
 - 0s - loss: 0.9421 - val_loss: 0.6221
AUC: 0.8774

Epoch 45/80
 - 0s - loss: 0.9378 - val_loss: 0.5628
AUC: 0.8776

Epoch 46/80
 - 0s - loss: 0.9388 - val_loss: 0.5731
AUC: 0.8781

Epoch 47/80
 - 0s - loss: 0.9294 - val_loss: 0.5954
AUC: 0.8780

Epoch 48/80
 - 0s - loss: 0.9327 - val_loss: 0.5808
AUC: 0.8778

Epoch 49/80
 - 0s - loss: 0.9285 - val_loss: 0.5508
AUC: 0.8770

Epoch 50/80
 - 0s - loss: 0.9334 - val_loss: 0.6906
AUC: 0.8780

Epoch 51/80
 - 0s - loss: 0.9269 - val_loss: 0.5628
AUC: 0.8776

Epoch 52/80
 - 0s - loss: 0.9207 - val_loss: 0.5821
AUC: 0.8779

Epoch 53/80
 - 0s - loss: 0.9122 - val_loss: 0.5473
AUC: 0.8778

Epoch 54/80
 - 0s - loss: 0.9150 - val_loss: 0.5787
AUC: 0.8781

Epoch 55/80
 - 0s - loss: 0.9157 - val_loss: 0.5753
AUC: 0.8779

Epoch 56/80
 - 0s - loss: 0.9121 - val_loss: 0.5426
AUC: 0.8773

Epoch 57/80
 - 0s - loss: 0.9138 - val_loss: 0.5947
AUC: 0.8779

Epoch 58/80
 - 0s - loss: 0.9113 - val_loss: 0.5757
AUC: 0.8777

Epoch 59/80
 - 0s - loss: 0.9154 - val_loss: 0.5800
AUC: 0.8774

Epoch 60/80
 - 0s - loss: 0.9102 - val_loss: 0.5957
AUC: 0.8779

Epoch 61/80
 - 0s - loss: 0.9070 - val_loss: 0.5673
AUC: 0.8777

Epoch 62/80
 - 0s - loss: 0.9094 - val_loss: 0.5824
AUC: 0.8778

Epoch 63/80
 - 0s - loss: 0.9067 - val_loss: 0.5681
AUC: 0.8777

Epoch 64/80
 - 0s - loss: 0.9069 - val_loss: 0.5689
AUC: 0.8778

Epoch 65/80
 - 0s - loss: 0.9045 - val_loss: 0.5681
AUC: 0.8777

Epoch 66/80
 - 0s - loss: 0.9031 - val_loss: 0.5728
AUC: 0.8778

Epoch 67/80
 - 0s - loss: 0.9059 - val_loss: 0.5677
AUC: 0.8777

Epoch 68/80
 - 0s - loss: 0.9054 - val_loss: 0.5678
AUC: 0.8777

Epoch 69/80
 - 0s - loss: 0.9027 - val_loss: 0.5724
AUC: 0.8778

Epoch 70/80
 - 0s - loss: 0.9044 - val_loss: 0.5719
AUC: 0.8778

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9362 - val_loss: 0.5811
AUC: 0.8781

Epoch 2/30
 - 0s - loss: 0.9286 - val_loss: 0.5624
AUC: 0.8779

Epoch 3/30
 - 0s - loss: 0.9329 - val_loss: 0.5722
AUC: 0.8779

Epoch 4/30
 - 0s - loss: 0.9204 - val_loss: 0.5666
AUC: 0.8778

Epoch 5/30
 - 0s - loss: 0.9246 - val_loss: 0.5718
AUC: 0.8779

Epoch 6/30
 - 0s - loss: 0.9218 - val_loss: 0.5616
AUC: 0.8777

Epoch 7/30
 - 0s - loss: 0.9184 - val_loss: 0.5795
AUC: 0.8779

Epoch 8/30
 - 0s - loss: 0.9190 - val_loss: 0.5787
AUC: 0.8781

Epoch 9/30
 - 0s - loss: 0.9171 - val_loss: 0.5756
AUC: 0.8780

Epoch 10/30
 - 0s - loss: 0.9149 - val_loss: 0.5703
AUC: 0.8781

Epoch 11/30
 - 0s - loss: 0.9119 - val_loss: 0.5594
AUC: 0.8782

Epoch 12/30
 - 0s - loss: 0.9095 - val_loss: 0.5725
AUC: 0.8782

Epoch 13/30
 - 0s - loss: 0.9145 - val_loss: 0.5651
AUC: 0.8783

Epoch 14/30
 - 0s - loss: 0.9100 - val_loss: 0.5762
AUC: 0.8784

Epoch 15/30
 - 0s - loss: 0.9065 - val_loss: 0.5575
AUC: 0.8782

Epoch 16/30
 - 0s - loss: 0.9038 - val_loss: 0.5905
AUC: 0.8787

Epoch 17/30
 - 0s - loss: 0.9024 - val_loss: 0.5650
AUC: 0.8782

Epoch 18/30
 - 0s - loss: 0.9020 - val_loss: 0.5583
AUC: 0.8785

Epoch 19/30
 - 0s - loss: 0.8979 - val_loss: 0.5765
AUC: 0.8788

Epoch 20/30
 - 0s - loss: 0.8975 - val_loss: 0.5932
AUC: 0.8790

Epoch 21/30
 - 0s - loss: 0.8971 - val_loss: 0.5622
AUC: 0.8788

Epoch 22/30
 - 0s - loss: 0.8940 - val_loss: 0.5700
AUC: 0.8788

Epoch 23/30
 - 0s - loss: 0.8928 - val_loss: 0.5756
AUC: 0.8788

Epoch 24/30
 - 0s - loss: 0.8943 - val_loss: 0.5607
AUC: 0.8786

Epoch 25/30
 - 0s - loss: 0.8928 - val_loss: 0.5695
AUC: 0.8790

Epoch 26/30
 - 0s - loss: 0.8895 - val_loss: 0.5685
AUC: 0.8789

Epoch 27/30
 - 0s - loss: 0.8884 - val_loss: 0.5675
AUC: 0.8789

Epoch 28/30
 - 0s - loss: 0.8870 - val_loss: 0.5645
AUC: 0.8789

Epoch 29/30
 - 0s - loss: 0.8867 - val_loss: 0.5661
AUC: 0.8789

Epoch 30/30
 - 0s - loss: 0.8879 - val_loss: 0.5668
Using TensorFlow backend.
AUC: 0.8789

2019-03-08 11:07:27.994113: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:07:28.159028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:07:28.159071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:07:28.458055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:07:28.458107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:07:28.458115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:07:28.458410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9697
Epoch 2/80
 - 2s - loss: 0.1810
Epoch 3/80
 - 2s - loss: 0.1593
Epoch 4/80
 - 2s - loss: 0.1421
Epoch 5/80
 - 2s - loss: 0.1272
Epoch 6/80
 - 2s - loss: 0.1132
Epoch 7/80
 - 2s - loss: 0.0997
Epoch 8/80
 - 2s - loss: 0.0881
Epoch 9/80
 - 2s - loss: 0.0793
Epoch 10/80
 - 2s - loss: 0.0723
Epoch 11/80
 - 2s - loss: 0.0668
Epoch 12/80
 - 2s - loss: 0.0624
Epoch 13/80
 - 2s - loss: 0.0587
Epoch 14/80
 - 2s - loss: 0.0557
Epoch 15/80
 - 2s - loss: 0.0532
Epoch 16/80
 - 2s - loss: 0.0511
Epoch 17/80
 - 2s - loss: 0.0492
Epoch 18/80
 - 2s - loss: 0.0476
Epoch 19/80
 - 2s - loss: 0.0462
Epoch 20/80
 - 2s - loss: 0.0450
Epoch 21/80
 - 2s - loss: 0.0439
Epoch 22/80
 - 2s - loss: 0.0430
Epoch 23/80
 - 2s - loss: 0.0422
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0404
Epoch 27/80
 - 2s - loss: 0.0400
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:08:33.138651: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:08:33.307082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:08:33.307127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:08:33.604534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:08:33.604586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:08:33.604594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:08:33.604849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6017
Epoch 2/80
 - 2s - loss: 0.0835
Epoch 3/80
 - 2s - loss: 0.0663
Epoch 4/80
 - 2s - loss: 0.0616
Epoch 5/80
 - 2s - loss: 0.0556
Epoch 6/80
 - 2s - loss: 0.0485
Epoch 7/80
 - 2s - loss: 0.0420
Epoch 8/80
 - 2s - loss: 0.0368
Epoch 9/80
 - 2s - loss: 0.0328
Epoch 10/80
 - 2s - loss: 0.0296
Epoch 11/80
 - 2s - loss: 0.0270
Epoch 12/80
 - 2s - loss: 0.0248
Epoch 13/80
 - 2s - loss: 0.0229
Epoch 14/80
 - 2s - loss: 0.0213
Epoch 15/80
 - 2s - loss: 0.0200
Epoch 16/80
 - 2s - loss: 0.0189
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0172
Epoch 19/80
 - 2s - loss: 0.0165
Epoch 20/80
 - 2s - loss: 0.0159
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0119
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0113
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:10:15.615448: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:10:15.778930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:10:15.778973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:10:16.072780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:10:16.072831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:10:16.072840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:10:16.073099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6093
Epoch 2/80
 - 2s - loss: 0.0839
Epoch 3/80
 - 2s - loss: 0.0632
Epoch 4/80
 - 2s - loss: 0.0555
Epoch 5/80
 - 2s - loss: 0.0499
Epoch 6/80
 - 2s - loss: 0.0452
Epoch 7/80
 - 2s - loss: 0.0408
Epoch 8/80
 - 2s - loss: 0.0366
Epoch 9/80
 - 2s - loss: 0.0328
Epoch 10/80
 - 2s - loss: 0.0296
Epoch 11/80
 - 2s - loss: 0.0269
Epoch 12/80
 - 2s - loss: 0.0247
Epoch 13/80
 - 2s - loss: 0.0229
Epoch 14/80
 - 2s - loss: 0.0213
Epoch 15/80
 - 2s - loss: 0.0200
Epoch 16/80
 - 2s - loss: 0.0189
Epoch 17/80
 - 2s - loss: 0.0179
Epoch 18/80
 - 2s - loss: 0.0171
Epoch 19/80
 - 2s - loss: 0.0165
Epoch 20/80
 - 2s - loss: 0.0159
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0149
Epoch 23/80
 - 2s - loss: 0.0146
Epoch 24/80
 - 2s - loss: 0.0142
Epoch 25/80
 - 2s - loss: 0.0139
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0129
Epoch 31/80
 - 2s - loss: 0.0128
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0124
Epoch 36/80
 - 2s - loss: 0.0123
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0118
Epoch 49/80
 - 2s - loss: 0.0118
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0111
Epoch 55/80
 - 2s - loss: 0.0111
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0110
Epoch 68/80
 - 2s - loss: 0.0110
Epoch 69/80
 - 2s - loss: 0.0110
Epoch 70/80
 - 2s - loss: 0.0110
Epoch 71/80
 - 2s - loss: 0.0110
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:12:28.643794: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:12:28.807278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:12:28.807323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:12:29.109391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:12:29.109442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:12:29.109451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:12:29.109712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5897
Epoch 2/80
 - 2s - loss: 0.0814
Epoch 3/80
 - 2s - loss: 0.0636
Epoch 4/80
 - 2s - loss: 0.0562
Epoch 5/80
 - 2s - loss: 0.0500
Epoch 6/80
 - 2s - loss: 0.0450
Epoch 7/80
 - 2s - loss: 0.0404
Epoch 8/80
 - 2s - loss: 0.0364
Epoch 9/80
 - 2s - loss: 0.0328
Epoch 10/80
 - 2s - loss: 0.0297
Epoch 11/80
 - 2s - loss: 0.0271
Epoch 12/80
 - 2s - loss: 0.0249
Epoch 13/80
 - 2s - loss: 0.0230
Epoch 14/80
 - 2s - loss: 0.0215
Epoch 15/80
 - 2s - loss: 0.0202
Epoch 16/80
 - 2s - loss: 0.0191
Epoch 17/80
 - 2s - loss: 0.0182
Epoch 18/80
 - 2s - loss: 0.0174
Epoch 19/80
 - 2s - loss: 0.0167
Epoch 20/80
 - 2s - loss: 0.0161
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0128
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0126
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0123
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0122
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0121
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0120
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0119
Epoch 49/80
 - 2s - loss: 0.0114
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0113
Epoch 52/80
 - 2s - loss: 0.0113
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0112
Epoch 56/80
 - 2s - loss: 0.0112
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.5922 - val_loss: 1.3848
AUC: 0.8108

Epoch 2/80
 - 0s - loss: 2.2598 - val_loss: 1.0254
AUC: 0.8343

Epoch 3/80
 - 0s - loss: 1.5912 - val_loss: 0.8420
AUC: 0.8386

Epoch 4/80
 - 0s - loss: 1.2758 - val_loss: 0.7535
AUC: 0.8449

Epoch 5/80
 - 0s - loss: 1.1806 - val_loss: 0.6749
AUC: 0.8475

Epoch 6/80
 - 0s - loss: 1.1368 - val_loss: 0.6225
AUC: 0.8474

Epoch 7/80
 - 0s - loss: 1.0998 - val_loss: 0.6294
AUC: 0.8491

Epoch 8/80
 - 0s - loss: 1.0845 - val_loss: 0.7024
AUC: 0.8536

Epoch 9/80
 - 0s - loss: 1.0702 - val_loss: 0.6595
AUC: 0.8524

Epoch 10/80
 - 0s - loss: 1.0573 - val_loss: 0.6239
AUC: 0.8553

Epoch 11/80
 - 0s - loss: 1.0498 - val_loss: 0.6746
AUC: 0.8569

Epoch 12/80
 - 0s - loss: 1.0407 - val_loss: 0.6099
AUC: 0.8548

Epoch 13/80
 - 0s - loss: 1.0344 - val_loss: 0.6542
AUC: 0.8563

Epoch 14/80
 - 0s - loss: 1.0305 - val_loss: 0.6026
AUC: 0.8570

Epoch 15/80
 - 0s - loss: 1.0238 - val_loss: 0.6005
AUC: 0.8578

Epoch 16/80
 - 0s - loss: 1.0232 - val_loss: 0.6221
AUC: 0.8580

Epoch 17/80
 - 0s - loss: 1.0118 - val_loss: 0.5901
AUC: 0.8581

Epoch 18/80
 - 0s - loss: 1.0114 - val_loss: 0.6063
AUC: 0.8599

Epoch 19/80
 - 0s - loss: 1.0095 - val_loss: 0.6405
AUC: 0.8592

Epoch 20/80
 - 0s - loss: 1.0004 - val_loss: 0.5862
AUC: 0.8593

Epoch 21/80
 - 0s - loss: 1.0003 - val_loss: 0.6300
AUC: 0.8601

Epoch 22/80
 - 0s - loss: 0.9937 - val_loss: 0.6348
AUC: 0.8603

Epoch 23/80
 - 0s - loss: 0.9953 - val_loss: 0.6618
AUC: 0.8602

Epoch 24/80
 - 0s - loss: 0.9857 - val_loss: 0.6442
AUC: 0.8600

Epoch 25/80
 - 0s - loss: 0.9801 - val_loss: 0.6515
AUC: 0.8615

Epoch 26/80
 - 0s - loss: 0.9880 - val_loss: 0.5931
AUC: 0.8616

Epoch 27/80
 - 0s - loss: 0.9835 - val_loss: 0.6516
AUC: 0.8631

Epoch 28/80
 - 0s - loss: 0.9821 - val_loss: 0.5842
AUC: 0.8614

Epoch 29/80
 - 0s - loss: 0.9769 - val_loss: 0.6158
AUC: 0.8614

Epoch 30/80
 - 0s - loss: 0.9732 - val_loss: 0.5785
AUC: 0.8618

Epoch 31/80
 - 0s - loss: 0.9686 - val_loss: 0.6552
AUC: 0.8636

Epoch 32/80
 - 0s - loss: 0.9725 - val_loss: 0.5309
AUC: 0.8607

Epoch 33/80
 - 0s - loss: 0.9705 - val_loss: 0.6375
AUC: 0.8647

Epoch 34/80
 - 0s - loss: 0.9709 - val_loss: 0.5591
AUC: 0.8627

Epoch 35/80
 - 0s - loss: 0.9600 - val_loss: 0.6531
AUC: 0.8641

Epoch 36/80
 - 0s - loss: 0.9613 - val_loss: 0.6027
AUC: 0.8646

Epoch 37/80
 - 0s - loss: 0.9604 - val_loss: 0.5981
AUC: 0.8647

Epoch 38/80
 - 0s - loss: 0.9529 - val_loss: 0.6274
AUC: 0.8647

Epoch 39/80
 - 0s - loss: 0.9520 - val_loss: 0.5802
AUC: 0.8647

Epoch 40/80
 - 0s - loss: 0.9457 - val_loss: 0.5817
AUC: 0.8644

Epoch 41/80
 - 0s - loss: 0.9539 - val_loss: 0.5831
AUC: 0.8646

Epoch 42/80
 - 0s - loss: 0.9423 - val_loss: 0.5563
AUC: 0.8641

Epoch 43/80
 - 0s - loss: 0.9369 - val_loss: 0.5638
AUC: 0.8652

Epoch 44/80
 - 0s - loss: 0.9363 - val_loss: 0.6009
AUC: 0.8654

Epoch 45/80
 - 0s - loss: 0.9307 - val_loss: 0.5777
AUC: 0.8650

Epoch 46/80
 - 0s - loss: 0.9306 - val_loss: 0.5577
AUC: 0.8653

Epoch 47/80
 - 0s - loss: 0.9272 - val_loss: 0.5973
AUC: 0.8656

Epoch 48/80
 - 0s - loss: 0.9352 - val_loss: 0.5938
AUC: 0.8657

Epoch 49/80
 - 0s - loss: 0.9247 - val_loss: 0.5673
AUC: 0.8654

Epoch 50/80
 - 0s - loss: 0.9292 - val_loss: 0.5799
AUC: 0.8653

Epoch 51/80
 - 0s - loss: 0.9318 - val_loss: 0.5991
AUC: 0.8659

Epoch 52/80
 - 0s - loss: 0.9278 - val_loss: 0.5619
AUC: 0.8655

Epoch 53/80
 - 0s - loss: 0.9234 - val_loss: 0.5883
AUC: 0.8658

Epoch 54/80
 - 0s - loss: 0.9221 - val_loss: 0.5797
AUC: 0.8656

Epoch 55/80
 - 0s - loss: 0.9199 - val_loss: 0.5820
AUC: 0.8656

Epoch 56/80
 - 0s - loss: 0.9246 - val_loss: 0.5863
AUC: 0.8656

Epoch 57/80
 - 0s - loss: 0.9217 - val_loss: 0.5886
AUC: 0.8656

Epoch 58/80
 - 0s - loss: 0.9224 - val_loss: 0.5791
AUC: 0.8655

Epoch 59/80
 - 0s - loss: 0.9246 - val_loss: 0.5918
AUC: 0.8656

Epoch 60/80
 - 0s - loss: 0.9232 - val_loss: 0.5832
AUC: 0.8656

Epoch 61/80
 - 0s - loss: 0.9219 - val_loss: 0.5912
AUC: 0.8656

Epoch 62/80
 - 0s - loss: 0.9187 - val_loss: 0.5830
AUC: 0.8655

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9245 - val_loss: 0.5925
AUC: 0.8658

Epoch 2/30
 - 0s - loss: 0.9244 - val_loss: 0.5825
AUC: 0.8656

Epoch 3/30
 - 0s - loss: 0.9227 - val_loss: 0.5667
AUC: 0.8656

Epoch 4/30
 - 0s - loss: 0.9194 - val_loss: 0.5876
AUC: 0.8659

Epoch 5/30
 - 0s - loss: 0.9194 - val_loss: 0.5828
AUC: 0.8661

Epoch 6/30
 - 0s - loss: 0.9103 - val_loss: 0.5832
AUC: 0.8661

Epoch 7/30
 - 0s - loss: 0.9203 - val_loss: 0.6082
AUC: 0.8665

Epoch 8/30
 - 0s - loss: 0.9131 - val_loss: 0.5828
AUC: 0.8664

Epoch 9/30
 - 0s - loss: 0.9106 - val_loss: 0.5768
AUC: 0.8663

Epoch 10/30
 - 0s - loss: 0.9095 - val_loss: 0.5910
AUC: 0.8665

Epoch 11/30
 - 0s - loss: 0.9083 - val_loss: 0.5550
AUC: 0.8661

Epoch 12/30
 - 0s - loss: 0.9061 - val_loss: 0.5703
AUC: 0.8665

Epoch 13/30
 - 0s - loss: 0.9034 - val_loss: 0.5827
AUC: 0.8667

Epoch 14/30
 - 0s - loss: 0.9002 - val_loss: 0.5767
AUC: 0.8667

Epoch 15/30
 - 0s - loss: 0.8986 - val_loss: 0.5780
AUC: 0.8666

Epoch 16/30
 - 0s - loss: 0.8984 - val_loss: 0.5609
AUC: 0.8666

Epoch 17/30
 - 0s - loss: 0.8954 - val_loss: 0.5767
AUC: 0.8669

Epoch 18/30
 - 0s - loss: 0.8931 - val_loss: 0.5684
AUC: 0.8667

Epoch 19/30
 - 0s - loss: 0.8952 - val_loss: 0.6004
AUC: 0.8673

Epoch 20/30
 - 0s - loss: 0.8911 - val_loss: 0.5792
AUC: 0.8670

Epoch 21/30
 - 0s - loss: 0.8887 - val_loss: 0.6088
AUC: 0.8674

Epoch 22/30
 - 0s - loss: 0.8895 - val_loss: 0.5780
AUC: 0.8672

Epoch 23/30
 - 0s - loss: 0.8853 - val_loss: 0.5740
AUC: 0.8671

Epoch 24/30
 - 0s - loss: 0.8900 - val_loss: 0.5729
AUC: 0.8671

Epoch 25/30
 - 0s - loss: 0.8886 - val_loss: 0.5680
AUC: 0.8671

Epoch 26/30
 - 0s - loss: 0.8892 - val_loss: 0.5749
AUC: 0.8672

Epoch 27/30
 - 0s - loss: 0.8823 - val_loss: 0.5675
AUC: 0.8671

Epoch 28/30
 - 0s - loss: 0.8888 - val_loss: 0.5705
AUC: 0.8672

Epoch 29/30
 - 0s - loss: 0.8842 - val_loss: 0.5715
AUC: 0.8672

Epoch 30/30
 - 0s - loss: 0.8882 - val_loss: 0.5737
Using TensorFlow backend.
AUC: 0.8672

2019-03-08 11:15:54.196311: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:15:54.363726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:15:54.363769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:15:54.660519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:15:54.660569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:15:54.660579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:15:54.660851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1973
Epoch 2/80
 - 2s - loss: 0.3087
Epoch 3/80
 - 2s - loss: 0.2558
Epoch 4/80
 - 2s - loss: 0.2231
Epoch 5/80
 - 2s - loss: 0.2008
Epoch 6/80
 - 2s - loss: 0.1828
Epoch 7/80
 - 2s - loss: 0.1678
Epoch 8/80
 - 2s - loss: 0.1552
Epoch 9/80
 - 2s - loss: 0.1449
Epoch 10/80
 - 2s - loss: 0.1365
Epoch 11/80
 - 2s - loss: 0.1295
Epoch 12/80
 - 2s - loss: 0.1239
Epoch 13/80
 - 2s - loss: 0.1191
Epoch 14/80
 - 2s - loss: 0.1151
Epoch 15/80
 - 2s - loss: 0.1116
Epoch 16/80
 - 2s - loss: 0.1085
Epoch 17/80
 - 2s - loss: 0.1057
Epoch 18/80
 - 2s - loss: 0.1032
Epoch 19/80
 - 2s - loss: 0.1010
Epoch 20/80
 - 2s - loss: 0.0991
Epoch 21/80
 - 2s - loss: 0.0974
Epoch 22/80
 - 2s - loss: 0.0960
Epoch 23/80
 - 2s - loss: 0.0948
Epoch 24/80
 - 2s - loss: 0.0937
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0921
Epoch 27/80
 - 2s - loss: 0.0914
Epoch 28/80
 - 2s - loss: 0.0908
Epoch 29/80
 - 2s - loss: 0.0903
Epoch 30/80
 - 2s - loss: 0.0898
Epoch 31/80
 - 2s - loss: 0.0894
Epoch 32/80
 - 2s - loss: 0.0891
Epoch 33/80
 - 2s - loss: 0.0888
Epoch 34/80
 - 2s - loss: 0.0885
Epoch 35/80
 - 2s - loss: 0.0883
Epoch 36/80
 - 2s - loss: 0.0880
Epoch 37/80
 - 2s - loss: 0.0878
Epoch 38/80
 - 2s - loss: 0.0876
Epoch 39/80
 - 2s - loss: 0.0874
Epoch 40/80
 - 2s - loss: 0.0872
Epoch 41/80
 - 2s - loss: 0.0871
Epoch 42/80
 - 2s - loss: 0.0869
Epoch 43/80
 - 2s - loss: 0.0868
Epoch 44/80
 - 2s - loss: 0.0866
Epoch 45/80
 - 2s - loss: 0.0865
Epoch 46/80
 - 2s - loss: 0.0864
Epoch 47/80
 - 2s - loss: 0.0863
Epoch 48/80
 - 2s - loss: 0.0862
Epoch 49/80
 - 2s - loss: 0.0862
Epoch 50/80
 - 2s - loss: 0.0860
Epoch 51/80
 - 2s - loss: 0.0860
Epoch 52/80
 - 2s - loss: 0.0859
Epoch 53/80
 - 2s - loss: 0.0858
Epoch 54/80
 - 2s - loss: 0.0857
Epoch 55/80
 - 2s - loss: 0.0857
Epoch 56/80
 - 2s - loss: 0.0856
Epoch 57/80
 - 2s - loss: 0.0856
Epoch 58/80
 - 2s - loss: 0.0855
Epoch 59/80
 - 2s - loss: 0.0855
Epoch 60/80
 - 2s - loss: 0.0854
Epoch 61/80
 - 2s - loss: 0.0854
Epoch 62/80
 - 2s - loss: 0.0853
Epoch 63/80
 - 2s - loss: 0.0853
Epoch 64/80
 - 2s - loss: 0.0852
Epoch 65/80
 - 2s - loss: 0.0852
Epoch 66/80
 - 2s - loss: 0.0851
Epoch 67/80
 - 2s - loss: 0.0851
Epoch 68/80
 - 2s - loss: 0.0851
Epoch 69/80
 - 2s - loss: 0.0851
Epoch 70/80
 - 2s - loss: 0.0817
Epoch 71/80
 - 2s - loss: 0.0814
Epoch 72/80
 - 2s - loss: 0.0814
Epoch 73/80
 - 2s - loss: 0.0814
Epoch 74/80
 - 2s - loss: 0.0813
Epoch 75/80
 - 2s - loss: 0.0805
Epoch 76/80
 - 2s - loss: 0.0805
Epoch 77/80
 - 2s - loss: 0.0805
Epoch 78/80
 - 2s - loss: 0.0805
Epoch 79/80
 - 2s - loss: 0.0803
Epoch 80/80
 - 2s - loss: 0.0803
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.6415 - val_loss: 1.2382
AUC: 0.8091

Epoch 2/80
 - 0s - loss: 2.2992 - val_loss: 1.1986
AUC: 0.8393

Epoch 3/80
 - 0s - loss: 1.6555 - val_loss: 0.7306
AUC: 0.8500

Epoch 4/80
 - 0s - loss: 1.3016 - val_loss: 0.6211
AUC: 0.8538

Epoch 5/80
 - 0s - loss: 1.1758 - val_loss: 0.6564
AUC: 0.8580

Epoch 6/80
 - 0s - loss: 1.1264 - val_loss: 0.7054
AUC: 0.8620

Epoch 7/80
 - 0s - loss: 1.0896 - val_loss: 0.7286
AUC: 0.8629

Epoch 8/80
 - 0s - loss: 1.0751 - val_loss: 0.6464
AUC: 0.8646

Epoch 9/80
 - 0s - loss: 1.0615 - val_loss: 0.6813
AUC: 0.8648

Epoch 10/80
 - 0s - loss: 1.0586 - val_loss: 0.6110
AUC: 0.8648

Epoch 11/80
 - 0s - loss: 1.0506 - val_loss: 0.6139
AUC: 0.8668

Epoch 12/80
 - 0s - loss: 1.0455 - val_loss: 0.6706
AUC: 0.8671

Epoch 13/80
 - 0s - loss: 1.0327 - val_loss: 0.6321
AUC: 0.8688

Epoch 14/80
 - 0s - loss: 1.0235 - val_loss: 0.6366
AUC: 0.8686

Epoch 15/80
 - 0s - loss: 1.0215 - val_loss: 0.6248
AUC: 0.8685

Epoch 16/80
 - 0s - loss: 1.0188 - val_loss: 0.6293
AUC: 0.8694

Epoch 17/80
 - 0s - loss: 1.0176 - val_loss: 0.6234
AUC: 0.8706

Epoch 18/80
 - 0s - loss: 1.0088 - val_loss: 0.5952
AUC: 0.8703

Epoch 19/80
 - 0s - loss: 0.9974 - val_loss: 0.6318
AUC: 0.8703

Epoch 20/80
 - 0s - loss: 1.0048 - val_loss: 0.6029
AUC: 0.8724

Epoch 21/80
 - 0s - loss: 1.0007 - val_loss: 0.5655
AUC: 0.8724

Epoch 22/80
 - 0s - loss: 0.9845 - val_loss: 0.6592
AUC: 0.8724

Epoch 23/80
 - 0s - loss: 0.9892 - val_loss: 0.5843
AUC: 0.8729

Epoch 24/80
 - 0s - loss: 0.9844 - val_loss: 0.6174
AUC: 0.8737

Epoch 25/80
 - 0s - loss: 0.9837 - val_loss: 0.6237
AUC: 0.8734

Epoch 26/80
 - 0s - loss: 0.9792 - val_loss: 0.5908
AUC: 0.8741

Epoch 27/80
 - 0s - loss: 0.9685 - val_loss: 0.6210
AUC: 0.8727

Epoch 28/80
 - 0s - loss: 0.9779 - val_loss: 0.7250
AUC: 0.8730

Epoch 29/80
 - 0s - loss: 0.9700 - val_loss: 0.6274
AUC: 0.8739

Epoch 30/80
 - 0s - loss: 0.9693 - val_loss: 0.6214
AUC: 0.8750

Epoch 31/80
 - 0s - loss: 0.9644 - val_loss: 0.5753
AUC: 0.8744

Epoch 32/80
 - 0s - loss: 0.9531 - val_loss: 0.5936
AUC: 0.8756

Epoch 33/80
 - 0s - loss: 0.9461 - val_loss: 0.6272
AUC: 0.8758

Epoch 34/80
 - 0s - loss: 0.9428 - val_loss: 0.5807
AUC: 0.8752

Epoch 35/80
 - 0s - loss: 0.9429 - val_loss: 0.5856
AUC: 0.8753

Epoch 36/80
 - 0s - loss: 0.9441 - val_loss: 0.6175
AUC: 0.8754

Epoch 37/80
 - 0s - loss: 0.9455 - val_loss: 0.5851
AUC: 0.8749

Epoch 38/80
 - 0s - loss: 0.9415 - val_loss: 0.6049
AUC: 0.8751

Epoch 39/80
 - 0s - loss: 0.9473 - val_loss: 0.6247
AUC: 0.8754

Epoch 40/80
 - 0s - loss: 0.9431 - val_loss: 0.6147
AUC: 0.8755

Epoch 41/80
 - 0s - loss: 0.9392 - val_loss: 0.6044
AUC: 0.8750

Epoch 42/80
 - 0s - loss: 0.9373 - val_loss: 0.5948
AUC: 0.8750

Epoch 43/80
 - 0s - loss: 0.9390 - val_loss: 0.5840
AUC: 0.8749

Epoch 44/80
 - 0s - loss: 0.9365 - val_loss: 0.5867
AUC: 0.8751

Epoch 45/80
 - 0s - loss: 0.9302 - val_loss: 0.5839
AUC: 0.8750

Epoch 46/80
 - 0s - loss: 0.9418 - val_loss: 0.5918
AUC: 0.8752

Epoch 47/80
 - 0s - loss: 0.9305 - val_loss: 0.5932
AUC: 0.8751

Epoch 48/80
 - 0s - loss: 0.9293 - val_loss: 0.5893
AUC: 0.8751

Epoch 49/80
 - 0s - loss: 0.9320 - val_loss: 0.5883
AUC: 0.8751

Epoch 50/80
 - 0s - loss: 0.9389 - val_loss: 0.6052
AUC: 0.8753

Epoch 51/80
 - 0s - loss: 0.9329 - val_loss: 0.5906
AUC: 0.8752

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9401 - val_loss: 0.6084
AUC: 0.8755

Epoch 2/30
 - 0s - loss: 0.9392 - val_loss: 0.5853
AUC: 0.8751

Epoch 3/30
 - 0s - loss: 0.9427 - val_loss: 0.5812
AUC: 0.8753

Epoch 4/30
 - 0s - loss: 0.9371 - val_loss: 0.5809
AUC: 0.8753

Epoch 5/30
 - 0s - loss: 0.9323 - val_loss: 0.6064
AUC: 0.8754

Epoch 6/30
 - 0s - loss: 0.9375 - val_loss: 0.5628
AUC: 0.8748

Epoch 7/30
 - 0s - loss: 0.9301 - val_loss: 0.5954
AUC: 0.8753

Epoch 8/30
 - 0s - loss: 0.9325 - val_loss: 0.6103
AUC: 0.8755

Epoch 9/30
 - 0s - loss: 0.9280 - val_loss: 0.5955
AUC: 0.8755

Epoch 10/30
 - 0s - loss: 0.9276 - val_loss: 0.5692
AUC: 0.8752

Epoch 11/30
 - 0s - loss: 0.9247 - val_loss: 0.5732
AUC: 0.8758

Epoch 12/30
 - 0s - loss: 0.9249 - val_loss: 0.6022
AUC: 0.8760

Epoch 13/30
 - 0s - loss: 0.9205 - val_loss: 0.5819
AUC: 0.8754

Epoch 14/30
 - 0s - loss: 0.9208 - val_loss: 0.5848
AUC: 0.8756

Epoch 15/30
 - 0s - loss: 0.9150 - val_loss: 0.5719
AUC: 0.8755

Epoch 16/30
 - 0s - loss: 0.9130 - val_loss: 0.5858
AUC: 0.8754

Epoch 17/30
 - 0s - loss: 0.9128 - val_loss: 0.5776
AUC: 0.8753

Epoch 18/30
 - 0s - loss: 0.9120 - val_loss: 0.5826
AUC: 0.8755

Epoch 19/30
 - 0s - loss: 0.9128 - val_loss: 0.5749
AUC: 0.8754

Epoch 20/30
 - 0s - loss: 0.9095 - val_loss: 0.5834
AUC: 0.8756

Epoch 21/30
 - 0s - loss: 0.9132 - val_loss: 0.5804
AUC: 0.8756

Epoch 22/30
 - 0s - loss: 0.9128 - val_loss: 0.5807
AUC: 0.8756

Epoch 23/30
 - 0s - loss: 0.9126 - val_loss: 0.5891
AUC: 0.8757

Epoch 24/30
 - 0s - loss: 0.9106 - val_loss: 0.5821
AUC: 0.8756

Epoch 25/30
 - 0s - loss: 0.9075 - val_loss: 0.5845
AUC: 0.8756

Epoch 26/30
 - 0s - loss: 0.9120 - val_loss: 0.5786
AUC: 0.8756

Epoch 27/30
 - 0s - loss: 0.9081 - val_loss: 0.5793
AUC: 0.8756

Epoch 28/30
 - 0s - loss: 0.9104 - val_loss: 0.5801
AUC: 0.8756

Epoch 29/30
 - 0s - loss: 0.9102 - val_loss: 0.5800
AUC: 0.8756

Epoch 30/30
 - 0s - loss: 0.9101 - val_loss: 0.5810
Using TensorFlow backend.
AUC: 0.8756

2019-03-08 11:19:14.353474: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:19:14.517771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:19:14.517815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:19:14.815313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:19:14.815364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:19:14.815373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:19:14.815627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2125
Epoch 2/80
 - 2s - loss: 0.3165
Epoch 3/80
 - 2s - loss: 0.2830
Epoch 4/80
 - 2s - loss: 0.2473
Epoch 5/80
 - 2s - loss: 0.2160
Epoch 6/80
 - 2s - loss: 0.1917
Epoch 7/80
 - 2s - loss: 0.1729
Epoch 8/80
 - 2s - loss: 0.1587
Epoch 9/80
 - 2s - loss: 0.1474
Epoch 10/80
 - 2s - loss: 0.1382
Epoch 11/80
 - 2s - loss: 0.1309
Epoch 12/80
 - 2s - loss: 0.1250
Epoch 13/80
 - 2s - loss: 0.1199
Epoch 14/80
 - 2s - loss: 0.1156
Epoch 15/80
 - 2s - loss: 0.1119
Epoch 16/80
 - 2s - loss: 0.1086
Epoch 17/80
 - 2s - loss: 0.1058
Epoch 18/80
 - 2s - loss: 0.1033
Epoch 19/80
 - 2s - loss: 0.1012
Epoch 20/80
 - 2s - loss: 0.0993
Epoch 21/80
 - 2s - loss: 0.0976
Epoch 22/80
 - 2s - loss: 0.0963
Epoch 23/80
 - 2s - loss: 0.0950
Epoch 24/80
 - 2s - loss: 0.0940
Epoch 25/80
 - 2s - loss: 0.0931
Epoch 26/80
 - 2s - loss: 0.0923
Epoch 27/80
 - 2s - loss: 0.0916
Epoch 28/80
 - 2s - loss: 0.0911
Epoch 29/80
 - 2s - loss: 0.0905
Epoch 30/80
 - 2s - loss: 0.0901
Epoch 31/80
 - 2s - loss: 0.0897
Epoch 32/80
 - 2s - loss: 0.0894
Epoch 33/80
 - 2s - loss: 0.0890
Epoch 34/80
 - 2s - loss: 0.0888
Epoch 35/80
 - 2s - loss: 0.0885
Epoch 36/80
 - 2s - loss: 0.0883
Epoch 37/80
 - 2s - loss: 0.0881
Epoch 38/80
 - 2s - loss: 0.0879
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0875
Epoch 41/80
 - 2s - loss: 0.0874
Epoch 42/80
 - 2s - loss: 0.0872
Epoch 43/80
 - 2s - loss: 0.0871
Epoch 44/80
 - 2s - loss: 0.0869
Epoch 45/80
 - 2s - loss: 0.0869
Epoch 46/80
 - 2s - loss: 0.0867
Epoch 47/80
 - 2s - loss: 0.0866
Epoch 48/80
 - 2s - loss: 0.0865
Epoch 49/80
 - 2s - loss: 0.0865
Epoch 50/80
 - 2s - loss: 0.0864
Epoch 51/80
 - 2s - loss: 0.0863
Epoch 52/80
 - 2s - loss: 0.0862
Epoch 53/80
 - 2s - loss: 0.0862
Epoch 54/80
 - 2s - loss: 0.0860
Epoch 55/80
 - 2s - loss: 0.0860
Epoch 56/80
 - 2s - loss: 0.0860
Epoch 57/80
 - 2s - loss: 0.0859
Epoch 58/80
 - 2s - loss: 0.0858
Epoch 59/80
 - 2s - loss: 0.0858
Epoch 60/80
 - 2s - loss: 0.0857
Epoch 61/80
 - 2s - loss: 0.0857
Epoch 62/80
 - 2s - loss: 0.0857
Epoch 63/80
 - 2s - loss: 0.0856
Epoch 64/80
 - 2s - loss: 0.0856
Epoch 65/80
 - 2s - loss: 0.0855
Epoch 66/80
 - 2s - loss: 0.0855
Epoch 67/80
 - 2s - loss: 0.0821
Epoch 68/80
 - 2s - loss: 0.0818
Epoch 69/80
 - 2s - loss: 0.0818
Epoch 70/80
 - 2s - loss: 0.0818
Epoch 71/80
 - 2s - loss: 0.0818
Epoch 72/80
 - 2s - loss: 0.0810
Epoch 73/80
 - 2s - loss: 0.0809
Epoch 74/80
 - 2s - loss: 0.0809
Epoch 75/80
 - 2s - loss: 0.0809
Epoch 76/80
 - 2s - loss: 0.0808
Epoch 77/80
 - 2s - loss: 0.0808
Epoch 78/80
 - 2s - loss: 0.0807
Epoch 79/80
 - 2s - loss: 0.0807
Epoch 80/80
 - 2s - loss: 0.0807
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.7702 - val_loss: 1.3660
AUC: 0.8206

Epoch 2/80
 - 0s - loss: 1.7703 - val_loss: 0.6744
AUC: 0.8481

Epoch 3/80
 - 0s - loss: 1.3274 - val_loss: 0.6452
AUC: 0.8521

Epoch 4/80
 - 0s - loss: 1.1799 - val_loss: 0.6365
AUC: 0.8604

Epoch 5/80
 - 0s - loss: 1.1124 - val_loss: 0.6574
AUC: 0.8617

Epoch 6/80
 - 0s - loss: 1.0900 - val_loss: 0.6075
AUC: 0.8642

Epoch 7/80
 - 0s - loss: 1.0765 - val_loss: 0.6502
AUC: 0.8662

Epoch 8/80
 - 0s - loss: 1.0520 - val_loss: 0.6223
AUC: 0.8664

Epoch 9/80
 - 0s - loss: 1.0359 - val_loss: 0.7008
AUC: 0.8685

Epoch 10/80
 - 0s - loss: 1.0335 - val_loss: 0.5358
AUC: 0.8666

Epoch 11/80
 - 0s - loss: 1.0264 - val_loss: 0.5493
AUC: 0.8672

Epoch 12/80
 - 0s - loss: 1.0123 - val_loss: 0.6335
AUC: 0.8686

Epoch 13/80
 - 0s - loss: 1.0079 - val_loss: 0.5928
AUC: 0.8700

Epoch 14/80
 - 0s - loss: 1.0006 - val_loss: 0.5698
AUC: 0.8679

Epoch 15/80
 - 0s - loss: 0.9959 - val_loss: 0.5881
AUC: 0.8707

Epoch 16/80
 - 0s - loss: 0.9948 - val_loss: 0.6636
AUC: 0.8695

Epoch 17/80
 - 0s - loss: 0.9951 - val_loss: 0.6325
AUC: 0.8723

Epoch 18/80
 - 0s - loss: 0.9875 - val_loss: 0.6290
AUC: 0.8710

Epoch 19/80
 - 0s - loss: 0.9832 - val_loss: 0.5289
AUC: 0.8703

Epoch 20/80
 - 0s - loss: 0.9820 - val_loss: 0.6404
AUC: 0.8714

Epoch 21/80
 - 0s - loss: 0.9797 - val_loss: 0.6117
AUC: 0.8708

Epoch 22/80
 - 0s - loss: 0.9697 - val_loss: 0.6408
AUC: 0.8716

Epoch 23/80
 - 0s - loss: 0.9705 - val_loss: 0.5880
AUC: 0.8712

Epoch 24/80
 - 0s - loss: 0.9702 - val_loss: 0.6410
AUC: 0.8703

Epoch 25/80
 - 0s - loss: 0.9603 - val_loss: 0.6085
AUC: 0.8714

Epoch 26/80
 - 0s - loss: 0.9606 - val_loss: 0.6686
AUC: 0.8715

Epoch 27/80
 - 0s - loss: 0.9556 - val_loss: 0.6029
AUC: 0.8712

Epoch 28/80
 - 0s - loss: 0.9546 - val_loss: 0.6215
AUC: 0.8721

Epoch 29/80
 - 0s - loss: 0.9482 - val_loss: 0.5655
AUC: 0.8722

Epoch 30/80
 - 0s - loss: 0.9336 - val_loss: 0.5838
AUC: 0.8727

Epoch 31/80
 - 0s - loss: 0.9257 - val_loss: 0.6123
AUC: 0.8728

Epoch 32/80
 - 0s - loss: 0.9287 - val_loss: 0.5834
AUC: 0.8726

Epoch 33/80
 - 0s - loss: 0.9275 - val_loss: 0.5548
AUC: 0.8721

Epoch 34/80
 - 0s - loss: 0.9224 - val_loss: 0.5817
AUC: 0.8724

Epoch 35/80
 - 0s - loss: 0.9251 - val_loss: 0.5434
AUC: 0.8724

Epoch 36/80
 - 0s - loss: 0.9231 - val_loss: 0.5557
AUC: 0.8726

Epoch 37/80
 - 0s - loss: 0.9236 - val_loss: 0.5717
AUC: 0.8727

Epoch 38/80
 - 0s - loss: 0.9178 - val_loss: 0.5619
AUC: 0.8721

Epoch 39/80
 - 0s - loss: 0.9195 - val_loss: 0.5432
AUC: 0.8723

Epoch 40/80
 - 0s - loss: 0.9202 - val_loss: 0.5790
AUC: 0.8726

Epoch 41/80
 - 0s - loss: 0.9168 - val_loss: 0.5652
AUC: 0.8726

Epoch 42/80
 - 0s - loss: 0.9146 - val_loss: 0.5771
AUC: 0.8726

Epoch 43/80
 - 0s - loss: 0.9142 - val_loss: 0.5704
AUC: 0.8725

Epoch 44/80
 - 0s - loss: 0.9150 - val_loss: 0.5710
AUC: 0.8726

Epoch 45/80
 - 0s - loss: 0.9132 - val_loss: 0.5733
AUC: 0.8725

Epoch 46/80
 - 0s - loss: 0.9173 - val_loss: 0.5736
AUC: 0.8725

Epoch 47/80
 - 0s - loss: 0.9137 - val_loss: 0.5657
AUC: 0.8724

Epoch 48/80
 - 0s - loss: 0.9162 - val_loss: 0.5723
AUC: 0.8724

Epoch 49/80
 - 0s - loss: 0.9088 - val_loss: 0.5676
AUC: 0.8724

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9240 - val_loss: 0.5950
AUC: 0.8727

Epoch 2/30
 - 0s - loss: 0.9252 - val_loss: 0.5578
AUC: 0.8725

Epoch 3/30
 - 0s - loss: 0.9248 - val_loss: 0.5708
AUC: 0.8726

Epoch 4/30
 - 0s - loss: 0.9213 - val_loss: 0.5753
AUC: 0.8726

Epoch 5/30
 - 0s - loss: 0.9199 - val_loss: 0.5836
AUC: 0.8728

Epoch 6/30
 - 0s - loss: 0.9181 - val_loss: 0.5523
AUC: 0.8724

Epoch 7/30
 - 0s - loss: 0.9112 - val_loss: 0.5848
AUC: 0.8729

Epoch 8/30
 - 0s - loss: 0.9098 - val_loss: 0.5868
AUC: 0.8729

Epoch 9/30
 - 0s - loss: 0.9095 - val_loss: 0.5796
AUC: 0.8732

Epoch 10/30
 - 0s - loss: 0.9076 - val_loss: 0.5788
AUC: 0.8732

Epoch 11/30
 - 0s - loss: 0.9093 - val_loss: 0.5846
AUC: 0.8731

Epoch 12/30
 - 0s - loss: 0.9058 - val_loss: 0.5884
AUC: 0.8734

Epoch 13/30
 - 0s - loss: 0.9005 - val_loss: 0.5701
AUC: 0.8733

Epoch 14/30
 - 0s - loss: 0.9000 - val_loss: 0.5820
AUC: 0.8733

Epoch 15/30
 - 0s - loss: 0.8957 - val_loss: 0.5656
AUC: 0.8734

Epoch 16/30
 - 0s - loss: 0.8956 - val_loss: 0.5659
AUC: 0.8734

Epoch 17/30
 - 0s - loss: 0.8988 - val_loss: 0.5623
AUC: 0.8733

Epoch 18/30
 - 0s - loss: 0.8929 - val_loss: 0.5669
AUC: 0.8734

Epoch 19/30
 - 0s - loss: 0.8934 - val_loss: 0.5622
AUC: 0.8733

Epoch 20/30
 - 0s - loss: 0.8891 - val_loss: 0.5602
AUC: 0.8733

Epoch 21/30
 - 0s - loss: 0.8922 - val_loss: 0.5605
AUC: 0.8733

Epoch 22/30
 - 0s - loss: 0.8894 - val_loss: 0.5661
AUC: 0.8734

Epoch 23/30
 - 0s - loss: 0.8926 - val_loss: 0.5597
AUC: 0.8733

Epoch 24/30
 - 0s - loss: 0.8940 - val_loss: 0.5588
AUC: 0.8733

Epoch 25/30
 - 0s - loss: 0.8971 - val_loss: 0.5666
AUC: 0.8734

Epoch 26/30
 - 0s - loss: 0.8880 - val_loss: 0.5641
AUC: 0.8734

Epoch 27/30
 - 0s - loss: 0.8856 - val_loss: 0.5617
AUC: 0.8734

Epoch 28/30
 - 0s - loss: 0.8913 - val_loss: 0.5622
AUC: 0.8734

Epoch 29/30
 - 0s - loss: 0.8870 - val_loss: 0.5627
AUC: 0.8734

Epoch 30/30
 - 0s - loss: 0.8878 - val_loss: 0.5634
Using TensorFlow backend.
AUC: 0.8734

2019-03-08 11:22:35.071364: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:22:35.241546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:22:35.241591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:22:35.552058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:22:35.552112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:22:35.552122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:22:35.552427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1966
Epoch 2/80
 - 2s - loss: 0.3124
Epoch 3/80
 - 2s - loss: 0.2660
Epoch 4/80
 - 2s - loss: 0.2297
Epoch 5/80
 - 2s - loss: 0.2028
Epoch 6/80
 - 2s - loss: 0.1835
Epoch 7/80
 - 2s - loss: 0.1694
Epoch 8/80
 - 2s - loss: 0.1574
Epoch 9/80
 - 2s - loss: 0.1468
Epoch 10/80
 - 2s - loss: 0.1379
Epoch 11/80
 - 2s - loss: 0.1307
Epoch 12/80
 - 2s - loss: 0.1248
Epoch 13/80
 - 2s - loss: 0.1198
Epoch 14/80
 - 2s - loss: 0.1156
Epoch 15/80
 - 2s - loss: 0.1121
Epoch 16/80
 - 2s - loss: 0.1089
Epoch 17/80
 - 2s - loss: 0.1060
Epoch 18/80
 - 2s - loss: 0.1035
Epoch 19/80
 - 2s - loss: 0.1013
Epoch 20/80
 - 2s - loss: 0.0994
Epoch 21/80
 - 2s - loss: 0.0977
Epoch 22/80
 - 2s - loss: 0.0963
Epoch 23/80
 - 2s - loss: 0.0951
Epoch 24/80
 - 2s - loss: 0.0940
Epoch 25/80
 - 2s - loss: 0.0931
Epoch 26/80
 - 2s - loss: 0.0923
Epoch 27/80
 - 2s - loss: 0.0916
Epoch 28/80
 - 2s - loss: 0.0910
Epoch 29/80
 - 2s - loss: 0.0905
Epoch 30/80
 - 2s - loss: 0.0901
Epoch 31/80
 - 2s - loss: 0.0897
Epoch 32/80
 - 2s - loss: 0.0893
Epoch 33/80
 - 2s - loss: 0.0890
Epoch 34/80
 - 2s - loss: 0.0887
Epoch 35/80
 - 2s - loss: 0.0885
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0880
Epoch 38/80
 - 2s - loss: 0.0878
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0875
Epoch 41/80
 - 2s - loss: 0.0873
Epoch 42/80
 - 2s - loss: 0.0872
Epoch 43/80
 - 2s - loss: 0.0871
Epoch 44/80
 - 2s - loss: 0.0869
Epoch 45/80
 - 2s - loss: 0.0868
Epoch 46/80
 - 2s - loss: 0.0867
Epoch 47/80
 - 2s - loss: 0.0866
Epoch 48/80
 - 2s - loss: 0.0865
Epoch 49/80
 - 2s - loss: 0.0864
Epoch 50/80
 - 2s - loss: 0.0863
Epoch 51/80
 - 2s - loss: 0.0862
Epoch 52/80
 - 2s - loss: 0.0861
Epoch 53/80
 - 2s - loss: 0.0861
Epoch 54/80
 - 2s - loss: 0.0860
Epoch 55/80
 - 2s - loss: 0.0859
Epoch 56/80
 - 2s - loss: 0.0858
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0857
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0857
Epoch 61/80
 - 2s - loss: 0.0856
Epoch 62/80
 - 2s - loss: 0.0855
Epoch 63/80
 - 2s - loss: 0.0855
Epoch 64/80
 - 2s - loss: 0.0855
Epoch 65/80
 - 2s - loss: 0.0854
Epoch 66/80
 - 2s - loss: 0.0854
Epoch 67/80
 - 2s - loss: 0.0853
Epoch 68/80
 - 2s - loss: 0.0853
Epoch 69/80
 - 2s - loss: 0.0853
Epoch 70/80
 - 2s - loss: 0.0852
Epoch 71/80
 - 2s - loss: 0.0819
Epoch 72/80
 - 2s - loss: 0.0816
Epoch 73/80
 - 2s - loss: 0.0815
Epoch 74/80
 - 2s - loss: 0.0815
Epoch 75/80
 - 2s - loss: 0.0815
Epoch 76/80
 - 2s - loss: 0.0807
Epoch 77/80
 - 2s - loss: 0.0807
Epoch 78/80
 - 2s - loss: 0.0807
Epoch 79/80
 - 2s - loss: 0.0807
Epoch 80/80
 - 2s - loss: 0.0805
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.5142 - val_loss: 1.3063
AUC: 0.7984

Epoch 2/80
 - 0s - loss: 2.2277 - val_loss: 0.8023
AUC: 0.8287

Epoch 3/80
 - 0s - loss: 1.4940 - val_loss: 0.8141
AUC: 0.8432

Epoch 4/80
 - 0s - loss: 1.2383 - val_loss: 0.7230
AUC: 0.8494

Epoch 5/80
 - 0s - loss: 1.1622 - val_loss: 0.7152
AUC: 0.8505

Epoch 6/80
 - 0s - loss: 1.1217 - val_loss: 0.6565
AUC: 0.8532

Epoch 7/80
 - 0s - loss: 1.1026 - val_loss: 0.5954
AUC: 0.8542

Epoch 8/80
 - 0s - loss: 1.0870 - val_loss: 0.6966
AUC: 0.8546

Epoch 9/80
 - 0s - loss: 1.0588 - val_loss: 0.6461
AUC: 0.8580

Epoch 10/80
 - 0s - loss: 1.0545 - val_loss: 0.6057
AUC: 0.8596

Epoch 11/80
 - 0s - loss: 1.0419 - val_loss: 0.6837
AUC: 0.8619

Epoch 12/80
 - 0s - loss: 1.0337 - val_loss: 0.6747
AUC: 0.8625

Epoch 13/80
 - 0s - loss: 1.0326 - val_loss: 0.7094
AUC: 0.8618

Epoch 14/80
 - 0s - loss: 1.0237 - val_loss: 0.6116
AUC: 0.8628

Epoch 15/80
 - 0s - loss: 1.0181 - val_loss: 0.7440
AUC: 0.8657

Epoch 16/80
 - 0s - loss: 1.0125 - val_loss: 0.7200
AUC: 0.8647

Epoch 17/80
 - 0s - loss: 1.0091 - val_loss: 0.5399
AUC: 0.8619

Epoch 18/80
 - 0s - loss: 0.9967 - val_loss: 0.6404
AUC: 0.8648

Epoch 19/80
 - 0s - loss: 1.0037 - val_loss: 0.6531
AUC: 0.8651

Epoch 20/80
 - 0s - loss: 0.9909 - val_loss: 0.5877
AUC: 0.8653

Epoch 21/80
 - 0s - loss: 0.9822 - val_loss: 0.6525
AUC: 0.8670

Epoch 22/80
 - 0s - loss: 0.9806 - val_loss: 0.5236
AUC: 0.8639

Epoch 23/80
 - 0s - loss: 0.9856 - val_loss: 0.5861
AUC: 0.8653

Epoch 24/80
 - 0s - loss: 0.9755 - val_loss: 0.5525
AUC: 0.8648

Epoch 25/80
 - 0s - loss: 0.9705 - val_loss: 0.6897
AUC: 0.8676

Epoch 26/80
 - 0s - loss: 0.9657 - val_loss: 0.6482
AUC: 0.8667

Epoch 27/80
 - 0s - loss: 0.9658 - val_loss: 0.5775
AUC: 0.8675

Epoch 28/80
 - 0s - loss: 0.9625 - val_loss: 0.6283
AUC: 0.8669

Epoch 29/80
 - 0s - loss: 0.9593 - val_loss: 0.5262
AUC: 0.8650

Epoch 30/80
 - 0s - loss: 0.9503 - val_loss: 0.6490
AUC: 0.8660

Epoch 31/80
 - 0s - loss: 0.9517 - val_loss: 0.5626
AUC: 0.8652

Epoch 32/80
 - 0s - loss: 0.9437 - val_loss: 0.6233
AUC: 0.8681

Epoch 33/80
 - 0s - loss: 0.9299 - val_loss: 0.5865
AUC: 0.8674

Epoch 34/80
 - 0s - loss: 0.9270 - val_loss: 0.5935
AUC: 0.8675

Epoch 35/80
 - 0s - loss: 0.9338 - val_loss: 0.6034
AUC: 0.8676

Epoch 36/80
 - 0s - loss: 0.9297 - val_loss: 0.5855
AUC: 0.8675

Epoch 37/80
 - 0s - loss: 0.9264 - val_loss: 0.5843
AUC: 0.8677

Epoch 38/80
 - 0s - loss: 0.9272 - val_loss: 0.5547
AUC: 0.8667

Epoch 39/80
 - 0s - loss: 0.9276 - val_loss: 0.5823
AUC: 0.8676

Epoch 40/80
 - 0s - loss: 0.9202 - val_loss: 0.6076
AUC: 0.8677

Epoch 41/80
 - 0s - loss: 0.9208 - val_loss: 0.6079
AUC: 0.8681

Epoch 42/80
 - 0s - loss: 0.9205 - val_loss: 0.5868
AUC: 0.8675

Epoch 43/80
 - 0s - loss: 0.9161 - val_loss: 0.5758
AUC: 0.8673

Epoch 44/80
 - 0s - loss: 0.9168 - val_loss: 0.5880
AUC: 0.8675

Epoch 45/80
 - 0s - loss: 0.9173 - val_loss: 0.5908
AUC: 0.8675

Epoch 46/80
 - 0s - loss: 0.9145 - val_loss: 0.5929
AUC: 0.8675

Epoch 47/80
 - 0s - loss: 0.9155 - val_loss: 0.5807
AUC: 0.8674

Epoch 48/80
 - 0s - loss: 0.9176 - val_loss: 0.5874
AUC: 0.8675

Epoch 49/80
 - 0s - loss: 0.9151 - val_loss: 0.5855
AUC: 0.8675

Epoch 50/80
 - 0s - loss: 0.9117 - val_loss: 0.5835
AUC: 0.8674

Epoch 51/80
 - 0s - loss: 0.9144 - val_loss: 0.5822
AUC: 0.8675

Epoch 52/80
 - 0s - loss: 0.9187 - val_loss: 0.5884
AUC: 0.8675

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9340 - val_loss: 0.5895
AUC: 0.8678

Epoch 2/30
 - 0s - loss: 0.9267 - val_loss: 0.5767
AUC: 0.8676

Epoch 3/30
 - 0s - loss: 0.9274 - val_loss: 0.5913
AUC: 0.8677

Epoch 4/30
 - 0s - loss: 0.9217 - val_loss: 0.6023
AUC: 0.8681

Epoch 5/30
 - 0s - loss: 0.9187 - val_loss: 0.5898
AUC: 0.8679

Epoch 6/30
 - 0s - loss: 0.9149 - val_loss: 0.5840
AUC: 0.8680

Epoch 7/30
 - 0s - loss: 0.9143 - val_loss: 0.6001
AUC: 0.8683

Epoch 8/30
 - 0s - loss: 0.9157 - val_loss: 0.5976
AUC: 0.8683

Epoch 9/30
 - 0s - loss: 0.9131 - val_loss: 0.5829
AUC: 0.8680

Epoch 10/30
 - 0s - loss: 0.9129 - val_loss: 0.6153
AUC: 0.8685

Epoch 11/30
 - 0s - loss: 0.9083 - val_loss: 0.5806
AUC: 0.8682

Epoch 12/30
 - 0s - loss: 0.9051 - val_loss: 0.5962
AUC: 0.8683

Epoch 13/30
 - 0s - loss: 0.9034 - val_loss: 0.5883
AUC: 0.8682

Epoch 14/30
 - 0s - loss: 0.9025 - val_loss: 0.5803
AUC: 0.8680

Epoch 15/30
 - 0s - loss: 0.9044 - val_loss: 0.5856
AUC: 0.8682

Epoch 16/30
 - 0s - loss: 0.9037 - val_loss: 0.5816
AUC: 0.8681

Epoch 17/30
 - 0s - loss: 0.9035 - val_loss: 0.5889
AUC: 0.8682

Epoch 18/30
 - 0s - loss: 0.8987 - val_loss: 0.5875
AUC: 0.8682

Epoch 19/30
 - 0s - loss: 0.9039 - val_loss: 0.5848
AUC: 0.8682

Epoch 20/30
 - 0s - loss: 0.8978 - val_loss: 0.5877
AUC: 0.8683

Epoch 21/30
 - 0s - loss: 0.9001 - val_loss: 0.5785
AUC: 0.8681

Epoch 22/30
 - 0s - loss: 0.9004 - val_loss: 0.5879
AUC: 0.8683

Epoch 23/30
 - 0s - loss: 0.8995 - val_loss: 0.5861
AUC: 0.8683

Epoch 24/30
 - 0s - loss: 0.8987 - val_loss: 0.5836
AUC: 0.8683

Epoch 25/30
 - 0s - loss: 0.9005 - val_loss: 0.5837
AUC: 0.8683

Epoch 26/30
 - 0s - loss: 0.8980 - val_loss: 0.5841
AUC: 0.8683

Epoch 27/30
 - 0s - loss: 0.9033 - val_loss: 0.5831
AUC: 0.8683

Epoch 28/30
 - 0s - loss: 0.9033 - val_loss: 0.5831
AUC: 0.8683

Epoch 29/30
 - 0s - loss: 0.9051 - val_loss: 0.5851
AUC: 0.8683

Epoch 30/30
 - 0s - loss: 0.9007 - val_loss: 0.5842
Using TensorFlow backend.
AUC: 0.8683

2019-03-08 11:25:58.340564: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:25:58.508266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:25:58.508313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:25:58.804662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:25:58.804714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:25:58.804723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:25:58.804977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2266
Epoch 2/80
 - 2s - loss: 0.3154
Epoch 3/80
 - 2s - loss: 0.2644
Epoch 4/80
 - 2s - loss: 0.2286
Epoch 5/80
 - 2s - loss: 0.2057
Epoch 6/80
 - 2s - loss: 0.1860
Epoch 7/80
 - 2s - loss: 0.1690
Epoch 8/80
 - 2s - loss: 0.1557
Epoch 9/80
 - 2s - loss: 0.1450
Epoch 10/80
 - 2s - loss: 0.1363
Epoch 11/80
 - 2s - loss: 0.1293
Epoch 12/80
 - 2s - loss: 0.1235
Epoch 13/80
 - 2s - loss: 0.1187
Epoch 14/80
 - 2s - loss: 0.1146
Epoch 15/80
 - 2s - loss: 0.1110
Epoch 16/80
 - 2s - loss: 0.1079
Epoch 17/80
 - 2s - loss: 0.1053
Epoch 18/80
 - 2s - loss: 0.1029
Epoch 19/80
 - 2s - loss: 0.1008
Epoch 20/80
 - 2s - loss: 0.0991
Epoch 21/80
 - 2s - loss: 0.0975
Epoch 22/80
 - 2s - loss: 0.0961
Epoch 23/80
 - 2s - loss: 0.0950
Epoch 24/80
 - 2s - loss: 0.0940
Epoch 25/80
 - 2s - loss: 0.0931
Epoch 26/80
 - 2s - loss: 0.0924
Epoch 27/80
 - 2s - loss: 0.0918
Epoch 28/80
 - 2s - loss: 0.0912
Epoch 29/80
 - 2s - loss: 0.0907
Epoch 30/80
 - 2s - loss: 0.0903
Epoch 31/80
 - 2s - loss: 0.0899
Epoch 32/80
 - 2s - loss: 0.0895
Epoch 33/80
 - 2s - loss: 0.0893
Epoch 34/80
 - 2s - loss: 0.0889
Epoch 35/80
 - 2s - loss: 0.0887
Epoch 36/80
 - 2s - loss: 0.0885
Epoch 37/80
 - 2s - loss: 0.0883
Epoch 38/80
 - 2s - loss: 0.0880
Epoch 39/80
 - 2s - loss: 0.0878
Epoch 40/80
 - 2s - loss: 0.0877
Epoch 41/80
 - 2s - loss: 0.0875
Epoch 42/80
 - 2s - loss: 0.0874
Epoch 43/80
 - 2s - loss: 0.0873
Epoch 44/80
 - 2s - loss: 0.0871
Epoch 45/80
 - 2s - loss: 0.0870
Epoch 46/80
 - 2s - loss: 0.0869
Epoch 47/80
 - 2s - loss: 0.0868
Epoch 48/80
 - 2s - loss: 0.0867
Epoch 49/80
 - 2s - loss: 0.0866
Epoch 50/80
 - 2s - loss: 0.0865
Epoch 51/80
 - 2s - loss: 0.0865
Epoch 52/80
 - 2s - loss: 0.0864
Epoch 53/80
 - 2s - loss: 0.0863
Epoch 54/80
 - 2s - loss: 0.0862
Epoch 55/80
 - 2s - loss: 0.0862
Epoch 56/80
 - 2s - loss: 0.0861
Epoch 57/80
 - 2s - loss: 0.0860
Epoch 58/80
 - 2s - loss: 0.0860
Epoch 59/80
 - 2s - loss: 0.0859
Epoch 60/80
 - 2s - loss: 0.0859
Epoch 61/80
 - 2s - loss: 0.0858
Epoch 62/80
 - 2s - loss: 0.0858
Epoch 63/80
 - 2s - loss: 0.0858
Epoch 64/80
 - 2s - loss: 0.0857
Epoch 65/80
 - 2s - loss: 0.0857
Epoch 66/80
 - 2s - loss: 0.0856
Epoch 67/80
 - 2s - loss: 0.0856
Epoch 68/80
 - 2s - loss: 0.0855
Epoch 69/80
 - 2s - loss: 0.0855
Epoch 70/80
 - 2s - loss: 0.0822
Epoch 71/80
 - 2s - loss: 0.0819
Epoch 72/80
 - 2s - loss: 0.0818
Epoch 73/80
 - 2s - loss: 0.0818
Epoch 74/80
 - 2s - loss: 0.0818
Epoch 75/80
 - 2s - loss: 0.0810
Epoch 76/80
 - 2s - loss: 0.0810
Epoch 77/80
 - 2s - loss: 0.0810
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:28:23.389693: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:28:23.556312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:28:23.556362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:28:23.856972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:28:23.857023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:28:23.857033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:28:23.857327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0008
Epoch 2/80
 - 2s - loss: 0.1804
Epoch 3/80
 - 2s - loss: 0.1519
Epoch 4/80
 - 2s - loss: 0.1336
Epoch 5/80
 - 2s - loss: 0.1192
Epoch 6/80
 - 2s - loss: 0.1059
Epoch 7/80
 - 2s - loss: 0.0941
Epoch 8/80
 - 2s - loss: 0.0843
Epoch 9/80
 - 2s - loss: 0.0765
Epoch 10/80
 - 2s - loss: 0.0702
Epoch 11/80
 - 2s - loss: 0.0652
Epoch 12/80
 - 2s - loss: 0.0612
Epoch 13/80
 - 2s - loss: 0.0579
Epoch 14/80
 - 2s - loss: 0.0551
Epoch 15/80
 - 2s - loss: 0.0527
Epoch 16/80
 - 2s - loss: 0.0507
Epoch 17/80
 - 2s - loss: 0.0489
Epoch 18/80
 - 2s - loss: 0.0474
Epoch 19/80
 - 2s - loss: 0.0461
Epoch 20/80
 - 2s - loss: 0.0449
Epoch 21/80
 - 2s - loss: 0.0439
Epoch 22/80
 - 2s - loss: 0.0430
Epoch 23/80
 - 2s - loss: 0.0423
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0405
Epoch 27/80
 - 2s - loss: 0.0400
Epoch 28/80
 - 2s - loss: 0.0396
Epoch 29/80
 - 2s - loss: 0.0393
Epoch 30/80
 - 2s - loss: 0.0390
Epoch 31/80
 - 2s - loss: 0.0387
Epoch 32/80
 - 2s - loss: 0.0385
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0381
Epoch 35/80
 - 2s - loss: 0.0379
Epoch 36/80
 - 2s - loss: 0.0378
Epoch 37/80
 - 2s - loss: 0.0376
Epoch 38/80
 - 2s - loss: 0.0375
Epoch 39/80
 - 2s - loss: 0.0374
Epoch 40/80
 - 2s - loss: 0.0373
Epoch 41/80
 - 2s - loss: 0.0372
Epoch 42/80
 - 2s - loss: 0.0371
Epoch 43/80
 - 2s - loss: 0.0370
Epoch 44/80
 - 2s - loss: 0.0369
Epoch 45/80
 - 2s - loss: 0.0369
Epoch 46/80
 - 2s - loss: 0.0368
Epoch 47/80
 - 2s - loss: 0.0368
Epoch 48/80
 - 2s - loss: 0.0367
Epoch 49/80
 - 2s - loss: 0.0366
Epoch 50/80
 - 2s - loss: 0.0366
Epoch 51/80
 - 2s - loss: 0.0366
Epoch 52/80
 - 2s - loss: 0.0365
Epoch 53/80
 - 2s - loss: 0.0365
Epoch 54/80
 - 2s - loss: 0.0364
Epoch 55/80
 - 2s - loss: 0.0364
Epoch 56/80
 - 2s - loss: 0.0363
Epoch 57/80
 - 2s - loss: 0.0363
Epoch 58/80
 - 2s - loss: 0.0363
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:30:17.016966: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:30:17.180547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:30:17.180590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:30:17.478689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:30:17.478755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:30:17.478775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:30:17.479028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9817
Epoch 2/80
 - 2s - loss: 0.1809
Epoch 3/80
 - 2s - loss: 0.1541
Epoch 4/80
 - 2s - loss: 0.1333
Epoch 5/80
 - 2s - loss: 0.1171
Epoch 6/80
 - 2s - loss: 0.1042
Epoch 7/80
 - 2s - loss: 0.0936
Epoch 8/80
 - 2s - loss: 0.0851
Epoch 9/80
 - 2s - loss: 0.0780
Epoch 10/80
 - 2s - loss: 0.0719
Epoch 11/80
 - 2s - loss: 0.0666
Epoch 12/80
 - 2s - loss: 0.0622
Epoch 13/80
 - 2s - loss: 0.0586
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:30:56.146790: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:30:56.316775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:30:56.316833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:30:56.613391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:30:56.613444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:30:56.613453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:30:56.613720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9806
Epoch 2/80
 - 2s - loss: 0.1809
Epoch 3/80
 - 2s - loss: 0.1565
Epoch 4/80
 - 2s - loss: 0.1322
Epoch 5/80
 - 2s - loss: 0.1142
Epoch 6/80
 - 2s - loss: 0.1023
Epoch 7/80
 - 2s - loss: 0.0927
Epoch 8/80
 - 2s - loss: 0.0845
Epoch 9/80
 - 2s - loss: 0.0773
Epoch 10/80
 - 2s - loss: 0.0710
Epoch 11/80
 - 2s - loss: 0.0658
Epoch 12/80
 - 2s - loss: 0.0615
Epoch 13/80
 - 2s - loss: 0.0580
Epoch 14/80
 - 2s - loss: 0.0551
Epoch 15/80
 - 2s - loss: 0.0527
Epoch 16/80
 - 2s - loss: 0.0505
Epoch 17/80
 - 2s - loss: 0.0487
Epoch 18/80
 - 2s - loss: 0.0472
Epoch 19/80
 - 2s - loss: 0.0458
Epoch 20/80
 - 2s - loss: 0.0447
Epoch 21/80
 - 2s - loss: 0.0437
Epoch 22/80
 - 2s - loss: 0.0428
Epoch 23/80
 - 2s - loss: 0.0421
Epoch 24/80
 - 2s - loss: 0.0414
Epoch 25/80
 - 2s - loss: 0.0408
Epoch 26/80
 - 2s - loss: 0.0404
Epoch 27/80
 - 2s - loss: 0.0399
Epoch 28/80
 - 2s - loss: 0.0395
Epoch 29/80
 - 2s - loss: 0.0392
Epoch 30/80
 - 2s - loss: 0.0389
Epoch 31/80
 - 2s - loss: 0.0386
Epoch 32/80
 - 2s - loss: 0.0384
Epoch 33/80
 - 2s - loss: 0.0382
Epoch 34/80
 - 2s - loss: 0.0380
Epoch 35/80
 - 2s - loss: 0.0379
Epoch 36/80
 - 2s - loss: 0.0377
Epoch 37/80
 - 2s - loss: 0.0376
Epoch 38/80
 - 2s - loss: 0.0374
Epoch 39/80
 - 2s - loss: 0.0373
Epoch 40/80
 - 2s - loss: 0.0372
Epoch 41/80
 - 2s - loss: 0.0371
Epoch 42/80
 - 2s - loss: 0.0370
Epoch 43/80
 - 2s - loss: 0.0370
Epoch 44/80
 - 2s - loss: 0.0369
Epoch 45/80
 - 2s - loss: 0.0368
Epoch 46/80
 - 2s - loss: 0.0368
Epoch 47/80
 - 2s - loss: 0.0367
Epoch 48/80
 - 2s - loss: 0.0367
Epoch 49/80
 - 2s - loss: 0.0366
Epoch 50/80
 - 2s - loss: 0.0365
Epoch 51/80
 - 2s - loss: 0.0365
Epoch 52/80
 - 2s - loss: 0.0365
Epoch 53/80
 - 2s - loss: 0.0364
Epoch 54/80
 - 2s - loss: 0.0364
Epoch 55/80
 - 2s - loss: 0.0363
Epoch 56/80
 - 2s - loss: 0.0363
Epoch 57/80
 - 2s - loss: 0.0363
Epoch 58/80
 - 2s - loss: 0.0362
Epoch 59/80
 - 2s - loss: 0.0362
Epoch 60/80
 - 2s - loss: 0.0362
Epoch 61/80
 - 2s - loss: 0.0361
Epoch 62/80
 - 2s - loss: 0.0361
Epoch 63/80
 - 2s - loss: 0.0346
Epoch 64/80
 - 2s - loss: 0.0344
Epoch 65/80
 - 2s - loss: 0.0344
Epoch 66/80
 - 2s - loss: 0.0344
Epoch 67/80
 - 2s - loss: 0.0344
Epoch 68/80
 - 2s - loss: 0.0341
Epoch 69/80
 - 2s - loss: 0.0340
Epoch 70/80
 - 2s - loss: 0.0340
Epoch 71/80
 - 2s - loss: 0.0340
Epoch 72/80
 - 2s - loss: 0.0340
Epoch 73/80
 - 2s - loss: 0.0340
Epoch 74/80
 - 2s - loss: 0.0340
Epoch 75/80
 - 2s - loss: 0.0340
Epoch 76/80
 - 2s - loss: 0.0339
Epoch 77/80
 - 2s - loss: 0.0339
Epoch 78/80
 - 2s - loss: 0.0339
Epoch 79/80
 - 2s - loss: 0.0339
Epoch 80/80
 - 2s - loss: 0.0339
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.2743 - val_loss: 1.2494
AUC: 0.8256

Epoch 2/80
 - 0s - loss: 2.0065 - val_loss: 0.8846
AUC: 0.8498

Epoch 3/80
 - 0s - loss: 1.4262 - val_loss: 0.7838
AUC: 0.8533

Epoch 4/80
 - 0s - loss: 1.2070 - val_loss: 0.7107
AUC: 0.8557

Epoch 5/80
 - 0s - loss: 1.1295 - val_loss: 0.6832
AUC: 0.8568

Epoch 6/80
 - 0s - loss: 1.0958 - val_loss: 0.6868
AUC: 0.8600

Epoch 7/80
 - 0s - loss: 1.0697 - val_loss: 0.6018
AUC: 0.8618

Epoch 8/80
 - 0s - loss: 1.0580 - val_loss: 0.6000
AUC: 0.8625

Epoch 9/80
 - 0s - loss: 1.0347 - val_loss: 0.5685
AUC: 0.8619

Epoch 10/80
 - 0s - loss: 1.0392 - val_loss: 0.6406
AUC: 0.8635

Epoch 11/80
 - 0s - loss: 1.0268 - val_loss: 0.5950
AUC: 0.8658

Epoch 12/80
 - 0s - loss: 1.0095 - val_loss: 0.6156
AUC: 0.8658

Epoch 13/80
 - 0s - loss: 1.0055 - val_loss: 0.6213
AUC: 0.8665

Epoch 14/80
 - 0s - loss: 0.9948 - val_loss: 0.5715
AUC: 0.8661

Epoch 15/80
 - 0s - loss: 0.9943 - val_loss: 0.5967
AUC: 0.8653

Epoch 16/80
 - 0s - loss: 0.9960 - val_loss: 0.6143
AUC: 0.8687

Epoch 17/80
 - 0s - loss: 0.9915 - val_loss: 0.5461
AUC: 0.8675

Epoch 18/80
 - 0s - loss: 0.9841 - val_loss: 0.5980
AUC: 0.8660

Epoch 19/80
 - 0s - loss: 0.9814 - val_loss: 0.5761
AUC: 0.8693

Epoch 20/80
 - 0s - loss: 0.9706 - val_loss: 0.5436
AUC: 0.8694

Epoch 21/80
 - 0s - loss: 0.9738 - val_loss: 0.6043
AUC: 0.8699

Epoch 22/80
 - 0s - loss: 0.9660 - val_loss: 0.5594
AUC: 0.8701

Epoch 23/80
 - 0s - loss: 0.9650 - val_loss: 0.5657
AUC: 0.8701

Epoch 24/80
 - 0s - loss: 0.9601 - val_loss: 0.5489
AUC: 0.8709

Epoch 25/80
 - 0s - loss: 0.9533 - val_loss: 0.5811
AUC: 0.8712

Epoch 26/80
 - 0s - loss: 0.9476 - val_loss: 0.5627
AUC: 0.8718

Epoch 27/80
 - 0s - loss: 0.9465 - val_loss: 0.5548
AUC: 0.8723

Epoch 28/80
 - 0s - loss: 0.9441 - val_loss: 0.6061
AUC: 0.8712

Epoch 29/80
 - 0s - loss: 0.9431 - val_loss: 0.5665
AUC: 0.8729

Epoch 30/80
 - 0s - loss: 0.9375 - val_loss: 0.6148
AUC: 0.8724

Epoch 31/80
 - 0s - loss: 0.9256 - val_loss: 0.5834
AUC: 0.8732

Epoch 32/80
 - 0s - loss: 0.9248 - val_loss: 0.6087
AUC: 0.8735

Epoch 33/80
 - 0s - loss: 0.9230 - val_loss: 0.5980
AUC: 0.8737

Epoch 34/80
 - 0s - loss: 0.9152 - val_loss: 0.5443
AUC: 0.8732

Epoch 35/80
 - 0s - loss: 0.9216 - val_loss: 0.5870
AUC: 0.8733

Epoch 36/80
 - 0s - loss: 0.9210 - val_loss: 0.5867
AUC: 0.8739

Epoch 37/80
 - 0s - loss: 0.9072 - val_loss: 0.5567
AUC: 0.8736

Epoch 38/80
 - 0s - loss: 0.9144 - val_loss: 0.5820
AUC: 0.8737

Epoch 39/80
 - 0s - loss: 0.9165 - val_loss: 0.5687
AUC: 0.8740

Epoch 40/80
 - 0s - loss: 0.9096 - val_loss: 0.5549
AUC: 0.8735

Epoch 41/80
 - 0s - loss: 0.9046 - val_loss: 0.5843
AUC: 0.8739

Epoch 42/80
 - 0s - loss: 0.9040 - val_loss: 0.5749
AUC: 0.8739

Epoch 43/80
 - 0s - loss: 0.9093 - val_loss: 0.5714
AUC: 0.8739

Epoch 44/80
 - 0s - loss: 0.9072 - val_loss: 0.5726
AUC: 0.8740

Epoch 45/80
 - 0s - loss: 0.9088 - val_loss: 0.5747
AUC: 0.8740

Epoch 46/80
 - 0s - loss: 0.9089 - val_loss: 0.5600
AUC: 0.8738

Epoch 47/80
 - 0s - loss: 0.9065 - val_loss: 0.5797
AUC: 0.8740

Epoch 48/80
 - 0s - loss: 0.9033 - val_loss: 0.5799
AUC: 0.8741

Epoch 49/80
 - 0s - loss: 0.9084 - val_loss: 0.5709
AUC: 0.8739

Epoch 50/80
 - 0s - loss: 0.9079 - val_loss: 0.5770
AUC: 0.8740

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9091 - val_loss: 0.5607
AUC: 0.8736

Epoch 2/30
 - 0s - loss: 0.9034 - val_loss: 0.5788
AUC: 0.8742

Epoch 3/30
 - 0s - loss: 0.9073 - val_loss: 0.5707
AUC: 0.8741

Epoch 4/30
 - 0s - loss: 0.9027 - val_loss: 0.5797
AUC: 0.8745

Epoch 5/30
 - 0s - loss: 0.9007 - val_loss: 0.5531
AUC: 0.8745

Epoch 6/30
 - 0s - loss: 0.8990 - val_loss: 0.5955
AUC: 0.8751

Epoch 7/30
 - 0s - loss: 0.8995 - val_loss: 0.5303
AUC: 0.8741

Epoch 8/30
 - 0s - loss: 0.8943 - val_loss: 0.5628
AUC: 0.8749

Epoch 9/30
 - 0s - loss: 0.8944 - val_loss: 0.5521
AUC: 0.8749

Epoch 10/30
 - 0s - loss: 0.8899 - val_loss: 0.5472
AUC: 0.8750

Epoch 11/30
 - 0s - loss: 0.8887 - val_loss: 0.5601
AUC: 0.8751

Epoch 12/30
 - 0s - loss: 0.8873 - val_loss: 0.5632
AUC: 0.8749

Epoch 13/30
 - 0s - loss: 0.8838 - val_loss: 0.5823
AUC: 0.8754

Epoch 14/30
 - 0s - loss: 0.8820 - val_loss: 0.5668
AUC: 0.8752

Epoch 15/30
 - 0s - loss: 0.8836 - val_loss: 0.5678
AUC: 0.8752

Epoch 16/30
 - 0s - loss: 0.8816 - val_loss: 0.5548
AUC: 0.8751

Epoch 17/30
 - 0s - loss: 0.8783 - val_loss: 0.5421
AUC: 0.8751

Epoch 18/30
 - 0s - loss: 0.8792 - val_loss: 0.5626
AUC: 0.8754

Epoch 19/30
 - 0s - loss: 0.8823 - val_loss: 0.5632
AUC: 0.8754

Epoch 20/30
 - 0s - loss: 0.8760 - val_loss: 0.5546
AUC: 0.8753

Epoch 21/30
 - 0s - loss: 0.8780 - val_loss: 0.5625
AUC: 0.8755

Epoch 22/30
 - 0s - loss: 0.8775 - val_loss: 0.5630
AUC: 0.8756

Epoch 23/30
 - 0s - loss: 0.8751 - val_loss: 0.5598
AUC: 0.8756

Epoch 24/30
 - 0s - loss: 0.8747 - val_loss: 0.5608
AUC: 0.8755

Epoch 25/30
 - 0s - loss: 0.8730 - val_loss: 0.5574
AUC: 0.8755

Epoch 26/30
 - 0s - loss: 0.8691 - val_loss: 0.5638
AUC: 0.8756

Epoch 27/30
 - 0s - loss: 0.8683 - val_loss: 0.5571
AUC: 0.8756

Epoch 28/30
 - 0s - loss: 0.8702 - val_loss: 0.5578
AUC: 0.8756

Epoch 29/30
 - 0s - loss: 0.8736 - val_loss: 0.5601
AUC: 0.8756

Epoch 30/30
 - 0s - loss: 0.8704 - val_loss: 0.5596
Using TensorFlow backend.
AUC: 0.8756

2019-03-08 11:34:16.937148: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:34:17.101954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:34:17.101996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:34:17.398465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:34:17.398517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:34:17.398526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:34:17.398778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6062
Epoch 2/80
 - 2s - loss: 0.0834
Epoch 3/80
 - 2s - loss: 0.0633
Epoch 4/80
 - 2s - loss: 0.0555
Epoch 5/80
 - 2s - loss: 0.0492
Epoch 6/80
 - 2s - loss: 0.0439
Epoch 7/80
 - 2s - loss: 0.0392
Epoch 8/80
 - 2s - loss: 0.0351
Epoch 9/80
 - 2s - loss: 0.0317
Epoch 10/80
 - 2s - loss: 0.0287
Epoch 11/80
 - 2s - loss: 0.0262
Epoch 12/80
 - 2s - loss: 0.0241
Epoch 13/80
 - 2s - loss: 0.0223
Epoch 14/80
 - 2s - loss: 0.0209
Epoch 15/80
 - 2s - loss: 0.0197
Epoch 16/80
 - 2s - loss: 0.0186
Epoch 17/80
 - 2s - loss: 0.0178
Epoch 18/80
 - 2s - loss: 0.0170
Epoch 19/80
 - 2s - loss: 0.0164
Epoch 20/80
 - 2s - loss: 0.0158
Epoch 21/80
 - 2s - loss: 0.0153
Epoch 22/80
 - 2s - loss: 0.0149
Epoch 23/80
 - 2s - loss: 0.0145
Epoch 24/80
 - 2s - loss: 0.0142
Epoch 25/80
 - 2s - loss: 0.0139
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0131
Epoch 30/80
 - 2s - loss: 0.0129
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:35:27.187091: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:35:27.354190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:35:27.354236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:35:27.649510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:35:27.649562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:35:27.649571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:35:27.649824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5987
Epoch 2/80
 - 2s - loss: 0.0843
Epoch 3/80
 - 2s - loss: 0.0652
Epoch 4/80
 - 2s - loss: 0.0584
Epoch 5/80
 - 2s - loss: 0.0509
Epoch 6/80
 - 2s - loss: 0.0444
Epoch 7/80
 - 2s - loss: 0.0395
Epoch 8/80
 - 2s - loss: 0.0356
Epoch 9/80
 - 2s - loss: 0.0323
Epoch 10/80
 - 2s - loss: 0.0294
Epoch 11/80
 - 2s - loss: 0.0268
Epoch 12/80
 - 2s - loss: 0.0247
Epoch 13/80
 - 2s - loss: 0.0228
Epoch 14/80
 - 2s - loss: 0.0213
Epoch 15/80
 - 2s - loss: 0.0200
Epoch 16/80
 - 2s - loss: 0.0189
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0172
Epoch 19/80
 - 2s - loss: 0.0165
Epoch 20/80
 - 2s - loss: 0.0160
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0146
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:36:21.072620: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:36:21.237848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:36:21.237892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:36:21.535758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:36:21.535810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:36:21.535819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:36:21.536074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6116
Epoch 2/80
 - 2s - loss: 0.0835
Epoch 3/80
 - 2s - loss: 0.0626
Epoch 4/80
 - 2s - loss: 0.0542
Epoch 5/80
 - 2s - loss: 0.0479
Epoch 6/80
 - 2s - loss: 0.0432
Epoch 7/80
 - 2s - loss: 0.0391
Epoch 8/80
 - 2s - loss: 0.0353
Epoch 9/80
 - 2s - loss: 0.0318
Epoch 10/80
 - 2s - loss: 0.0288
Epoch 11/80
 - 2s - loss: 0.0262
Epoch 12/80
 - 2s - loss: 0.0241
Epoch 13/80
 - 2s - loss: 0.0224
Epoch 14/80
 - 2s - loss: 0.0210
Epoch 15/80
 - 2s - loss: 0.0198
Epoch 16/80
 - 2s - loss: 0.0188
Epoch 17/80
 - 2s - loss: 0.0180
Epoch 18/80
 - 2s - loss: 0.0172
Epoch 19/80
 - 2s - loss: 0.0166
Epoch 20/80
 - 2s - loss: 0.0160
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0144
Epoch 25/80
 - 2s - loss: 0.0141
Epoch 26/80
 - 2s - loss: 0.0139
Epoch 27/80
 - 2s - loss: 0.0136
Epoch 28/80
 - 2s - loss: 0.0134
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 11:37:27.457394: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:37:27.619838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:37:27.619882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:37:27.912464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:37:27.912515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:37:27.912524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:37:27.912781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1997
Epoch 2/80
 - 2s - loss: 0.3199
Epoch 3/80
 - 2s - loss: 0.2941
Epoch 4/80
 - 2s - loss: 0.2603
Epoch 5/80
 - 2s - loss: 0.2234
Epoch 6/80
 - 2s - loss: 0.1971
Epoch 7/80
 - 2s - loss: 0.1767
Epoch 8/80
 - 2s - loss: 0.1604
Epoch 9/80
 - 2s - loss: 0.1481
Epoch 10/80
 - 2s - loss: 0.1383
Epoch 11/80
 - 2s - loss: 0.1306
Epoch 12/80
 - 2s - loss: 0.1245
Epoch 13/80
 - 2s - loss: 0.1196
Epoch 14/80
 - 2s - loss: 0.1155
Epoch 15/80
 - 2s - loss: 0.1118
Epoch 16/80
 - 2s - loss: 0.1087
Epoch 17/80
 - 2s - loss: 0.1060
Epoch 18/80
 - 2s - loss: 0.1036
Epoch 19/80
 - 2s - loss: 0.1014
Epoch 20/80
 - 2s - loss: 0.0996
Epoch 21/80
 - 2s - loss: 0.0979
Epoch 22/80
 - 2s - loss: 0.0965
Epoch 23/80
 - 2s - loss: 0.0953
Epoch 24/80
 - 2s - loss: 0.0942
Epoch 25/80
 - 2s - loss: 0.0933
Epoch 26/80
 - 2s - loss: 0.0925
Epoch 27/80
 - 2s - loss: 0.0918
Epoch 28/80
 - 2s - loss: 0.0912
Epoch 29/80
 - 2s - loss: 0.0907
Epoch 30/80
 - 2s - loss: 0.0902
Epoch 31/80
 - 2s - loss: 0.0897
Epoch 32/80
 - 2s - loss: 0.0894
Epoch 33/80
 - 2s - loss: 0.0891
Epoch 34/80
 - 2s - loss: 0.0888
Epoch 35/80
 - 2s - loss: 0.0885
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0880
Epoch 38/80
 - 2s - loss: 0.0878
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0874
Epoch 41/80
 - 2s - loss: 0.0873
Epoch 42/80
 - 2s - loss: 0.0871
Epoch 43/80
 - 2s - loss: 0.0870
Epoch 44/80
 - 2s - loss: 0.0868
Epoch 45/80
 - 2s - loss: 0.0867
Epoch 46/80
 - 2s - loss: 0.0866
Epoch 47/80
 - 2s - loss: 0.0865
Epoch 48/80
 - 2s - loss: 0.0864
Epoch 49/80
 - 2s - loss: 0.0863
Epoch 50/80
 - 2s - loss: 0.0862
Epoch 51/80
 - 2s - loss: 0.0861
Epoch 52/80
 - 2s - loss: 0.0860
Epoch 53/80
 - 2s - loss: 0.0859
Epoch 54/80
 - 2s - loss: 0.0858
Epoch 55/80
 - 2s - loss: 0.0858
Epoch 56/80
 - 1s - loss: 0.0857
Epoch 57/80
 - 2s - loss: 0.0857
Epoch 58/80
 - 2s - loss: 0.0856
Epoch 59/80
 - 2s - loss: 0.0855
Epoch 60/80
 - 2s - loss: 0.0855
Epoch 61/80
 - 2s - loss: 0.0855
Epoch 62/80
 - 2s - loss: 0.0854
Epoch 63/80
 - 2s - loss: 0.0853
Epoch 64/80
 - 2s - loss: 0.0853
Epoch 65/80
 - 2s - loss: 0.0852
Epoch 66/80
 - 2s - loss: 0.0852
Epoch 67/80
 - 2s - loss: 0.0852
Epoch 68/80
 - 2s - loss: 0.0851
Epoch 69/80
 - 2s - loss: 0.0851
Epoch 70/80
 - 2s - loss: 0.0851
Epoch 71/80
 - 2s - loss: 0.0817
Epoch 72/80
 - 2s - loss: 0.0814
Epoch 73/80
 - 2s - loss: 0.0814
Epoch 74/80
 - 2s - loss: 0.0814
Epoch 75/80
 - 2s - loss: 0.0814
Epoch 76/80
 - 2s - loss: 0.0806
Epoch 77/80
 - 2s - loss: 0.0805
Epoch 78/80
 - 2s - loss: 0.0805
Epoch 79/80
 - 2s - loss: 0.0805
Epoch 80/80
 - 2s - loss: 0.0803
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0788 - val_loss: 1.1051
AUC: 0.8043

Epoch 2/80
 - 0s - loss: 1.8611 - val_loss: 0.8243
AUC: 0.8372

Epoch 3/80
 - 0s - loss: 1.3846 - val_loss: 0.6865
AUC: 0.8542

Epoch 4/80
 - 0s - loss: 1.1910 - val_loss: 0.6747
AUC: 0.8563

Epoch 5/80
 - 0s - loss: 1.1219 - val_loss: 0.6255
AUC: 0.8617

Epoch 6/80
 - 0s - loss: 1.0887 - val_loss: 0.7017
AUC: 0.8652

Epoch 7/80
 - 0s - loss: 1.0701 - val_loss: 0.6094
AUC: 0.8661

Epoch 8/80
 - 0s - loss: 1.0521 - val_loss: 0.6086
AUC: 0.8660

Epoch 9/80
 - 0s - loss: 1.0372 - val_loss: 0.6420
AUC: 0.8699

Epoch 10/80
 - 0s - loss: 1.0318 - val_loss: 0.5427
AUC: 0.8682

Epoch 11/80
 - 0s - loss: 1.0267 - val_loss: 0.6097
AUC: 0.8697

Epoch 12/80
 - 0s - loss: 1.0180 - val_loss: 0.6509
AUC: 0.8708

Epoch 13/80
 - 0s - loss: 1.0117 - val_loss: 0.6814
AUC: 0.8703

Epoch 14/80
 - 0s - loss: 1.0063 - val_loss: 0.6594
AUC: 0.8713

Epoch 15/80
 - 0s - loss: 0.9971 - val_loss: 0.6706
AUC: 0.8727

Epoch 16/80
 - 0s - loss: 0.9988 - val_loss: 0.5986
AUC: 0.8718

Epoch 17/80
 - 0s - loss: 0.9880 - val_loss: 0.5535
AUC: 0.8722

Epoch 18/80
 - 0s - loss: 0.9844 - val_loss: 0.6590
AUC: 0.8737

Epoch 19/80
 - 0s - loss: 0.9851 - val_loss: 0.6064
AUC: 0.8732

Epoch 20/80
 - 0s - loss: 0.9692 - val_loss: 0.5973
AUC: 0.8723

Epoch 21/80
 - 0s - loss: 0.9622 - val_loss: 0.6104
AUC: 0.8737

Epoch 22/80
 - 0s - loss: 0.9464 - val_loss: 0.6101
AUC: 0.8739

Epoch 23/80
 - 0s - loss: 0.9529 - val_loss: 0.5876
AUC: 0.8737

Epoch 24/80
 - 0s - loss: 0.9514 - val_loss: 0.5830
AUC: 0.8737

Epoch 25/80
 - 0s - loss: 0.9492 - val_loss: 0.5748
AUC: 0.8736

Epoch 26/80
 - 0s - loss: 0.9509 - val_loss: 0.6276
AUC: 0.8741

Epoch 27/80
 - 0s - loss: 0.9486 - val_loss: 0.5941
AUC: 0.8736

Epoch 28/80
 - 0s - loss: 0.9508 - val_loss: 0.6028
AUC: 0.8738

Epoch 29/80
 - 0s - loss: 0.9459 - val_loss: 0.6090
AUC: 0.8740

Epoch 30/80
 - 0s - loss: 0.9439 - val_loss: 0.6094
AUC: 0.8743

Epoch 31/80
 - 0s - loss: 0.9378 - val_loss: 0.5994
AUC: 0.8741

Epoch 32/80
 - 0s - loss: 0.9399 - val_loss: 0.5995
AUC: 0.8740

Epoch 33/80
 - 0s - loss: 0.9327 - val_loss: 0.5941
AUC: 0.8738

Epoch 34/80
 - 0s - loss: 0.9419 - val_loss: 0.5926
AUC: 0.8740

Epoch 35/80
 - 0s - loss: 0.9386 - val_loss: 0.5962
AUC: 0.8740

Epoch 36/80
 - 0s - loss: 0.9340 - val_loss: 0.5974
AUC: 0.8740

Epoch 37/80
 - 0s - loss: 0.9355 - val_loss: 0.5989
AUC: 0.8741

Epoch 38/80
 - 0s - loss: 0.9394 - val_loss: 0.6036
AUC: 0.8741

Epoch 39/80
 - 0s - loss: 0.9373 - val_loss: 0.5686
AUC: 0.8737

Epoch 40/80
 - 0s - loss: 0.9375 - val_loss: 0.5892
AUC: 0.8740

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9393 - val_loss: 0.6325
AUC: 0.8744

Epoch 2/30
 - 1s - loss: 0.9380 - val_loss: 0.5930
AUC: 0.8741

Epoch 3/30
 - 1s - loss: 0.9423 - val_loss: 0.6029
AUC: 0.8743

Epoch 4/30
 - 1s - loss: 0.9316 - val_loss: 0.6027
AUC: 0.8746

Epoch 5/30
 - 1s - loss: 0.9296 - val_loss: 0.5818
AUC: 0.8743

Epoch 6/30
 - 1s - loss: 0.9280 - val_loss: 0.5939
AUC: 0.8742

Epoch 7/30
 - 1s - loss: 0.9266 - val_loss: 0.5814
AUC: 0.8742

Epoch 8/30
 - 1s - loss: 0.9291 - val_loss: 0.5731
AUC: 0.8741

Epoch 9/30
 - 1s - loss: 0.9213 - val_loss: 0.5915
AUC: 0.8746

Epoch 10/30
 - 1s - loss: 0.9219 - val_loss: 0.5892
AUC: 0.8743

Epoch 11/30
 - 1s - loss: 0.9206 - val_loss: 0.5846
AUC: 0.8748

Epoch 12/30
 - 1s - loss: 0.9179 - val_loss: 0.5725
AUC: 0.8743

Epoch 13/30
 - 1s - loss: 0.9141 - val_loss: 0.6105
AUC: 0.8747

Epoch 14/30
 - 0s - loss: 0.9187 - val_loss: 0.5912
AUC: 0.8749

Epoch 15/30
 - 1s - loss: 0.9104 - val_loss: 0.6012
AUC: 0.8750

Epoch 16/30
 - 1s - loss: 0.9138 - val_loss: 0.5682
AUC: 0.8746

Epoch 17/30
 - 1s - loss: 0.9099 - val_loss: 0.6322
AUC: 0.8754

Epoch 18/30
 - 1s - loss: 0.9125 - val_loss: 0.6036
AUC: 0.8747

Epoch 19/30
 - 1s - loss: 0.9096 - val_loss: 0.5845
AUC: 0.8747

Epoch 20/30
 - 1s - loss: 0.9015 - val_loss: 0.5842
AUC: 0.8750

Epoch 21/30
 - 0s - loss: 0.9031 - val_loss: 0.5966
AUC: 0.8747

Epoch 22/30
 - 1s - loss: 0.9027 - val_loss: 0.5705
AUC: 0.8746

Epoch 23/30
 - 0s - loss: 0.9032 - val_loss: 0.5715
AUC: 0.8741

Epoch 24/30
 - 1s - loss: 0.8972 - val_loss: 0.6132
AUC: 0.8752

Epoch 25/30
 - 1s - loss: 0.9035 - val_loss: 0.5754
AUC: 0.8748

Epoch 26/30
 - 1s - loss: 0.8953 - val_loss: 0.5935
AUC: 0.8743

Epoch 27/30
 - 1s - loss: 0.8892 - val_loss: 0.5711
AUC: 0.8742

Epoch 28/30
 - 0s - loss: 0.8947 - val_loss: 0.5807
AUC: 0.8746

Epoch 29/30
 - 0s - loss: 0.8905 - val_loss: 0.5731
AUC: 0.8745

Epoch 30/30
 - 1s - loss: 0.8860 - val_loss: 0.5715
Using TensorFlow backend.
AUC: 0.8744

2019-03-08 11:40:45.705457: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:40:45.875901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:40:45.875946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:40:46.169200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:40:46.169251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:40:46.169261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:40:46.169549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2052
Epoch 2/80
 - 2s - loss: 0.3129
Epoch 3/80
 - 2s - loss: 0.2636
Epoch 4/80
 - 2s - loss: 0.2295
Epoch 5/80
 - 2s - loss: 0.2057
Epoch 6/80
 - 2s - loss: 0.1870
Epoch 7/80
 - 2s - loss: 0.1712
Epoch 8/80
 - 2s - loss: 0.1581
Epoch 9/80
 - 2s - loss: 0.1471
Epoch 10/80
 - 2s - loss: 0.1380
Epoch 11/80
 - 2s - loss: 0.1305
Epoch 12/80
 - 2s - loss: 0.1245
Epoch 13/80
 - 2s - loss: 0.1193
Epoch 14/80
 - 2s - loss: 0.1150
Epoch 15/80
 - 2s - loss: 0.1113
Epoch 16/80
 - 2s - loss: 0.1082
Epoch 17/80
 - 2s - loss: 0.1053
Epoch 18/80
 - 2s - loss: 0.1028
Epoch 19/80
 - 2s - loss: 0.1007
Epoch 20/80
 - 2s - loss: 0.0989
Epoch 21/80
 - 2s - loss: 0.0973
Epoch 22/80
 - 2s - loss: 0.0959
Epoch 23/80
 - 2s - loss: 0.0947
Epoch 24/80
 - 2s - loss: 0.0937
Epoch 25/80
 - 2s - loss: 0.0929
Epoch 26/80
 - 2s - loss: 0.0921
Epoch 27/80
 - 2s - loss: 0.0915
Epoch 28/80
 - 2s - loss: 0.0909
Epoch 29/80
 - 2s - loss: 0.0904
Epoch 30/80
 - 2s - loss: 0.0900
Epoch 31/80
 - 2s - loss: 0.0896
Epoch 32/80
 - 2s - loss: 0.0892
Epoch 33/80
 - 2s - loss: 0.0889
Epoch 34/80
 - 2s - loss: 0.0887
Epoch 35/80
 - 2s - loss: 0.0884
Epoch 36/80
 - 2s - loss: 0.0882
Epoch 37/80
 - 2s - loss: 0.0880
Epoch 38/80
 - 2s - loss: 0.0878
Epoch 39/80
 - 2s - loss: 0.0876
Epoch 40/80
 - 2s - loss: 0.0874
Epoch 41/80
 - 2s - loss: 0.0873
Epoch 42/80
 - 2s - loss: 0.0871
Epoch 43/80
 - 2s - loss: 0.0870
Epoch 44/80
 - 2s - loss: 0.0869
Epoch 45/80
 - 2s - loss: 0.0867
Epoch 46/80
 - 2s - loss: 0.0866
Epoch 47/80
 - 2s - loss: 0.0865
Epoch 48/80
 - 2s - loss: 0.0864
Epoch 49/80
 - 2s - loss: 0.0863
Epoch 50/80
 - 2s - loss: 0.0862
Epoch 51/80
 - 2s - loss: 0.0862
Epoch 52/80
 - 2s - loss: 0.0861
Epoch 53/80
 - 2s - loss: 0.0860
Epoch 54/80
 - 2s - loss: 0.0860
Epoch 55/80
 - 2s - loss: 0.0859
Epoch 56/80
 - 2s - loss: 0.0858
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0857
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0856
Epoch 61/80
 - 2s - loss: 0.0856
Epoch 62/80
 - 2s - loss: 0.0855
Epoch 63/80
 - 2s - loss: 0.0855
Epoch 64/80
 - 2s - loss: 0.0821
Epoch 65/80
 - 2s - loss: 0.0818
Epoch 66/80
 - 2s - loss: 0.0818
Epoch 67/80
 - 2s - loss: 0.0818
Epoch 68/80
 - 2s - loss: 0.0818
Epoch 69/80
 - 2s - loss: 0.0810
Epoch 70/80
 - 2s - loss: 0.0809
Epoch 71/80
 - 2s - loss: 0.0809
Epoch 72/80
 - 2s - loss: 0.0809
Epoch 73/80
 - 2s - loss: 0.0808
Epoch 74/80
 - 2s - loss: 0.0808
Epoch 75/80
 - 2s - loss: 0.0808
Epoch 76/80
 - 2s - loss: 0.0808
Epoch 77/80
 - 2s - loss: 0.0807
Epoch 78/80
 - 2s - loss: 0.0807
Epoch 79/80
 - 2s - loss: 0.0807
Epoch 80/80
 - 2s - loss: 0.0807
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.6284 - val_loss: 1.0904
AUC: 0.8245

Epoch 2/80
 - 0s - loss: 1.9992 - val_loss: 0.9343
AUC: 0.8535

Epoch 3/80
 - 0s - loss: 1.3472 - val_loss: 0.7222
AUC: 0.8549

Epoch 4/80
 - 0s - loss: 1.1709 - val_loss: 0.7274
AUC: 0.8578

Epoch 5/80
 - 0s - loss: 1.1336 - val_loss: 0.5805
AUC: 0.8596

Epoch 6/80
 - 0s - loss: 1.0896 - val_loss: 0.6484
AUC: 0.8640

Epoch 7/80
 - 0s - loss: 1.0730 - val_loss: 0.6471
AUC: 0.8639

Epoch 8/80
 - 0s - loss: 1.0519 - val_loss: 0.5926
AUC: 0.8660

Epoch 9/80
 - 0s - loss: 1.0370 - val_loss: 0.6851
AUC: 0.8682

Epoch 10/80
 - 0s - loss: 1.0320 - val_loss: 0.6186
AUC: 0.8666

Epoch 11/80
 - 0s - loss: 1.0217 - val_loss: 0.5877
AUC: 0.8692

Epoch 12/80
 - 0s - loss: 1.0213 - val_loss: 0.5407
AUC: 0.8670

Epoch 13/80
 - 0s - loss: 1.0113 - val_loss: 0.6401
AUC: 0.8709

Epoch 14/80
 - 0s - loss: 0.9957 - val_loss: 0.6026
AUC: 0.8707

Epoch 15/80
 - 0s - loss: 0.9961 - val_loss: 0.5855
AUC: 0.8698

Epoch 16/80
 - 0s - loss: 0.9965 - val_loss: 0.5561
AUC: 0.8693

Epoch 17/80
 - 0s - loss: 0.9868 - val_loss: 0.5876
AUC: 0.8707

Epoch 18/80
 - 0s - loss: 0.9845 - val_loss: 0.5900
AUC: 0.8718

Epoch 19/80
 - 0s - loss: 0.9789 - val_loss: 0.5391
AUC: 0.8709

Epoch 20/80
 - 0s - loss: 0.9671 - val_loss: 0.6387
AUC: 0.8723

Epoch 21/80
 - 0s - loss: 0.9718 - val_loss: 0.5450
AUC: 0.8715

Epoch 22/80
 - 0s - loss: 0.9639 - val_loss: 0.5948
AUC: 0.8736

Epoch 23/80
 - 0s - loss: 0.9628 - val_loss: 0.6421
AUC: 0.8729

Epoch 24/80
 - 0s - loss: 0.9554 - val_loss: 0.5494
AUC: 0.8716

Epoch 25/80
 - 0s - loss: 0.9535 - val_loss: 0.5751
AUC: 0.8725

Epoch 26/80
 - 0s - loss: 0.9489 - val_loss: 0.6037
AUC: 0.8711

Epoch 27/80
 - 0s - loss: 0.9456 - val_loss: 0.5219
AUC: 0.8721

Epoch 28/80
 - 0s - loss: 0.9442 - val_loss: 0.6050
AUC: 0.8744

Epoch 29/80
 - 0s - loss: 0.9368 - val_loss: 0.5937
AUC: 0.8736

Epoch 30/80
 - 0s - loss: 0.9417 - val_loss: 0.6066
AUC: 0.8736

Epoch 31/80
 - 0s - loss: 0.9313 - val_loss: 0.5782
AUC: 0.8740

Epoch 32/80
 - 0s - loss: 0.9373 - val_loss: 0.5990
AUC: 0.8745

Epoch 33/80
 - 0s - loss: 0.9235 - val_loss: 0.6508
AUC: 0.8752

Epoch 34/80
 - 0s - loss: 0.9207 - val_loss: 0.5444
AUC: 0.8744

Epoch 35/80
 - 0s - loss: 0.9134 - val_loss: 0.5997
AUC: 0.8730

Epoch 36/80
 - 0s - loss: 0.9127 - val_loss: 0.5286
AUC: 0.8731

Epoch 37/80
 - 0s - loss: 0.9090 - val_loss: 0.5749
AUC: 0.8746

Epoch 38/80
 - 0s - loss: 0.8975 - val_loss: 0.5766
AUC: 0.8756

Epoch 39/80
 - 0s - loss: 0.8831 - val_loss: 0.5787
AUC: 0.8755

Epoch 40/80
 - 0s - loss: 0.8830 - val_loss: 0.6078
AUC: 0.8759

Epoch 41/80
 - 0s - loss: 0.8831 - val_loss: 0.5422
AUC: 0.8749

Epoch 42/80
 - 0s - loss: 0.8830 - val_loss: 0.6088
AUC: 0.8757

Epoch 43/80
 - 0s - loss: 0.8782 - val_loss: 0.5795
AUC: 0.8759

Epoch 44/80
 - 0s - loss: 0.8759 - val_loss: 0.5481
AUC: 0.8749

Epoch 45/80
 - 0s - loss: 0.8815 - val_loss: 0.5530
AUC: 0.8750

Epoch 46/80
 - 0s - loss: 0.8784 - val_loss: 0.5746
AUC: 0.8756

Epoch 47/80
 - 0s - loss: 0.8763 - val_loss: 0.5831
AUC: 0.8756

Epoch 48/80
 - 0s - loss: 0.8763 - val_loss: 0.5509
AUC: 0.8752

Epoch 49/80
 - 0s - loss: 0.8729 - val_loss: 0.5571
AUC: 0.8753

Epoch 50/80
 - 0s - loss: 0.8710 - val_loss: 0.5647
AUC: 0.8754

Epoch 51/80
 - 0s - loss: 0.8729 - val_loss: 0.5565
AUC: 0.8752

Epoch 52/80
 - 0s - loss: 0.8704 - val_loss: 0.5497
AUC: 0.8751

Epoch 53/80
 - 0s - loss: 0.8657 - val_loss: 0.5456
AUC: 0.8751

Epoch 54/80
 - 0s - loss: 0.8732 - val_loss: 0.5529
AUC: 0.8752

Epoch 55/80
 - 0s - loss: 0.8689 - val_loss: 0.5658
AUC: 0.8753

Epoch 56/80
 - 0s - loss: 0.8632 - val_loss: 0.5549
AUC: 0.8752

Epoch 57/80
 - 0s - loss: 0.8655 - val_loss: 0.5591
AUC: 0.8753

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.8782 - val_loss: 0.5321
AUC: 0.8750

Epoch 2/30
 - 1s - loss: 0.8770 - val_loss: 0.5499
AUC: 0.8752

Epoch 3/30
 - 1s - loss: 0.8756 - val_loss: 0.5672
AUC: 0.8756

Epoch 4/30
 - 1s - loss: 0.8688 - val_loss: 0.5379
AUC: 0.8753

Epoch 5/30
 - 1s - loss: 0.8709 - val_loss: 0.5536
AUC: 0.8755

Epoch 6/30
 - 1s - loss: 0.8635 - val_loss: 0.5848
AUC: 0.8759

Epoch 7/30
 - 1s - loss: 0.8610 - val_loss: 0.5537
AUC: 0.8752

Epoch 8/30
 - 1s - loss: 0.8647 - val_loss: 0.5946
AUC: 0.8761

Epoch 9/30
 - 1s - loss: 0.8633 - val_loss: 0.5658
AUC: 0.8757

Epoch 10/30
 - 1s - loss: 0.8579 - val_loss: 0.5445
AUC: 0.8753

Epoch 11/30
 - 1s - loss: 0.8571 - val_loss: 0.5329
AUC: 0.8752

Epoch 12/30
 - 1s - loss: 0.8583 - val_loss: 0.5509
AUC: 0.8755

Epoch 13/30
 - 1s - loss: 0.8515 - val_loss: 0.5516
AUC: 0.8755

Epoch 14/30
 - 1s - loss: 0.8560 - val_loss: 0.5511
AUC: 0.8754

Epoch 15/30
 - 1s - loss: 0.8476 - val_loss: 0.5414
AUC: 0.8752

Epoch 16/30
 - 1s - loss: 0.8513 - val_loss: 0.5497
AUC: 0.8753

Epoch 17/30
 - 1s - loss: 0.8478 - val_loss: 0.5596
AUC: 0.8756

Epoch 18/30
 - 1s - loss: 0.8470 - val_loss: 0.5486
AUC: 0.8753

Epoch 19/30
 - 1s - loss: 0.8500 - val_loss: 0.5497
AUC: 0.8754

Epoch 20/30
 - 1s - loss: 0.8485 - val_loss: 0.5584
AUC: 0.8756

Epoch 21/30
 - 1s - loss: 0.8511 - val_loss: 0.5592
AUC: 0.8756

Epoch 22/30
 - 1s - loss: 0.8515 - val_loss: 0.5532
AUC: 0.8755

Epoch 23/30
 - 1s - loss: 0.8491 - val_loss: 0.5513
AUC: 0.8754

Epoch 24/30
 - 1s - loss: 0.8452 - val_loss: 0.5493
AUC: 0.8754

Epoch 25/30
 - 1s - loss: 0.8483 - val_loss: 0.5498
AUC: 0.8754

Epoch 26/30
 - 1s - loss: 0.8481 - val_loss: 0.5490
AUC: 0.8754

Epoch 27/30
 - 1s - loss: 0.8451 - val_loss: 0.5511
AUC: 0.8754

Epoch 28/30
 - 1s - loss: 0.8422 - val_loss: 0.5494
AUC: 0.8754

Epoch 29/30
 - 1s - loss: 0.8450 - val_loss: 0.5493
AUC: 0.8754

Epoch 30/30
 - 1s - loss: 0.8484 - val_loss: 0.5500
Using TensorFlow backend.
AUC: 0.8754

2019-03-08 11:44:16.424615: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:44:16.586582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:44:16.586626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:44:16.883401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:44:16.883453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:44:16.883477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:44:16.883731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2185
Epoch 2/80
 - 2s - loss: 0.3186
Epoch 3/80
 - 2s - loss: 0.2744
Epoch 4/80
 - 2s - loss: 0.2360
Epoch 5/80
 - 2s - loss: 0.2087
Epoch 6/80
 - 2s - loss: 0.1870
Epoch 7/80
 - 2s - loss: 0.1705
Epoch 8/80
 - 2s - loss: 0.1577
Epoch 9/80
 - 2s - loss: 0.1470
Epoch 10/80
 - 2s - loss: 0.1380
Epoch 11/80
 - 2s - loss: 0.1306
Epoch 12/80
 - 2s - loss: 0.1246
Epoch 13/80
 - 2s - loss: 0.1197
Epoch 14/80
 - 2s - loss: 0.1155
Epoch 15/80
 - 2s - loss: 0.1120
Epoch 16/80
 - 2s - loss: 0.1088
Epoch 17/80
 - 2s - loss: 0.1060
Epoch 18/80
 - 2s - loss: 0.1036
Epoch 19/80
 - 2s - loss: 0.1015
Epoch 20/80
 - 2s - loss: 0.0996
Epoch 21/80
 - 2s - loss: 0.0980
Epoch 22/80
 - 2s - loss: 0.0966
Epoch 23/80
 - 2s - loss: 0.0953
Epoch 24/80
 - 2s - loss: 0.0943
Epoch 25/80
 - 2s - loss: 0.0934
Epoch 26/80
 - 2s - loss: 0.0926
Epoch 27/80
 - 2s - loss: 0.0919
Epoch 28/80
 - 2s - loss: 0.0913
Epoch 29/80
 - 2s - loss: 0.0908
Epoch 30/80
 - 2s - loss: 0.0903
Epoch 31/80
 - 2s - loss: 0.0899
Epoch 32/80
 - 2s - loss: 0.0895
Epoch 33/80
 - 2s - loss: 0.0892
Epoch 34/80
 - 2s - loss: 0.0889
Epoch 35/80
 - 2s - loss: 0.0886
Epoch 36/80
 - 2s - loss: 0.0884
Epoch 37/80
 - 2s - loss: 0.0881
Epoch 38/80
 - 2s - loss: 0.0879
Epoch 39/80
 - 2s - loss: 0.0878
Epoch 40/80
 - 2s - loss: 0.0876
Epoch 41/80
 - 2s - loss: 0.0874
Epoch 42/80
 - 2s - loss: 0.0873
Epoch 43/80
 - 2s - loss: 0.0871
Epoch 44/80
 - 2s - loss: 0.0870
Epoch 45/80
 - 2s - loss: 0.0869
Epoch 46/80
 - 2s - loss: 0.0867
Epoch 47/80
 - 2s - loss: 0.0867
Epoch 48/80
 - 2s - loss: 0.0865
Epoch 49/80
 - 2s - loss: 0.0864
Epoch 50/80
 - 2s - loss: 0.0864
Epoch 51/80
 - 2s - loss: 0.0863
Epoch 52/80
 - 2s - loss: 0.0862
Epoch 53/80
 - 2s - loss: 0.0862
Epoch 54/80
 - 2s - loss: 0.0861
Epoch 55/80
 - 2s - loss: 0.0860
Epoch 56/80
 - 2s - loss: 0.0859
Epoch 57/80
 - 2s - loss: 0.0858
Epoch 58/80
 - 2s - loss: 0.0858
Epoch 59/80
 - 2s - loss: 0.0857
Epoch 60/80
 - 2s - loss: 0.0857
Epoch 61/80
 - 2s - loss: 0.0856
Epoch 62/80
 - 2s - loss: 0.0856
Epoch 63/80
 - 2s - loss: 0.0855
Epoch 64/80
 - 2s - loss: 0.0855
Epoch 65/80
 - 2s - loss: 0.0855
Epoch 66/80
 - 2s - loss: 0.0854
Epoch 67/80
 - 2s - loss: 0.0854
Epoch 68/80
 - 2s - loss: 0.0853
Epoch 69/80
 - 2s - loss: 0.0853
Epoch 70/80
 - 2s - loss: 0.0853
Epoch 71/80
 - 2s - loss: 0.0852
Epoch 72/80
 - 2s - loss: 0.0852
Epoch 73/80
 - 2s - loss: 0.0818
Epoch 74/80
 - 2s - loss: 0.0815
Epoch 75/80
 - 2s - loss: 0.0815
Epoch 76/80
 - 2s - loss: 0.0815
Epoch 77/80
 - 2s - loss: 0.0815
Epoch 78/80
 - 2s - loss: 0.0807
Epoch 79/80
 - 2s - loss: 0.0807
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:46:42.510064: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:46:42.672127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:46:42.672190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:46:42.969333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:46:42.969381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:46:42.969390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:46:42.969643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2179
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:47:01.855308: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:47:02.016720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:47:02.016763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:47:02.312469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:47:02.312530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:47:02.312539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:47:02.312796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9733
Epoch 2/80
 - 2s - loss: 0.1827
Epoch 3/80
 - 2s - loss: 0.1631
Epoch 4/80
 - 2s - loss: 0.1429
Epoch 5/80
 - 2s - loss: 0.1225
Epoch 6/80
 - 2s - loss: 0.1078
Epoch 7/80
 - 2s - loss: 0.0965
Epoch 8/80
 - 2s - loss: 0.0870
Epoch 9/80
 - 2s - loss: 0.0787
Epoch 10/80
 - 2s - loss: 0.0719
Epoch 11/80
 - 2s - loss: 0.0663
Epoch 12/80
 - 2s - loss: 0.0620
Epoch 13/80
 - 2s - loss: 0.0586
Epoch 14/80
 - 2s - loss: 0.0557
Epoch 15/80
 - 2s - loss: 0.0532
Epoch 16/80
 - 2s - loss: 0.0511
Epoch 17/80
 - 2s - loss: 0.0493
Epoch 18/80
 - 2s - loss: 0.0477
Epoch 19/80
 - 2s - loss: 0.0463
Epoch 20/80
 - 2s - loss: 0.0451
Epoch 21/80
 - 2s - loss: 0.0440
Epoch 22/80
 - 2s - loss: 0.0431
Epoch 23/80
 - 2s - loss: 0.0423
Epoch 24/80
 - 2s - loss: 0.0416
Epoch 25/80
 - 2s - loss: 0.0410
Epoch 26/80
 - 2s - loss: 0.0405
Epoch 27/80
 - 2s - loss: 0.0400
Epoch 28/80
 - 2s - loss: 0.0396
Epoch 29/80
 - 2s - loss: 0.0393
Epoch 30/80
 - 2s - loss: 0.0390
Epoch 31/80
 - 2s - loss: 0.0387
Epoch 32/80
 - 2s - loss: 0.0385
Epoch 33/80
 - 2s - loss: 0.0383
Epoch 34/80
 - 2s - loss: 0.0381
Epoch 35/80
 - 2s - loss: 0.0379
Epoch 36/80
 - 2s - loss: 0.0377
Epoch 37/80
 - 2s - loss: 0.0376
Epoch 38/80
 - 2s - loss: 0.0375
Epoch 39/80
 - 2s - loss: 0.0374
Epoch 40/80
 - 2s - loss: 0.0373
Epoch 41/80
 - 2s - loss: 0.0372
Epoch 42/80
 - 2s - loss: 0.0371
Epoch 43/80
 - 2s - loss: 0.0370
Epoch 44/80
 - 2s - loss: 0.0369
Epoch 45/80
 - 2s - loss: 0.0369
Epoch 46/80
 - 2s - loss: 0.0368
Epoch 47/80
 - 2s - loss: 0.0367
Epoch 48/80
 - 2s - loss: 0.0367
Epoch 49/80
 - 2s - loss: 0.0366
Epoch 50/80
 - 2s - loss: 0.0366
Epoch 51/80
 - 2s - loss: 0.0365
Epoch 52/80
 - 2s - loss: 0.0365
Epoch 53/80
 - 2s - loss: 0.0364
Epoch 54/80
 - 2s - loss: 0.0364
Epoch 55/80
 - 2s - loss: 0.0363
Epoch 56/80
 - 2s - loss: 0.0363
Epoch 57/80
 - 2s - loss: 0.0363
Epoch 58/80
 - 2s - loss: 0.0363
Epoch 59/80
 - 2s - loss: 0.0362
Epoch 60/80
 - 2s - loss: 0.0362
Epoch 61/80
 - 2s - loss: 0.0347
Epoch 62/80
 - 2s - loss: 0.0345
Epoch 63/80
 - 2s - loss: 0.0345
Epoch 64/80
 - 2s - loss: 0.0345
Epoch 65/80
 - 2s - loss: 0.0345
Epoch 66/80
 - 2s - loss: 0.0341
Epoch 67/80
 - 2s - loss: 0.0341
Epoch 68/80
 - 2s - loss: 0.0341
Epoch 69/80
 - 2s - loss: 0.0341
Epoch 70/80
 - 2s - loss: 0.0340
Epoch 71/80
 - 2s - loss: 0.0340
Epoch 72/80
 - 2s - loss: 0.0340
Epoch 73/80
 - 2s - loss: 0.0340
Epoch 74/80
 - 2s - loss: 0.0340
Epoch 75/80
 - 2s - loss: 0.0340
Epoch 76/80
 - 2s - loss: 0.0340
Epoch 77/80
 - 2s - loss: 0.0340
Epoch 78/80
 - 2s - loss: 0.0340
Epoch 79/80
 - 2s - loss: 0.0340
Epoch 80/80
 - 2s - loss: 0.0340
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.7787 - val_loss: 0.9833
AUC: 0.8259

Epoch 2/80
 - 0s - loss: 1.5877 - val_loss: 0.7374
AUC: 0.8372

Epoch 3/80
 - 0s - loss: 1.2185 - val_loss: 0.7274
AUC: 0.8468

Epoch 4/80
 - 0s - loss: 1.1176 - val_loss: 0.7239
AUC: 0.8536

Epoch 5/80
 - 0s - loss: 1.0676 - val_loss: 0.6693
AUC: 0.8569

Epoch 6/80
 - 0s - loss: 1.0521 - val_loss: 0.6502
AUC: 0.8584

Epoch 7/80
 - 0s - loss: 1.0367 - val_loss: 0.6221
AUC: 0.8572

Epoch 8/80
 - 0s - loss: 1.0268 - val_loss: 0.7014
AUC: 0.8597

Epoch 9/80
 - 0s - loss: 1.0222 - val_loss: 0.6139
AUC: 0.8595

Epoch 10/80
 - 0s - loss: 1.0139 - val_loss: 0.6141
AUC: 0.8623

Epoch 11/80
 - 0s - loss: 1.0027 - val_loss: 0.6008
AUC: 0.8629

Epoch 12/80
 - 0s - loss: 0.9901 - val_loss: 0.5769
AUC: 0.8635

Epoch 13/80
 - 0s - loss: 0.9906 - val_loss: 0.6433
AUC: 0.8643

Epoch 14/80
 - 0s - loss: 0.9757 - val_loss: 0.6348
AUC: 0.8642

Epoch 15/80
 - 0s - loss: 0.9820 - val_loss: 0.6903
AUC: 0.8646

Epoch 16/80
 - 0s - loss: 0.9669 - val_loss: 0.6081
AUC: 0.8636

Epoch 17/80
 - 0s - loss: 0.9672 - val_loss: 0.7001
AUC: 0.8645

Epoch 18/80
 - 0s - loss: 0.9626 - val_loss: 0.6238
AUC: 0.8632

Epoch 19/80
 - 0s - loss: 0.9618 - val_loss: 0.5935
AUC: 0.8651

Epoch 20/80
 - 0s - loss: 0.9507 - val_loss: 0.6789
AUC: 0.8650

Epoch 21/80
 - 0s - loss: 0.9464 - val_loss: 0.5941
AUC: 0.8636

Epoch 22/80
 - 0s - loss: 0.9484 - val_loss: 0.6606
AUC: 0.8657

Epoch 23/80
 - 0s - loss: 0.9283 - val_loss: 0.5788
AUC: 0.8661

Epoch 24/80
 - 0s - loss: 0.9214 - val_loss: 0.6221
AUC: 0.8668

Epoch 25/80
 - 0s - loss: 0.9203 - val_loss: 0.5800
AUC: 0.8660

Epoch 26/80
 - 0s - loss: 0.9239 - val_loss: 0.6140
AUC: 0.8662

Epoch 27/80
 - 0s - loss: 0.9130 - val_loss: 0.5649
AUC: 0.8651

Epoch 28/80
 - 0s - loss: 0.9160 - val_loss: 0.5991
AUC: 0.8652

Epoch 29/80
 - 0s - loss: 0.9133 - val_loss: 0.5857
AUC: 0.8655

Epoch 30/80
 - 0s - loss: 0.9122 - val_loss: 0.6039
AUC: 0.8651

Epoch 31/80
 - 0s - loss: 0.9126 - val_loss: 0.5690
AUC: 0.8649

Epoch 32/80
 - 0s - loss: 0.9109 - val_loss: 0.5891
AUC: 0.8653

Epoch 33/80
 - 0s - loss: 0.9105 - val_loss: 0.5908
AUC: 0.8659

Epoch 34/80
 - 0s - loss: 0.9112 - val_loss: 0.5878
AUC: 0.8656

Epoch 35/80
 - 0s - loss: 0.9115 - val_loss: 0.5951
AUC: 0.8658

Epoch 36/80
 - 0s - loss: 0.8974 - val_loss: 0.5951
AUC: 0.8662

Epoch 37/80
 - 0s - loss: 0.9033 - val_loss: 0.5755
AUC: 0.8655

Epoch 38/80
 - 0s - loss: 0.8999 - val_loss: 0.5910
AUC: 0.8658

Epoch 39/80
 - 0s - loss: 0.9007 - val_loss: 0.5829
AUC: 0.8656

Epoch 40/80
 - 0s - loss: 0.9026 - val_loss: 0.5866
AUC: 0.8656

Epoch 41/80
 - 0s - loss: 0.9023 - val_loss: 0.5919
AUC: 0.8655

Epoch 42/80
 - 0s - loss: 0.8985 - val_loss: 0.5811
AUC: 0.8654

Epoch 43/80
 - 0s - loss: 0.8988 - val_loss: 0.5935
AUC: 0.8656

Epoch 44/80
 - 0s - loss: 0.8959 - val_loss: 0.5914
AUC: 0.8658

Epoch 45/80
 - 0s - loss: 0.8987 - val_loss: 0.5771
AUC: 0.8655

Epoch 46/80
 - 0s - loss: 0.8920 - val_loss: 0.5919
AUC: 0.8658

Epoch 47/80
 - 0s - loss: 0.8951 - val_loss: 0.5752
AUC: 0.8655

Epoch 48/80
 - 0s - loss: 0.8977 - val_loss: 0.5851
AUC: 0.8656

Epoch 49/80
 - 0s - loss: 0.8965 - val_loss: 0.5866
AUC: 0.8656

Epoch 50/80
 - 0s - loss: 0.8967 - val_loss: 0.5856
AUC: 0.8656

Epoch 51/80
 - 0s - loss: 0.8940 - val_loss: 0.5874
AUC: 0.8656

Epoch 52/80
 - 0s - loss: 0.8953 - val_loss: 0.5887
AUC: 0.8656

Epoch 53/80
 - 0s - loss: 0.8940 - val_loss: 0.5861
AUC: 0.8655

Epoch 54/80
 - 0s - loss: 0.8949 - val_loss: 0.5869
AUC: 0.8656

Epoch 55/80
 - 0s - loss: 0.8995 - val_loss: 0.5869
AUC: 0.8655

Epoch 56/80
 - 0s - loss: 0.9005 - val_loss: 0.5862
AUC: 0.8656

Epoch 57/80
 - 0s - loss: 0.8927 - val_loss: 0.5835
AUC: 0.8656

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9174 - val_loss: 0.5947
AUC: 0.8665

Epoch 2/30
 - 1s - loss: 0.9143 - val_loss: 0.6190
AUC: 0.8667

Epoch 3/30
 - 1s - loss: 0.9162 - val_loss: 0.6049
AUC: 0.8664

Epoch 4/30
 - 0s - loss: 0.9131 - val_loss: 0.5861
AUC: 0.8657

Epoch 5/30
 - 0s - loss: 0.9075 - val_loss: 0.6023
AUC: 0.8662

Epoch 6/30
 - 0s - loss: 0.9077 - val_loss: 0.5839
AUC: 0.8658

Epoch 7/30
 - 0s - loss: 0.9081 - val_loss: 0.6073
AUC: 0.8663

Epoch 8/30
 - 1s - loss: 0.9031 - val_loss: 0.6330
AUC: 0.8662

Epoch 9/30
 - 1s - loss: 0.8986 - val_loss: 0.6001
AUC: 0.8663

Epoch 10/30
 - 0s - loss: 0.8962 - val_loss: 0.5831
AUC: 0.8663

Epoch 11/30
 - 1s - loss: 0.8990 - val_loss: 0.5841
AUC: 0.8660

Epoch 12/30
 - 1s - loss: 0.8944 - val_loss: 0.6093
AUC: 0.8665

Epoch 13/30
 - 0s - loss: 0.8929 - val_loss: 0.5894
AUC: 0.8663

Epoch 14/30
 - 1s - loss: 0.8942 - val_loss: 0.5948
AUC: 0.8664

Epoch 15/30
 - 1s - loss: 0.8903 - val_loss: 0.5896
AUC: 0.8664

Epoch 16/30
 - 1s - loss: 0.8866 - val_loss: 0.5844
AUC: 0.8663

Epoch 17/30
 - 1s - loss: 0.8847 - val_loss: 0.5934
AUC: 0.8664

Epoch 18/30
 - 0s - loss: 0.8755 - val_loss: 0.5864
AUC: 0.8662

Epoch 19/30
 - 1s - loss: 0.8756 - val_loss: 0.5761
AUC: 0.8662

Epoch 20/30
 - 1s - loss: 0.8778 - val_loss: 0.5655
AUC: 0.8660

Epoch 21/30
 - 1s - loss: 0.8796 - val_loss: 0.5917
AUC: 0.8665

Epoch 22/30
 - 1s - loss: 0.8763 - val_loss: 0.5565
AUC: 0.8659

Epoch 23/30
 - 1s - loss: 0.8789 - val_loss: 0.5948
AUC: 0.8665

Epoch 24/30
 - 1s - loss: 0.8718 - val_loss: 0.5746
AUC: 0.8662

Epoch 25/30
 - 1s - loss: 0.8686 - val_loss: 0.5642
AUC: 0.8661

Epoch 26/30
 - 0s - loss: 0.8698 - val_loss: 0.6003
AUC: 0.8669

Epoch 27/30
 - 1s - loss: 0.8681 - val_loss: 0.5851
AUC: 0.8669

Epoch 28/30
 - 1s - loss: 0.8630 - val_loss: 0.5884
AUC: 0.8668

Epoch 29/30
 - 1s - loss: 0.8677 - val_loss: 0.5626
AUC: 0.8662

Epoch 30/30
 - 1s - loss: 0.8581 - val_loss: 0.5719
Using TensorFlow backend.
AUC: 0.8666

2019-03-08 11:50:31.953350: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:50:32.118067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:50:32.118111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:50:32.412028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:50:32.412079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:50:32.412088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:50:32.412358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.0024
Epoch 2/80
 - 2s - loss: 0.1821
Epoch 3/80
 - 2s - loss: 0.1566
Epoch 4/80
 - 2s - loss: 0.1333
Epoch 5/80
 - 2s - loss: 0.1153
Epoch 6/80
 - 2s - loss: 0.1021
Epoch 7/80
 - 2s - loss: 0.0915
Epoch 8/80
 - 2s - loss: 0.0828
Epoch 9/80
 - 2s - loss: 0.0757
Epoch 10/80
 - 2s - loss: 0.0698
Epoch 11/80
 - 2s - loss: 0.0650
Epoch 12/80
 - 2s - loss: 0.0611
Epoch 13/80
 - 2s - loss: 0.0580
Epoch 14/80
 - 2s - loss: 0.0553
Epoch 15/80
 - 2s - loss: 0.0531
Epoch 16/80
 - 2s - loss: 0.0511
Epoch 17/80
 - 2s - loss: 0.0493
Epoch 18/80
 - 2s - loss: 0.0477
Epoch 19/80
 - 2s - loss: 0.0464
Epoch 20/80
 - 2s - loss: 0.0452
Epoch 21/80
 - 2s - loss: 0.0442
Epoch 22/80
 - 2s - loss: 0.0432
Epoch 23/80
 - 2s - loss: 0.0425
Epoch 24/80
 - 2s - loss: 0.0417
Epoch 25/80
 - 2s - loss: 0.0411
Epoch 26/80
 - 2s - loss: 0.0406
Epoch 27/80
 - 2s - loss: 0.0402
Epoch 28/80
 - 2s - loss: 0.0398
Epoch 29/80
 - 2s - loss: 0.0394
Epoch 30/80
 - 2s - loss: 0.0391
Epoch 31/80
 - 2s - loss: 0.0388
Epoch 32/80
 - 2s - loss: 0.0386
Epoch 33/80
 - 2s - loss: 0.0384
Epoch 34/80
 - 2s - loss: 0.0382
Epoch 35/80
 - 2s - loss: 0.0380
Epoch 36/80
 - 2s - loss: 0.0379
Epoch 37/80
 - 2s - loss: 0.0377
Epoch 38/80
 - 2s - loss: 0.0376
Epoch 39/80
 - 2s - loss: 0.0375
Epoch 40/80
 - 2s - loss: 0.0374
Epoch 41/80
 - 2s - loss: 0.0373
Epoch 42/80
 - 2s - loss: 0.0372
Epoch 43/80
 - 2s - loss: 0.0371
Epoch 44/80
 - 2s - loss: 0.0370
Epoch 45/80
 - 2s - loss: 0.0370
Epoch 46/80
 - 2s - loss: 0.0369
Epoch 47/80
 - 2s - loss: 0.0369
Epoch 48/80
 - 2s - loss: 0.0368
Epoch 49/80
 - 2s - loss: 0.0367
Epoch 50/80
 - 2s - loss: 0.0367
Epoch 51/80
 - 2s - loss: 0.0367
Epoch 52/80
 - 2s - loss: 0.0366
Epoch 53/80
 - 2s - loss: 0.0366
Epoch 54/80
 - 2s - loss: 0.0365
Epoch 55/80
 - 2s - loss: 0.0365
Epoch 56/80
 - 2s - loss: 0.0365
Epoch 57/80
 - 2s - loss: 0.0364
Epoch 58/80
 - 2s - loss: 0.0349
Epoch 59/80
 - 2s - loss: 0.0347
Epoch 60/80
 - 2s - loss: 0.0347
Epoch 61/80
 - 2s - loss: 0.0347
Epoch 62/80
 - 2s - loss: 0.0347
Epoch 63/80
 - 2s - loss: 0.0344
Epoch 64/80
 - 2s - loss: 0.0343
Epoch 65/80
 - 2s - loss: 0.0343
Epoch 66/80
 - 2s - loss: 0.0343
Epoch 67/80
 - 2s - loss: 0.0343
Epoch 68/80
 - 2s - loss: 0.0342
Epoch 69/80
 - 2s - loss: 0.0342
Epoch 70/80
 - 2s - loss: 0.0342
Epoch 71/80
 - 2s - loss: 0.0342
Epoch 72/80
 - 2s - loss: 0.0342
Epoch 73/80
 - 2s - loss: 0.0342
Epoch 74/80
 - 2s - loss: 0.0342
Epoch 75/80
 - 2s - loss: 0.0342
Epoch 76/80
 - 2s - loss: 0.0342
Epoch 77/80
 - 2s - loss: 0.0342
Epoch 78/80
 - 2s - loss: 0.0342
Epoch 79/80
 - 2s - loss: 0.0342
Epoch 80/80
 - 2s - loss: 0.0342
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.0127 - val_loss: 1.2548
AUC: 0.8338

Epoch 2/80
 - 0s - loss: 1.6610 - val_loss: 0.9910
AUC: 0.8528

Epoch 3/80
 - 0s - loss: 1.2793 - val_loss: 0.6720
AUC: 0.8582

Epoch 4/80
 - 0s - loss: 1.1523 - val_loss: 0.7070
AUC: 0.8598

Epoch 5/80
 - 0s - loss: 1.0982 - val_loss: 0.6371
AUC: 0.8645

Epoch 6/80
 - 0s - loss: 1.0821 - val_loss: 0.6345
AUC: 0.8652

Epoch 7/80
 - 0s - loss: 1.0575 - val_loss: 0.6565
AUC: 0.8687

Epoch 8/80
 - 0s - loss: 1.0414 - val_loss: 0.6345
AUC: 0.8714

Epoch 9/80
 - 0s - loss: 1.0293 - val_loss: 0.6278
AUC: 0.8717

Epoch 10/80
 - 0s - loss: 1.0260 - val_loss: 0.6633
AUC: 0.8713

Epoch 11/80
 - 0s - loss: 1.0219 - val_loss: 0.6061
AUC: 0.8725

Epoch 12/80
 - 0s - loss: 1.0115 - val_loss: 0.6196
AUC: 0.8732

Epoch 13/80
 - 0s - loss: 1.0073 - val_loss: 0.5969
AUC: 0.8737

Epoch 14/80
 - 0s - loss: 1.0063 - val_loss: 0.6303
AUC: 0.8737

Epoch 15/80
 - 0s - loss: 0.9918 - val_loss: 0.5946
AUC: 0.8748

Epoch 16/80
 - 0s - loss: 0.9888 - val_loss: 0.6685
AUC: 0.8759

Epoch 17/80
 - 0s - loss: 0.9827 - val_loss: 0.5758
AUC: 0.8751

Epoch 18/80
 - 0s - loss: 0.9846 - val_loss: 0.5491
AUC: 0.8737

Epoch 19/80
 - 0s - loss: 0.9832 - val_loss: 0.6092
AUC: 0.8750

Epoch 20/80
 - 0s - loss: 0.9714 - val_loss: 0.5864
AUC: 0.8768

Epoch 21/80
 - 0s - loss: 0.9653 - val_loss: 0.6102
AUC: 0.8776

Epoch 22/80
 - 0s - loss: 0.9676 - val_loss: 0.6223
AUC: 0.8763

Epoch 23/80
 - 0s - loss: 0.9608 - val_loss: 0.6258
AUC: 0.8766

Epoch 24/80
 - 0s - loss: 0.9510 - val_loss: 0.5981
AUC: 0.8779

Epoch 25/80
 - 0s - loss: 0.9502 - val_loss: 0.5988
AUC: 0.8775

Epoch 26/80
 - 0s - loss: 0.9441 - val_loss: 0.5374
AUC: 0.8768

Epoch 27/80
 - 0s - loss: 0.9389 - val_loss: 0.5960
AUC: 0.8768

Epoch 28/80
 - 0s - loss: 0.9399 - val_loss: 0.5960
AUC: 0.8779

Epoch 29/80
 - 0s - loss: 0.9306 - val_loss: 0.6140
AUC: 0.8779

Epoch 30/80
 - 0s - loss: 0.9284 - val_loss: 0.6320
AUC: 0.8771

Epoch 31/80
 - 0s - loss: 0.9274 - val_loss: 0.5711
AUC: 0.8789

Epoch 32/80
 - 0s - loss: 0.9241 - val_loss: 0.5335
AUC: 0.8776

Epoch 33/80
 - 0s - loss: 0.9248 - val_loss: 0.6016
AUC: 0.8781

Epoch 34/80
 - 0s - loss: 0.9207 - val_loss: 0.5647
AUC: 0.8774

Epoch 35/80
 - 0s - loss: 0.9157 - val_loss: 0.5338
AUC: 0.8777

Epoch 36/80
 - 0s - loss: 0.9056 - val_loss: 0.5844
AUC: 0.8789

Epoch 37/80
 - 0s - loss: 0.9113 - val_loss: 0.5400
AUC: 0.8771

Epoch 38/80
 - 0s - loss: 0.9048 - val_loss: 0.5408
AUC: 0.8777

Epoch 39/80
 - 0s - loss: 0.9065 - val_loss: 0.5316
AUC: 0.8779

Epoch 40/80
 - 0s - loss: 0.9017 - val_loss: 0.5076
AUC: 0.8785

Epoch 41/80
 - 0s - loss: 0.8934 - val_loss: 0.5249
AUC: 0.8774

Epoch 42/80
 - 0s - loss: 0.8907 - val_loss: 0.5902
AUC: 0.8786

Epoch 43/80
 - 0s - loss: 0.8828 - val_loss: 0.5142
AUC: 0.8764

Epoch 44/80
 - 0s - loss: 0.8803 - val_loss: 0.5598
AUC: 0.8757

Epoch 45/80
 - 0s - loss: 0.8798 - val_loss: 0.5521
AUC: 0.8789

Epoch 46/80
 - 0s - loss: 0.8799 - val_loss: 0.6375
AUC: 0.8776

Epoch 47/80
 - 0s - loss: 0.8752 - val_loss: 0.5872
AUC: 0.8775

Epoch 48/80
 - 0s - loss: 0.8631 - val_loss: 0.5260
AUC: 0.8790

Epoch 49/80
 - 0s - loss: 0.8604 - val_loss: 0.5681
AUC: 0.8780

Epoch 50/80
 - 0s - loss: 0.8532 - val_loss: 0.6021
AUC: 0.8775

Epoch 51/80
 - 0s - loss: 0.8329 - val_loss: 0.5554
AUC: 0.8785

Epoch 52/80
 - 0s - loss: 0.8296 - val_loss: 0.5464
AUC: 0.8776

Epoch 53/80
 - 0s - loss: 0.8267 - val_loss: 0.5493
AUC: 0.8781

Epoch 54/80
 - 0s - loss: 0.8260 - val_loss: 0.5220
AUC: 0.8770

Epoch 55/80
 - 0s - loss: 0.8216 - val_loss: 0.5333
AUC: 0.8769

Epoch 56/80
 - 0s - loss: 0.8220 - val_loss: 0.5505
AUC: 0.8778

Epoch 57/80
 - 0s - loss: 0.8220 - val_loss: 0.5382
AUC: 0.8773

Epoch 58/80
 - 0s - loss: 0.8181 - val_loss: 0.5720
AUC: 0.8777

Epoch 59/80
 - 0s - loss: 0.8198 - val_loss: 0.5457
AUC: 0.8773

Epoch 60/80
 - 0s - loss: 0.8167 - val_loss: 0.5524
AUC: 0.8774

Epoch 61/80
 - 0s - loss: 0.8113 - val_loss: 0.5377
AUC: 0.8776

Epoch 62/80
 - 0s - loss: 0.8080 - val_loss: 0.5410
AUC: 0.8775

Epoch 63/80
 - 0s - loss: 0.8145 - val_loss: 0.5528
AUC: 0.8775

Epoch 64/80
 - 0s - loss: 0.8128 - val_loss: 0.5504
AUC: 0.8774

Epoch 65/80
 - 0s - loss: 0.8091 - val_loss: 0.5415
AUC: 0.8774

Epoch 66/80
 - 0s - loss: 0.8099 - val_loss: 0.5301
AUC: 0.8774

Epoch 67/80
 - 0s - loss: 0.8057 - val_loss: 0.5510
AUC: 0.8776

Epoch 68/80
 - 0s - loss: 0.8067 - val_loss: 0.5349
AUC: 0.8773

Epoch 69/80
 - 0s - loss: 0.8060 - val_loss: 0.5301
AUC: 0.8773

Epoch 70/80
 - 0s - loss: 0.8072 - val_loss: 0.5460
AUC: 0.8774

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.8466 - val_loss: 0.5467
AUC: 0.8796

Epoch 2/30
 - 1s - loss: 0.8381 - val_loss: 0.5584
AUC: 0.8791

Epoch 3/30
 - 1s - loss: 0.8315 - val_loss: 0.5258
AUC: 0.8785

Epoch 4/30
 - 1s - loss: 0.8299 - val_loss: 0.5384
AUC: 0.8782

Epoch 5/30
 - 1s - loss: 0.8307 - val_loss: 0.5526
AUC: 0.8787

Epoch 6/30
 - 1s - loss: 0.8258 - val_loss: 0.5273
AUC: 0.8780

Epoch 7/30
 - 1s - loss: 0.8252 - val_loss: 0.5460
AUC: 0.8785

Epoch 8/30
 - 1s - loss: 0.8208 - val_loss: 0.5370
AUC: 0.8785

Epoch 9/30
 - 1s - loss: 0.8146 - val_loss: 0.5275
AUC: 0.8778

Epoch 10/30
 - 1s - loss: 0.8152 - val_loss: 0.5372
AUC: 0.8782

Epoch 11/30
 - 1s - loss: 0.8126 - val_loss: 0.5478
AUC: 0.8785

Epoch 12/30
 - 1s - loss: 0.8114 - val_loss: 0.5498
AUC: 0.8782

Epoch 13/30
 - 1s - loss: 0.8135 - val_loss: 0.5268
AUC: 0.8783

Epoch 14/30
 - 1s - loss: 0.8043 - val_loss: 0.5385
AUC: 0.8782

Epoch 15/30
 - 1s - loss: 0.8081 - val_loss: 0.5382
AUC: 0.8780

Epoch 16/30
 - 1s - loss: 0.8049 - val_loss: 0.5365
AUC: 0.8780

Epoch 17/30
 - 1s - loss: 0.8054 - val_loss: 0.5347
AUC: 0.8781

Epoch 18/30
 - 1s - loss: 0.8076 - val_loss: 0.5392
AUC: 0.8781

Epoch 19/30
 - 1s - loss: 0.8009 - val_loss: 0.5405
AUC: 0.8781

Epoch 20/30
 - 1s - loss: 0.8024 - val_loss: 0.5379
AUC: 0.8779

Epoch 21/30
 - 1s - loss: 0.8046 - val_loss: 0.5364
AUC: 0.8779

Epoch 22/30
 - 1s - loss: 0.8037 - val_loss: 0.5363
AUC: 0.8779

Epoch 23/30
 - 1s - loss: 0.7975 - val_loss: 0.5306
AUC: 0.8779

Epoch 24/30
 - 1s - loss: 0.7995 - val_loss: 0.5338
AUC: 0.8780

Epoch 25/30
 - 1s - loss: 0.8030 - val_loss: 0.5353
AUC: 0.8780

Epoch 26/30
 - 1s - loss: 0.7974 - val_loss: 0.5343
AUC: 0.8780

Epoch 27/30
 - 1s - loss: 0.7960 - val_loss: 0.5342
AUC: 0.8780

Epoch 28/30
 - 1s - loss: 0.8014 - val_loss: 0.5354
AUC: 0.8780

Epoch 29/30
 - 1s - loss: 0.8013 - val_loss: 0.5349
AUC: 0.8779

Epoch 30/30
 - 1s - loss: 0.7996 - val_loss: 0.5361
Using TensorFlow backend.
AUC: 0.8779

2019-03-08 11:54:12.644536: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:54:12.808639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:54:12.808682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:54:13.104931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:54:13.104993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:54:13.105002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:54:13.105269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9880
Epoch 2/80
 - 2s - loss: 0.1809
Epoch 3/80
 - 2s - loss: 0.1596
Epoch 4/80
 - 2s - loss: 0.1369
Epoch 5/80
 - 2s - loss: 0.1190
Epoch 6/80
 - 2s - loss: 0.1071
Epoch 7/80
 - 2s - loss: 0.0963
Epoch 8/80
 - 2s - loss: 0.0865
Epoch 9/80
 - 2s - loss: 0.0782
Epoch 10/80
 - 2s - loss: 0.0716
Epoch 11/80
 - 2s - loss: 0.0662
Epoch 12/80
 - 2s - loss: 0.0619
Epoch 13/80
 - 2s - loss: 0.0585
Epoch 14/80
 - 2s - loss: 0.0556
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 11:54:52.795918: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:54:52.960355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:54:52.960399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:54:53.254460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:54:53.254512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:54:53.254521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:54:53.254774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6048
Epoch 2/80
 - 2s - loss: 0.0836
Epoch 3/80
 - 2s - loss: 0.0643
Epoch 4/80
 - 2s - loss: 0.0579
Epoch 5/80
 - 2s - loss: 0.0509
Epoch 6/80
 - 2s - loss: 0.0444
Epoch 7/80
 - 2s - loss: 0.0390
Epoch 8/80
 - 2s - loss: 0.0347
Epoch 9/80
 - 2s - loss: 0.0314
Epoch 10/80
 - 2s - loss: 0.0287
Epoch 11/80
 - 2s - loss: 0.0263
Epoch 12/80
 - 2s - loss: 0.0243
Epoch 13/80
 - 2s - loss: 0.0225
Epoch 14/80
 - 2s - loss: 0.0210
Epoch 15/80
 - 2s - loss: 0.0198
Epoch 16/80
 - 2s - loss: 0.0187
Epoch 17/80
 - 2s - loss: 0.0178
Epoch 18/80
 - 2s - loss: 0.0171
Epoch 19/80
 - 2s - loss: 0.0164
Epoch 20/80
 - 2s - loss: 0.0159
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0150
Epoch 23/80
 - 2s - loss: 0.0146
Epoch 24/80
 - 2s - loss: 0.0143
Epoch 25/80
 - 2s - loss: 0.0140
Epoch 26/80
 - 2s - loss: 0.0137
Epoch 27/80
 - 2s - loss: 0.0135
Epoch 28/80
 - 2s - loss: 0.0133
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0130
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0127
Epoch 33/80
 - 2s - loss: 0.0126
Epoch 34/80
 - 2s - loss: 0.0125
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0123
Epoch 38/80
 - 2s - loss: 0.0122
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0121
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0120
Epoch 43/80
 - 2s - loss: 0.0120
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0119
Epoch 46/80
 - 2s - loss: 0.0119
Epoch 47/80
 - 2s - loss: 0.0114
Epoch 48/80
 - 2s - loss: 0.0113
Epoch 49/80
 - 2s - loss: 0.0113
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0112
Epoch 52/80
 - 2s - loss: 0.0112
Epoch 53/80
 - 2s - loss: 0.0112
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0111
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.8742 - val_loss: 1.2841
AUC: 0.8265

Epoch 2/80
 - 0s - loss: 1.6564 - val_loss: 0.6516
AUC: 0.8354

Epoch 3/80
 - 0s - loss: 1.2522 - val_loss: 0.6634
AUC: 0.8465

Epoch 4/80
 - 0s - loss: 1.1544 - val_loss: 0.6882
AUC: 0.8500

Epoch 5/80
 - 0s - loss: 1.0997 - val_loss: 0.7197
AUC: 0.8560

Epoch 6/80
 - 0s - loss: 1.0730 - val_loss: 0.7946
AUC: 0.8555

Epoch 7/80
 - 0s - loss: 1.0528 - val_loss: 0.7170
AUC: 0.8580

Epoch 8/80
 - 0s - loss: 1.0495 - val_loss: 0.6676
AUC: 0.8575

Epoch 9/80
 - 0s - loss: 1.0213 - val_loss: 0.6190
AUC: 0.8579

Epoch 10/80
 - 0s - loss: 1.0161 - val_loss: 0.6534
AUC: 0.8606

Epoch 11/80
 - 0s - loss: 1.0143 - val_loss: 0.6084
AUC: 0.8589

Epoch 12/80
 - 0s - loss: 0.9948 - val_loss: 0.5899
AUC: 0.8607

Epoch 13/80
 - 0s - loss: 0.9970 - val_loss: 0.5884
AUC: 0.8622

Epoch 14/80
 - 0s - loss: 0.9865 - val_loss: 0.4998
AUC: 0.8585

Epoch 15/80
 - 0s - loss: 0.9809 - val_loss: 0.6526
AUC: 0.8613

Epoch 16/80
 - 0s - loss: 0.9711 - val_loss: 0.5792
AUC: 0.8623

Epoch 17/80
 - 0s - loss: 0.9703 - val_loss: 0.5715
AUC: 0.8614

Epoch 18/80
 - 0s - loss: 0.9626 - val_loss: 0.6292
AUC: 0.8636

Epoch 19/80
 - 0s - loss: 0.9565 - val_loss: 0.5635
AUC: 0.8633

Epoch 20/80
 - 0s - loss: 0.9535 - val_loss: 0.6066
AUC: 0.8607

Epoch 21/80
 - 0s - loss: 0.9576 - val_loss: 0.6166
AUC: 0.8645

Epoch 22/80
 - 0s - loss: 0.9476 - val_loss: 0.5467
AUC: 0.8628

Epoch 23/80
 - 0s - loss: 0.9437 - val_loss: 0.6885
AUC: 0.8653

Epoch 24/80
 - 0s - loss: 0.9505 - val_loss: 0.6182
AUC: 0.8647

Epoch 25/80
 - 0s - loss: 0.9288 - val_loss: 0.5836
AUC: 0.8645

Epoch 26/80
 - 0s - loss: 0.9226 - val_loss: 0.5809
AUC: 0.8645

Epoch 27/80
 - 0s - loss: 0.9208 - val_loss: 0.6010
AUC: 0.8653

Epoch 28/80
 - 0s - loss: 0.9209 - val_loss: 0.5700
AUC: 0.8648

Epoch 29/80
 - 0s - loss: 0.9202 - val_loss: 0.6122
AUC: 0.8652

Epoch 30/80
 - 0s - loss: 0.9091 - val_loss: 0.6009
AUC: 0.8654

Epoch 31/80
 - 0s - loss: 0.9128 - val_loss: 0.6019
AUC: 0.8649

Epoch 32/80
 - 0s - loss: 0.9102 - val_loss: 0.5608
AUC: 0.8648

Epoch 33/80
 - 0s - loss: 0.9079 - val_loss: 0.5864
AUC: 0.8643

Epoch 34/80
 - 0s - loss: 0.9156 - val_loss: 0.5855
AUC: 0.8647

Epoch 35/80
 - 0s - loss: 0.9095 - val_loss: 0.5891
AUC: 0.8649

Epoch 36/80
 - 0s - loss: 0.9073 - val_loss: 0.5836
AUC: 0.8648

Epoch 37/80
 - 0s - loss: 0.9087 - val_loss: 0.5936
AUC: 0.8650

Epoch 38/80
 - 0s - loss: 0.9056 - val_loss: 0.5881
AUC: 0.8650

Epoch 39/80
 - 0s - loss: 0.9081 - val_loss: 0.5856
AUC: 0.8650

Epoch 40/80
 - 0s - loss: 0.9049 - val_loss: 0.5731
AUC: 0.8646

Epoch 41/80
 - 0s - loss: 0.9016 - val_loss: 0.5960
AUC: 0.8650

Epoch 42/80
 - 0s - loss: 0.9031 - val_loss: 0.5847
AUC: 0.8649

Epoch 43/80
 - 0s - loss: 0.9025 - val_loss: 0.5755
AUC: 0.8648

Epoch 44/80
 - 0s - loss: 0.9028 - val_loss: 0.5823
AUC: 0.8647

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9147 - val_loss: 0.5893
AUC: 0.8650

Epoch 2/30
 - 1s - loss: 0.9092 - val_loss: 0.5649
AUC: 0.8649

Epoch 3/30
 - 1s - loss: 0.9118 - val_loss: 0.5924
AUC: 0.8649

Epoch 4/30
 - 1s - loss: 0.9063 - val_loss: 0.5731
AUC: 0.8650

Epoch 5/30
 - 1s - loss: 0.9018 - val_loss: 0.6055
AUC: 0.8651

Epoch 6/30
 - 1s - loss: 0.9017 - val_loss: 0.5845
AUC: 0.8648

Epoch 7/30
 - 1s - loss: 0.9036 - val_loss: 0.5899
AUC: 0.8650

Epoch 8/30
 - 1s - loss: 0.9029 - val_loss: 0.5955
AUC: 0.8651

Epoch 9/30
 - 1s - loss: 0.8960 - val_loss: 0.5992
AUC: 0.8651

Epoch 10/30
 - 1s - loss: 0.8953 - val_loss: 0.5923
AUC: 0.8650

Epoch 11/30
 - 1s - loss: 0.8932 - val_loss: 0.5786
AUC: 0.8646

Epoch 12/30
 - 1s - loss: 0.8983 - val_loss: 0.5607
AUC: 0.8648

Epoch 13/30
 - 1s - loss: 0.8897 - val_loss: 0.5627
AUC: 0.8650

Epoch 14/30
 - 1s - loss: 0.8871 - val_loss: 0.5801
AUC: 0.8652

Epoch 15/30
 - 1s - loss: 0.8850 - val_loss: 0.5674
AUC: 0.8650

Epoch 16/30
 - 1s - loss: 0.8804 - val_loss: 0.5633
AUC: 0.8645

Epoch 17/30
 - 1s - loss: 0.8784 - val_loss: 0.5734
AUC: 0.8648

Epoch 18/30
 - 1s - loss: 0.8768 - val_loss: 0.6167
AUC: 0.8650

Epoch 19/30
 - 1s - loss: 0.8748 - val_loss: 0.5790
AUC: 0.8648

Epoch 20/30
 - 1s - loss: 0.8765 - val_loss: 0.5658
AUC: 0.8646

Epoch 21/30
 - 1s - loss: 0.8753 - val_loss: 0.5668
AUC: 0.8645

Epoch 22/30
 - 1s - loss: 0.8756 - val_loss: 0.5849
AUC: 0.8648

Epoch 23/30
 - 1s - loss: 0.8672 - val_loss: 0.5709
AUC: 0.8646

Epoch 24/30
 - 1s - loss: 0.8672 - val_loss: 0.5722
AUC: 0.8647

Epoch 25/30
 - 1s - loss: 0.8659 - val_loss: 0.5818
AUC: 0.8647

Epoch 26/30
 - 1s - loss: 0.8616 - val_loss: 0.5679
AUC: 0.8646

Epoch 27/30
 - 1s - loss: 0.8649 - val_loss: 0.5708
AUC: 0.8646

Epoch 28/30
 - 1s - loss: 0.8656 - val_loss: 0.5744
AUC: 0.8647

Epoch 29/30
 - 1s - loss: 0.8620 - val_loss: 0.5713
AUC: 0.8646

Epoch 30/30
 - 1s - loss: 0.8691 - val_loss: 0.5838
Using TensorFlow backend.
AUC: 0.8647

2019-03-08 11:58:16.282499: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:58:16.448260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:58:16.448304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:58:16.746116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:58:16.746187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:58:16.746197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:58:16.746464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.6020
Epoch 2/80
 - 2s - loss: 0.0830
Epoch 3/80
 - 2s - loss: 0.0637
Epoch 4/80
 - 2s - loss: 0.0561
Epoch 5/80
 - 2s - loss: 0.0493
Epoch 6/80
 - 2s - loss: 0.0432
Epoch 7/80
 - 2s - loss: 0.0380
Epoch 8/80
 - 2s - loss: 0.0338
Epoch 9/80
 - 2s - loss: 0.0306
Epoch 10/80
 - 2s - loss: 0.0279
Epoch 11/80
 - 2s - loss: 0.0257
Epoch 12/80
 - 2s - loss: 0.0239
Epoch 13/80
 - 2s - loss: 0.0222
Epoch 14/80
 - 2s - loss: 0.0209
Epoch 15/80
 - 2s - loss: 0.0197
Epoch 16/80
 - 2s - loss: 0.0187
Epoch 17/80
 - 2s - loss: 0.0178
Epoch 18/80
 - 2s - loss: 0.0171
Epoch 19/80
 - 2s - loss: 0.0164
Epoch 20/80
 - 2s - loss: 0.0158
Epoch 21/80
 - 2s - loss: 0.0154
Epoch 22/80
 - 2s - loss: 0.0149
Epoch 23/80
 - 2s - loss: 0.0146
Epoch 24/80
 - 2s - loss: 0.0142
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b63bd0e91d0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 11:59:16.903775: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 11:59:17.064278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 11:59:17.064324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 11:59:17.362177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 11:59:17.362228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 11:59:17.362237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 11:59:17.362493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.5954
Epoch 2/80
 - 2s - loss: 0.0827
Epoch 3/80
 - 2s - loss: 0.0646
Epoch 4/80
 - 2s - loss: 0.0566
Epoch 5/80
 - 2s - loss: 0.0491
Epoch 6/80
 - 2s - loss: 0.0435
Epoch 7/80
 - 2s - loss: 0.0391
Epoch 8/80
 - 2s - loss: 0.0354
Epoch 9/80
 - 2s - loss: 0.0322
Epoch 10/80
 - 2s - loss: 0.0294
Epoch 11/80
 - 2s - loss: 0.0269
Epoch 12/80
 - 2s - loss: 0.0248
Epoch 13/80
 - 2s - loss: 0.0229
Epoch 14/80
 - 2s - loss: 0.0214
Epoch 15/80
 - 2s - loss: 0.0201
Epoch 16/80
 - 2s - loss: 0.0190
Epoch 17/80
 - 2s - loss: 0.0181
Epoch 18/80
 - 2s - loss: 0.0173
Epoch 19/80
 - 2s - loss: 0.0166
Epoch 20/80
 - 2s - loss: 0.0160
Epoch 21/80
 - 2s - loss: 0.0155
Epoch 22/80
 - 2s - loss: 0.0151
Epoch 23/80
 - 2s - loss: 0.0147
Epoch 24/80
 - 2s - loss: 0.0144
Epoch 25/80
 - 2s - loss: 0.0141
Epoch 26/80
 - 2s - loss: 0.0138
Epoch 27/80
 - 2s - loss: 0.0136
Epoch 28/80
 - 2s - loss: 0.0134
Epoch 29/80
 - 2s - loss: 0.0132
Epoch 30/80
 - 2s - loss: 0.0131
Epoch 31/80
 - 2s - loss: 0.0129
Epoch 32/80
 - 2s - loss: 0.0128
Epoch 33/80
 - 2s - loss: 0.0127
Epoch 34/80
 - 2s - loss: 0.0126
Epoch 35/80
 - 2s - loss: 0.0125
Epoch 36/80
 - 2s - loss: 0.0124
Epoch 37/80
 - 2s - loss: 0.0124
Epoch 38/80
 - 2s - loss: 0.0123
Epoch 39/80
 - 2s - loss: 0.0122
Epoch 40/80
 - 2s - loss: 0.0122
Epoch 41/80
 - 2s - loss: 0.0121
Epoch 42/80
 - 2s - loss: 0.0121
Epoch 43/80
 - 2s - loss: 0.0121
Epoch 44/80
 - 2s - loss: 0.0120
Epoch 45/80
 - 2s - loss: 0.0120
Epoch 46/80
 - 2s - loss: 0.0120
Epoch 47/80
 - 2s - loss: 0.0119
Epoch 48/80
 - 2s - loss: 0.0119
Epoch 49/80
 - 2s - loss: 0.0119
Epoch 50/80
 - 2s - loss: 0.0113
Epoch 51/80
 - 2s - loss: 0.0113
Epoch 52/80
 - 2s - loss: 0.0113
Epoch 53/80
 - 2s - loss: 0.0113
Epoch 54/80
 - 2s - loss: 0.0112
Epoch 55/80
 - 2s - loss: 0.0112
Epoch 56/80
 - 2s - loss: 0.0111
Epoch 57/80
 - 2s - loss: 0.0111
Epoch 58/80
 - 2s - loss: 0.0111
Epoch 59/80
 - 2s - loss: 0.0111
Epoch 60/80
 - 2s - loss: 0.0111
Epoch 61/80
 - 2s - loss: 0.0111
Epoch 62/80
 - 2s - loss: 0.0111
Epoch 63/80
 - 2s - loss: 0.0111
Epoch 64/80
 - 2s - loss: 0.0111
Epoch 65/80
 - 2s - loss: 0.0111
Epoch 66/80
 - 2s - loss: 0.0111
Epoch 67/80
 - 2s - loss: 0.0111
Epoch 68/80
 - 2s - loss: 0.0111
Epoch 69/80
 - 2s - loss: 0.0111
Epoch 70/80
 - 2s - loss: 0.0111
Epoch 71/80
 - 2s - loss: 0.0111
Epoch 72/80
 - 2s - loss: 0.0111
Epoch 73/80
 - 2s - loss: 0.0111
Epoch 74/80
 - 2s - loss: 0.0111
Epoch 75/80
 - 2s - loss: 0.0111
Epoch 76/80
 - 2s - loss: 0.0111
Epoch 77/80
 - 2s - loss: 0.0111
Epoch 78/80
 - 2s - loss: 0.0111
Epoch 79/80
 - 2s - loss: 0.0111
Epoch 80/80
 - 2s - loss: 0.0111
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 2.6447 - val_loss: 0.7020
AUC: 0.8101

Epoch 2/80
 - 0s - loss: 1.6012 - val_loss: 0.6246
AUC: 0.8397

Epoch 3/80
 - 0s - loss: 1.2258 - val_loss: 0.6719
AUC: 0.8487

Epoch 4/80
 - 0s - loss: 1.1413 - val_loss: 0.6372
AUC: 0.8492

Epoch 5/80
 - 0s - loss: 1.0900 - val_loss: 0.6919
AUC: 0.8532

Epoch 6/80
 - 0s - loss: 1.0717 - val_loss: 0.5612
AUC: 0.8538

Epoch 7/80
 - 0s - loss: 1.0589 - val_loss: 0.5592
AUC: 0.8555

Epoch 8/80
 - 0s - loss: 1.0489 - val_loss: 0.6008
AUC: 0.8592

Epoch 9/80
 - 0s - loss: 1.0259 - val_loss: 0.6475
AUC: 0.8607

Epoch 10/80
 - 0s - loss: 1.0243 - val_loss: 0.5961
AUC: 0.8613

Epoch 11/80
 - 0s - loss: 1.0069 - val_loss: 0.6611
AUC: 0.8618

Epoch 12/80
 - 0s - loss: 1.0037 - val_loss: 0.6964
AUC: 0.8640

Epoch 13/80
 - 0s - loss: 1.0051 - val_loss: 0.6083
AUC: 0.8631

Epoch 14/80
 - 0s - loss: 0.9965 - val_loss: 0.7008
AUC: 0.8649

Epoch 15/80
 - 0s - loss: 0.9825 - val_loss: 0.6220
AUC: 0.8642

Epoch 16/80
 - 0s - loss: 0.9783 - val_loss: 0.5854
AUC: 0.8641

Epoch 17/80
 - 0s - loss: 0.9782 - val_loss: 0.5511
AUC: 0.8639

Epoch 18/80
 - 0s - loss: 0.9699 - val_loss: 0.5966
AUC: 0.8658

Epoch 19/80
 - 0s - loss: 0.9671 - val_loss: 0.5824
AUC: 0.8644

Epoch 20/80
 - 0s - loss: 0.9609 - val_loss: 0.6662
AUC: 0.8672

Epoch 21/80
 - 0s - loss: 0.9652 - val_loss: 0.5261
AUC: 0.8644

Epoch 22/80
 - 0s - loss: 0.9532 - val_loss: 0.5962
AUC: 0.8664

Epoch 23/80
 - 0s - loss: 0.9553 - val_loss: 0.5887
AUC: 0.8638

Epoch 24/80
 - 0s - loss: 0.9462 - val_loss: 0.6025
AUC: 0.8677

Epoch 25/80
 - 0s - loss: 0.9382 - val_loss: 0.6427
AUC: 0.8671

Epoch 26/80
 - 0s - loss: 0.9359 - val_loss: 0.5669
AUC: 0.8664

Epoch 27/80
 - 0s - loss: 0.9370 - val_loss: 0.5864
AUC: 0.8682

Epoch 28/80
 - 0s - loss: 0.9233 - val_loss: 0.6401
AUC: 0.8651

Epoch 29/80
 - 0s - loss: 0.9208 - val_loss: 0.6327
AUC: 0.8677

Epoch 30/80
 - 0s - loss: 0.9227 - val_loss: 0.5414
AUC: 0.8674

Epoch 31/80
 - 0s - loss: 0.9227 - val_loss: 0.5258
AUC: 0.8669

Epoch 32/80
 - 0s - loss: 0.9153 - val_loss: 0.5468
AUC: 0.8671

Epoch 33/80
 - 0s - loss: 0.9056 - val_loss: 0.5544
AUC: 0.8658

Epoch 34/80
 - 0s - loss: 0.9036 - val_loss: 0.6625
AUC: 0.8673

Epoch 35/80
 - 0s - loss: 0.9031 - val_loss: 0.6485
AUC: 0.8696

Epoch 36/80
 - 0s - loss: 0.8948 - val_loss: 0.6560
AUC: 0.8669

Epoch 37/80
 - 0s - loss: 0.8979 - val_loss: 0.5634
AUC: 0.8666

Epoch 38/80
 - 0s - loss: 0.8963 - val_loss: 0.5030
AUC: 0.8675

Epoch 39/80
 - 0s - loss: 0.8964 - val_loss: 0.6242
AUC: 0.8681

Epoch 40/80
 - 0s - loss: 0.8876 - val_loss: 0.6832
AUC: 0.8679

Epoch 41/80
 - 0s - loss: 0.8875 - val_loss: 0.5746
AUC: 0.8661

Epoch 42/80
 - 0s - loss: 0.8796 - val_loss: 0.5146
AUC: 0.8661

Epoch 43/80
 - 0s - loss: 0.8701 - val_loss: 0.5929
AUC: 0.8682

Epoch 44/80
 - 0s - loss: 0.8717 - val_loss: 0.5407
AUC: 0.8672

Epoch 45/80
 - 0s - loss: 0.8600 - val_loss: 0.6656
AUC: 0.8674

Epoch 46/80
 - 0s - loss: 0.8562 - val_loss: 0.5834
AUC: 0.8673

Epoch 47/80
 - 0s - loss: 0.8557 - val_loss: 0.5955
AUC: 0.8677

Epoch 48/80
 - 0s - loss: 0.8521 - val_loss: 0.6007
AUC: 0.8672

Epoch 49/80
 - 0s - loss: 0.8370 - val_loss: 0.5934
AUC: 0.8679

Epoch 50/80
 - 0s - loss: 0.8248 - val_loss: 0.5429
AUC: 0.8675

Epoch 51/80
 - 0s - loss: 0.8305 - val_loss: 0.5546
AUC: 0.8674

Epoch 52/80
 - 0s - loss: 0.8242 - val_loss: 0.5567
AUC: 0.8673

Epoch 53/80
 - 0s - loss: 0.8241 - val_loss: 0.5574
AUC: 0.8673

Epoch 54/80
 - 0s - loss: 0.8252 - val_loss: 0.5586
AUC: 0.8674

Epoch 55/80
 - 0s - loss: 0.8165 - val_loss: 0.5740
AUC: 0.8670

Epoch 56/80
 - 0s - loss: 0.8171 - val_loss: 0.5475
AUC: 0.8671

Epoch 57/80
 - 0s - loss: 0.8205 - val_loss: 0.5530
AUC: 0.8670

Epoch 58/80
 - 0s - loss: 0.8183 - val_loss: 0.5497
AUC: 0.8670

Epoch 59/80
 - 0s - loss: 0.8111 - val_loss: 0.5454
AUC: 0.8670

Epoch 60/80
 - 0s - loss: 0.8089 - val_loss: 0.5475
AUC: 0.8671

Epoch 61/80
 - 0s - loss: 0.8095 - val_loss: 0.5487
AUC: 0.8670

Epoch 62/80
 - 0s - loss: 0.8094 - val_loss: 0.5517
AUC: 0.8671

Epoch 63/80
 - 0s - loss: 0.8116 - val_loss: 0.5532
AUC: 0.8671

Epoch 64/80
 - 0s - loss: 0.8066 - val_loss: 0.5547
AUC: 0.8672

Epoch 65/80
 - 0s - loss: 0.8107 - val_loss: 0.5621
AUC: 0.8672

Epoch 66/80
 - 0s - loss: 0.8080 - val_loss: 0.5428
AUC: 0.8669

Epoch 67/80
 - 0s - loss: 0.8098 - val_loss: 0.5455
AUC: 0.8669

Epoch 68/80
 - 0s - loss: 0.8113 - val_loss: 0.5630
AUC: 0.8671

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.8864 - val_loss: 0.5856
AUC: 0.8683

Epoch 2/30
 - 1s - loss: 0.8784 - val_loss: 0.5679
AUC: 0.8684

Epoch 3/30
 - 1s - loss: 0.8715 - val_loss: 0.5758
AUC: 0.8685

Epoch 4/30
 - 1s - loss: 0.8741 - val_loss: 0.5487
AUC: 0.8679

Epoch 5/30
 - 1s - loss: 0.8704 - val_loss: 0.5796
AUC: 0.8681

Epoch 6/30
 - 1s - loss: 0.8687 - val_loss: 0.5672
AUC: 0.8679

Epoch 7/30
 - 1s - loss: 0.8635 - val_loss: 0.5614
AUC: 0.8680

Epoch 8/30
 - 1s - loss: 0.8656 - val_loss: 0.5591
AUC: 0.8680

Epoch 9/30
 - 1s - loss: 0.8617 - val_loss: 0.5576
AUC: 0.8682

Epoch 10/30
 - 1s - loss: 0.8620 - val_loss: 0.5623
AUC: 0.8678

Epoch 11/30
 - 1s - loss: 0.8599 - val_loss: 0.5388
AUC: 0.8677

Epoch 12/30
 - 1s - loss: 0.8559 - val_loss: 0.5713
AUC: 0.8679

Epoch 13/30
 - 1s - loss: 0.8525 - val_loss: 0.5776
AUC: 0.8682

Epoch 14/30
 - 1s - loss: 0.8537 - val_loss: 0.5727
AUC: 0.8682

Epoch 15/30
 - 1s - loss: 0.8471 - val_loss: 0.5712
AUC: 0.8681

Epoch 16/30
 - 1s - loss: 0.8472 - val_loss: 0.5814
AUC: 0.8683

Epoch 17/30
 - 1s - loss: 0.8446 - val_loss: 0.5604
AUC: 0.8682

Epoch 18/30
 - 1s - loss: 0.8428 - val_loss: 0.5760
AUC: 0.8682

Epoch 19/30
 - 1s - loss: 0.8417 - val_loss: 0.5635
AUC: 0.8683

Epoch 20/30
 - 1s - loss: 0.8394 - val_loss: 0.5746
AUC: 0.8680

Epoch 21/30
 - 1s - loss: 0.8400 - val_loss: 0.5649
AUC: 0.8680

Epoch 22/30
 - 1s - loss: 0.8356 - val_loss: 0.5601
AUC: 0.8680

Epoch 23/30
 - 1s - loss: 0.8326 - val_loss: 0.5639
AUC: 0.8680

Epoch 24/30
 - 1s - loss: 0.8374 - val_loss: 0.5593
AUC: 0.8680

Epoch 25/30
 - 1s - loss: 0.8303 - val_loss: 0.5614
AUC: 0.8680

Epoch 26/30
 - 1s - loss: 0.8386 - val_loss: 0.5668
AUC: 0.8681

Epoch 27/30
 - 1s - loss: 0.8299 - val_loss: 0.5636
AUC: 0.8680

Epoch 28/30
 - 1s - loss: 0.8311 - val_loss: 0.5535
AUC: 0.8678

Epoch 29/30
 - 1s - loss: 0.8279 - val_loss: 0.5623
AUC: 0.8679

Epoch 30/30
 - 1s - loss: 0.8327 - val_loss: 0.5600
Using TensorFlow backend.
AUC: 0.8679

2019-03-08 12:03:01.018908: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:03:01.183357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:03:01.183404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:03:01.470711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:03:01.470760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:03:01.470769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:03:01.471022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36278 rows...
Finished. It takes 5.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4513
Epoch 2/80
 - 3s - loss: 0.1069
Epoch 3/80
 - 3s - loss: 0.0965
Epoch 4/80
 - 3s - loss: 0.0881
Epoch 5/80
 - 3s - loss: 0.0807
Epoch 6/80
 - 3s - loss: 0.0742
Epoch 7/80
 - 3s - loss: 0.0678
Epoch 8/80
 - 3s - loss: 0.0620
Epoch 9/80
 - 3s - loss: 0.0568
Epoch 10/80
 - 3s - loss: 0.0525
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 12:03:55.047242: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:03:55.211101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:03:55.211145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:03:55.506934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:03:55.506985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:03:55.506993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:03:55.507253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36194 rows...
Finished. It takes 5.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.5534
Epoch 2/80
 - 3s - loss: 0.1236
Epoch 3/80
 - 3s - loss: 0.1123
Epoch 4/80
 - 3s - loss: 0.1042
Epoch 5/80
 - 3s - loss: 0.0958
Epoch 6/80
 - 3s - loss: 0.0876
Epoch 7/80
 - 3s - loss: 0.0795
Epoch 8/80
 - 3s - loss: 0.0722
Epoch 9/80
 - 3s - loss: 0.0661
Epoch 10/80
 - 3s - loss: 0.0610
Epoch 11/80
 - 3s - loss: 0.0571
Epoch 12/80
 - 3s - loss: 0.0539
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2af8bbf22198>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 12:04:50.682250: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:04:50.847108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:04:50.847150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:04:51.143824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:04:51.143874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:04:51.143883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:04:51.144136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35874 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9784
Epoch 2/80
 - 2s - loss: 0.1882
Epoch 3/80
 - 2s - loss: 0.1580
Epoch 4/80
 - 2s - loss: 0.1492
Epoch 5/80
 - 2s - loss: 0.1412
Epoch 6/80
 - 2s - loss: 0.1328
Epoch 7/80
 - 2s - loss: 0.1239
Epoch 8/80
 - 2s - loss: 0.1139
Epoch 9/80
 - 2s - loss: 0.1039
Epoch 10/80
 - 2s - loss: 0.0956
Epoch 11/80
 - 2s - loss: 0.0889
Epoch 12/80
 - 2s - loss: 0.0832
Epoch 13/80
 - 2s - loss: 0.0782
Epoch 14/80
 - 2s - loss: 0.0738
Epoch 15/80
 - 2s - loss: 0.0701
Epoch 16/80
 - 2s - loss: 0.0669
Epoch 17/80
 - 2s - loss: 0.0642
Epoch 18/80
 - 2s - loss: 0.0618
Epoch 19/80
 - 2s - loss: 0.0598
Epoch 20/80
 - 2s - loss: 0.0581
Epoch 21/80
 - 2s - loss: 0.0568
Epoch 22/80
 - 2s - loss: 0.0556
Epoch 23/80
 - 2s - loss: 0.0546
Epoch 24/80
 - 2s - loss: 0.0538
Epoch 25/80
 - 2s - loss: 0.0530
Epoch 26/80
 - 2s - loss: 0.0524
Epoch 27/80
 - 2s - loss: 0.0519
Epoch 28/80
 - 2s - loss: 0.0515
Epoch 29/80
 - 2s - loss: 0.0511
Epoch 30/80
 - 2s - loss: 0.0508
Epoch 31/80
 - 2s - loss: 0.0505
Epoch 32/80
 - 2s - loss: 0.0502
Epoch 33/80
 - 2s - loss: 0.0500
Epoch 34/80
 - 2s - loss: 0.0498
Epoch 35/80
 - 2s - loss: 0.0496
Epoch 36/80
 - 2s - loss: 0.0494
Epoch 37/80
 - 2s - loss: 0.0493
Epoch 38/80
 - 2s - loss: 0.0492
Epoch 39/80
 - 2s - loss: 0.0490
Epoch 40/80
 - 2s - loss: 0.0489
Epoch 41/80
 - 2s - loss: 0.0488
Epoch 42/80
 - 2s - loss: 0.0487
Epoch 43/80
 - 2s - loss: 0.0486
Epoch 44/80
 - 2s - loss: 0.0486
Epoch 45/80
 - 2s - loss: 0.0485
Epoch 46/80
 - 2s - loss: 0.0484
Epoch 47/80
 - 2s - loss: 0.0484
Epoch 48/80
 - 2s - loss: 0.0483
Epoch 49/80
 - 2s - loss: 0.0483
Epoch 50/80
 - 2s - loss: 0.0482
Epoch 51/80
 - 2s - loss: 0.0482
Epoch 52/80
 - 2s - loss: 0.0481
Epoch 53/80
 - 2s - loss: 0.0481
Epoch 54/80
 - 2s - loss: 0.0481
Epoch 55/80
 - 2s - loss: 0.0480
Epoch 56/80
 - 2s - loss: 0.0480
Epoch 57/80
 - 2s - loss: 0.0480
Epoch 58/80
 - 2s - loss: 0.0479
Epoch 59/80
 - 2s - loss: 0.0468
Epoch 60/80
 - 2s - loss: 0.0467
Epoch 61/80
 - 2s - loss: 0.0467
Epoch 62/80
 - 2s - loss: 0.0466
Epoch 63/80
 - 2s - loss: 0.0466
Epoch 64/80
 - 2s - loss: 0.0464
Epoch 65/80
 - 2s - loss: 0.0463
Epoch 66/80
 - 2s - loss: 0.0463
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 12:07:05.998069: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:07:06.161328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:07:06.161374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:07:06.461150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:07:06.461222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:07:06.461242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:07:06.461527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35230 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 2.3628
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b3db85b80f0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 12:07:29.339733: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:07:29.501050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:07:29.501094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:07:29.786035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:07:29.786087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:07:29.786096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:07:29.786355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36244 rows...
Finished. It takes 5.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4781
Epoch 2/80
 - 3s - loss: 0.1145
Epoch 3/80
 - 3s - loss: 0.1054
Epoch 4/80
 - 3s - loss: 0.0996
Epoch 5/80
 - 3s - loss: 0.0929
Epoch 6/80
 - 3s - loss: 0.0850
Epoch 7/80
 - 3s - loss: 0.0763
Epoch 8/80
 - 3s - loss: 0.0683
Epoch 9/80
 - 3s - loss: 0.0617
Epoch 10/80
 - 3s - loss: 0.0567
Epoch 11/80
 - 3s - loss: 0.0530
Epoch 12/80
 - 3s - loss: 0.0500
Epoch 13/80
 - 3s - loss: 0.0477
Epoch 14/80
 - 3s - loss: 0.0458
Epoch 15/80
 - 3s - loss: 0.0442
Epoch 16/80
 - 3s - loss: 0.0430
Epoch 17/80
 - 3s - loss: 0.0421
Epoch 18/80
 - 3s - loss: 0.0413
Epoch 19/80
 - 3s - loss: 0.0406
Epoch 20/80
 - 3s - loss: 0.0401
Epoch 21/80
 - 3s - loss: 0.0396
Epoch 22/80
 - 3s - loss: 0.0392
Epoch 23/80
 - 3s - loss: 0.0389
Epoch 24/80
 - 3s - loss: 0.0386
Epoch 25/80
 - 3s - loss: 0.0384
Epoch 26/80
 - 3s - loss: 0.0382
Epoch 27/80
 - 3s - loss: 0.0380
Epoch 28/80
 - 3s - loss: 0.0378
Epoch 29/80
 - 3s - loss: 0.0377
Epoch 30/80
 - 3s - loss: 0.0376
Epoch 31/80
 - 3s - loss: 0.0375
Epoch 32/80
 - 3s - loss: 0.0374
Epoch 33/80
 - 3s - loss: 0.0373
Epoch 34/80
 - 3s - loss: 0.0372
Epoch 35/80
 - 3s - loss: 0.0371
Epoch 36/80
 - 3s - loss: 0.0370
Epoch 37/80
 - 3s - loss: 0.0370
Epoch 38/80
 - 3s - loss: 0.0369
Epoch 39/80
 - 3s - loss: 0.0368
Epoch 40/80
 - 3s - loss: 0.0368
Epoch 41/80
 - 3s - loss: 0.0368
Epoch 42/80
 - 3s - loss: 0.0367
Epoch 43/80
 - 3s - loss: 0.0367
Epoch 44/80
 - 3s - loss: 0.0366
Epoch 45/80
 - 3s - loss: 0.0366
Epoch 46/80
 - 3s - loss: 0.0366
Epoch 47/80
 - 3s - loss: 0.0365
Epoch 48/80
 - 3s - loss: 0.0354
Epoch 49/80
 - 3s - loss: 0.0352
Epoch 50/80
 - 3s - loss: 0.0352
Epoch 51/80
 - 3s - loss: 0.0352
Epoch 52/80
 - 3s - loss: 0.0352
Epoch 53/80
 - 3s - loss: 0.0349
Epoch 54/80
 - 3s - loss: 0.0349
Epoch 55/80
 - 3s - loss: 0.0349
Epoch 56/80
 - 3s - loss: 0.0349
Epoch 57/80
 - 3s - loss: 0.0348
Epoch 58/80
 - 3s - loss: 0.0348
Epoch 59/80
 - 3s - loss: 0.0348
Epoch 60/80
 - 3s - loss: 0.0348
Epoch 61/80
 - 3s - loss: 0.0348
Epoch 62/80
 - 3s - loss: 0.0348
Epoch 63/80
 - 3s - loss: 0.0348
Epoch 64/80
 - 3s - loss: 0.0348
Epoch 65/80
 - 3s - loss: 0.0348
Epoch 66/80
 - 3s - loss: 0.0348
Epoch 67/80
 - 3s - loss: 0.0348
Epoch 68/80
 - 3s - loss: 0.0348
Epoch 69/80
 - 3s - loss: 0.0348
Epoch 70/80
 - 3s - loss: 0.0348
Epoch 71/80
 - 3s - loss: 0.0348
Epoch 72/80
 - 3s - loss: 0.0348
Epoch 73/80
 - 3s - loss: 0.0348
Epoch 74/80
 - 3s - loss: 0.0348
Epoch 75/80
 - 3s - loss: 0.0348
Epoch 76/80
 - 3s - loss: 0.0348
Epoch 77/80
 - 3s - loss: 0.0348
Epoch 78/80
 - 3s - loss: 0.0348
Epoch 79/80
 - 3s - loss: 0.0348
Epoch 80/80
 - 3s - loss: 0.0348
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28995 samples, validate on 7249 samples
Epoch 1/80
 - 1s - loss: 5.0217 - val_loss: 1.7246
AUC: 0.7688

Epoch 2/80
 - 0s - loss: 3.1485 - val_loss: 1.2811
AUC: 0.7929

Epoch 3/80
 - 0s - loss: 2.2372 - val_loss: 0.9830
AUC: 0.8023

Epoch 4/80
 - 0s - loss: 1.6567 - val_loss: 0.9410
AUC: 0.8185

Epoch 5/80
 - 0s - loss: 1.3826 - val_loss: 0.8123
AUC: 0.8322

Epoch 6/80
 - 0s - loss: 1.2529 - val_loss: 0.7603
AUC: 0.8394

Epoch 7/80
 - 0s - loss: 1.1881 - val_loss: 0.7185
AUC: 0.8461

Epoch 8/80
 - 0s - loss: 1.1572 - val_loss: 0.6609
AUC: 0.8482

Epoch 9/80
 - 0s - loss: 1.1289 - val_loss: 0.6735
AUC: 0.8499

Epoch 10/80
 - 0s - loss: 1.1069 - val_loss: 0.6957
AUC: 0.8530

Epoch 11/80
 - 0s - loss: 1.0826 - val_loss: 0.6982
AUC: 0.8551

Epoch 12/80
 - 0s - loss: 1.0780 - val_loss: 0.6454
AUC: 0.8554

Epoch 13/80
 - 0s - loss: 1.0720 - val_loss: 0.7031
AUC: 0.8593

Epoch 14/80
 - 0s - loss: 1.0628 - val_loss: 0.6663
AUC: 0.8596

Epoch 15/80
 - 0s - loss: 1.0509 - val_loss: 0.6350
AUC: 0.8583

Epoch 16/80
 - 0s - loss: 1.0498 - val_loss: 0.7519
AUC: 0.8607

Epoch 17/80
 - 0s - loss: 1.0478 - val_loss: 0.6711
AUC: 0.8625

Epoch 18/80
 - 0s - loss: 1.0371 - val_loss: 0.6360
AUC: 0.8632

Epoch 19/80
 - 0s - loss: 1.0312 - val_loss: 0.6800
AUC: 0.8636

Epoch 20/80
 - 0s - loss: 1.0308 - val_loss: 0.6372
AUC: 0.8648

Epoch 21/80
 - 0s - loss: 1.0289 - val_loss: 0.6551
AUC: 0.8647

Epoch 22/80
 - 0s - loss: 1.0253 - val_loss: 0.5950
AUC: 0.8653

Epoch 23/80
 - 0s - loss: 1.0150 - val_loss: 0.6207
AUC: 0.8664

Epoch 24/80
 - 0s - loss: 1.0154 - val_loss: 0.6285
AUC: 0.8661

Epoch 25/80
 - 0s - loss: 1.0162 - val_loss: 0.6535
AUC: 0.8683

Epoch 26/80
 - 0s - loss: 1.0158 - val_loss: 0.6197
AUC: 0.8679

Epoch 27/80
 - 0s - loss: 1.0094 - val_loss: 0.6738
AUC: 0.8680

Epoch 28/80
 - 0s - loss: 1.0016 - val_loss: 0.6451
AUC: 0.8683

Epoch 29/80
 - 0s - loss: 1.0013 - val_loss: 0.6211
AUC: 0.8688

Epoch 30/80
 - 0s - loss: 0.9967 - val_loss: 0.5565
AUC: 0.8687

Epoch 31/80
 - 0s - loss: 0.9907 - val_loss: 0.5947
AUC: 0.8699

Epoch 32/80
 - 0s - loss: 0.9971 - val_loss: 0.6220
AUC: 0.8703

Epoch 33/80
 - 0s - loss: 0.9890 - val_loss: 0.6137
AUC: 0.8694

Epoch 34/80
 - 0s - loss: 0.9911 - val_loss: 0.6564
AUC: 0.8706

Epoch 35/80
 - 0s - loss: 0.9920 - val_loss: 0.6222
AUC: 0.8708

Epoch 36/80
 - 0s - loss: 0.9783 - val_loss: 0.6155
AUC: 0.8712

Epoch 37/80
 - 0s - loss: 0.9792 - val_loss: 0.5955
AUC: 0.8714

Epoch 38/80
 - 0s - loss: 0.9804 - val_loss: 0.5608
AUC: 0.8719

Epoch 39/80
 - 0s - loss: 0.9761 - val_loss: 0.6173
AUC: 0.8719

Epoch 40/80
 - 0s - loss: 0.9762 - val_loss: 0.6186
AUC: 0.8720

Epoch 41/80
 - 0s - loss: 0.9705 - val_loss: 0.6094
AUC: 0.8724

Epoch 42/80
 - 0s - loss: 0.9649 - val_loss: 0.6101
AUC: 0.8725

Epoch 43/80
 - 0s - loss: 0.9728 - val_loss: 0.6144
AUC: 0.8727

Epoch 44/80
 - 0s - loss: 0.9662 - val_loss: 0.6143
AUC: 0.8728

Epoch 45/80
 - 0s - loss: 0.9621 - val_loss: 0.6004
AUC: 0.8728

Epoch 46/80
 - 0s - loss: 0.9664 - val_loss: 0.6256
AUC: 0.8729

Epoch 47/80
 - 0s - loss: 0.9671 - val_loss: 0.6243
AUC: 0.8730

Epoch 48/80
 - 0s - loss: 0.9645 - val_loss: 0.6226
AUC: 0.8728

Epoch 49/80
 - 0s - loss: 0.9651 - val_loss: 0.5981
AUC: 0.8731

Epoch 50/80
 - 0s - loss: 0.9645 - val_loss: 0.6169
AUC: 0.8729

Epoch 51/80
 - 0s - loss: 0.9587 - val_loss: 0.6126
AUC: 0.8730

Epoch 52/80
 - 0s - loss: 0.9601 - val_loss: 0.6077
AUC: 0.8730

Epoch 53/80
 - 0s - loss: 0.9599 - val_loss: 0.6121
AUC: 0.8730

Epoch 54/80
 - 0s - loss: 0.9630 - val_loss: 0.6098
AUC: 0.8731

Epoch 55/80
 - 0s - loss: 0.9563 - val_loss: 0.6046
AUC: 0.8730

Epoch 56/80
 - 0s - loss: 0.9605 - val_loss: 0.6169
AUC: 0.8731

Epoch 57/80
 - 0s - loss: 0.9578 - val_loss: 0.6142
AUC: 0.8731

Epoch 58/80
 - 0s - loss: 0.9596 - val_loss: 0.6131
AUC: 0.8731

Epoch 59/80
 - 0s - loss: 0.9626 - val_loss: 0.6240
AUC: 0.8730

Epoch 60/80
 - 0s - loss: 0.9595 - val_loss: 0.6109
AUC: 0.8730

Train on 28995 samples, validate on 7249 samples
Epoch 1/30
 - 1s - loss: 0.9626 - val_loss: 0.6127
AUC: 0.8734

Epoch 2/30
 - 0s - loss: 0.9590 - val_loss: 0.6179
AUC: 0.8734

Epoch 3/30
 - 0s - loss: 0.9591 - val_loss: 0.6195
AUC: 0.8735

Epoch 4/30
 - 0s - loss: 0.9578 - val_loss: 0.6284
AUC: 0.8737

Epoch 5/30
 - 0s - loss: 0.9548 - val_loss: 0.6138
AUC: 0.8739

Epoch 6/30
 - 0s - loss: 0.9582 - val_loss: 0.6076
AUC: 0.8740

Epoch 7/30
 - 0s - loss: 0.9519 - val_loss: 0.6056
AUC: 0.8741

Epoch 8/30
 - 0s - loss: 0.9503 - val_loss: 0.6161
AUC: 0.8741

Epoch 9/30
 - 0s - loss: 0.9491 - val_loss: 0.6107
AUC: 0.8741

Epoch 10/30
 - 0s - loss: 0.9450 - val_loss: 0.6195
AUC: 0.8742

Epoch 11/30
 - 0s - loss: 0.9469 - val_loss: 0.5923
AUC: 0.8744

Epoch 12/30
 - 0s - loss: 0.9432 - val_loss: 0.5886
AUC: 0.8745

Epoch 13/30
 - 0s - loss: 0.9418 - val_loss: 0.6071
AUC: 0.8748

Epoch 14/30
 - 0s - loss: 0.9411 - val_loss: 0.6003
AUC: 0.8749

Epoch 15/30
 - 0s - loss: 0.9448 - val_loss: 0.5937
AUC: 0.8750

Epoch 16/30
 - 0s - loss: 0.9411 - val_loss: 0.5977
AUC: 0.8750

Epoch 17/30
 - 0s - loss: 0.9468 - val_loss: 0.5955
AUC: 0.8753

Epoch 18/30
 - 0s - loss: 0.9362 - val_loss: 0.5949
AUC: 0.8753

Epoch 19/30
 - 0s - loss: 0.9358 - val_loss: 0.6076
AUC: 0.8754

Epoch 20/30
 - 0s - loss: 0.9339 - val_loss: 0.5989
AUC: 0.8756

Epoch 21/30
 - 0s - loss: 0.9314 - val_loss: 0.5969
AUC: 0.8754

Epoch 22/30
 - 0s - loss: 0.9329 - val_loss: 0.5981
AUC: 0.8755

Epoch 23/30
 - 0s - loss: 0.9312 - val_loss: 0.5998
AUC: 0.8755

Epoch 24/30
 - 0s - loss: 0.9307 - val_loss: 0.5999
AUC: 0.8755

Epoch 25/30
 - 0s - loss: 0.9269 - val_loss: 0.5983
AUC: 0.8755

Epoch 26/30
 - 0s - loss: 0.9276 - val_loss: 0.5982
AUC: 0.8755

Epoch 27/30
 - 0s - loss: 0.9241 - val_loss: 0.5975
AUC: 0.8756

Epoch 28/30
 - 0s - loss: 0.9291 - val_loss: 0.5986
AUC: 0.8756

Epoch 29/30
 - 0s - loss: 0.9296 - val_loss: 0.5999
AUC: 0.8757

Epoch 30/30
 - 0s - loss: 0.9275 - val_loss: 0.5996
Using TensorFlow backend.
AUC: 0.8757

2019-03-08 12:12:43.237721: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:12:43.422151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:12:43.422215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:12:43.714305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:12:43.714356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:12:43.714366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:12:43.714623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35997 rows...
Finished. It takes 5.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.7916
Epoch 2/80
 - 2s - loss: 0.1627
Epoch 3/80
 - 2s - loss: 0.1450
Epoch 4/80
 - 2s - loss: 0.1386
Epoch 5/80
 - 2s - loss: 0.1315
Epoch 6/80
 - 2s - loss: 0.1223
Epoch 7/80
 - 2s - loss: 0.1116
Epoch 8/80
 - 2s - loss: 0.1011
Epoch 9/80
 - 2s - loss: 0.0919
Epoch 10/80
 - 2s - loss: 0.0841
Epoch 11/80
 - 2s - loss: 0.0777
Epoch 12/80
 - 2s - loss: 0.0725
Epoch 13/80
 - 2s - loss: 0.0682
Epoch 14/80
 - 2s - loss: 0.0648
Epoch 15/80
 - 2s - loss: 0.0618
Epoch 16/80
 - 2s - loss: 0.0594
Epoch 17/80
 - 2s - loss: 0.0574
Epoch 18/80
 - 2s - loss: 0.0558
Epoch 19/80
 - 2s - loss: 0.0544
Epoch 20/80
 - 2s - loss: 0.0533
Epoch 21/80
 - 2s - loss: 0.0522
Epoch 22/80
 - 2s - loss: 0.0514
Epoch 23/80
 - 2s - loss: 0.0507
Epoch 24/80
 - 2s - loss: 0.0501
Epoch 25/80
 - 2s - loss: 0.0495
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2ab59dcd26a0>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 12:13:54.839790: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:13:55.003763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:13:55.003807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:13:55.306357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:13:55.306398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:13:55.306408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:13:55.306690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35692 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3753
Epoch 2/80
 - 1s - loss: 0.2595
Epoch 3/80
 - 1s - loss: 0.1850
Epoch 4/80
 - 1s - loss: 0.1762
Epoch 5/80
 - 1s - loss: 0.1690
Epoch 6/80
 - 1s - loss: 0.1606
Epoch 7/80
 - 1s - loss: 0.1510
Epoch 8/80
 - 1s - loss: 0.1407
Epoch 9/80
 - 1s - loss: 0.1301
Epoch 10/80
 - 1s - loss: 0.1201
Epoch 11/80
 - 1s - loss: 0.1111
Epoch 12/80
 - 1s - loss: 0.1030
Epoch 13/80
 - 1s - loss: 0.0960
Epoch 14/80
 - 1s - loss: 0.0899
Epoch 15/80
 - 1s - loss: 0.0848
Epoch 16/80
 - 1s - loss: 0.0805
Epoch 17/80
 - 1s - loss: 0.0768
Epoch 18/80
 - 1s - loss: 0.0737
Epoch 19/80
 - 1s - loss: 0.0709
Epoch 20/80
 - 1s - loss: 0.0685
Epoch 21/80
 - 1s - loss: 0.0666
Epoch 22/80
 - 1s - loss: 0.0649
Epoch 23/80
 - 1s - loss: 0.0634
Epoch 24/80
 - 1s - loss: 0.0622
Epoch 25/80
 - 1s - loss: 0.0611
Epoch 26/80
 - 1s - loss: 0.0601
Epoch 27/80
 - 1s - loss: 0.0592
Epoch 28/80
 - 1s - loss: 0.0584
Epoch 29/80
 - 1s - loss: 0.0577
Epoch 30/80
 - 1s - loss: 0.0571
Epoch 31/80
 - 1s - loss: 0.0566
Epoch 32/80
 - 1s - loss: 0.0561
Epoch 33/80
 - 1s - loss: 0.0557
Epoch 34/80
 - 1s - loss: 0.0553
Epoch 35/80
 - 1s - loss: 0.0550
Epoch 36/80
 - 1s - loss: 0.0547
Epoch 37/80
 - 1s - loss: 0.0545
Epoch 38/80
 - 1s - loss: 0.0543
Epoch 39/80
 - 1s - loss: 0.0540
Epoch 40/80
 - 1s - loss: 0.0538
Epoch 41/80
 - 1s - loss: 0.0537
Epoch 42/80
 - 1s - loss: 0.0535
Epoch 43/80
 - 1s - loss: 0.0534
Epoch 44/80
 - 1s - loss: 0.0532
Epoch 45/80
 - 1s - loss: 0.0531
Epoch 46/80
 - 1s - loss: 0.0530
Epoch 47/80
 - 1s - loss: 0.0529
Epoch 48/80
 - 1s - loss: 0.0528
Epoch 49/80
 - 1s - loss: 0.0527
Epoch 50/80
 - 1s - loss: 0.0527
Epoch 51/80
 - 1s - loss: 0.0526
Epoch 52/80
 - 1s - loss: 0.0525
Epoch 53/80
 - 1s - loss: 0.0525
Epoch 54/80
 - 1s - loss: 0.0524
Epoch 55/80
 - 1s - loss: 0.0523
Epoch 56/80
 - 1s - loss: 0.0523
Epoch 57/80
 - 1s - loss: 0.0522
Epoch 58/80
 - 1s - loss: 0.0522
Epoch 59/80
 - 1s - loss: 0.0521
Epoch 60/80
 - 1s - loss: 0.0521
Epoch 61/80
 - 1s - loss: 0.0521
Epoch 62/80
 - 1s - loss: 0.0520
Epoch 63/80
 - 1s - loss: 0.0520
Epoch 64/80
 - 1s - loss: 0.0520
Epoch 65/80
 - 1s - loss: 0.0519
Epoch 66/80
 - 1s - loss: 0.0519
Epoch 67/80
 - 1s - loss: 0.0519
Epoch 68/80
 - 1s - loss: 0.0508
Epoch 69/80
 - 1s - loss: 0.0507
Epoch 70/80
 - 1s - loss: 0.0506
Epoch 71/80
 - 1s - loss: 0.0506
Epoch 72/80
 - 1s - loss: 0.0506
Epoch 73/80
 - 1s - loss: 0.0503
Epoch 74/80
 - 1s - loss: 0.0503
Epoch 75/80
 - 1s - loss: 0.0503
Epoch 76/80
 - 1s - loss: 0.0503
Epoch 77/80
 - 1s - loss: 0.0503
Epoch 78/80
 - 1s - loss: 0.0503
Epoch 79/80
 - 1s - loss: 0.0503
Epoch 80/80
 - 1s - loss: 0.0503
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28553 samples, validate on 7139 samples
Epoch 1/80
 - 1s - loss: 4.6611 - val_loss: 1.8414
AUC: 0.7882

Epoch 2/80
 - 0s - loss: 3.1804 - val_loss: 1.3174
AUC: 0.8074

Epoch 3/80
 - 0s - loss: 2.3161 - val_loss: 1.0634
AUC: 0.8213

Epoch 4/80
 - 0s - loss: 1.7130 - val_loss: 0.8697
AUC: 0.8306

Epoch 5/80
 - 0s - loss: 1.4357 - val_loss: 0.7476
AUC: 0.8338

Epoch 6/80
 - 0s - loss: 1.2684 - val_loss: 0.6486
AUC: 0.8355

Epoch 7/80
 - 0s - loss: 1.1926 - val_loss: 0.6006
AUC: 0.8376

Epoch 8/80
 - 0s - loss: 1.1686 - val_loss: 0.6957
AUC: 0.8422

Epoch 9/80
 - 0s - loss: 1.1414 - val_loss: 0.6559
AUC: 0.8450

Epoch 10/80
 - 0s - loss: 1.1230 - val_loss: 0.6753
AUC: 0.8479

Epoch 11/80
 - 0s - loss: 1.1096 - val_loss: 0.6455
AUC: 0.8503

Epoch 12/80
 - 0s - loss: 1.0942 - val_loss: 0.6965
AUC: 0.8509

Epoch 13/80
 - 0s - loss: 1.0821 - val_loss: 0.7019
AUC: 0.8531

Epoch 14/80
 - 0s - loss: 1.0820 - val_loss: 0.5976
AUC: 0.8533

Epoch 15/80
 - 0s - loss: 1.0671 - val_loss: 0.7086
AUC: 0.8559

Epoch 16/80
 - 0s - loss: 1.0660 - val_loss: 0.6469
AUC: 0.8544

Epoch 17/80
 - 0s - loss: 1.0620 - val_loss: 0.6711
AUC: 0.8555

Epoch 18/80
 - 0s - loss: 1.0523 - val_loss: 0.7008
AUC: 0.8569

Epoch 19/80
 - 0s - loss: 1.0506 - val_loss: 0.6594
AUC: 0.8570

Epoch 20/80
 - 0s - loss: 1.0463 - val_loss: 0.5976
AUC: 0.8568

Epoch 21/80
 - 0s - loss: 1.0445 - val_loss: 0.6048
AUC: 0.8570

Epoch 22/80
 - 0s - loss: 1.0399 - val_loss: 0.6198
AUC: 0.8571

Epoch 23/80
 - 0s - loss: 1.0370 - val_loss: 0.6283
AUC: 0.8588

Epoch 24/80
 - 0s - loss: 1.0322 - val_loss: 0.7055
AUC: 0.8595

Epoch 25/80
 - 0s - loss: 1.0298 - val_loss: 0.6443
AUC: 0.8596

Epoch 26/80
 - 0s - loss: 1.0282 - val_loss: 0.6155
AUC: 0.8595

Epoch 27/80
 - 0s - loss: 1.0175 - val_loss: 0.6240
AUC: 0.8597

Epoch 28/80
 - 0s - loss: 1.0252 - val_loss: 0.6338
AUC: 0.8598

Epoch 29/80
 - 0s - loss: 1.0188 - val_loss: 0.6066
AUC: 0.8594

Epoch 30/80
 - 0s - loss: 1.0152 - val_loss: 0.6189
AUC: 0.8598

Epoch 31/80
 - 0s - loss: 1.0224 - val_loss: 0.6547
AUC: 0.8602

Epoch 32/80
 - 0s - loss: 1.0177 - val_loss: 0.6039
AUC: 0.8597

Epoch 33/80
 - 0s - loss: 1.0149 - val_loss: 0.6240
AUC: 0.8600

Epoch 34/80
 - 0s - loss: 1.0198 - val_loss: 0.5974
AUC: 0.8598

Epoch 35/80
 - 0s - loss: 1.0234 - val_loss: 0.6210
AUC: 0.8603

Epoch 36/80
 - 0s - loss: 1.0157 - val_loss: 0.6100
AUC: 0.8600

Epoch 37/80
 - 0s - loss: 1.0141 - val_loss: 0.6262
AUC: 0.8604

Epoch 38/80
 - 0s - loss: 1.0107 - val_loss: 0.6487
AUC: 0.8607

Epoch 39/80
 - 0s - loss: 1.0187 - val_loss: 0.6314
AUC: 0.8608

Epoch 40/80
 - 0s - loss: 1.0137 - val_loss: 0.6297
AUC: 0.8611

Epoch 41/80
 - 0s - loss: 1.0135 - val_loss: 0.6263
AUC: 0.8610

Epoch 42/80
 - 0s - loss: 1.0184 - val_loss: 0.6098
AUC: 0.8609

Epoch 43/80
 - 0s - loss: 1.0091 - val_loss: 0.6025
AUC: 0.8608

Epoch 44/80
 - 0s - loss: 1.0096 - val_loss: 0.6206
AUC: 0.8611

Epoch 45/80
 - 0s - loss: 1.0103 - val_loss: 0.6113
AUC: 0.8610

Epoch 46/80
 - 0s - loss: 1.0063 - val_loss: 0.6156
AUC: 0.8611

Epoch 47/80
 - 0s - loss: 1.0066 - val_loss: 0.6105
AUC: 0.8610

Epoch 48/80
 - 0s - loss: 1.0072 - val_loss: 0.6221
AUC: 0.8612

Epoch 49/80
 - 0s - loss: 1.0080 - val_loss: 0.6179
AUC: 0.8611

Epoch 50/80
 - 0s - loss: 1.0102 - val_loss: 0.6271
AUC: 0.8613

Epoch 51/80
 - 0s - loss: 1.0092 - val_loss: 0.6145
AUC: 0.8612

Epoch 52/80
 - 0s - loss: 1.0106 - val_loss: 0.6259
AUC: 0.8613

Epoch 53/80
 - 0s - loss: 1.0114 - val_loss: 0.6175
AUC: 0.8613

Epoch 54/80
 - 0s - loss: 1.0072 - val_loss: 0.6233
AUC: 0.8613

Epoch 55/80
 - 0s - loss: 1.0121 - val_loss: 0.6224
AUC: 0.8613

Epoch 56/80
 - 0s - loss: 1.0154 - val_loss: 0.6211
AUC: 0.8613

Epoch 57/80
 - 0s - loss: 1.0073 - val_loss: 0.6194
AUC: 0.8613

Epoch 58/80
 - 0s - loss: 1.0104 - val_loss: 0.6188
AUC: 0.8613

Epoch 59/80
 - 0s - loss: 1.0071 - val_loss: 0.6172
AUC: 0.8613

Epoch 60/80
 - 0s - loss: 1.0088 - val_loss: 0.6176
AUC: 0.8613

Epoch 61/80
 - 0s - loss: 1.0084 - val_loss: 0.6164
AUC: 0.8613

Epoch 62/80
 - 0s - loss: 1.0103 - val_loss: 0.6193
AUC: 0.8613

Epoch 63/80
 - 0s - loss: 1.0051 - val_loss: 0.6165
AUC: 0.8613

Epoch 64/80
 - 0s - loss: 1.0072 - val_loss: 0.6176
AUC: 0.8613

Train on 28553 samples, validate on 7139 samples
Epoch 1/30
 - 1s - loss: 1.0036 - val_loss: 0.6141
AUC: 0.8613

Epoch 2/30
 - 0s - loss: 1.0062 - val_loss: 0.6354
AUC: 0.8617

Epoch 3/30
 - 0s - loss: 1.0107 - val_loss: 0.6245
AUC: 0.8618

Epoch 4/30
 - 0s - loss: 1.0054 - val_loss: 0.6228
AUC: 0.8618

Epoch 5/30
 - 0s - loss: 1.0093 - val_loss: 0.6173
AUC: 0.8619

Epoch 6/30
 - 0s - loss: 0.9968 - val_loss: 0.6034
AUC: 0.8618

Epoch 7/30
 - 0s - loss: 1.0014 - val_loss: 0.6086
AUC: 0.8622

Epoch 8/30
 - 0s - loss: 1.0018 - val_loss: 0.6135
AUC: 0.8623

Epoch 9/30
 - 0s - loss: 0.9996 - val_loss: 0.6185
AUC: 0.8626

Epoch 10/30
 - 0s - loss: 0.9998 - val_loss: 0.6034
AUC: 0.8627

Epoch 11/30
 - 0s - loss: 0.9916 - val_loss: 0.6264
AUC: 0.8630

Epoch 12/30
 - 0s - loss: 0.9936 - val_loss: 0.5975
AUC: 0.8627

Epoch 13/30
 - 0s - loss: 0.9949 - val_loss: 0.6171
AUC: 0.8631

Epoch 14/30
 - 0s - loss: 0.9988 - val_loss: 0.6055
AUC: 0.8632

Epoch 15/30
 - 0s - loss: 0.9937 - val_loss: 0.6014
AUC: 0.8633

Epoch 16/30
 - 0s - loss: 0.9920 - val_loss: 0.6082
AUC: 0.8635

Epoch 17/30
 - 0s - loss: 0.9908 - val_loss: 0.6263
AUC: 0.8638

Epoch 18/30
 - 0s - loss: 0.9886 - val_loss: 0.5916
AUC: 0.8636

Epoch 19/30
 - 0s - loss: 0.9906 - val_loss: 0.6004
AUC: 0.8639

Epoch 20/30
 - 0s - loss: 0.9849 - val_loss: 0.6154
AUC: 0.8641

Epoch 21/30
 - 0s - loss: 0.9845 - val_loss: 0.6055
AUC: 0.8640

Epoch 22/30
 - 0s - loss: 0.9780 - val_loss: 0.6047
AUC: 0.8639

Epoch 23/30
 - 0s - loss: 0.9843 - val_loss: 0.5940
AUC: 0.8640

Epoch 24/30
 - 0s - loss: 0.9815 - val_loss: 0.6123
AUC: 0.8643

Epoch 25/30
 - 0s - loss: 0.9840 - val_loss: 0.5970
AUC: 0.8643

Epoch 26/30
 - 0s - loss: 0.9801 - val_loss: 0.6040
AUC: 0.8644

Epoch 27/30
 - 0s - loss: 0.9803 - val_loss: 0.6057
AUC: 0.8647

Epoch 28/30
 - 0s - loss: 0.9790 - val_loss: 0.6195
AUC: 0.8650

Epoch 29/30
 - 0s - loss: 0.9746 - val_loss: 0.6009
AUC: 0.8648

Epoch 30/30
 - 0s - loss: 0.9825 - val_loss: 0.6039
Using TensorFlow backend.
AUC: 0.8649

2019-03-08 12:17:10.480236: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:17:10.644012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:17:10.644056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:17:10.928838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:17:10.928890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:17:10.928899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:17:10.929152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36264 rows...
Finished. It takes 5.3 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4780
Epoch 2/80
 - 3s - loss: 0.1105
Epoch 3/80
 - 3s - loss: 0.1002
Epoch 4/80
 - 3s - loss: 0.0902
Epoch 5/80
 - 3s - loss: 0.0819
Epoch 6/80
 - 3s - loss: 0.0756
Epoch 7/80
 - 3s - loss: 0.0697
Epoch 8/80
 - 3s - loss: 0.0639
Epoch 9/80
 - 3s - loss: 0.0586
Epoch 10/80
 - 3s - loss: 0.0541
Epoch 11/80
 - 3s - loss: 0.0506
Epoch 12/80
 - 3s - loss: 0.0480
Epoch 13/80
 - 3s - loss: 0.0459
Epoch 14/80
 - 3s - loss: 0.0442
Epoch 15/80
 - 3s - loss: 0.0428
Epoch 16/80
 - 3s - loss: 0.0417
Epoch 17/80
 - 3s - loss: 0.0407
Epoch 18/80
 - 3s - loss: 0.0400
Epoch 19/80
 - 3s - loss: 0.0394
Epoch 20/80
 - 3s - loss: 0.0389
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b9ec240c198>>
Traceback (most recent call last):
  File "/home/wsliu/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
2019-03-08 12:18:37.886500: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:18:38.049584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:18:38.049628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:18:38.342817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:18:38.342869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:18:38.342879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:18:38.343147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36115 rows...
Finished. It takes 5.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.6165
Epoch 2/80
 - 2s - loss: 0.1371
Epoch 3/80
 - 2s - loss: 0.1262
Epoch 4/80
 - 2s - loss: 0.1211
Epoch 5/80
 - 2s - loss: 0.1152
Epoch 6/80
 - 2s - loss: 0.1075
Epoch 7/80
 - 2s - loss: 0.0977
Epoch 8/80
 - 2s - loss: 0.0872
Epoch 9/80
 - 2s - loss: 0.0782
Epoch 10/80
 - 2s - loss: 0.0709
Epoch 11/80
 - 2s - loss: 0.0652
Epoch 12/80
 - 2s - loss: 0.0610
Epoch 13/80
 - 2s - loss: 0.0576
Epoch 14/80
 - 2s - loss: 0.0550
Epoch 15/80
 - 2s - loss: 0.0529
Epoch 16/80
 - 2s - loss: 0.0512
Epoch 17/80
 - 2s - loss: 0.0498
Epoch 18/80
 - 2s - loss: 0.0486
Epoch 19/80
 - 2s - loss: 0.0476
Epoch 20/80
 - 2s - loss: 0.0468
Epoch 21/80
 - 2s - loss: 0.0461
Epoch 22/80
 - 2s - loss: 0.0455
Epoch 23/80
 - 2s - loss: 0.0450
Epoch 24/80
 - 3s - loss: 0.0446
Epoch 25/80
 - 2s - loss: 0.0442
Epoch 26/80
 - 2s - loss: 0.0439
Epoch 27/80
 - 2s - loss: 0.0436
Epoch 28/80
 - 2s - loss: 0.0434
Epoch 29/80
 - 2s - loss: 0.0432
Epoch 30/80
 - 2s - loss: 0.0430
Epoch 31/80
 - 2s - loss: 0.0428
Epoch 32/80
 - 2s - loss: 0.0426
Epoch 33/80
 - 2s - loss: 0.0425
Epoch 34/80
 - 2s - loss: 0.0424
Epoch 35/80
 - 2s - loss: 0.0423
Epoch 36/80
 - 2s - loss: 0.0422
Epoch 37/80
 - 2s - loss: 0.0421
Epoch 38/80
 - 2s - loss: 0.0420
Epoch 39/80
 - 2s - loss: 0.0419
Epoch 40/80
 - 2s - loss: 0.0419
Epoch 41/80
 - 2s - loss: 0.0418
Epoch 42/80
 - 2s - loss: 0.0417
Epoch 43/80
 - 2s - loss: 0.0417
Epoch 44/80
 - 2s - loss: 0.0416
Epoch 45/80
 - 2s - loss: 0.0416
Epoch 46/80
 - 2s - loss: 0.0415
Epoch 47/80
 - 2s - loss: 0.0415
Epoch 48/80
 - 2s - loss: 0.0415
Epoch 49/80
 - 2s - loss: 0.0414
Epoch 50/80
 - 2s - loss: 0.0414
Epoch 51/80
 - 2s - loss: 0.0414
Epoch 52/80
 - 2s - loss: 0.0413
Epoch 53/80
 - 2s - loss: 0.0413
Epoch 54/80
 - 2s - loss: 0.0402
Epoch 55/80
 - 2s - loss: 0.0400
Epoch 56/80
 - 2s - loss: 0.0400
Epoch 57/80
 - 2s - loss: 0.0400
Epoch 58/80
 - 2s - loss: 0.0400
Epoch 59/80
 - 2s - loss: 0.0397
Epoch 60/80
 - 2s - loss: 0.0397
Epoch 61/80
 - 2s - loss: 0.0397
Epoch 62/80
 - 2s - loss: 0.0397
Epoch 63/80
 - 2s - loss: 0.0396
Epoch 64/80
 - 2s - loss: 0.0396
Epoch 65/80
 - 2s - loss: 0.0396
Epoch 66/80
 - 2s - loss: 0.0396
Epoch 67/80
 - 2s - loss: 0.0396
Epoch 68/80
 - 2s - loss: 0.0396
Epoch 69/80
 - 2s - loss: 0.0396
Epoch 70/80
 - 2s - loss: 0.0396
Epoch 71/80
 - 2s - loss: 0.0396
Epoch 72/80
 - 2s - loss: 0.0396
Epoch 73/80
 - 2s - loss: 0.0396
Epoch 74/80
 - 2s - loss: 0.0396
Epoch 75/80
 - 2s - loss: 0.0396
Epoch 76/80
 - 2s - loss: 0.0396
Epoch 77/80
 - 2s - loss: 0.0396
Epoch 78/80
 - 2s - loss: 0.0396
Epoch 79/80
 - 2s - loss: 0.0396
Epoch 80/80
 - 2s - loss: 0.0396
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28892 samples, validate on 7223 samples
Epoch 1/80
 - 1s - loss: 7.0124 - val_loss: 1.6905
AUC: 0.7506

Epoch 2/80
 - 0s - loss: 4.0277 - val_loss: 1.6439
AUC: 0.8139

Epoch 3/80
 - 0s - loss: 3.1081 - val_loss: 1.0975
AUC: 0.8299

Epoch 4/80
 - 0s - loss: 2.3966 - val_loss: 1.0605
AUC: 0.8387

Epoch 5/80
 - 0s - loss: 1.8297 - val_loss: 0.8668
AUC: 0.8417

Epoch 6/80
 - 0s - loss: 1.4840 - val_loss: 0.7082
AUC: 0.8425

Epoch 7/80
 - 0s - loss: 1.2839 - val_loss: 0.7630
AUC: 0.8462

Epoch 8/80
 - 0s - loss: 1.1910 - val_loss: 0.6968
AUC: 0.8470

Epoch 9/80
 - 0s - loss: 1.1608 - val_loss: 0.6869
AUC: 0.8485

Epoch 10/80
 - 0s - loss: 1.1163 - val_loss: 0.6852
AUC: 0.8501

Epoch 11/80
 - 0s - loss: 1.1121 - val_loss: 0.6560
AUC: 0.8505

Epoch 12/80
 - 0s - loss: 1.0950 - val_loss: 0.6422
AUC: 0.8512

Epoch 13/80
 - 0s - loss: 1.0889 - val_loss: 0.6687
AUC: 0.8529

Epoch 14/80
 - 0s - loss: 1.0759 - val_loss: 0.6875
AUC: 0.8551

Epoch 15/80
 - 0s - loss: 1.0558 - val_loss: 0.6500
AUC: 0.8545

Epoch 16/80
 - 0s - loss: 1.0548 - val_loss: 0.7013
AUC: 0.8565

Epoch 17/80
 - 0s - loss: 1.0571 - val_loss: 0.6548
AUC: 0.8561

Epoch 18/80
 - 0s - loss: 1.0444 - val_loss: 0.6621
AUC: 0.8570

Epoch 19/80
 - 0s - loss: 1.0375 - val_loss: 0.6342
AUC: 0.8566

Epoch 20/80
 - 0s - loss: 1.0341 - val_loss: 0.6452
AUC: 0.8578

Epoch 21/80
 - 0s - loss: 1.0276 - val_loss: 0.6388
AUC: 0.8575

Epoch 22/80
 - 0s - loss: 1.0282 - val_loss: 0.6164
AUC: 0.8575

Epoch 23/80
 - 0s - loss: 1.0194 - val_loss: 0.6444
AUC: 0.8580

Epoch 24/80
 - 0s - loss: 1.0161 - val_loss: 0.5926
AUC: 0.8587

Epoch 25/80
 - 0s - loss: 1.0120 - val_loss: 0.6420
AUC: 0.8602

Epoch 26/80
 - 0s - loss: 1.0112 - val_loss: 0.5979
AUC: 0.8599

Epoch 27/80
 - 0s - loss: 1.0081 - val_loss: 0.6450
AUC: 0.8603

Epoch 28/80
 - 0s - loss: 1.0010 - val_loss: 0.6374
AUC: 0.8602

Epoch 29/80
 - 0s - loss: 0.9940 - val_loss: 0.6039
AUC: 0.8603

Epoch 30/80
 - 0s - loss: 0.9992 - val_loss: 0.6686
AUC: 0.8616

Epoch 31/80
 - 0s - loss: 0.9984 - val_loss: 0.6453
AUC: 0.8615

Epoch 32/80
 - 0s - loss: 0.9961 - val_loss: 0.5806
AUC: 0.8609

Epoch 33/80
 - 0s - loss: 0.9915 - val_loss: 0.7166
AUC: 0.8624

Epoch 34/80
 - 0s - loss: 0.9916 - val_loss: 0.6603
AUC: 0.8625

Epoch 35/80
 - 0s - loss: 0.9880 - val_loss: 0.6730
AUC: 0.8632

Epoch 36/80
 - 0s - loss: 0.9883 - val_loss: 0.5820
AUC: 0.8626

Epoch 37/80
 - 0s - loss: 0.9896 - val_loss: 0.5891
AUC: 0.8628

Epoch 38/80
 - 0s - loss: 0.9815 - val_loss: 0.6445
AUC: 0.8639

Epoch 39/80
 - 0s - loss: 0.9772 - val_loss: 0.6518
AUC: 0.8636

Epoch 40/80
 - 0s - loss: 0.9809 - val_loss: 0.6447
AUC: 0.8648

Epoch 41/80
 - 0s - loss: 0.9789 - val_loss: 0.6295
AUC: 0.8637

Epoch 42/80
 - 0s - loss: 0.9788 - val_loss: 0.6412
AUC: 0.8641

Epoch 43/80
 - 0s - loss: 0.9631 - val_loss: 0.6168
AUC: 0.8641

Epoch 44/80
 - 0s - loss: 0.9738 - val_loss: 0.5960
AUC: 0.8642

Epoch 45/80
 - 0s - loss: 0.9657 - val_loss: 0.6109
AUC: 0.8647

Epoch 46/80
 - 0s - loss: 0.9658 - val_loss: 0.5679
AUC: 0.8642

Epoch 47/80
 - 0s - loss: 0.9700 - val_loss: 0.5962
AUC: 0.8649

Epoch 48/80
 - 0s - loss: 0.9630 - val_loss: 0.5960
AUC: 0.8648

Epoch 49/80
 - 0s - loss: 0.9670 - val_loss: 0.6164
AUC: 0.8649

Epoch 50/80
 - 0s - loss: 0.9650 - val_loss: 0.6263
AUC: 0.8647

Epoch 51/80
 - 0s - loss: 0.9713 - val_loss: 0.5938
AUC: 0.8647

Epoch 52/80
 - 0s - loss: 0.9642 - val_loss: 0.5888
AUC: 0.8644

Epoch 53/80
 - 0s - loss: 0.9643 - val_loss: 0.6025
AUC: 0.8647

Epoch 54/80
 - 0s - loss: 0.9613 - val_loss: 0.5957
AUC: 0.8649

Epoch 55/80
 - 0s - loss: 0.9641 - val_loss: 0.6091
AUC: 0.8652

Epoch 56/80
 - 0s - loss: 0.9639 - val_loss: 0.6175
AUC: 0.8652

Epoch 57/80
 - 0s - loss: 0.9608 - val_loss: 0.6004
AUC: 0.8650

Epoch 58/80
 - 0s - loss: 0.9562 - val_loss: 0.5977
AUC: 0.8650

Epoch 59/80
 - 0s - loss: 0.9615 - val_loss: 0.6021
AUC: 0.8651

Epoch 60/80
 - 0s - loss: 0.9574 - val_loss: 0.6032
AUC: 0.8651

Epoch 61/80
 - 0s - loss: 0.9601 - val_loss: 0.6006
AUC: 0.8651

Epoch 62/80
 - 0s - loss: 0.9579 - val_loss: 0.6022
AUC: 0.8652

Epoch 63/80
 - 0s - loss: 0.9603 - val_loss: 0.6072
AUC: 0.8653

Epoch 64/80
 - 0s - loss: 0.9617 - val_loss: 0.6031
AUC: 0.8652

Epoch 65/80
 - 0s - loss: 0.9576 - val_loss: 0.6041
AUC: 0.8652

Epoch 66/80
 - 0s - loss: 0.9599 - val_loss: 0.6075
AUC: 0.8652

Epoch 67/80
 - 0s - loss: 0.9554 - val_loss: 0.6043
AUC: 0.8652

Epoch 68/80
 - 0s - loss: 0.9566 - val_loss: 0.6016
AUC: 0.8652

Epoch 69/80
 - 0s - loss: 0.9556 - val_loss: 0.6024
AUC: 0.8652

Epoch 70/80
 - 0s - loss: 0.9548 - val_loss: 0.6005
AUC: 0.8651

Epoch 71/80
 - 0s - loss: 0.9554 - val_loss: 0.6027
AUC: 0.8652

Epoch 72/80
 - 0s - loss: 0.9604 - val_loss: 0.6015
AUC: 0.8652

Epoch 73/80
 - 0s - loss: 0.9572 - val_loss: 0.6017
AUC: 0.8652

Epoch 74/80
 - 0s - loss: 0.9642 - val_loss: 0.6012
AUC: 0.8652

Epoch 75/80
 - 0s - loss: 0.9542 - val_loss: 0.6017
AUC: 0.8652

Epoch 76/80
 - 0s - loss: 0.9609 - val_loss: 0.6021
AUC: 0.8652

Train on 28892 samples, validate on 7223 samples
Epoch 1/30
 - 1s - loss: 0.9582 - val_loss: 0.6048
AUC: 0.8656

Epoch 2/30
 - 0s - loss: 0.9614 - val_loss: 0.6104
AUC: 0.8657

Epoch 3/30
 - 0s - loss: 0.9631 - val_loss: 0.5920
AUC: 0.8655

Epoch 4/30
 - 0s - loss: 0.9527 - val_loss: 0.6123
AUC: 0.8659

Epoch 5/30
 - 0s - loss: 0.9598 - val_loss: 0.5996
AUC: 0.8658

Epoch 6/30
 - 0s - loss: 0.9540 - val_loss: 0.5984
AUC: 0.8657

Epoch 7/30
 - 0s - loss: 0.9531 - val_loss: 0.5914
AUC: 0.8657

Epoch 8/30
 - 0s - loss: 0.9528 - val_loss: 0.5844
AUC: 0.8658

Epoch 9/30
 - 0s - loss: 0.9458 - val_loss: 0.5920
AUC: 0.8660

Epoch 10/30
 - 0s - loss: 0.9540 - val_loss: 0.5991
AUC: 0.8664

Epoch 11/30
 - 0s - loss: 0.9512 - val_loss: 0.6015
AUC: 0.8666

Epoch 12/30
 - 0s - loss: 0.9524 - val_loss: 0.5933
AUC: 0.8664

Epoch 13/30
 - 0s - loss: 0.9429 - val_loss: 0.5951
AUC: 0.8664

Epoch 14/30
 - 0s - loss: 0.9448 - val_loss: 0.5909
AUC: 0.8666

Epoch 15/30
 - 0s - loss: 0.9449 - val_loss: 0.6034
AUC: 0.8670

Epoch 16/30
 - 0s - loss: 0.9380 - val_loss: 0.5840
AUC: 0.8666

Epoch 17/30
 - 0s - loss: 0.9383 - val_loss: 0.6229
AUC: 0.8670

Epoch 18/30
 - 0s - loss: 0.9414 - val_loss: 0.6089
AUC: 0.8670

Epoch 19/30
 - 0s - loss: 0.9379 - val_loss: 0.5884
AUC: 0.8669

Epoch 20/30
 - 0s - loss: 0.9318 - val_loss: 0.5978
AUC: 0.8671

Epoch 21/30
 - 0s - loss: 0.9314 - val_loss: 0.6032
AUC: 0.8672

Epoch 22/30
 - 0s - loss: 0.9318 - val_loss: 0.5794
AUC: 0.8670

Epoch 23/30
 - 0s - loss: 0.9312 - val_loss: 0.5971
AUC: 0.8675

Epoch 24/30
 - 0s - loss: 0.9297 - val_loss: 0.5938
AUC: 0.8675

Epoch 25/30
 - 0s - loss: 0.9249 - val_loss: 0.5912
AUC: 0.8675

Epoch 26/30
 - 0s - loss: 0.9290 - val_loss: 0.6096
AUC: 0.8677

Epoch 27/30
 - 0s - loss: 0.9292 - val_loss: 0.5812
AUC: 0.8673

Epoch 28/30
 - 0s - loss: 0.9140 - val_loss: 0.5636
AUC: 0.8670

Epoch 29/30
 - 0s - loss: 0.9264 - val_loss: 0.5774
AUC: 0.8677

Epoch 30/30
 - 0s - loss: 0.9257 - val_loss: 0.5928
Using TensorFlow backend.
AUC: 0.8678

2019-03-08 12:23:19.395159: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:23:19.559083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:23:19.559125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:23:19.850902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:23:19.850953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:23:19.850962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:23:19.851228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1553
Epoch 2/80
 - 1s - loss: 0.2179
Epoch 3/80
 - 2s - loss: 0.1743
Epoch 4/80
 - 2s - loss: 0.1673
Epoch 5/80
 - 2s - loss: 0.1617
Epoch 6/80
 - 2s - loss: 0.1542
Epoch 7/80
 - 2s - loss: 0.1439
Epoch 8/80
 - 1s - loss: 0.1317
Epoch 9/80
 - 2s - loss: 0.1200
Epoch 10/80
 - 2s - loss: 0.1101
Epoch 11/80
 - 2s - loss: 0.1019
Epoch 12/80
 - 2s - loss: 0.0947
Epoch 13/80
 - 2s - loss: 0.0883
Epoch 14/80
 - 2s - loss: 0.0828
Epoch 15/80
 - 2s - loss: 0.0781
Epoch 16/80
 - 2s - loss: 0.0741
Epoch 17/80
 - 2s - loss: 0.0707
Epoch 18/80
 - 2s - loss: 0.0677
Epoch 19/80
 - 2s - loss: 0.0651
Epoch 20/80
 - 2s - loss: 0.0629
Epoch 21/80
 - 2s - loss: 0.0610
Epoch 22/80
 - 2s - loss: 0.0595
Epoch 23/80
 - 2s - loss: 0.0582
Epoch 24/80
 - 2s - loss: 0.0572
Epoch 25/80
 - 2s - loss: 0.0563
Epoch 26/80
 - 2s - loss: 0.0555
Epoch 27/80
 - 2s - loss: 0.0549
Epoch 28/80
 - 2s - loss: 0.0543
Epoch 29/80
 - 2s - loss: 0.0538
Epoch 30/80
 - 2s - loss: 0.0534
Epoch 31/80
 - 2s - loss: 0.0531
Epoch 32/80
 - 2s - loss: 0.0528
Epoch 33/80
 - 2s - loss: 0.0525
Epoch 34/80
 - 2s - loss: 0.0523
Epoch 35/80
 - 2s - loss: 0.0521
Epoch 36/80
 - 2s - loss: 0.0519
Epoch 37/80
 - 2s - loss: 0.0517
Epoch 38/80
 - 2s - loss: 0.0516
Epoch 39/80
 - 2s - loss: 0.0514
Epoch 40/80
 - 2s - loss: 0.0513
Epoch 41/80
 - 2s - loss: 0.0512
Epoch 42/80
 - 2s - loss: 0.0511
Epoch 43/80
 - 2s - loss: 0.0510
Epoch 44/80
 - 2s - loss: 0.0509
Epoch 45/80
 - 2s - loss: 0.0508
Epoch 46/80
 - 2s - loss: 0.0507
Epoch 47/80
 - 2s - loss: 0.0507
Epoch 48/80
 - 2s - loss: 0.0506
Epoch 49/80
 - 2s - loss: 0.0506
Epoch 50/80
 - 2s - loss: 0.0505
Epoch 51/80
 - 2s - loss: 0.0504
Epoch 52/80
 - 2s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0503
Epoch 54/80
 - 2s - loss: 0.0503
Epoch 55/80
 - 2s - loss: 0.0503
Epoch 56/80
 - 2s - loss: 0.0502
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0502
Epoch 59/80
 - 2s - loss: 0.0501
Epoch 60/80
 - 2s - loss: 0.0501
Epoch 61/80
 - 2s - loss: 0.0501
Epoch 62/80
 - 2s - loss: 0.0501
Epoch 63/80
 - 2s - loss: 0.0489
Epoch 64/80
 - 2s - loss: 0.0488
Epoch 65/80
 - 2s - loss: 0.0488
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0488
Epoch 68/80
 - 2s - loss: 0.0485
Epoch 69/80
 - 2s - loss: 0.0485
Epoch 70/80
 - 2s - loss: 0.0485
Epoch 71/80
 - 2s - loss: 0.0485
Epoch 72/80
 - 2s - loss: 0.0484
Epoch 73/80
 - 2s - loss: 0.0484
Epoch 74/80
 - 2s - loss: 0.0484
Epoch 75/80
 - 2s - loss: 0.0484
Epoch 76/80
 - 2s - loss: 0.0484
Epoch 77/80
 - 2s - loss: 0.0484
Epoch 78/80
 - 2s - loss: 0.0484
Epoch 79/80
 - 2s - loss: 0.0484
Epoch 80/80
 - 2s - loss: 0.0484
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.1820 - val_loss: 1.6181
AUC: 0.7996

Epoch 2/80
 - 0s - loss: 3.5559 - val_loss: 1.2647
AUC: 0.8149

Epoch 3/80
 - 0s - loss: 2.4860 - val_loss: 1.0621
AUC: 0.8283

Epoch 4/80
 - 0s - loss: 1.7592 - val_loss: 0.9131
AUC: 0.8358

Epoch 5/80
 - 0s - loss: 1.3977 - val_loss: 0.7282
AUC: 0.8373

Epoch 6/80
 - 0s - loss: 1.2442 - val_loss: 0.7478
AUC: 0.8403

Epoch 7/80
 - 0s - loss: 1.1977 - val_loss: 0.6848
AUC: 0.8426

Epoch 8/80
 - 0s - loss: 1.1533 - val_loss: 0.6850
AUC: 0.8428

Epoch 9/80
 - 0s - loss: 1.1235 - val_loss: 0.6315
AUC: 0.8453

Epoch 10/80
 - 0s - loss: 1.1134 - val_loss: 0.6141
AUC: 0.8458

Epoch 11/80
 - 0s - loss: 1.0949 - val_loss: 0.6714
AUC: 0.8503

Epoch 12/80
 - 0s - loss: 1.0902 - val_loss: 0.6619
AUC: 0.8508

Epoch 13/80
 - 0s - loss: 1.0800 - val_loss: 0.6168
AUC: 0.8510

Epoch 14/80
 - 0s - loss: 1.0722 - val_loss: 0.6593
AUC: 0.8541

Epoch 15/80
 - 0s - loss: 1.0641 - val_loss: 0.6609
AUC: 0.8538

Epoch 16/80
 - 0s - loss: 1.0616 - val_loss: 0.6565
AUC: 0.8550

Epoch 17/80
 - 0s - loss: 1.0583 - val_loss: 0.6846
AUC: 0.8559

Epoch 18/80
 - 0s - loss: 1.0476 - val_loss: 0.6039
AUC: 0.8562

Epoch 19/80
 - 0s - loss: 1.0363 - val_loss: 0.6389
AUC: 0.8561

Epoch 20/80
 - 0s - loss: 1.0431 - val_loss: 0.6220
AUC: 0.8563

Epoch 21/80
 - 0s - loss: 1.0370 - val_loss: 0.5744
AUC: 0.8558

Epoch 22/80
 - 0s - loss: 1.0270 - val_loss: 0.6287
AUC: 0.8582

Epoch 23/80
 - 0s - loss: 1.0297 - val_loss: 0.6760
AUC: 0.8586

Epoch 24/80
 - 0s - loss: 1.0223 - val_loss: 0.6113
AUC: 0.8587

Epoch 25/80
 - 0s - loss: 1.0150 - val_loss: 0.6370
AUC: 0.8577

Epoch 26/80
 - 0s - loss: 1.0254 - val_loss: 0.6396
AUC: 0.8603

Epoch 27/80
 - 0s - loss: 1.0111 - val_loss: 0.5992
AUC: 0.8599

Epoch 28/80
 - 0s - loss: 1.0119 - val_loss: 0.6334
AUC: 0.8601

Epoch 29/80
 - 0s - loss: 1.0100 - val_loss: 0.6815
AUC: 0.8599

Epoch 30/80
 - 0s - loss: 1.0086 - val_loss: 0.6008
AUC: 0.8608

Epoch 31/80
 - 0s - loss: 1.0099 - val_loss: 0.6068
AUC: 0.8617

Epoch 32/80
 - 0s - loss: 0.9996 - val_loss: 0.6084
AUC: 0.8614

Epoch 33/80
 - 0s - loss: 0.9973 - val_loss: 0.6100
AUC: 0.8615

Epoch 34/80
 - 0s - loss: 0.9996 - val_loss: 0.6180
AUC: 0.8618

Epoch 35/80
 - 0s - loss: 0.9936 - val_loss: 0.6155
AUC: 0.8617

Epoch 36/80
 - 0s - loss: 0.9936 - val_loss: 0.6232
AUC: 0.8620

Epoch 37/80
 - 0s - loss: 0.9961 - val_loss: 0.5978
AUC: 0.8610

Epoch 38/80
 - 0s - loss: 0.9960 - val_loss: 0.6228
AUC: 0.8618

Epoch 39/80
 - 0s - loss: 0.9934 - val_loss: 0.6018
AUC: 0.8616

Epoch 40/80
 - 0s - loss: 0.9934 - val_loss: 0.6191
AUC: 0.8622

Epoch 41/80
 - 0s - loss: 0.9875 - val_loss: 0.6086
AUC: 0.8617

Epoch 42/80
 - 0s - loss: 0.9929 - val_loss: 0.6115
AUC: 0.8618

Epoch 43/80
 - 0s - loss: 0.9955 - val_loss: 0.6161
AUC: 0.8619

Epoch 44/80
 - 0s - loss: 0.9878 - val_loss: 0.6140
AUC: 0.8618

Epoch 45/80
 - 0s - loss: 0.9902 - val_loss: 0.6173
AUC: 0.8618

Epoch 46/80
 - 0s - loss: 0.9910 - val_loss: 0.6173
AUC: 0.8618

Epoch 47/80
 - 0s - loss: 0.9882 - val_loss: 0.6097
AUC: 0.8617

Epoch 48/80
 - 0s - loss: 0.9925 - val_loss: 0.6145
AUC: 0.8618

Epoch 49/80
 - 0s - loss: 0.9865 - val_loss: 0.6097
AUC: 0.8617

Epoch 50/80
 - 0s - loss: 0.9906 - val_loss: 0.6155
AUC: 0.8618

Epoch 51/80
 - 0s - loss: 0.9862 - val_loss: 0.6085
AUC: 0.8617

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9886 - val_loss: 0.6120
AUC: 0.8619

Epoch 2/30
 - 0s - loss: 0.9879 - val_loss: 0.6208
AUC: 0.8623

Epoch 3/30
 - 0s - loss: 0.9888 - val_loss: 0.6168
AUC: 0.8624

Epoch 4/30
 - 0s - loss: 0.9851 - val_loss: 0.6205
AUC: 0.8625

Epoch 5/30
 - 0s - loss: 0.9826 - val_loss: 0.5881
AUC: 0.8619

Epoch 6/30
 - 0s - loss: 0.9827 - val_loss: 0.5975
AUC: 0.8623

Epoch 7/30
 - 0s - loss: 0.9843 - val_loss: 0.6037
AUC: 0.8624

Epoch 8/30
 - 0s - loss: 0.9776 - val_loss: 0.5985
AUC: 0.8624

Epoch 9/30
 - 0s - loss: 0.9823 - val_loss: 0.6132
AUC: 0.8628

Epoch 10/30
 - 0s - loss: 0.9787 - val_loss: 0.6033
AUC: 0.8628

Epoch 11/30
 - 0s - loss: 0.9788 - val_loss: 0.6171
AUC: 0.8632

Epoch 12/30
 - 0s - loss: 0.9810 - val_loss: 0.5950
AUC: 0.8630

Epoch 13/30
 - 0s - loss: 0.9771 - val_loss: 0.6100
AUC: 0.8633

Epoch 14/30
 - 0s - loss: 0.9717 - val_loss: 0.6036
AUC: 0.8634

Epoch 15/30
 - 0s - loss: 0.9753 - val_loss: 0.6052
AUC: 0.8636

Epoch 16/30
 - 0s - loss: 0.9716 - val_loss: 0.6028
AUC: 0.8635

Epoch 17/30
 - 0s - loss: 0.9711 - val_loss: 0.6022
AUC: 0.8635

Epoch 18/30
 - 0s - loss: 0.9780 - val_loss: 0.6031
AUC: 0.8636

Epoch 19/30
 - 0s - loss: 0.9734 - val_loss: 0.6041
AUC: 0.8637

Epoch 20/30
 - 0s - loss: 0.9726 - val_loss: 0.6025
AUC: 0.8637

Epoch 21/30
 - 0s - loss: 0.9785 - val_loss: 0.6084
AUC: 0.8638

Epoch 22/30
 - 0s - loss: 0.9694 - val_loss: 0.6071
AUC: 0.8638

Epoch 23/30
 - 0s - loss: 0.9673 - val_loss: 0.6027
AUC: 0.8637

Epoch 24/30
 - 0s - loss: 0.9712 - val_loss: 0.6043
AUC: 0.8637

Epoch 25/30
 - 0s - loss: 0.9741 - val_loss: 0.6031
AUC: 0.8638

Epoch 26/30
 - 0s - loss: 0.9709 - val_loss: 0.6039
AUC: 0.8638

Epoch 27/30
 - 0s - loss: 0.9746 - val_loss: 0.6045
AUC: 0.8638

Epoch 28/30
 - 0s - loss: 0.9697 - val_loss: 0.6051
AUC: 0.8638

Epoch 29/30
 - 0s - loss: 0.9687 - val_loss: 0.6044
AUC: 0.8638

Epoch 30/30
 - 0s - loss: 0.9711 - val_loss: 0.6050
Using TensorFlow backend.
AUC: 0.8638

2019-03-08 12:26:39.896690: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:26:40.058668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:26:40.058713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:26:40.343156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:26:40.343209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:26:40.343219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:26:40.343510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36278 rows...
Finished. It takes 5.3 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4482
Epoch 2/80
 - 3s - loss: 0.1079
Epoch 3/80
 - 3s - loss: 0.1012
Epoch 4/80
 - 3s - loss: 0.0971
Epoch 5/80
 - 3s - loss: 0.0913
Epoch 6/80
 - 3s - loss: 0.0823
Epoch 7/80
 - 3s - loss: 0.0722
Epoch 8/80
 - 3s - loss: 0.0642
Epoch 9/80
 - 3s - loss: 0.0582
Epoch 10/80
 - 3s - loss: 0.0537
Epoch 11/80
 - 3s - loss: 0.0503
Epoch 12/80
 - 3s - loss: 0.0476
Epoch 13/80
 - 3s - loss: 0.0454
Epoch 14/80
 - 3s - loss: 0.0436
Epoch 15/80
 - 3s - loss: 0.0421
Epoch 16/80
 - 3s - loss: 0.0409
Epoch 17/80
 - 3s - loss: 0.0399
Epoch 18/80
 - 3s - loss: 0.0391
Epoch 19/80
 - 3s - loss: 0.0385
Epoch 20/80
 - 3s - loss: 0.0379
Epoch 21/80
 - 3s - loss: 0.0375
Epoch 22/80
 - 3s - loss: 0.0371
Epoch 23/80
 - 3s - loss: 0.0368
Epoch 24/80
 - 3s - loss: 0.0365
Epoch 25/80
 - 3s - loss: 0.0363
Epoch 26/80
 - 3s - loss: 0.0361
Epoch 27/80
 - 3s - loss: 0.0359
Epoch 28/80
 - 3s - loss: 0.0358
Epoch 29/80
 - 3s - loss: 0.0357
Epoch 30/80
 - 3s - loss: 0.0355
Epoch 31/80
 - 3s - loss: 0.0354
Epoch 32/80
 - 3s - loss: 0.0353
Epoch 33/80
 - 3s - loss: 0.0353
Epoch 34/80
 - 3s - loss: 0.0352
Epoch 35/80
 - 3s - loss: 0.0351
Epoch 36/80
 - 3s - loss: 0.0350
Epoch 37/80
 - 3s - loss: 0.0350
Epoch 38/80
 - 3s - loss: 0.0349
Epoch 39/80
 - 3s - loss: 0.0349
Epoch 40/80
 - 3s - loss: 0.0348
Epoch 41/80
 - 3s - loss: 0.0348
Epoch 42/80
 - 3s - loss: 0.0347
Epoch 43/80
 - 3s - loss: 0.0347
Epoch 44/80
 - 3s - loss: 0.0347
Epoch 45/80
 - 3s - loss: 0.0346
Epoch 46/80
 - 3s - loss: 0.0346
Epoch 47/80
 - 3s - loss: 0.0346
Epoch 48/80
 - 3s - loss: 0.0335
Epoch 49/80
 - 3s - loss: 0.0333
Epoch 50/80
 - 3s - loss: 0.0333
Epoch 51/80
 - 3s - loss: 0.0333
Epoch 52/80
 - 3s - loss: 0.0333
Epoch 53/80
 - 3s - loss: 0.0330
Epoch 54/80
 - 3s - loss: 0.0330
Epoch 55/80
 - 3s - loss: 0.0330
Epoch 56/80
 - 3s - loss: 0.0330
Epoch 57/80
 - 3s - loss: 0.0329
Epoch 58/80
 - 3s - loss: 0.0329
Epoch 59/80
 - 3s - loss: 0.0329
Epoch 60/80
 - 3s - loss: 0.0329
Epoch 61/80
 - 3s - loss: 0.0329
Epoch 62/80
 - 3s - loss: 0.0329
Epoch 63/80
 - 3s - loss: 0.0329
Epoch 64/80
 - 3s - loss: 0.0329
Epoch 65/80
 - 3s - loss: 0.0329
Epoch 66/80
 - 3s - loss: 0.0329
Epoch 67/80
 - 3s - loss: 0.0329
Epoch 68/80
 - 3s - loss: 0.0329
Epoch 69/80
 - 3s - loss: 0.0329
Epoch 70/80
 - 3s - loss: 0.0329
Epoch 71/80
 - 3s - loss: 0.0329
Epoch 72/80
 - 3s - loss: 0.0329
Epoch 73/80
 - 3s - loss: 0.0329
Epoch 74/80
 - 3s - loss: 0.0329
Epoch 75/80
 - 3s - loss: 0.0329
Epoch 76/80
 - 3s - loss: 0.0329
Epoch 77/80
 - 3s - loss: 0.0329
Epoch 78/80
 - 3s - loss: 0.0329
Epoch 79/80
 - 3s - loss: 0.0329
Epoch 80/80
 - 3s - loss: 0.0329
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 29022 samples, validate on 7256 samples
Epoch 1/80
 - 1s - loss: 6.4971 - val_loss: 2.6414
AUC: 0.7860

Epoch 2/80
 - 0s - loss: 4.6100 - val_loss: 1.8894
AUC: 0.8095

Epoch 3/80
 - 0s - loss: 3.3745 - val_loss: 1.2186
AUC: 0.8269

Epoch 4/80
 - 0s - loss: 2.3951 - val_loss: 1.1697
AUC: 0.8411

Epoch 5/80
 - 0s - loss: 1.7868 - val_loss: 0.9006
AUC: 0.8453

Epoch 6/80
 - 0s - loss: 1.4442 - val_loss: 0.7282
AUC: 0.8475

Epoch 7/80
 - 0s - loss: 1.2322 - val_loss: 0.6877
AUC: 0.8489

Epoch 8/80
 - 0s - loss: 1.1788 - val_loss: 0.7045
AUC: 0.8498

Epoch 9/80
 - 0s - loss: 1.1459 - val_loss: 0.7287
AUC: 0.8521

Epoch 10/80
 - 0s - loss: 1.1246 - val_loss: 0.6503
AUC: 0.8533

Epoch 11/80
 - 0s - loss: 1.1000 - val_loss: 0.6402
AUC: 0.8554

Epoch 12/80
 - 0s - loss: 1.0931 - val_loss: 0.6258
AUC: 0.8566

Epoch 13/80
 - 0s - loss: 1.0863 - val_loss: 0.6806
AUC: 0.8591

Epoch 14/80
 - 0s - loss: 1.0748 - val_loss: 0.6743
AUC: 0.8593

Epoch 15/80
 - 0s - loss: 1.0666 - val_loss: 0.6685
AUC: 0.8603

Epoch 16/80
 - 0s - loss: 1.0635 - val_loss: 0.7068
AUC: 0.8609

Epoch 17/80
 - 0s - loss: 1.0502 - val_loss: 0.6380
AUC: 0.8615

Epoch 18/80
 - 0s - loss: 1.0460 - val_loss: 0.6630
AUC: 0.8609

Epoch 19/80
 - 0s - loss: 1.0397 - val_loss: 0.7036
AUC: 0.8638

Epoch 20/80
 - 0s - loss: 1.0363 - val_loss: 0.6174
AUC: 0.8626

Epoch 21/80
 - 0s - loss: 1.0355 - val_loss: 0.6116
AUC: 0.8621

Epoch 22/80
 - 0s - loss: 1.0297 - val_loss: 0.6105
AUC: 0.8631

Epoch 23/80
 - 0s - loss: 1.0230 - val_loss: 0.6615
AUC: 0.8651

Epoch 24/80
 - 0s - loss: 1.0203 - val_loss: 0.6571
AUC: 0.8657

Epoch 25/80
 - 0s - loss: 1.0170 - val_loss: 0.6117
AUC: 0.8644

Epoch 26/80
 - 0s - loss: 1.0188 - val_loss: 0.6283
AUC: 0.8657

Epoch 27/80
 - 0s - loss: 1.0119 - val_loss: 0.6062
AUC: 0.8661

Epoch 28/80
 - 0s - loss: 1.0123 - val_loss: 0.6179
AUC: 0.8666

Epoch 29/80
 - 0s - loss: 1.0052 - val_loss: 0.6341
AUC: 0.8680

Epoch 30/80
 - 0s - loss: 1.0061 - val_loss: 0.6148
AUC: 0.8676

Epoch 31/80
 - 0s - loss: 1.0112 - val_loss: 0.5480
AUC: 0.8678

Epoch 32/80
 - 0s - loss: 1.0051 - val_loss: 0.5974
AUC: 0.8683

Epoch 33/80
 - 0s - loss: 0.9992 - val_loss: 0.6413
AUC: 0.8677

Epoch 34/80
 - 0s - loss: 1.0026 - val_loss: 0.5753
AUC: 0.8686

Epoch 35/80
 - 0s - loss: 0.9906 - val_loss: 0.5434
AUC: 0.8671

Epoch 36/80
 - 0s - loss: 1.0014 - val_loss: 0.5805
AUC: 0.8692

Epoch 37/80
 - 0s - loss: 0.9837 - val_loss: 0.6025
AUC: 0.8694

Epoch 38/80
 - 0s - loss: 0.9861 - val_loss: 0.6211
AUC: 0.8700

Epoch 39/80
 - 0s - loss: 0.9865 - val_loss: 0.6277
AUC: 0.8709

Epoch 40/80
 - 0s - loss: 0.9894 - val_loss: 0.5824
AUC: 0.8702

Epoch 41/80
 - 0s - loss: 0.9846 - val_loss: 0.6063
AUC: 0.8703

Epoch 42/80
 - 0s - loss: 0.9847 - val_loss: 0.5884
AUC: 0.8696

Epoch 43/80
 - 0s - loss: 0.9882 - val_loss: 0.5703
AUC: 0.8685

Epoch 44/80
 - 0s - loss: 0.9822 - val_loss: 0.5632
AUC: 0.8700

Epoch 45/80
 - 0s - loss: 0.9791 - val_loss: 0.5829
AUC: 0.8694

Epoch 46/80
 - 0s - loss: 0.9726 - val_loss: 0.6235
AUC: 0.8710

Epoch 47/80
 - 0s - loss: 0.9716 - val_loss: 0.5888
AUC: 0.8707

Epoch 48/80
 - 0s - loss: 0.9701 - val_loss: 0.5880
AUC: 0.8709

Epoch 49/80
 - 0s - loss: 0.9691 - val_loss: 0.6143
AUC: 0.8712

Epoch 50/80
 - 0s - loss: 0.9698 - val_loss: 0.6024
AUC: 0.8711

Epoch 51/80
 - 0s - loss: 0.9682 - val_loss: 0.5879
AUC: 0.8708

Epoch 52/80
 - 0s - loss: 0.9641 - val_loss: 0.6031
AUC: 0.8712

Epoch 53/80
 - 0s - loss: 0.9679 - val_loss: 0.6164
AUC: 0.8714

Epoch 54/80
 - 0s - loss: 0.9695 - val_loss: 0.5729
AUC: 0.8705

Epoch 55/80
 - 0s - loss: 0.9665 - val_loss: 0.6035
AUC: 0.8714

Epoch 56/80
 - 0s - loss: 0.9631 - val_loss: 0.5957
AUC: 0.8713

Epoch 57/80
 - 0s - loss: 0.9636 - val_loss: 0.5998
AUC: 0.8714

Epoch 58/80
 - 0s - loss: 0.9653 - val_loss: 0.6044
AUC: 0.8715

Epoch 59/80
 - 0s - loss: 0.9706 - val_loss: 0.5968
AUC: 0.8714

Epoch 60/80
 - 0s - loss: 0.9655 - val_loss: 0.6005
AUC: 0.8715

Epoch 61/80
 - 0s - loss: 0.9630 - val_loss: 0.6045
AUC: 0.8715

Epoch 62/80
 - 0s - loss: 0.9655 - val_loss: 0.6010
AUC: 0.8715

Epoch 63/80
 - 0s - loss: 0.9628 - val_loss: 0.5927
AUC: 0.8714

Epoch 64/80
 - 0s - loss: 0.9611 - val_loss: 0.5981
AUC: 0.8714

Epoch 65/80
 - 0s - loss: 0.9589 - val_loss: 0.5930
AUC: 0.8713

Train on 29022 samples, validate on 7256 samples
Epoch 1/30
 - 1s - loss: 0.9648 - val_loss: 0.5989
AUC: 0.8715

Epoch 2/30
 - 0s - loss: 0.9599 - val_loss: 0.6070
AUC: 0.8719

Epoch 3/30
 - 0s - loss: 0.9619 - val_loss: 0.6015
AUC: 0.8719

Epoch 4/30
 - 0s - loss: 0.9612 - val_loss: 0.5913
AUC: 0.8718

Epoch 5/30
 - 0s - loss: 0.9621 - val_loss: 0.5996
AUC: 0.8721

Epoch 6/30
 - 0s - loss: 0.9553 - val_loss: 0.5991
AUC: 0.8722

Epoch 7/30
 - 0s - loss: 0.9519 - val_loss: 0.6123
AUC: 0.8724

Epoch 8/30
 - 0s - loss: 0.9507 - val_loss: 0.5955
AUC: 0.8722

Epoch 9/30
 - 0s - loss: 0.9480 - val_loss: 0.5792
AUC: 0.8721

Epoch 10/30
 - 0s - loss: 0.9538 - val_loss: 0.5938
AUC: 0.8725

Epoch 11/30
 - 0s - loss: 0.9512 - val_loss: 0.5956
AUC: 0.8727

Epoch 12/30
 - 0s - loss: 0.9460 - val_loss: 0.6172
AUC: 0.8730

Epoch 13/30
 - 0s - loss: 0.9461 - val_loss: 0.5993
AUC: 0.8728

Epoch 14/30
 - 0s - loss: 0.9459 - val_loss: 0.5845
AUC: 0.8727

Epoch 15/30
 - 0s - loss: 0.9447 - val_loss: 0.5960
AUC: 0.8729

Epoch 16/30
 - 0s - loss: 0.9391 - val_loss: 0.5941
AUC: 0.8731

Epoch 17/30
 - 0s - loss: 0.9391 - val_loss: 0.5912
AUC: 0.8731

Epoch 18/30
 - 0s - loss: 0.9432 - val_loss: 0.5849
AUC: 0.8732

Epoch 19/30
 - 0s - loss: 0.9330 - val_loss: 0.6083
AUC: 0.8736

Epoch 20/30
 - 0s - loss: 0.9338 - val_loss: 0.5885
AUC: 0.8733

Epoch 21/30
 - 0s - loss: 0.9359 - val_loss: 0.5891
AUC: 0.8734

Epoch 22/30
 - 0s - loss: 0.9320 - val_loss: 0.5870
AUC: 0.8734

Epoch 23/30
 - 0s - loss: 0.9316 - val_loss: 0.5877
AUC: 0.8734

Epoch 24/30
 - 0s - loss: 0.9309 - val_loss: 0.5894
AUC: 0.8735

Epoch 25/30
 - 0s - loss: 0.9324 - val_loss: 0.5833
AUC: 0.8734

Epoch 26/30
 - 0s - loss: 0.9346 - val_loss: 0.5887
AUC: 0.8735

Epoch 27/30
 - 0s - loss: 0.9330 - val_loss: 0.5810
AUC: 0.8734

Epoch 28/30
 - 0s - loss: 0.9402 - val_loss: 0.5853
AUC: 0.8735

Epoch 29/30
 - 0s - loss: 0.9310 - val_loss: 0.5869
AUC: 0.8736

Epoch 30/30
 - 0s - loss: 0.9316 - val_loss: 0.5862
Using TensorFlow backend.
AUC: 0.8736

2019-03-08 12:32:16.572549: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:32:16.739355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:32:16.739401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:32:17.026959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:32:17.027009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:32:17.027018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:32:17.027289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36194 rows...
Finished. It takes 5.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.5320
Epoch 2/80
 - 3s - loss: 0.1237
Epoch 3/80
 - 3s - loss: 0.1150
Epoch 4/80
 - 3s - loss: 0.1096
Epoch 5/80
 - 3s - loss: 0.1017
Epoch 6/80
 - 3s - loss: 0.0917
Epoch 7/80
 - 3s - loss: 0.0827
Epoch 8/80
 - 3s - loss: 0.0749
Epoch 9/80
 - 3s - loss: 0.0681
Epoch 10/80
 - 3s - loss: 0.0623
Epoch 11/80
 - 3s - loss: 0.0579
Epoch 12/80
 - 3s - loss: 0.0546
Epoch 13/80
 - 3s - loss: 0.0519
Epoch 14/80
 - 3s - loss: 0.0498
Epoch 15/80
 - 3s - loss: 0.0481
Epoch 16/80
 - 3s - loss: 0.0466
Epoch 17/80
 - 3s - loss: 0.0455
Epoch 18/80
 - 3s - loss: 0.0445
Epoch 19/80
 - 3s - loss: 0.0437
Epoch 20/80
 - 3s - loss: 0.0430
Epoch 21/80
 - 3s - loss: 0.0424
Epoch 22/80
 - 3s - loss: 0.0420
Epoch 23/80
 - 3s - loss: 0.0416
Epoch 24/80
 - 3s - loss: 0.0412
Epoch 25/80
 - 3s - loss: 0.0410
Epoch 26/80
 - 3s - loss: 0.0407
Epoch 27/80
 - 3s - loss: 0.0405
Epoch 28/80
 - 3s - loss: 0.0403
Epoch 29/80
 - 3s - loss: 0.0401
Epoch 30/80
 - 3s - loss: 0.0400
Epoch 31/80
 - 3s - loss: 0.0399
Epoch 32/80
 - 3s - loss: 0.0398
Epoch 33/80
 - 3s - loss: 0.0397
Epoch 34/80
 - 3s - loss: 0.0396
Epoch 35/80
 - 3s - loss: 0.0395
Epoch 36/80
 - 3s - loss: 0.0394
Epoch 37/80
 - 3s - loss: 0.0393
Epoch 38/80
 - 3s - loss: 0.0393
Epoch 39/80
 - 3s - loss: 0.0392
Epoch 40/80
 - 3s - loss: 0.0391
Epoch 41/80
 - 3s - loss: 0.0391
Epoch 42/80
 - 3s - loss: 0.0391
Epoch 43/80
 - 3s - loss: 0.0390
Epoch 44/80
 - 3s - loss: 0.0390
Epoch 45/80
 - 3s - loss: 0.0389
Epoch 46/80
 - 3s - loss: 0.0389
Epoch 47/80
 - 3s - loss: 0.0389
Epoch 48/80
 - 3s - loss: 0.0388
Epoch 49/80
 - 3s - loss: 0.0388
Epoch 50/80
 - 3s - loss: 0.0388
Epoch 51/80
 - 3s - loss: 0.0376
Epoch 52/80
 - 3s - loss: 0.0375
Epoch 53/80
 - 3s - loss: 0.0375
Epoch 54/80
 - 3s - loss: 0.0375
Epoch 55/80
 - 3s - loss: 0.0375
Epoch 56/80
 - 3s - loss: 0.0372
Epoch 57/80
 - 3s - loss: 0.0372
Epoch 58/80
 - 3s - loss: 0.0372
Epoch 59/80
 - 3s - loss: 0.0372
Epoch 60/80
 - 3s - loss: 0.0371
Epoch 61/80
 - 3s - loss: 0.0371
Epoch 62/80
 - 3s - loss: 0.0371
Epoch 63/80
 - 3s - loss: 0.0371
Epoch 64/80
 - 3s - loss: 0.0371
Epoch 65/80
 - 3s - loss: 0.0371
Epoch 66/80
 - 3s - loss: 0.0371
Epoch 67/80
 - 3s - loss: 0.0371
Epoch 68/80
 - 3s - loss: 0.0371
Epoch 69/80
 - 3s - loss: 0.0371
Epoch 70/80
 - 3s - loss: 0.0371
Epoch 71/80
 - 3s - loss: 0.0371
Epoch 72/80
 - 3s - loss: 0.0371
Epoch 73/80
 - 3s - loss: 0.0371
Epoch 74/80
 - 3s - loss: 0.0371
Epoch 75/80
 - 3s - loss: 0.0371
Epoch 76/80
 - 3s - loss: 0.0371
Epoch 77/80
 - 3s - loss: 0.0371
Epoch 78/80
 - 3s - loss: 0.0371
Epoch 79/80
 - 3s - loss: 0.0371
Epoch 80/80
 - 3s - loss: 0.0371
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28955 samples, validate on 7239 samples
Epoch 1/80
 - 1s - loss: 4.0215 - val_loss: 1.3065
AUC: 0.7976

Epoch 2/80
 - 0s - loss: 2.2567 - val_loss: 0.8966
AUC: 0.8130

Epoch 3/80
 - 0s - loss: 1.5428 - val_loss: 0.7590
AUC: 0.8242

Epoch 4/80
 - 0s - loss: 1.2782 - val_loss: 0.7827
AUC: 0.8308

Epoch 5/80
 - 0s - loss: 1.1938 - val_loss: 0.7685
AUC: 0.8372

Epoch 6/80
 - 0s - loss: 1.1518 - val_loss: 0.7039
AUC: 0.8407

Epoch 7/80
 - 0s - loss: 1.1198 - val_loss: 0.6537
AUC: 0.8435

Epoch 8/80
 - 0s - loss: 1.1021 - val_loss: 0.6656
AUC: 0.8457

Epoch 9/80
 - 0s - loss: 1.0804 - val_loss: 0.6447
AUC: 0.8490

Epoch 10/80
 - 0s - loss: 1.0795 - val_loss: 0.6119
AUC: 0.8501

Epoch 11/80
 - 0s - loss: 1.0709 - val_loss: 0.6776
AUC: 0.8510

Epoch 12/80
 - 0s - loss: 1.0621 - val_loss: 0.6835
AUC: 0.8541

Epoch 13/80
 - 0s - loss: 1.0505 - val_loss: 0.6400
AUC: 0.8543

Epoch 14/80
 - 0s - loss: 1.0533 - val_loss: 0.5833
AUC: 0.8545

Epoch 15/80
 - 0s - loss: 1.0455 - val_loss: 0.6642
AUC: 0.8560

Epoch 16/80
 - 0s - loss: 1.0409 - val_loss: 0.7019
AUC: 0.8573

Epoch 17/80
 - 0s - loss: 1.0348 - val_loss: 0.6400
AUC: 0.8572

Epoch 18/80
 - 0s - loss: 1.0271 - val_loss: 0.6728
AUC: 0.8579

Epoch 19/80
 - 0s - loss: 1.0286 - val_loss: 0.6790
AUC: 0.8586

Epoch 20/80
 - 0s - loss: 1.0198 - val_loss: 0.6795
AUC: 0.8597

Epoch 21/80
 - 0s - loss: 1.0181 - val_loss: 0.6401
AUC: 0.8595

Epoch 22/80
 - 0s - loss: 1.0168 - val_loss: 0.5581
AUC: 0.8584

Epoch 23/80
 - 0s - loss: 1.0156 - val_loss: 0.5924
AUC: 0.8596

Epoch 24/80
 - 0s - loss: 1.0065 - val_loss: 0.5393
AUC: 0.8594

Epoch 25/80
 - 0s - loss: 1.0204 - val_loss: 0.6326
AUC: 0.8605

Epoch 26/80
 - 0s - loss: 1.0086 - val_loss: 0.6770
AUC: 0.8613

Epoch 27/80
 - 0s - loss: 1.0075 - val_loss: 0.6070
AUC: 0.8618

Epoch 28/80
 - 0s - loss: 0.9959 - val_loss: 0.6966
AUC: 0.8610

Epoch 29/80
 - 0s - loss: 0.9988 - val_loss: 0.6217
AUC: 0.8614

Epoch 30/80
 - 0s - loss: 0.9990 - val_loss: 0.5853
AUC: 0.8608

Epoch 31/80
 - 0s - loss: 0.9982 - val_loss: 0.6563
AUC: 0.8617

Epoch 32/80
 - 0s - loss: 0.9930 - val_loss: 0.6289
AUC: 0.8620

Epoch 33/80
 - 0s - loss: 0.9934 - val_loss: 0.5849
AUC: 0.8620

Epoch 34/80
 - 0s - loss: 0.9850 - val_loss: 0.6171
AUC: 0.8628

Epoch 35/80
 - 0s - loss: 0.9835 - val_loss: 0.6096
AUC: 0.8630

Epoch 36/80
 - 0s - loss: 0.9815 - val_loss: 0.6474
AUC: 0.8631

Epoch 37/80
 - 0s - loss: 0.9841 - val_loss: 0.6322
AUC: 0.8630

Epoch 38/80
 - 0s - loss: 0.9803 - val_loss: 0.6328
AUC: 0.8630

Epoch 39/80
 - 0s - loss: 0.9793 - val_loss: 0.6228
AUC: 0.8631

Epoch 40/80
 - 0s - loss: 0.9771 - val_loss: 0.6200
AUC: 0.8632

Epoch 41/80
 - 0s - loss: 0.9799 - val_loss: 0.6259
AUC: 0.8633

Epoch 42/80
 - 0s - loss: 0.9807 - val_loss: 0.6540
AUC: 0.8635

Epoch 43/80
 - 0s - loss: 0.9772 - val_loss: 0.6061
AUC: 0.8634

Epoch 44/80
 - 0s - loss: 0.9782 - val_loss: 0.6256
AUC: 0.8632

Epoch 45/80
 - 0s - loss: 0.9778 - val_loss: 0.6214
AUC: 0.8633

Epoch 46/80
 - 0s - loss: 0.9737 - val_loss: 0.6148
AUC: 0.8634

Epoch 47/80
 - 0s - loss: 0.9757 - val_loss: 0.6198
AUC: 0.8634

Epoch 48/80
 - 0s - loss: 0.9724 - val_loss: 0.6101
AUC: 0.8634

Epoch 49/80
 - 0s - loss: 0.9773 - val_loss: 0.6182
AUC: 0.8634

Epoch 50/80
 - 0s - loss: 0.9716 - val_loss: 0.6156
AUC: 0.8635

Epoch 51/80
 - 0s - loss: 0.9749 - val_loss: 0.6144
AUC: 0.8635

Epoch 52/80
 - 0s - loss: 0.9733 - val_loss: 0.6221
AUC: 0.8635

Epoch 53/80
 - 0s - loss: 0.9738 - val_loss: 0.6174
AUC: 0.8635

Epoch 54/80
 - 0s - loss: 0.9724 - val_loss: 0.6198
AUC: 0.8636

Train on 28955 samples, validate on 7239 samples
Epoch 1/30
 - 1s - loss: 0.9782 - val_loss: 0.6122
AUC: 0.8635

Epoch 2/30
 - 0s - loss: 0.9753 - val_loss: 0.6192
AUC: 0.8638

Epoch 3/30
 - 0s - loss: 0.9695 - val_loss: 0.6252
AUC: 0.8641

Epoch 4/30
 - 0s - loss: 0.9703 - val_loss: 0.6060
AUC: 0.8639

Epoch 5/30
 - 0s - loss: 0.9664 - val_loss: 0.6180
AUC: 0.8642

Epoch 6/30
 - 0s - loss: 0.9668 - val_loss: 0.6106
AUC: 0.8642

Epoch 7/30
 - 0s - loss: 0.9644 - val_loss: 0.6266
AUC: 0.8644

Epoch 8/30
 - 0s - loss: 0.9660 - val_loss: 0.6166
AUC: 0.8645

Epoch 9/30
 - 0s - loss: 0.9646 - val_loss: 0.6040
AUC: 0.8645

Epoch 10/30
 - 0s - loss: 0.9661 - val_loss: 0.6175
AUC: 0.8647

Epoch 11/30
 - 0s - loss: 0.9632 - val_loss: 0.6181
AUC: 0.8648

Epoch 12/30
 - 0s - loss: 0.9603 - val_loss: 0.5947
AUC: 0.8649

Epoch 13/30
 - 0s - loss: 0.9611 - val_loss: 0.6128
AUC: 0.8649

Epoch 14/30
 - 0s - loss: 0.9556 - val_loss: 0.6044
AUC: 0.8651

Epoch 15/30
 - 0s - loss: 0.9523 - val_loss: 0.6154
AUC: 0.8652

Epoch 16/30
 - 0s - loss: 0.9460 - val_loss: 0.6029
AUC: 0.8651

Epoch 17/30
 - 0s - loss: 0.9498 - val_loss: 0.6048
AUC: 0.8654

Epoch 18/30
 - 0s - loss: 0.9533 - val_loss: 0.6251
AUC: 0.8656

Epoch 19/30
 - 0s - loss: 0.9457 - val_loss: 0.6177
AUC: 0.8657

Epoch 20/30
 - 0s - loss: 0.9481 - val_loss: 0.6023
AUC: 0.8656

Epoch 21/30
 - 0s - loss: 0.9470 - val_loss: 0.6082
AUC: 0.8657

Epoch 22/30
 - 0s - loss: 0.9461 - val_loss: 0.6096
AUC: 0.8657

Epoch 23/30
 - 0s - loss: 0.9451 - val_loss: 0.5988
AUC: 0.8657

Epoch 24/30
 - 0s - loss: 0.9415 - val_loss: 0.6002
AUC: 0.8657

Epoch 25/30
 - 0s - loss: 0.9433 - val_loss: 0.6056
AUC: 0.8658

Epoch 26/30
 - 0s - loss: 0.9416 - val_loss: 0.6058
AUC: 0.8658

Epoch 27/30
 - 0s - loss: 0.9460 - val_loss: 0.6044
AUC: 0.8658

Epoch 28/30
 - 0s - loss: 0.9406 - val_loss: 0.6013
AUC: 0.8658

Epoch 29/30
 - 0s - loss: 0.9418 - val_loss: 0.6039
AUC: 0.8658

Epoch 30/30
 - 0s - loss: 0.9426 - val_loss: 0.6025
Using TensorFlow backend.
AUC: 0.8658

2019-03-08 12:37:09.791621: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:37:09.960469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:37:09.960515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:37:10.253629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:37:10.253669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:37:10.253677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:37:10.253933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35874 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9603
Epoch 2/80
 - 2s - loss: 0.1856
Epoch 3/80
 - 2s - loss: 0.1527
Epoch 4/80
 - 2s - loss: 0.1407
Epoch 5/80
 - 2s - loss: 0.1303
Epoch 6/80
 - 2s - loss: 0.1216
Epoch 7/80
 - 2s - loss: 0.1140
Epoch 8/80
 - 2s - loss: 0.1069
Epoch 9/80
 - 2s - loss: 0.1003
Epoch 10/80
 - 2s - loss: 0.0938
Epoch 11/80
 - 2s - loss: 0.0879
Epoch 12/80
 - 2s - loss: 0.0824
Epoch 13/80
 - 2s - loss: 0.0775
Epoch 14/80
 - 2s - loss: 0.0732
Epoch 15/80
 - 2s - loss: 0.0695
Epoch 16/80
 - 2s - loss: 0.0663
Epoch 17/80
 - 2s - loss: 0.0637
Epoch 18/80
 - 2s - loss: 0.0614
Epoch 19/80
 - 2s - loss: 0.0596
Epoch 20/80
 - 2s - loss: 0.0580
Epoch 21/80
 - 2s - loss: 0.0567
Epoch 22/80
 - 2s - loss: 0.0555
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 12:38:08.125053: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:38:08.288113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:38:08.288157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:38:08.588710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:38:08.588763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:38:08.588772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:38:08.589025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35230 rows...
Finished. It takes 4.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 2.3983
Epoch 2/80
 - 1s - loss: 0.7447
Epoch 3/80
 - 1s - loss: 0.2694
Epoch 4/80
 - 1s - loss: 0.2314
Epoch 5/80
 - 1s - loss: 0.2208
Epoch 6/80
 - 1s - loss: 0.2117
Epoch 7/80
 - 1s - loss: 0.2001
Epoch 8/80
 - 1s - loss: 0.1875
Epoch 9/80
 - 1s - loss: 0.1764
Epoch 10/80
 - 1s - loss: 0.1676
Epoch 11/80
 - 1s - loss: 0.1604
Epoch 12/80
 - 1s - loss: 0.1543
Epoch 13/80
 - 1s - loss: 0.1485
Epoch 14/80
 - 1s - loss: 0.1431
Epoch 15/80
 - 1s - loss: 0.1378
Epoch 16/80
 - 1s - loss: 0.1324
Epoch 17/80
 - 1s - loss: 0.1270
Epoch 18/80
 - 1s - loss: 0.1216
Epoch 19/80
 - 1s - loss: 0.1162
Epoch 20/80
 - 1s - loss: 0.1110
Epoch 21/80
 - 1s - loss: 0.1061
Epoch 22/80
 - 1s - loss: 0.1016
Epoch 23/80
 - 1s - loss: 0.0975
Epoch 24/80
 - 1s - loss: 0.0939
Epoch 25/80
 - 1s - loss: 0.0905
Epoch 26/80
 - 1s - loss: 0.0875
Epoch 27/80
 - 1s - loss: 0.0848
Epoch 28/80
 - 1s - loss: 0.0823
Epoch 29/80
 - 1s - loss: 0.0800
Epoch 30/80
 - 1s - loss: 0.0779
Epoch 31/80
 - 1s - loss: 0.0760
Epoch 32/80
 - 1s - loss: 0.0743
Epoch 33/80
 - 1s - loss: 0.0727
Epoch 34/80
 - 1s - loss: 0.0714
Epoch 35/80
 - 1s - loss: 0.0701
Epoch 36/80
 - 1s - loss: 0.0690
Epoch 37/80
 - 1s - loss: 0.0680
Epoch 38/80
 - 1s - loss: 0.0670
Epoch 39/80
 - 1s - loss: 0.0662
Epoch 40/80
 - 1s - loss: 0.0654
Epoch 41/80
 - 1s - loss: 0.0647
Epoch 42/80
 - 1s - loss: 0.0641
Epoch 43/80
 - 1s - loss: 0.0636
Epoch 44/80
 - 1s - loss: 0.0631
Epoch 45/80
 - 1s - loss: 0.0627
Epoch 46/80
 - 1s - loss: 0.0623
Epoch 47/80
 - 1s - loss: 0.0619
Epoch 48/80
 - 1s - loss: 0.0616
Epoch 49/80
 - 1s - loss: 0.0613
Epoch 50/80
 - 1s - loss: 0.0610
Epoch 51/80
 - 1s - loss: 0.0608
Epoch 52/80
 - 1s - loss: 0.0606
Epoch 53/80
 - 1s - loss: 0.0604
Epoch 54/80
 - 1s - loss: 0.0602
Epoch 55/80
 - 1s - loss: 0.0600
Epoch 56/80
 - 1s - loss: 0.0599
Epoch 57/80
 - 1s - loss: 0.0598
Epoch 58/80
 - 1s - loss: 0.0596
Epoch 59/80
 - 1s - loss: 0.0595
Epoch 60/80
 - 1s - loss: 0.0594
Epoch 61/80
 - 1s - loss: 0.0593
Epoch 62/80
 - 1s - loss: 0.0592
Epoch 63/80
 - 1s - loss: 0.0591
Epoch 64/80
 - 1s - loss: 0.0591
Epoch 65/80
 - 1s - loss: 0.0590
Epoch 66/80
 - 1s - loss: 0.0589
Epoch 67/80
 - 1s - loss: 0.0588
Epoch 68/80
 - 1s - loss: 0.0588
Epoch 69/80
 - 1s - loss: 0.0587
Epoch 70/80
 - 1s - loss: 0.0586
Epoch 71/80
 - 1s - loss: 0.0586
Epoch 72/80
 - 1s - loss: 0.0586
Epoch 73/80
 - 1s - loss: 0.0585
Epoch 74/80
 - 1s - loss: 0.0584
Epoch 75/80
 - 1s - loss: 0.0584
Epoch 76/80
 - 1s - loss: 0.0584
Epoch 77/80
 - 1s - loss: 0.0583
Epoch 78/80
 - 1s - loss: 0.0583
Epoch 79/80
 - 1s - loss: 0.0583
Epoch 80/80
 - 1s - loss: 0.0582
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28184 samples, validate on 7046 samples
Epoch 1/80
 - 1s - loss: 4.9807 - val_loss: 1.9905
AUC: 0.8029

Epoch 2/80
 - 0s - loss: 2.8695 - val_loss: 1.2882
AUC: 0.8268

Epoch 3/80
 - 0s - loss: 1.9169 - val_loss: 0.7482
AUC: 0.8333

Epoch 4/80
 - 0s - loss: 1.4302 - val_loss: 0.8787
AUC: 0.8396

Epoch 5/80
 - 0s - loss: 1.2755 - val_loss: 0.7344
AUC: 0.8378

Epoch 6/80
 - 0s - loss: 1.1879 - val_loss: 0.6815
AUC: 0.8415

Epoch 7/80
 - 0s - loss: 1.1503 - val_loss: 0.6556
AUC: 0.8430

Epoch 8/80
 - 0s - loss: 1.1227 - val_loss: 0.6160
AUC: 0.8445

Epoch 9/80
 - 0s - loss: 1.1298 - val_loss: 0.7191
AUC: 0.8489

Epoch 10/80
 - 0s - loss: 1.0973 - val_loss: 0.7067
AUC: 0.8507

Epoch 11/80
 - 0s - loss: 1.0946 - val_loss: 0.6207
AUC: 0.8508

Epoch 12/80
 - 0s - loss: 1.0847 - val_loss: 0.6589
AUC: 0.8531

Epoch 13/80
 - 0s - loss: 1.0797 - val_loss: 0.5954
AUC: 0.8525

Epoch 14/80
 - 0s - loss: 1.0758 - val_loss: 0.6651
AUC: 0.8536

Epoch 15/80
 - 0s - loss: 1.0590 - val_loss: 0.6415
AUC: 0.8535

Epoch 16/80
 - 0s - loss: 1.0586 - val_loss: 0.6618
AUC: 0.8558

Epoch 17/80
 - 0s - loss: 1.0588 - val_loss: 0.7076
AUC: 0.8569

Epoch 18/80
 - 0s - loss: 1.0490 - val_loss: 0.6934
AUC: 0.8584

Epoch 19/80
 - 0s - loss: 1.0428 - val_loss: 0.6589
AUC: 0.8575

Epoch 20/80
 - 0s - loss: 1.0412 - val_loss: 0.6211
AUC: 0.8578

Epoch 21/80
 - 0s - loss: 1.0401 - val_loss: 0.6780
AUC: 0.8589

Epoch 22/80
 - 0s - loss: 1.0342 - val_loss: 0.5907
AUC: 0.8580

Epoch 23/80
 - 0s - loss: 1.0305 - val_loss: 0.6239
AUC: 0.8584

Epoch 24/80
 - 0s - loss: 1.0317 - val_loss: 0.6239
AUC: 0.8596

Epoch 25/80
 - 0s - loss: 1.0294 - val_loss: 0.6397
AUC: 0.8602

Epoch 26/80
 - 0s - loss: 1.0275 - val_loss: 0.6385
AUC: 0.8596

Epoch 27/80
 - 0s - loss: 1.0205 - val_loss: 0.5879
AUC: 0.8602

Epoch 28/80
 - 0s - loss: 1.0219 - val_loss: 0.5991
AUC: 0.8603

Epoch 29/80
 - 0s - loss: 1.0208 - val_loss: 0.6479
AUC: 0.8612

Epoch 30/80
 - 0s - loss: 1.0126 - val_loss: 0.6339
AUC: 0.8614

Epoch 31/80
 - 0s - loss: 1.0191 - val_loss: 0.7227
AUC: 0.8620

Epoch 32/80
 - 0s - loss: 1.0094 - val_loss: 0.5942
AUC: 0.8607

Epoch 33/80
 - 0s - loss: 1.0149 - val_loss: 0.5869
AUC: 0.8613

Epoch 34/80
 - 0s - loss: 1.0102 - val_loss: 0.6616
AUC: 0.8628

Epoch 35/80
 - 0s - loss: 1.0086 - val_loss: 0.5855
AUC: 0.8618

Epoch 36/80
 - 0s - loss: 1.0002 - val_loss: 0.5544
AUC: 0.8610

Epoch 37/80
 - 0s - loss: 1.0020 - val_loss: 0.6868
AUC: 0.8630

Epoch 38/80
 - 0s - loss: 0.9966 - val_loss: 0.6686
AUC: 0.8630

Epoch 39/80
 - 0s - loss: 1.0026 - val_loss: 0.5993
AUC: 0.8619

Epoch 40/80
 - 0s - loss: 1.0021 - val_loss: 0.6062
AUC: 0.8622

Epoch 41/80
 - 0s - loss: 0.9962 - val_loss: 0.6116
AUC: 0.8633

Epoch 42/80
 - 0s - loss: 0.9947 - val_loss: 0.5899
AUC: 0.8627

Epoch 43/80
 - 0s - loss: 0.9946 - val_loss: 0.6508
AUC: 0.8629

Epoch 44/80
 - 0s - loss: 0.9936 - val_loss: 0.6537
AUC: 0.8629

Epoch 45/80
 - 0s - loss: 0.9920 - val_loss: 0.5323
AUC: 0.8613

Epoch 46/80
 - 0s - loss: 0.9983 - val_loss: 0.5961
AUC: 0.8629

Epoch 47/80
 - 0s - loss: 0.9908 - val_loss: 0.5609
AUC: 0.8623

Epoch 48/80
 - 0s - loss: 0.9905 - val_loss: 0.6304
AUC: 0.8640

Epoch 49/80
 - 0s - loss: 0.9833 - val_loss: 0.5889
AUC: 0.8633

Epoch 50/80
 - 0s - loss: 0.9866 - val_loss: 0.5924
AUC: 0.8631

Epoch 51/80
 - 0s - loss: 0.9830 - val_loss: 0.5530
AUC: 0.8622

Epoch 52/80
 - 0s - loss: 0.9838 - val_loss: 0.6540
AUC: 0.8643

Epoch 53/80
 - 0s - loss: 0.9836 - val_loss: 0.6571
AUC: 0.8639

Epoch 54/80
 - 0s - loss: 0.9856 - val_loss: 0.5897
AUC: 0.8639

Epoch 55/80
 - 0s - loss: 0.9773 - val_loss: 0.6360
AUC: 0.8643

Epoch 56/80
 - 0s - loss: 0.9739 - val_loss: 0.6038
AUC: 0.8642

Epoch 57/80
 - 0s - loss: 0.9752 - val_loss: 0.6012
AUC: 0.8645

Epoch 58/80
 - 0s - loss: 0.9727 - val_loss: 0.5706
AUC: 0.8641

Epoch 59/80
 - 0s - loss: 0.9722 - val_loss: 0.5891
AUC: 0.8643

Epoch 60/80
 - 0s - loss: 0.9748 - val_loss: 0.6058
AUC: 0.8647

Epoch 61/80
 - 0s - loss: 0.9711 - val_loss: 0.6100
AUC: 0.8647

Epoch 62/80
 - 0s - loss: 0.9668 - val_loss: 0.6201
AUC: 0.8648

Epoch 63/80
 - 0s - loss: 0.9652 - val_loss: 0.6025
AUC: 0.8647

Epoch 64/80
 - 0s - loss: 0.9652 - val_loss: 0.6106
AUC: 0.8646

Epoch 65/80
 - 0s - loss: 0.9685 - val_loss: 0.6292
AUC: 0.8649

Epoch 66/80
 - 0s - loss: 0.9679 - val_loss: 0.6000
AUC: 0.8646

Epoch 67/80
 - 0s - loss: 0.9626 - val_loss: 0.5916
AUC: 0.8645

Epoch 68/80
 - 0s - loss: 0.9677 - val_loss: 0.5987
AUC: 0.8646

Epoch 69/80
 - 0s - loss: 0.9632 - val_loss: 0.5947
AUC: 0.8645

Epoch 70/80
 - 0s - loss: 0.9657 - val_loss: 0.5945
AUC: 0.8645

Epoch 71/80
 - 0s - loss: 0.9622 - val_loss: 0.5959
AUC: 0.8645

Epoch 72/80
 - 0s - loss: 0.9656 - val_loss: 0.5995
AUC: 0.8646

Epoch 73/80
 - 0s - loss: 0.9655 - val_loss: 0.5930
AUC: 0.8645

Epoch 74/80
 - 0s - loss: 0.9654 - val_loss: 0.5935
AUC: 0.8645

Epoch 75/80
 - 0s - loss: 0.9635 - val_loss: 0.5933
AUC: 0.8645

Train on 28184 samples, validate on 7046 samples
Epoch 1/30
 - 1s - loss: 0.9693 - val_loss: 0.5896
AUC: 0.8647

Epoch 2/30
 - 0s - loss: 0.9649 - val_loss: 0.6068
AUC: 0.8649

Epoch 3/30
 - 0s - loss: 0.9648 - val_loss: 0.5947
AUC: 0.8649

Epoch 4/30
 - 0s - loss: 0.9631 - val_loss: 0.6001
AUC: 0.8650

Epoch 5/30
 - 0s - loss: 0.9663 - val_loss: 0.5912
AUC: 0.8652

Epoch 6/30
 - 0s - loss: 0.9590 - val_loss: 0.5761
AUC: 0.8651

Epoch 7/30
 - 0s - loss: 0.9573 - val_loss: 0.5995
AUC: 0.8652

Epoch 8/30
 - 0s - loss: 0.9592 - val_loss: 0.6039
AUC: 0.8652

Epoch 9/30
 - 0s - loss: 0.9556 - val_loss: 0.5920
AUC: 0.8652

Epoch 10/30
 - 0s - loss: 0.9600 - val_loss: 0.5972
AUC: 0.8652

Epoch 11/30
 - 0s - loss: 0.9529 - val_loss: 0.5890
AUC: 0.8654

Epoch 12/30
 - 0s - loss: 0.9563 - val_loss: 0.5900
AUC: 0.8653

Epoch 13/30
 - 0s - loss: 0.9573 - val_loss: 0.5960
AUC: 0.8656

Epoch 14/30
 - 0s - loss: 0.9605 - val_loss: 0.5851
AUC: 0.8656

Epoch 15/30
 - 0s - loss: 0.9543 - val_loss: 0.5898
AUC: 0.8657

Epoch 16/30
 - 0s - loss: 0.9501 - val_loss: 0.5855
AUC: 0.8658

Epoch 17/30
 - 0s - loss: 0.9552 - val_loss: 0.5886
AUC: 0.8658

Epoch 18/30
 - 0s - loss: 0.9534 - val_loss: 0.5883
AUC: 0.8658

Epoch 19/30
 - 0s - loss: 0.9516 - val_loss: 0.5874
AUC: 0.8658

Epoch 20/30
 - 0s - loss: 0.9467 - val_loss: 0.5882
AUC: 0.8657

Epoch 21/30
 - 0s - loss: 0.9510 - val_loss: 0.5855
AUC: 0.8658

Epoch 22/30
 - 0s - loss: 0.9474 - val_loss: 0.5882
AUC: 0.8658

Epoch 23/30
 - 0s - loss: 0.9517 - val_loss: 0.5865
AUC: 0.8658

Epoch 24/30
 - 0s - loss: 0.9536 - val_loss: 0.5855
AUC: 0.8658

Epoch 25/30
 - 0s - loss: 0.9499 - val_loss: 0.5857
AUC: 0.8658

Epoch 26/30
 - 0s - loss: 0.9502 - val_loss: 0.5823
AUC: 0.8658

Epoch 27/30
 - 0s - loss: 0.9495 - val_loss: 0.5840
AUC: 0.8658

Epoch 28/30
 - 0s - loss: 0.9491 - val_loss: 0.5848
AUC: 0.8658

Epoch 29/30
 - 0s - loss: 0.9488 - val_loss: 0.5866
AUC: 0.8658

Epoch 30/30
 - 0s - loss: 0.9521 - val_loss: 0.5871
Using TensorFlow backend.
AUC: 0.8658

2019-03-08 12:40:43.656712: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:40:43.819135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:40:43.819200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:40:44.117687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:40:44.117740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:40:44.117749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:40:44.118001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36244 rows...
Finished. It takes 5.4 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4801
Epoch 2/80
 - 3s - loss: 0.1137
Epoch 3/80
 - 3s - loss: 0.1028
Epoch 4/80
 - 3s - loss: 0.0924
Epoch 5/80
 - 3s - loss: 0.0840
Epoch 6/80
 - 3s - loss: 0.0780
Epoch 7/80
 - 3s - loss: 0.0725
Epoch 8/80
 - 3s - loss: 0.0670
Epoch 9/80
 - 3s - loss: 0.0618
Epoch 10/80
 - 3s - loss: 0.0572
Epoch 11/80
 - 3s - loss: 0.0534
Epoch 12/80
 - 3s - loss: 0.0503
Epoch 13/80
 - 3s - loss: 0.0478
Epoch 14/80
 - 3s - loss: 0.0458
Epoch 15/80
 - 3s - loss: 0.0442
Epoch 16/80
 - 3s - loss: 0.0430
Epoch 17/80
 - 3s - loss: 0.0420
Epoch 18/80
 - 3s - loss: 0.0411
Epoch 19/80
 - 3s - loss: 0.0405
Epoch 20/80
 - 3s - loss: 0.0399
Epoch 21/80
 - 3s - loss: 0.0395
Epoch 22/80
 - 3s - loss: 0.0391
Epoch 23/80
 - 3s - loss: 0.0388
Epoch 24/80
 - 3s - loss: 0.0385
Epoch 25/80
 - 3s - loss: 0.0383
Epoch 26/80
 - 3s - loss: 0.0381
Epoch 27/80
 - 3s - loss: 0.0379
Epoch 28/80
 - 3s - loss: 0.0378
Epoch 29/80
 - 3s - loss: 0.0376
Epoch 30/80
 - 3s - loss: 0.0375
Epoch 31/80
 - 3s - loss: 0.0374
Epoch 32/80
 - 3s - loss: 0.0373
Epoch 33/80
 - 3s - loss: 0.0372
Epoch 34/80
 - 3s - loss: 0.0371
Epoch 35/80
 - 3s - loss: 0.0371
Epoch 36/80
 - 3s - loss: 0.0370
Epoch 37/80
 - 3s - loss: 0.0369
Epoch 38/80
 - 3s - loss: 0.0369
Epoch 39/80
 - 3s - loss: 0.0368
Epoch 40/80
 - 3s - loss: 0.0368
Epoch 41/80
 - 3s - loss: 0.0367
Epoch 42/80
 - 3s - loss: 0.0367
Epoch 43/80
 - 3s - loss: 0.0367
Epoch 44/80
 - 3s - loss: 0.0366
Epoch 45/80
 - 3s - loss: 0.0366
Epoch 46/80
 - 3s - loss: 0.0365
Epoch 47/80
 - 3s - loss: 0.0365
Epoch 48/80
 - 3s - loss: 0.0365
Epoch 49/80
 - 3s - loss: 0.0365
Epoch 50/80
 - 3s - loss: 0.0353
Epoch 51/80
 - 3s - loss: 0.0352
Epoch 52/80
 - 3s - loss: 0.0352
Epoch 53/80
 - 3s - loss: 0.0352
Epoch 54/80
 - 3s - loss: 0.0351
Epoch 55/80
 - 3s - loss: 0.0348
Epoch 56/80
 - 3s - loss: 0.0348
Epoch 57/80
 - 3s - loss: 0.0348
Epoch 58/80
 - 3s - loss: 0.0348
Epoch 59/80
 - 3s - loss: 0.0348
Epoch 60/80
 - 3s - loss: 0.0348
Epoch 61/80
 - 3s - loss: 0.0348
Epoch 62/80
 - 3s - loss: 0.0348
Epoch 63/80
 - 3s - loss: 0.0348
Epoch 64/80
 - 3s - loss: 0.0348
Epoch 65/80
 - 3s - loss: 0.0348
Epoch 66/80
 - 3s - loss: 0.0348
Epoch 67/80
 - 3s - loss: 0.0348
Epoch 68/80
 - 3s - loss: 0.0348
Epoch 69/80
 - 3s - loss: 0.0348
Epoch 70/80
 - 3s - loss: 0.0348
Epoch 71/80
 - 3s - loss: 0.0348
Epoch 72/80
 - 3s - loss: 0.0348
Epoch 73/80
 - 3s - loss: 0.0348
Epoch 74/80
 - 3s - loss: 0.0348
Epoch 75/80
 - 3s - loss: 0.0348
Epoch 76/80
 - 3s - loss: 0.0348
Epoch 77/80
 - 3s - loss: 0.0348
Epoch 78/80
 - 3s - loss: 0.0348
Epoch 79/80
 - 3s - loss: 0.0348
Epoch 80/80
 - 3s - loss: 0.0348
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28995 samples, validate on 7249 samples
Epoch 1/80
 - 1s - loss: 5.4536 - val_loss: 1.5305
AUC: 0.7815

Epoch 2/80
 - 0s - loss: 3.5638 - val_loss: 1.3577
AUC: 0.8138

Epoch 3/80
 - 0s - loss: 2.2936 - val_loss: 0.9323
AUC: 0.8262

Epoch 4/80
 - 0s - loss: 1.6392 - val_loss: 0.7260
AUC: 0.8298

Epoch 5/80
 - 0s - loss: 1.3373 - val_loss: 0.7393
AUC: 0.8393

Epoch 6/80
 - 0s - loss: 1.2083 - val_loss: 0.6411
AUC: 0.8412

Epoch 7/80
 - 0s - loss: 1.1905 - val_loss: 0.6926
AUC: 0.8423

Epoch 8/80
 - 0s - loss: 1.1556 - val_loss: 0.6500
AUC: 0.8459

Epoch 9/80
 - 0s - loss: 1.1210 - val_loss: 0.6861
AUC: 0.8463

Epoch 10/80
 - 0s - loss: 1.1110 - val_loss: 0.6230
AUC: 0.8474

Epoch 11/80
 - 0s - loss: 1.1020 - val_loss: 0.6180
AUC: 0.8493

Epoch 12/80
 - 0s - loss: 1.0869 - val_loss: 0.6571
AUC: 0.8500

Epoch 13/80
 - 0s - loss: 1.0786 - val_loss: 0.6529
AUC: 0.8523

Epoch 14/80
 - 0s - loss: 1.0672 - val_loss: 0.6287
AUC: 0.8515

Epoch 15/80
 - 0s - loss: 1.0576 - val_loss: 0.6797
AUC: 0.8553

Epoch 16/80
 - 0s - loss: 1.0569 - val_loss: 0.6848
AUC: 0.8556

Epoch 17/80
 - 0s - loss: 1.0585 - val_loss: 0.7023
AUC: 0.8560

Epoch 18/80
 - 0s - loss: 1.0483 - val_loss: 0.6622
AUC: 0.8565

Epoch 19/80
 - 0s - loss: 1.0461 - val_loss: 0.6335
AUC: 0.8566

Epoch 20/80
 - 0s - loss: 1.0416 - val_loss: 0.6376
AUC: 0.8570

Epoch 21/80
 - 0s - loss: 1.0296 - val_loss: 0.5868
AUC: 0.8576

Epoch 22/80
 - 0s - loss: 1.0310 - val_loss: 0.5801
AUC: 0.8584

Epoch 23/80
 - 0s - loss: 1.0244 - val_loss: 0.6240
AUC: 0.8589

Epoch 24/80
 - 0s - loss: 1.0249 - val_loss: 0.5727
AUC: 0.8589

Epoch 25/80
 - 0s - loss: 1.0197 - val_loss: 0.6359
AUC: 0.8597

Epoch 26/80
 - 0s - loss: 1.0180 - val_loss: 0.5916
AUC: 0.8601

Epoch 27/80
 - 0s - loss: 1.0154 - val_loss: 0.5654
AUC: 0.8586

Epoch 28/80
 - 0s - loss: 1.0121 - val_loss: 0.6191
AUC: 0.8609

Epoch 29/80
 - 0s - loss: 1.0143 - val_loss: 0.6089
AUC: 0.8606

Epoch 30/80
 - 0s - loss: 1.0052 - val_loss: 0.6264
AUC: 0.8605

Epoch 31/80
 - 0s - loss: 1.0055 - val_loss: 0.6269
AUC: 0.8611

Epoch 32/80
 - 0s - loss: 0.9999 - val_loss: 0.5771
AUC: 0.8611

Epoch 33/80
 - 0s - loss: 0.9990 - val_loss: 0.5696
AUC: 0.8609

Epoch 34/80
 - 0s - loss: 1.0015 - val_loss: 0.6976
AUC: 0.8623

Epoch 35/80
 - 0s - loss: 0.9939 - val_loss: 0.6458
AUC: 0.8625

Epoch 36/80
 - 0s - loss: 0.9941 - val_loss: 0.5967
AUC: 0.8631

Epoch 37/80
 - 0s - loss: 0.9918 - val_loss: 0.6175
AUC: 0.8633

Epoch 38/80
 - 0s - loss: 0.9805 - val_loss: 0.6175
AUC: 0.8634

Epoch 39/80
 - 0s - loss: 0.9834 - val_loss: 0.6145
AUC: 0.8632

Epoch 40/80
 - 0s - loss: 0.9806 - val_loss: 0.5964
AUC: 0.8633

Epoch 41/80
 - 0s - loss: 0.9830 - val_loss: 0.5849
AUC: 0.8631

Epoch 42/80
 - 0s - loss: 0.9820 - val_loss: 0.6097
AUC: 0.8635

Epoch 43/80
 - 0s - loss: 0.9819 - val_loss: 0.6013
AUC: 0.8634

Epoch 44/80
 - 0s - loss: 0.9783 - val_loss: 0.6188
AUC: 0.8635

Epoch 45/80
 - 0s - loss: 0.9798 - val_loss: 0.5703
AUC: 0.8631

Epoch 46/80
 - 0s - loss: 0.9808 - val_loss: 0.6004
AUC: 0.8633

Epoch 47/80
 - 0s - loss: 0.9780 - val_loss: 0.6196
AUC: 0.8634

Epoch 48/80
 - 0s - loss: 0.9775 - val_loss: 0.6095
AUC: 0.8634

Epoch 49/80
 - 0s - loss: 0.9799 - val_loss: 0.6108
AUC: 0.8634

Epoch 50/80
 - 0s - loss: 0.9816 - val_loss: 0.6108
AUC: 0.8634

Epoch 51/80
 - 0s - loss: 0.9758 - val_loss: 0.6077
AUC: 0.8634

Epoch 52/80
 - 0s - loss: 0.9783 - val_loss: 0.6137
AUC: 0.8635

Epoch 53/80
 - 0s - loss: 0.9743 - val_loss: 0.6079
AUC: 0.8634

Epoch 54/80
 - 0s - loss: 0.9778 - val_loss: 0.6030
AUC: 0.8634

Epoch 55/80
 - 0s - loss: 0.9726 - val_loss: 0.6135
AUC: 0.8635

Epoch 56/80
 - 0s - loss: 0.9830 - val_loss: 0.6057
AUC: 0.8635

Epoch 57/80
 - 0s - loss: 0.9741 - val_loss: 0.6075
AUC: 0.8634

Train on 28995 samples, validate on 7249 samples
Epoch 1/30
 - 1s - loss: 0.9801 - val_loss: 0.6209
AUC: 0.8637

Epoch 2/30
 - 0s - loss: 0.9801 - val_loss: 0.6084
AUC: 0.8637

Epoch 3/30
 - 0s - loss: 0.9719 - val_loss: 0.6012
AUC: 0.8637

Epoch 4/30
 - 0s - loss: 0.9735 - val_loss: 0.5955
AUC: 0.8638

Epoch 5/30
 - 0s - loss: 0.9738 - val_loss: 0.6099
AUC: 0.8640

Epoch 6/30
 - 0s - loss: 0.9744 - val_loss: 0.6112
AUC: 0.8643

Epoch 7/30
 - 0s - loss: 0.9675 - val_loss: 0.6095
AUC: 0.8644

Epoch 8/30
 - 0s - loss: 0.9675 - val_loss: 0.6178
AUC: 0.8646

Epoch 9/30
 - 0s - loss: 0.9668 - val_loss: 0.6079
AUC: 0.8644

Epoch 10/30
 - 0s - loss: 0.9642 - val_loss: 0.6031
AUC: 0.8647

Epoch 11/30
 - 0s - loss: 0.9635 - val_loss: 0.6081
AUC: 0.8649

Epoch 12/30
 - 0s - loss: 0.9582 - val_loss: 0.6116
AUC: 0.8649

Epoch 13/30
 - 0s - loss: 0.9597 - val_loss: 0.5965
AUC: 0.8650

Epoch 14/30
 - 0s - loss: 0.9603 - val_loss: 0.6123
AUC: 0.8653

Epoch 15/30
 - 0s - loss: 0.9555 - val_loss: 0.5966
AUC: 0.8652

Epoch 16/30
 - 0s - loss: 0.9536 - val_loss: 0.5986
AUC: 0.8652

Epoch 17/30
 - 0s - loss: 0.9546 - val_loss: 0.5970
AUC: 0.8652

Epoch 18/30
 - 0s - loss: 0.9566 - val_loss: 0.5974
AUC: 0.8653

Epoch 19/30
 - 0s - loss: 0.9602 - val_loss: 0.5996
AUC: 0.8653

Epoch 20/30
 - 0s - loss: 0.9566 - val_loss: 0.6009
AUC: 0.8653

Epoch 21/30
 - 0s - loss: 0.9543 - val_loss: 0.6001
AUC: 0.8653

Epoch 22/30
 - 0s - loss: 0.9541 - val_loss: 0.5988
AUC: 0.8654

Epoch 23/30
 - 0s - loss: 0.9539 - val_loss: 0.5977
AUC: 0.8654

Epoch 24/30
 - 0s - loss: 0.9559 - val_loss: 0.5972
AUC: 0.8654

Epoch 25/30
 - 0s - loss: 0.9532 - val_loss: 0.5974
AUC: 0.8654

Epoch 26/30
 - 0s - loss: 0.9537 - val_loss: 0.5977
AUC: 0.8654

Epoch 27/30
 - 0s - loss: 0.9535 - val_loss: 0.5977
AUC: 0.8654

Epoch 28/30
 - 0s - loss: 0.9500 - val_loss: 0.5972
AUC: 0.8654

Epoch 29/30
 - 0s - loss: 0.9602 - val_loss: 0.5969
AUC: 0.8654

Epoch 30/30
 - 0s - loss: 0.9517 - val_loss: 0.5965
Using TensorFlow backend.
AUC: 0.8654

2019-03-08 12:45:52.459994: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:45:52.625906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:45:52.625951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:45:52.919363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:45:52.919417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:45:52.919426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:45:52.919696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35997 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.8238
Epoch 2/80
 - 2s - loss: 0.1625
Epoch 3/80
 - 2s - loss: 0.1371
Epoch 4/80
 - 2s - loss: 0.1237
Epoch 5/80
 - 2s - loss: 0.1136
Epoch 6/80
 - 2s - loss: 0.1052
Epoch 7/80
 - 2s - loss: 0.0972
Epoch 8/80
 - 2s - loss: 0.0900
Epoch 9/80
 - 2s - loss: 0.0840
Epoch 10/80
 - 2s - loss: 0.0789
Epoch 11/80
 - 2s - loss: 0.0746
Epoch 12/80
 - 2s - loss: 0.0707
Epoch 13/80
 - 2s - loss: 0.0672
Epoch 14/80
 - 2s - loss: 0.0641
Epoch 15/80
 - 2s - loss: 0.0615
Epoch 16/80
 - 2s - loss: 0.0593
Epoch 17/80
 - 2s - loss: 0.0573
Epoch 18/80
 - 2s - loss: 0.0556
Epoch 19/80
 - 2s - loss: 0.0542
Epoch 20/80
 - 2s - loss: 0.0529
Epoch 21/80
 - 2s - loss: 0.0518
Epoch 22/80
 - 2s - loss: 0.0509
Epoch 23/80
 - 2s - loss: 0.0501
Epoch 24/80
 - 2s - loss: 0.0495
Epoch 25/80
 - 2s - loss: 0.0489
Epoch 26/80
 - 2s - loss: 0.0485
Epoch 27/80
 - 2s - loss: 0.0481
Epoch 28/80
 - 2s - loss: 0.0478
Epoch 29/80
 - 2s - loss: 0.0475
Epoch 30/80
 - 2s - loss: 0.0472
Epoch 31/80
 - 2s - loss: 0.0470
Epoch 32/80
 - 2s - loss: 0.0468
Epoch 33/80
 - 2s - loss: 0.0466
Epoch 34/80
 - 2s - loss: 0.0465
Epoch 35/80
 - 2s - loss: 0.0463
Epoch 36/80
 - 2s - loss: 0.0462
Epoch 37/80
 - 2s - loss: 0.0461
Epoch 38/80
 - 2s - loss: 0.0460
Epoch 39/80
 - 2s - loss: 0.0459
Epoch 40/80
 - 2s - loss: 0.0458
Epoch 41/80
 - 2s - loss: 0.0457
Epoch 42/80
 - 2s - loss: 0.0457
Epoch 43/80
 - 2s - loss: 0.0456
Epoch 44/80
 - 2s - loss: 0.0455
Epoch 45/80
 - 2s - loss: 0.0455
Epoch 46/80
 - 2s - loss: 0.0454
Epoch 47/80
 - 2s - loss: 0.0454
Epoch 48/80
 - 2s - loss: 0.0453
Epoch 49/80
 - 2s - loss: 0.0453
Epoch 50/80
 - 2s - loss: 0.0453
Epoch 51/80
 - 2s - loss: 0.0452
Epoch 52/80
 - 2s - loss: 0.0452
Epoch 53/80
 - 2s - loss: 0.0452
Epoch 54/80
 - 2s - loss: 0.0451
Epoch 55/80
 - 2s - loss: 0.0451
Epoch 56/80
 - 2s - loss: 0.0440
Epoch 57/80
 - 2s - loss: 0.0438
Epoch 58/80
 - 2s - loss: 0.0438
Epoch 59/80
 - 2s - loss: 0.0438
Epoch 60/80
 - 2s - loss: 0.0438
Epoch 61/80
 - 2s - loss: 0.0435
Epoch 62/80
 - 2s - loss: 0.0435
Epoch 63/80
 - 2s - loss: 0.0435
Epoch 64/80
 - 2s - loss: 0.0435
Epoch 65/80
 - 2s - loss: 0.0434
Epoch 66/80
 - 2s - loss: 0.0434
Epoch 67/80
 - 2s - loss: 0.0434
Epoch 68/80
 - 2s - loss: 0.0434
Epoch 69/80
 - 2s - loss: 0.0434
Epoch 70/80
 - 2s - loss: 0.0434
Epoch 71/80
 - 2s - loss: 0.0434
Epoch 72/80
 - 2s - loss: 0.0434
Epoch 73/80
 - 2s - loss: 0.0434
Epoch 74/80
 - 2s - loss: 0.0434
Epoch 75/80
 - 2s - loss: 0.0434
Epoch 76/80
 - 2s - loss: 0.0434
Epoch 77/80
 - 2s - loss: 0.0434
Epoch 78/80
 - 2s - loss: 0.0434
Epoch 79/80
 - 2s - loss: 0.0434
Epoch 80/80
 - 2s - loss: 0.0434
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28797 samples, validate on 7200 samples
Epoch 1/80
 - 1s - loss: 3.9933 - val_loss: 1.2932
AUC: 0.8252

Epoch 2/80
 - 0s - loss: 2.4205 - val_loss: 1.0519
AUC: 0.8344

Epoch 3/80
 - 0s - loss: 1.6773 - val_loss: 0.7396
AUC: 0.8418

Epoch 4/80
 - 0s - loss: 1.3330 - val_loss: 0.7483
AUC: 0.8436

Epoch 5/80
 - 0s - loss: 1.2177 - val_loss: 0.7346
AUC: 0.8469

Epoch 6/80
 - 0s - loss: 1.1637 - val_loss: 0.6487
AUC: 0.8483

Epoch 7/80
 - 0s - loss: 1.1412 - val_loss: 0.6490
AUC: 0.8496

Epoch 8/80
 - 0s - loss: 1.1154 - val_loss: 0.6731
AUC: 0.8534

Epoch 9/80
 - 0s - loss: 1.1037 - val_loss: 0.6678
AUC: 0.8541

Epoch 10/80
 - 0s - loss: 1.0972 - val_loss: 0.6731
AUC: 0.8557

Epoch 11/80
 - 0s - loss: 1.0810 - val_loss: 0.6990
AUC: 0.8576

Epoch 12/80
 - 0s - loss: 1.0682 - val_loss: 0.6347
AUC: 0.8574

Epoch 13/80
 - 0s - loss: 1.0586 - val_loss: 0.6125
AUC: 0.8577

Epoch 14/80
 - 0s - loss: 1.0576 - val_loss: 0.6184
AUC: 0.8574

Epoch 15/80
 - 0s - loss: 1.0487 - val_loss: 0.6520
AUC: 0.8604

Epoch 16/80
 - 0s - loss: 1.0485 - val_loss: 0.6373
AUC: 0.8597

Epoch 17/80
 - 0s - loss: 1.0422 - val_loss: 0.6058
AUC: 0.8606

Epoch 18/80
 - 0s - loss: 1.0347 - val_loss: 0.6348
AUC: 0.8615

Epoch 19/80
 - 0s - loss: 1.0328 - val_loss: 0.6878
AUC: 0.8626

Epoch 20/80
 - 0s - loss: 1.0296 - val_loss: 0.5707
AUC: 0.8620

Epoch 21/80
 - 0s - loss: 1.0260 - val_loss: 0.6672
AUC: 0.8642

Epoch 22/80
 - 0s - loss: 1.0226 - val_loss: 0.5916
AUC: 0.8632

Epoch 23/80
 - 0s - loss: 1.0177 - val_loss: 0.6695
AUC: 0.8640

Epoch 24/80
 - 0s - loss: 1.0106 - val_loss: 0.6323
AUC: 0.8649

Epoch 25/80
 - 0s - loss: 1.0103 - val_loss: 0.6978
AUC: 0.8651

Epoch 26/80
 - 0s - loss: 1.0102 - val_loss: 0.6207
AUC: 0.8655

Epoch 27/80
 - 0s - loss: 1.0139 - val_loss: 0.6358
AUC: 0.8645

Epoch 28/80
 - 0s - loss: 1.0045 - val_loss: 0.5853
AUC: 0.8655

Epoch 29/80
 - 0s - loss: 1.0055 - val_loss: 0.5778
AUC: 0.8658

Epoch 30/80
 - 0s - loss: 0.9971 - val_loss: 0.5617
AUC: 0.8654

Epoch 31/80
 - 0s - loss: 0.9991 - val_loss: 0.7233
AUC: 0.8676

Epoch 32/80
 - 0s - loss: 0.9996 - val_loss: 0.6072
AUC: 0.8674

Epoch 33/80
 - 0s - loss: 0.9936 - val_loss: 0.5984
AUC: 0.8677

Epoch 34/80
 - 0s - loss: 0.9885 - val_loss: 0.6294
AUC: 0.8687

Epoch 35/80
 - 0s - loss: 0.9866 - val_loss: 0.5754
AUC: 0.8681

Epoch 36/80
 - 0s - loss: 0.9914 - val_loss: 0.5422
AUC: 0.8674

Epoch 37/80
 - 0s - loss: 0.9819 - val_loss: 0.6909
AUC: 0.8690

Epoch 38/80
 - 0s - loss: 0.9825 - val_loss: 0.6130
AUC: 0.8689

Epoch 39/80
 - 0s - loss: 0.9788 - val_loss: 0.5319
AUC: 0.8685

Epoch 40/80
 - 0s - loss: 0.9788 - val_loss: 0.5959
AUC: 0.8683

Epoch 41/80
 - 0s - loss: 0.9758 - val_loss: 0.5949
AUC: 0.8684

Epoch 42/80
 - 0s - loss: 0.9746 - val_loss: 0.6068
AUC: 0.8688

Epoch 43/80
 - 0s - loss: 0.9773 - val_loss: 0.6172
AUC: 0.8693

Epoch 44/80
 - 0s - loss: 0.9744 - val_loss: 0.6181
AUC: 0.8689

Epoch 45/80
 - 0s - loss: 0.9720 - val_loss: 0.5686
AUC: 0.8682

Epoch 46/80
 - 0s - loss: 0.9659 - val_loss: 0.6400
AUC: 0.8704

Epoch 47/80
 - 0s - loss: 0.9655 - val_loss: 0.6014
AUC: 0.8682

Epoch 48/80
 - 0s - loss: 0.9641 - val_loss: 0.6331
AUC: 0.8691

Epoch 49/80
 - 0s - loss: 0.9621 - val_loss: 0.5544
AUC: 0.8686

Epoch 50/80
 - 0s - loss: 0.9585 - val_loss: 0.6008
AUC: 0.8698

Epoch 51/80
 - 0s - loss: 0.9573 - val_loss: 0.6074
AUC: 0.8696

Epoch 52/80
 - 0s - loss: 0.9543 - val_loss: 0.6163
AUC: 0.8699

Epoch 53/80
 - 0s - loss: 0.9520 - val_loss: 0.5845
AUC: 0.8698

Epoch 54/80
 - 0s - loss: 0.9510 - val_loss: 0.6172
AUC: 0.8699

Epoch 55/80
 - 0s - loss: 0.9505 - val_loss: 0.5878
AUC: 0.8692

Epoch 56/80
 - 0s - loss: 0.9530 - val_loss: 0.5805
AUC: 0.8699

Epoch 57/80
 - 0s - loss: 0.9548 - val_loss: 0.6011
AUC: 0.8700

Epoch 58/80
 - 0s - loss: 0.9497 - val_loss: 0.5987
AUC: 0.8700

Epoch 59/80
 - 0s - loss: 0.9495 - val_loss: 0.5787
AUC: 0.8699

Epoch 60/80
 - 0s - loss: 0.9441 - val_loss: 0.5941
AUC: 0.8700

Epoch 61/80
 - 0s - loss: 0.9450 - val_loss: 0.5888
AUC: 0.8699

Epoch 62/80
 - 0s - loss: 0.9477 - val_loss: 0.5907
AUC: 0.8700

Epoch 63/80
 - 0s - loss: 0.9427 - val_loss: 0.5830
AUC: 0.8698

Epoch 64/80
 - 0s - loss: 0.9448 - val_loss: 0.5935
AUC: 0.8701

Epoch 65/80
 - 0s - loss: 0.9508 - val_loss: 0.5897
AUC: 0.8700

Epoch 66/80
 - 0s - loss: 0.9494 - val_loss: 0.5896
AUC: 0.8701

Epoch 67/80
 - 0s - loss: 0.9444 - val_loss: 0.5831
AUC: 0.8700

Epoch 68/80
 - 0s - loss: 0.9493 - val_loss: 0.5890
AUC: 0.8701

Epoch 69/80
 - 0s - loss: 0.9484 - val_loss: 0.5881
AUC: 0.8701

Train on 28797 samples, validate on 7200 samples
Epoch 1/30
 - 1s - loss: 0.9622 - val_loss: 0.5952
AUC: 0.8702

Epoch 2/30
 - 0s - loss: 0.9582 - val_loss: 0.5744
AUC: 0.8700

Epoch 3/30
 - 0s - loss: 0.9524 - val_loss: 0.5846
AUC: 0.8699

Epoch 4/30
 - 0s - loss: 0.9571 - val_loss: 0.5968
AUC: 0.8699

Epoch 5/30
 - 0s - loss: 0.9477 - val_loss: 0.5956
AUC: 0.8702

Epoch 6/30
 - 0s - loss: 0.9511 - val_loss: 0.5864
AUC: 0.8701

Epoch 7/30
 - 0s - loss: 0.9472 - val_loss: 0.6041
AUC: 0.8704

Epoch 8/30
 - 0s - loss: 0.9491 - val_loss: 0.5913
AUC: 0.8704

Epoch 9/30
 - 0s - loss: 0.9421 - val_loss: 0.5882
AUC: 0.8706

Epoch 10/30
 - 0s - loss: 0.9441 - val_loss: 0.5919
AUC: 0.8706

Epoch 11/30
 - 0s - loss: 0.9418 - val_loss: 0.5820
AUC: 0.8706

Epoch 12/30
 - 0s - loss: 0.9428 - val_loss: 0.5798
AUC: 0.8707

Epoch 13/30
 - 0s - loss: 0.9423 - val_loss: 0.5845
AUC: 0.8708

Epoch 14/30
 - 0s - loss: 0.9405 - val_loss: 0.5821
AUC: 0.8708

Epoch 15/30
 - 0s - loss: 0.9437 - val_loss: 0.5842
AUC: 0.8709

Epoch 16/30
 - 0s - loss: 0.9374 - val_loss: 0.5861
AUC: 0.8709

Epoch 17/30
 - 0s - loss: 0.9342 - val_loss: 0.5856
AUC: 0.8709

Epoch 18/30
 - 0s - loss: 0.9386 - val_loss: 0.5847
AUC: 0.8709

Epoch 19/30
 - 0s - loss: 0.9417 - val_loss: 0.5813
AUC: 0.8709

Epoch 20/30
 - 0s - loss: 0.9349 - val_loss: 0.5863
AUC: 0.8709

Epoch 21/30
 - 0s - loss: 0.9389 - val_loss: 0.5846
AUC: 0.8709

Epoch 22/30
 - 0s - loss: 0.9368 - val_loss: 0.5860
AUC: 0.8709

Epoch 23/30
 - 0s - loss: 0.9380 - val_loss: 0.5850
AUC: 0.8709

Epoch 24/30
 - 0s - loss: 0.9357 - val_loss: 0.5839
AUC: 0.8709

Epoch 25/30
 - 0s - loss: 0.9365 - val_loss: 0.5830
AUC: 0.8709

Epoch 26/30
 - 0s - loss: 0.9307 - val_loss: 0.5821
AUC: 0.8709

Epoch 27/30
 - 0s - loss: 0.9332 - val_loss: 0.5835
AUC: 0.8709

Epoch 28/30
 - 0s - loss: 0.9347 - val_loss: 0.5839
AUC: 0.8709

Epoch 29/30
 - 0s - loss: 0.9407 - val_loss: 0.5837
AUC: 0.8709

Epoch 30/30
 - 0s - loss: 0.9381 - val_loss: 0.5832
Using TensorFlow backend.
AUC: 0.8709

2019-03-08 12:49:54.574528: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:49:54.738323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:49:54.738367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:49:55.033771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:49:55.033822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:49:55.033831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:49:55.034088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35692 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2990
Epoch 2/80
 - 1s - loss: 0.2434
Epoch 3/80
 - 1s - loss: 0.1860
Epoch 4/80
 - 1s - loss: 0.1799
Epoch 5/80
 - 1s - loss: 0.1756
Epoch 6/80
 - 1s - loss: 0.1698
Epoch 7/80
 - 1s - loss: 0.1612
Epoch 8/80
 - 1s - loss: 0.1506
Epoch 9/80
 - 1s - loss: 0.1401
Epoch 10/80
 - 1s - loss: 0.1305
Epoch 11/80
 - 1s - loss: 0.1213
Epoch 12/80
 - 1s - loss: 0.1121
Epoch 13/80
 - 1s - loss: 0.1035
Epoch 14/80
 - 1s - loss: 0.0960
Epoch 15/80
 - 1s - loss: 0.0897
Epoch 16/80
 - 1s - loss: 0.0845
Epoch 17/80
 - 1s - loss: 0.0800
Epoch 18/80
 - 1s - loss: 0.0761
Epoch 19/80
 - 1s - loss: 0.0727
Epoch 20/80
 - 1s - loss: 0.0699
Epoch 21/80
 - 1s - loss: 0.0674
Epoch 22/80
 - 1s - loss: 0.0653
Epoch 23/80
 - 1s - loss: 0.0636
Epoch 24/80
 - 1s - loss: 0.0621
Epoch 25/80
 - 1s - loss: 0.0608
Epoch 26/80
 - 1s - loss: 0.0597
Epoch 27/80
 - 1s - loss: 0.0588
Epoch 28/80
 - 1s - loss: 0.0580
Epoch 29/80
 - 1s - loss: 0.0573
Epoch 30/80
 - 1s - loss: 0.0567
Epoch 31/80
 - 1s - loss: 0.0562
Epoch 32/80
 - 1s - loss: 0.0558
Epoch 33/80
 - 1s - loss: 0.0554
Epoch 34/80
 - 1s - loss: 0.0550
Epoch 35/80
 - 1s - loss: 0.0547
Epoch 36/80
 - 1s - loss: 0.0545
Epoch 37/80
 - 1s - loss: 0.0542
Epoch 38/80
 - 1s - loss: 0.0540
Epoch 39/80
 - 1s - loss: 0.0538
Epoch 40/80
 - 1s - loss: 0.0537
Epoch 41/80
 - 1s - loss: 0.0535
Epoch 42/80
 - 1s - loss: 0.0534
Epoch 43/80
 - 1s - loss: 0.0532
Epoch 44/80
 - 1s - loss: 0.0531
Epoch 45/80
 - 1s - loss: 0.0530
Epoch 46/80
 - 1s - loss: 0.0529
Epoch 47/80
 - 1s - loss: 0.0528
Epoch 48/80
 - 1s - loss: 0.0528
Epoch 49/80
 - 1s - loss: 0.0527
Epoch 50/80
 - 1s - loss: 0.0526
Epoch 51/80
 - 1s - loss: 0.0525
Epoch 52/80
 - 1s - loss: 0.0525
Epoch 53/80
 - 1s - loss: 0.0524
Epoch 54/80
 - 1s - loss: 0.0524
Epoch 55/80
 - 1s - loss: 0.0523
Epoch 56/80
 - 1s - loss: 0.0523
Epoch 57/80
 - 1s - loss: 0.0522
Epoch 58/80
 - 1s - loss: 0.0522
Epoch 59/80
 - 1s - loss: 0.0521
Epoch 60/80
 - 1s - loss: 0.0521
Epoch 61/80
 - 1s - loss: 0.0521
Epoch 62/80
 - 1s - loss: 0.0520
Epoch 63/80
 - 1s - loss: 0.0520
Epoch 64/80
 - 1s - loss: 0.0520
Epoch 65/80
 - 1s - loss: 0.0519
Epoch 66/80
 - 1s - loss: 0.0508
Epoch 67/80
 - 1s - loss: 0.0507
Epoch 68/80
 - 1s - loss: 0.0507
Epoch 69/80
 - 1s - loss: 0.0507
Epoch 70/80
 - 1s - loss: 0.0507
Epoch 71/80
 - 1s - loss: 0.0504
Epoch 72/80
 - 1s - loss: 0.0504
Epoch 73/80
 - 1s - loss: 0.0504
Epoch 74/80
 - 1s - loss: 0.0504
Epoch 75/80
 - 1s - loss: 0.0503
Epoch 76/80
 - 1s - loss: 0.0503
Epoch 77/80
 - 1s - loss: 0.0503
Epoch 78/80
 - 1s - loss: 0.0503
Epoch 79/80
 - 1s - loss: 0.0503
Epoch 80/80
 - 1s - loss: 0.0503
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28553 samples, validate on 7139 samples
Epoch 1/80
 - 1s - loss: 9.4953 - val_loss: 2.3291
AUC: 0.6737

Epoch 2/80
 - 0s - loss: 3.7075 - val_loss: 1.5337
AUC: 0.7836

Epoch 3/80
 - 0s - loss: 2.8021 - val_loss: 1.1891
AUC: 0.8097

Epoch 4/80
 - 0s - loss: 2.1889 - val_loss: 0.9288
AUC: 0.8229

Epoch 5/80
 - 0s - loss: 1.7648 - val_loss: 0.8544
AUC: 0.8270

Epoch 6/80
 - 0s - loss: 1.4252 - val_loss: 0.7352
AUC: 0.8301

Epoch 7/80
 - 0s - loss: 1.2719 - val_loss: 0.7028
AUC: 0.8321

Epoch 8/80
 - 0s - loss: 1.1845 - val_loss: 0.6925
AUC: 0.8363

Epoch 9/80
 - 0s - loss: 1.1399 - val_loss: 0.7002
AUC: 0.8376

Epoch 10/80
 - 0s - loss: 1.1239 - val_loss: 0.6757
AUC: 0.8411

Epoch 11/80
 - 0s - loss: 1.1014 - val_loss: 0.6562
AUC: 0.8418

Epoch 12/80
 - 0s - loss: 1.0879 - val_loss: 0.6219
AUC: 0.8426

Epoch 13/80
 - 0s - loss: 1.0871 - val_loss: 0.6985
AUC: 0.8459

Epoch 14/80
 - 0s - loss: 1.0700 - val_loss: 0.6750
AUC: 0.8461

Epoch 15/80
 - 0s - loss: 1.0626 - val_loss: 0.6163
AUC: 0.8462

Epoch 16/80
 - 0s - loss: 1.0548 - val_loss: 0.6017
AUC: 0.8466

Epoch 17/80
 - 0s - loss: 1.0475 - val_loss: 0.6357
AUC: 0.8487

Epoch 18/80
 - 0s - loss: 1.0456 - val_loss: 0.6498
AUC: 0.8492

Epoch 19/80
 - 0s - loss: 1.0391 - val_loss: 0.5998
AUC: 0.8500

Epoch 20/80
 - 0s - loss: 1.0351 - val_loss: 0.6896
AUC: 0.8511

Epoch 21/80
 - 0s - loss: 1.0269 - val_loss: 0.6568
AUC: 0.8504

Epoch 22/80
 - 0s - loss: 1.0283 - val_loss: 0.6896
AUC: 0.8513

Epoch 23/80
 - 0s - loss: 1.0197 - val_loss: 0.6116
AUC: 0.8510

Epoch 24/80
 - 0s - loss: 1.0173 - val_loss: 0.6574
AUC: 0.8520

Epoch 25/80
 - 0s - loss: 1.0105 - val_loss: 0.6471
AUC: 0.8531

Epoch 26/80
 - 0s - loss: 1.0086 - val_loss: 0.6378
AUC: 0.8521

Epoch 27/80
 - 0s - loss: 1.0019 - val_loss: 0.6506
AUC: 0.8527

Epoch 28/80
 - 0s - loss: 1.0057 - val_loss: 0.6279
AUC: 0.8529

Epoch 29/80
 - 0s - loss: 1.0023 - val_loss: 0.6738
AUC: 0.8538

Epoch 30/80
 - 0s - loss: 0.9918 - val_loss: 0.6045
AUC: 0.8530

Epoch 31/80
 - 0s - loss: 0.9939 - val_loss: 0.6488
AUC: 0.8541

Epoch 32/80
 - 0s - loss: 0.9941 - val_loss: 0.6207
AUC: 0.8533

Epoch 33/80
 - 0s - loss: 0.9914 - val_loss: 0.6197
AUC: 0.8536

Epoch 34/80
 - 0s - loss: 0.9855 - val_loss: 0.6076
AUC: 0.8536

Epoch 35/80
 - 0s - loss: 0.9904 - val_loss: 0.6108
AUC: 0.8533

Epoch 36/80
 - 0s - loss: 0.9931 - val_loss: 0.6377
AUC: 0.8540

Epoch 37/80
 - 0s - loss: 0.9894 - val_loss: 0.6345
AUC: 0.8543

Epoch 38/80
 - 0s - loss: 0.9863 - val_loss: 0.6162
AUC: 0.8540

Epoch 39/80
 - 0s - loss: 0.9870 - val_loss: 0.6117
AUC: 0.8540

Epoch 40/80
 - 0s - loss: 0.9876 - val_loss: 0.6221
AUC: 0.8542

Epoch 41/80
 - 0s - loss: 0.9830 - val_loss: 0.6286
AUC: 0.8542

Epoch 42/80
 - 0s - loss: 0.9873 - val_loss: 0.6274
AUC: 0.8542

Epoch 43/80
 - 0s - loss: 0.9878 - val_loss: 0.6246
AUC: 0.8541

Epoch 44/80
 - 0s - loss: 0.9881 - val_loss: 0.6224
AUC: 0.8541

Epoch 45/80
 - 0s - loss: 0.9873 - val_loss: 0.6255
AUC: 0.8541

Epoch 46/80
 - 0s - loss: 0.9895 - val_loss: 0.6249
AUC: 0.8542

Epoch 47/80
 - 0s - loss: 0.9877 - val_loss: 0.6314
AUC: 0.8543

Epoch 48/80
 - 0s - loss: 0.9855 - val_loss: 0.6281
AUC: 0.8542

Epoch 49/80
 - 0s - loss: 0.9897 - val_loss: 0.6221
AUC: 0.8541

Train on 28553 samples, validate on 7139 samples
Epoch 1/30
 - 1s - loss: 0.9820 - val_loss: 0.6243
AUC: 0.8543

Epoch 2/30
 - 0s - loss: 0.9872 - val_loss: 0.6383
AUC: 0.8546

Epoch 3/30
 - 0s - loss: 0.9854 - val_loss: 0.6108
AUC: 0.8542

Epoch 4/30
 - 0s - loss: 0.9866 - val_loss: 0.6105
AUC: 0.8544

Epoch 5/30
 - 0s - loss: 0.9819 - val_loss: 0.6251
AUC: 0.8548

Epoch 6/30
 - 0s - loss: 0.9842 - val_loss: 0.6166
AUC: 0.8549

Epoch 7/30
 - 0s - loss: 0.9806 - val_loss: 0.6139
AUC: 0.8551

Epoch 8/30
 - 0s - loss: 0.9788 - val_loss: 0.6326
AUC: 0.8555

Epoch 9/30
 - 0s - loss: 0.9795 - val_loss: 0.6282
AUC: 0.8555

Epoch 10/30
 - 0s - loss: 0.9757 - val_loss: 0.6162
AUC: 0.8553

Epoch 11/30
 - 0s - loss: 0.9740 - val_loss: 0.6071
AUC: 0.8553

Epoch 12/30
 - 0s - loss: 0.9713 - val_loss: 0.6091
AUC: 0.8557

Epoch 13/30
 - 0s - loss: 0.9694 - val_loss: 0.6137
AUC: 0.8559

Epoch 14/30
 - 0s - loss: 0.9736 - val_loss: 0.6196
AUC: 0.8559

Epoch 15/30
 - 0s - loss: 0.9656 - val_loss: 0.6158
AUC: 0.8558

Epoch 16/30
 - 0s - loss: 0.9653 - val_loss: 0.6240
AUC: 0.8560

Epoch 17/30
 - 0s - loss: 0.9676 - val_loss: 0.6242
AUC: 0.8562

Epoch 18/30
 - 0s - loss: 0.9711 - val_loss: 0.6245
AUC: 0.8564

Epoch 19/30
 - 0s - loss: 0.9584 - val_loss: 0.6333
AUC: 0.8566

Epoch 20/30
 - 0s - loss: 0.9677 - val_loss: 0.6220
AUC: 0.8565

Epoch 21/30
 - 0s - loss: 0.9589 - val_loss: 0.6089
AUC: 0.8563

Epoch 22/30
 - 0s - loss: 0.9605 - val_loss: 0.6117
AUC: 0.8564

Epoch 23/30
 - 0s - loss: 0.9619 - val_loss: 0.6143
AUC: 0.8564

Epoch 24/30
 - 0s - loss: 0.9583 - val_loss: 0.6150
AUC: 0.8565

Epoch 25/30
 - 0s - loss: 0.9628 - val_loss: 0.6160
AUC: 0.8565

Epoch 26/30
 - 0s - loss: 0.9593 - val_loss: 0.6164
AUC: 0.8566

Epoch 27/30
 - 0s - loss: 0.9568 - val_loss: 0.6107
AUC: 0.8565

Epoch 28/30
 - 0s - loss: 0.9588 - val_loss: 0.6119
AUC: 0.8565

Epoch 29/30
 - 0s - loss: 0.9562 - val_loss: 0.6089
AUC: 0.8565

Epoch 30/30
 - 0s - loss: 0.9586 - val_loss: 0.6138
Using TensorFlow backend.
AUC: 0.8566

2019-03-08 12:53:02.812550: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:53:02.976862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:53:02.976907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:53:03.263260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:53:03.263315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:53:03.263324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:53:03.263608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36264 rows...
Finished. It takes 5.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4800
Epoch 2/80
 - 3s - loss: 0.1111
Epoch 3/80
 - 3s - loss: 0.1008
Epoch 4/80
 - 3s - loss: 0.0909
Epoch 5/80
 - 3s - loss: 0.0805
Epoch 6/80
 - 3s - loss: 0.0726
Epoch 7/80
 - 3s - loss: 0.0663
Epoch 8/80
 - 3s - loss: 0.0611
Epoch 9/80
 - 3s - loss: 0.0568
Epoch 10/80
 - 3s - loss: 0.0533
Epoch 11/80
 - 3s - loss: 0.0503
Epoch 12/80
 - 3s - loss: 0.0479
Epoch 13/80
 - 3s - loss: 0.0458
Epoch 14/80
 - 3s - loss: 0.0441
Epoch 15/80
 - 3s - loss: 0.0428
Epoch 16/80
 - 3s - loss: 0.0417
Epoch 17/80
 - 3s - loss: 0.0408
Epoch 18/80
 - 3s - loss: 0.0400
Epoch 19/80
 - 3s - loss: 0.0394
Epoch 20/80
 - 3s - loss: 0.0389
Epoch 21/80
 - 3s - loss: 0.0385
Epoch 22/80
 - 3s - loss: 0.0382
Epoch 23/80
 - 3s - loss: 0.0379
Epoch 24/80
 - 3s - loss: 0.0376
Epoch 25/80
 - 3s - loss: 0.0374
Epoch 26/80
 - 3s - loss: 0.0372
Epoch 27/80
 - 3s - loss: 0.0371
Epoch 28/80
 - 3s - loss: 0.0369
Epoch 29/80
 - 3s - loss: 0.0368
Epoch 30/80
 - 3s - loss: 0.0367
Epoch 31/80
 - 3s - loss: 0.0366
Epoch 32/80
 - 3s - loss: 0.0364
Epoch 33/80
 - 3s - loss: 0.0364
Epoch 34/80
 - 3s - loss: 0.0363
Epoch 35/80
 - 3s - loss: 0.0362
Epoch 36/80
 - 3s - loss: 0.0362
Epoch 37/80
 - 3s - loss: 0.0361
Epoch 38/80
 - 3s - loss: 0.0360
Epoch 39/80
 - 3s - loss: 0.0360
Epoch 40/80
 - 3s - loss: 0.0359
Epoch 41/80
 - 3s - loss: 0.0359
Epoch 42/80
 - 3s - loss: 0.0359
Epoch 43/80
 - 3s - loss: 0.0358
Epoch 44/80
 - 3s - loss: 0.0358
Epoch 45/80
 - 3s - loss: 0.0357
Epoch 46/80
 - 3s - loss: 0.0357
Epoch 47/80
 - 3s - loss: 0.0357
Epoch 48/80
 - 3s - loss: 0.0356
Epoch 49/80
 - 3s - loss: 0.0356
Epoch 50/80
 - 3s - loss: 0.0356
Epoch 51/80
 - 3s - loss: 0.0345
Epoch 52/80
 - 3s - loss: 0.0343
Epoch 53/80
 - 3s - loss: 0.0343
Epoch 54/80
 - 3s - loss: 0.0343
Epoch 55/80
 - 3s - loss: 0.0343
Epoch 56/80
 - 3s - loss: 0.0340
Epoch 57/80
 - 3s - loss: 0.0340
Epoch 58/80
 - 3s - loss: 0.0340
Epoch 59/80
 - 3s - loss: 0.0340
Epoch 60/80
 - 3s - loss: 0.0339
Epoch 61/80
 - 3s - loss: 0.0339
Epoch 62/80
 - 3s - loss: 0.0339
Epoch 63/80
 - 3s - loss: 0.0339
Epoch 64/80
 - 3s - loss: 0.0339
Epoch 65/80
 - 3s - loss: 0.0339
Epoch 66/80
 - 3s - loss: 0.0339
Epoch 67/80
 - 3s - loss: 0.0339
Epoch 68/80
 - 3s - loss: 0.0339
Epoch 69/80
 - 3s - loss: 0.0339
Epoch 70/80
 - 3s - loss: 0.0339
Epoch 71/80
 - 3s - loss: 0.0339
Epoch 72/80
 - 3s - loss: 0.0339
Epoch 73/80
 - 3s - loss: 0.0339
Epoch 74/80
 - 3s - loss: 0.0339
Epoch 75/80
 - 3s - loss: 0.0339
Epoch 76/80
 - 3s - loss: 0.0339
Epoch 77/80
 - 3s - loss: 0.0339
Epoch 78/80
 - 3s - loss: 0.0339
Epoch 79/80
 - 3s - loss: 0.0339
Epoch 80/80
 - 3s - loss: 0.0339
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 29011 samples, validate on 7253 samples
Epoch 1/80
 - 1s - loss: 3.8998 - val_loss: 1.4917
AUC: 0.7921

Epoch 2/80
 - 0s - loss: 2.3950 - val_loss: 0.8964
AUC: 0.8109

Epoch 3/80
 - 0s - loss: 1.6802 - val_loss: 0.7950
AUC: 0.8146

Epoch 4/80
 - 0s - loss: 1.3554 - val_loss: 0.6901
AUC: 0.8262

Epoch 5/80
 - 0s - loss: 1.2326 - val_loss: 0.8307
AUC: 0.8340

Epoch 6/80
 - 0s - loss: 1.1745 - val_loss: 0.7290
AUC: 0.8370

Epoch 7/80
 - 0s - loss: 1.1444 - val_loss: 0.6809
AUC: 0.8418

Epoch 8/80
 - 0s - loss: 1.1198 - val_loss: 0.6555
AUC: 0.8459

Epoch 9/80
 - 0s - loss: 1.1094 - val_loss: 0.6843
AUC: 0.8464

Epoch 10/80
 - 0s - loss: 1.0823 - val_loss: 0.7305
AUC: 0.8505

Epoch 11/80
 - 0s - loss: 1.0877 - val_loss: 0.6611
AUC: 0.8524

Epoch 12/80
 - 0s - loss: 1.0748 - val_loss: 0.6346
AUC: 0.8535

Epoch 13/80
 - 0s - loss: 1.0678 - val_loss: 0.6200
AUC: 0.8543

Epoch 14/80
 - 0s - loss: 1.0610 - val_loss: 0.7039
AUC: 0.8569

Epoch 15/80
 - 0s - loss: 1.0558 - val_loss: 0.6109
AUC: 0.8573

Epoch 16/80
 - 0s - loss: 1.0537 - val_loss: 0.6974
AUC: 0.8588

Epoch 17/80
 - 0s - loss: 1.0445 - val_loss: 0.5704
AUC: 0.8573

Epoch 18/80
 - 0s - loss: 1.0422 - val_loss: 0.6165
AUC: 0.8595

Epoch 19/80
 - 0s - loss: 1.0338 - val_loss: 0.6649
AUC: 0.8601

Epoch 20/80
 - 0s - loss: 1.0304 - val_loss: 0.6261
AUC: 0.8611

Epoch 21/80
 - 0s - loss: 1.0261 - val_loss: 0.5955
AUC: 0.8616

Epoch 22/80
 - 0s - loss: 1.0249 - val_loss: 0.6037
AUC: 0.8618

Epoch 23/80
 - 0s - loss: 1.0260 - val_loss: 0.6216
AUC: 0.8603

Epoch 24/80
 - 0s - loss: 1.0155 - val_loss: 0.6716
AUC: 0.8639

Epoch 25/80
 - 0s - loss: 1.0195 - val_loss: 0.6509
AUC: 0.8639

Epoch 26/80
 - 0s - loss: 1.0198 - val_loss: 0.6790
AUC: 0.8650

Epoch 27/80
 - 0s - loss: 1.0112 - val_loss: 0.6151
AUC: 0.8657

Epoch 28/80
 - 0s - loss: 1.0050 - val_loss: 0.6552
AUC: 0.8657

Epoch 29/80
 - 0s - loss: 0.9988 - val_loss: 0.6222
AUC: 0.8650

Epoch 30/80
 - 0s - loss: 0.9993 - val_loss: 0.6164
AUC: 0.8649

Epoch 31/80
 - 0s - loss: 0.9961 - val_loss: 0.6321
AUC: 0.8655

Epoch 32/80
 - 0s - loss: 0.9975 - val_loss: 0.6224
AUC: 0.8658

Epoch 33/80
 - 0s - loss: 0.9974 - val_loss: 0.6075
AUC: 0.8656

Epoch 34/80
 - 0s - loss: 0.9933 - val_loss: 0.6328
AUC: 0.8660

Epoch 35/80
 - 0s - loss: 0.9947 - val_loss: 0.6172
AUC: 0.8659

Epoch 36/80
 - 0s - loss: 0.9950 - val_loss: 0.6043
AUC: 0.8659

Epoch 37/80
 - 0s - loss: 0.9970 - val_loss: 0.6178
AUC: 0.8657

Epoch 38/80
 - 0s - loss: 0.9897 - val_loss: 0.6099
AUC: 0.8657

Epoch 39/80
 - 0s - loss: 0.9947 - val_loss: 0.6120
AUC: 0.8658

Epoch 40/80
 - 0s - loss: 0.9925 - val_loss: 0.6141
AUC: 0.8659

Epoch 41/80
 - 0s - loss: 0.9866 - val_loss: 0.6085
AUC: 0.8658

Epoch 42/80
 - 0s - loss: 0.9876 - val_loss: 0.6029
AUC: 0.8657

Epoch 43/80
 - 0s - loss: 0.9941 - val_loss: 0.6079
AUC: 0.8657

Epoch 44/80
 - 0s - loss: 0.9874 - val_loss: 0.6038
AUC: 0.8658

Epoch 45/80
 - 0s - loss: 0.9897 - val_loss: 0.6161
AUC: 0.8659

Epoch 46/80
 - 0s - loss: 0.9911 - val_loss: 0.6108
AUC: 0.8659

Epoch 47/80
 - 0s - loss: 0.9921 - val_loss: 0.6137
AUC: 0.8658

Train on 29011 samples, validate on 7253 samples
Epoch 1/30
 - 1s - loss: 0.9978 - val_loss: 0.6105
AUC: 0.8658

Epoch 2/30
 - 0s - loss: 0.9924 - val_loss: 0.6156
AUC: 0.8660

Epoch 3/30
 - 0s - loss: 0.9881 - val_loss: 0.6164
AUC: 0.8664

Epoch 4/30
 - 0s - loss: 0.9866 - val_loss: 0.6040
AUC: 0.8665

Epoch 5/30
 - 0s - loss: 0.9881 - val_loss: 0.6091
AUC: 0.8665

Epoch 6/30
 - 0s - loss: 0.9826 - val_loss: 0.6045
AUC: 0.8666

Epoch 7/30
 - 0s - loss: 0.9832 - val_loss: 0.6213
AUC: 0.8669

Epoch 8/30
 - 0s - loss: 0.9801 - val_loss: 0.5959
AUC: 0.8668

Epoch 9/30
 - 0s - loss: 0.9817 - val_loss: 0.6134
AUC: 0.8670

Epoch 10/30
 - 0s - loss: 0.9758 - val_loss: 0.6099
AUC: 0.8673

Epoch 11/30
 - 0s - loss: 0.9770 - val_loss: 0.6004
AUC: 0.8674

Epoch 12/30
 - 0s - loss: 0.9775 - val_loss: 0.6146
AUC: 0.8676

Epoch 13/30
 - 0s - loss: 0.9744 - val_loss: 0.6160
AUC: 0.8678

Epoch 14/30
 - 0s - loss: 0.9740 - val_loss: 0.6039
AUC: 0.8680

Epoch 15/30
 - 0s - loss: 0.9687 - val_loss: 0.6110
AUC: 0.8681

Epoch 16/30
 - 0s - loss: 0.9671 - val_loss: 0.6064
AUC: 0.8684

Epoch 17/30
 - 0s - loss: 0.9705 - val_loss: 0.6137
AUC: 0.8686

Epoch 18/30
 - 0s - loss: 0.9603 - val_loss: 0.6002
AUC: 0.8684

Epoch 19/30
 - 0s - loss: 0.9645 - val_loss: 0.5964
AUC: 0.8684

Epoch 20/30
 - 0s - loss: 0.9650 - val_loss: 0.5994
AUC: 0.8685

Epoch 21/30
 - 0s - loss: 0.9627 - val_loss: 0.5938
AUC: 0.8685

Epoch 22/30
 - 0s - loss: 0.9642 - val_loss: 0.5960
AUC: 0.8686

Epoch 23/30
 - 0s - loss: 0.9671 - val_loss: 0.5993
AUC: 0.8687

Epoch 24/30
 - 0s - loss: 0.9605 - val_loss: 0.5955
AUC: 0.8686

Epoch 25/30
 - 0s - loss: 0.9642 - val_loss: 0.5996
AUC: 0.8687

Epoch 26/30
 - 0s - loss: 0.9678 - val_loss: 0.6004
AUC: 0.8688

Epoch 27/30
 - 0s - loss: 0.9574 - val_loss: 0.5960
AUC: 0.8688

Epoch 28/30
 - 0s - loss: 0.9641 - val_loss: 0.5955
AUC: 0.8688

Epoch 29/30
 - 0s - loss: 0.9639 - val_loss: 0.5997
AUC: 0.8689

Epoch 30/30
 - 0s - loss: 0.9611 - val_loss: 0.5932
Using TensorFlow backend.
AUC: 0.8689

2019-03-08 12:58:17.233939: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 12:58:17.395643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 12:58:17.395687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 12:58:17.680211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 12:58:17.680264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 12:58:17.680273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 12:58:17.680564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36115 rows...
Finished. It takes 5.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.6169
Epoch 2/80
 - 2s - loss: 0.1359
Epoch 3/80
 - 2s - loss: 0.1168
Epoch 4/80
 - 2s - loss: 0.1066
Epoch 5/80
 - 2s - loss: 0.0997
Epoch 6/80
 - 2s - loss: 0.0941
Epoch 7/80
 - 2s - loss: 0.0885
Epoch 8/80
 - 2s - loss: 0.0824
Epoch 9/80
 - 2s - loss: 0.0757
Epoch 10/80
 - 2s - loss: 0.0695
Epoch 11/80
 - 2s - loss: 0.0645
Epoch 12/80
 - 2s - loss: 0.0606
Epoch 13/80
 - 2s - loss: 0.0573
Epoch 14/80
 - 2s - loss: 0.0546
Epoch 15/80
 - 2s - loss: 0.0524
Epoch 16/80
 - 2s - loss: 0.0506
Epoch 17/80
 - 2s - loss: 0.0491
Epoch 18/80
 - 2s - loss: 0.0479
Epoch 19/80
 - 2s - loss: 0.0469
Epoch 20/80
 - 2s - loss: 0.0462
Epoch 21/80
 - 2s - loss: 0.0455
Epoch 22/80
 - 2s - loss: 0.0450
Epoch 23/80
 - 2s - loss: 0.0445
Epoch 24/80
 - 2s - loss: 0.0441
Epoch 25/80
 - 2s - loss: 0.0438
Epoch 26/80
 - 2s - loss: 0.0435
Epoch 27/80
 - 2s - loss: 0.0433
Epoch 28/80
 - 2s - loss: 0.0431
Epoch 29/80
 - 2s - loss: 0.0429
Epoch 30/80
 - 2s - loss: 0.0427
Epoch 31/80
 - 2s - loss: 0.0426
Epoch 32/80
 - 2s - loss: 0.0424
Epoch 33/80
 - 2s - loss: 0.0423
Epoch 34/80
 - 2s - loss: 0.0422
Epoch 35/80
 - 2s - loss: 0.0421
Epoch 36/80
 - 2s - loss: 0.0420
Epoch 37/80
 - 2s - loss: 0.0420
Epoch 38/80
 - 2s - loss: 0.0419
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:00:09.432602: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:00:09.594203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:00:09.594257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:00:09.886351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:00:09.886404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:00:09.886413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:00:09.886696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.7 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1537
Epoch 2/80
 - 2s - loss: 0.2191
Epoch 3/80
 - 2s - loss: 0.1752
Epoch 4/80
 - 2s - loss: 0.1671
Epoch 5/80
 - 2s - loss: 0.1610
Epoch 6/80
 - 2s - loss: 0.1532
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:00:42.224067: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:00:42.389886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:00:42.389933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:00:42.676321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:00:42.676389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:00:42.676398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:00:42.676675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36278 rows...
Finished. It takes 5.3 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4487
Epoch 2/80
 - 3s - loss: 0.1079
Epoch 3/80
 - 3s - loss: 0.0997
Epoch 4/80
 - 3s - loss: 0.0924
Epoch 5/80
 - 3s - loss: 0.0832
Epoch 6/80
 - 3s - loss: 0.0743
Epoch 7/80
 - 3s - loss: 0.0670
Epoch 8/80
 - 3s - loss: 0.0614
Epoch 9/80
 - 3s - loss: 0.0569
Epoch 10/80
 - 3s - loss: 0.0531
Epoch 11/80
 - 3s - loss: 0.0499
Epoch 12/80
 - 3s - loss: 0.0472
Epoch 13/80
 - 3s - loss: 0.0449
Epoch 14/80
 - 3s - loss: 0.0432
Epoch 15/80
 - 3s - loss: 0.0417
Epoch 16/80
 - 3s - loss: 0.0406
Epoch 17/80
 - 3s - loss: 0.0398
Epoch 18/80
 - 3s - loss: 0.0390
Epoch 19/80
 - 3s - loss: 0.0385
Epoch 20/80
 - 3s - loss: 0.0380
Epoch 21/80
 - 3s - loss: 0.0376
Epoch 22/80
 - 3s - loss: 0.0372
Epoch 23/80
 - 3s - loss: 0.0369
Epoch 24/80
 - 3s - loss: 0.0367
Epoch 25/80
 - 3s - loss: 0.0365
Epoch 26/80
 - 3s - loss: 0.0363
Epoch 27/80
 - 3s - loss: 0.0361
Epoch 28/80
 - 3s - loss: 0.0360
Epoch 29/80
 - 3s - loss: 0.0358
Epoch 30/80
 - 3s - loss: 0.0357
Epoch 31/80
 - 3s - loss: 0.0356
Epoch 32/80
 - 3s - loss: 0.0355
Epoch 33/80
 - 3s - loss: 0.0355
Epoch 34/80
 - 3s - loss: 0.0354
Epoch 35/80
 - 3s - loss: 0.0353
Epoch 36/80
 - 3s - loss: 0.0353
Epoch 37/80
 - 3s - loss: 0.0352
Epoch 38/80
 - 3s - loss: 0.0351
Epoch 39/80
 - 3s - loss: 0.0351
Epoch 40/80
 - 3s - loss: 0.0351
Epoch 41/80
 - 3s - loss: 0.0350
Epoch 42/80
 - 3s - loss: 0.0350
Epoch 43/80
 - 3s - loss: 0.0349
Epoch 44/80
 - 3s - loss: 0.0349
Epoch 45/80
 - 3s - loss: 0.0338
Epoch 46/80
 - 3s - loss: 0.0336
Epoch 47/80
 - 3s - loss: 0.0336
Epoch 48/80
 - 3s - loss: 0.0336
Epoch 49/80
 - 3s - loss: 0.0336
Epoch 50/80
 - 3s - loss: 0.0333
Epoch 51/80
 - 3s - loss: 0.0333
Epoch 52/80
 - 3s - loss: 0.0333
Epoch 53/80
 - 3s - loss: 0.0333
Epoch 54/80
 - 3s - loss: 0.0332
Epoch 55/80
 - 3s - loss: 0.0332
Epoch 56/80
 - 3s - loss: 0.0332
Epoch 57/80
 - 3s - loss: 0.0332
Epoch 58/80
 - 3s - loss: 0.0332
Epoch 59/80
 - 3s - loss: 0.0332
Epoch 60/80
 - 3s - loss: 0.0332
Epoch 61/80
 - 3s - loss: 0.0332
Epoch 62/80
 - 3s - loss: 0.0332
Epoch 63/80
 - 3s - loss: 0.0332
Epoch 64/80
 - 3s - loss: 0.0332
Epoch 65/80
 - 3s - loss: 0.0332
Epoch 66/80
 - 3s - loss: 0.0332
Epoch 67/80
 - 3s - loss: 0.0332
Epoch 68/80
 - 3s - loss: 0.0332
Epoch 69/80
 - 3s - loss: 0.0332
Epoch 70/80
 - 3s - loss: 0.0332
Epoch 71/80
 - 3s - loss: 0.0332
Epoch 72/80
 - 3s - loss: 0.0332
Epoch 73/80
 - 3s - loss: 0.0332
Epoch 74/80
 - 3s - loss: 0.0332
Epoch 75/80
 - 3s - loss: 0.0332
Epoch 76/80
 - 3s - loss: 0.0332
Epoch 77/80
 - 3s - loss: 0.0332
Epoch 78/80
 - 3s - loss: 0.0332
Epoch 79/80
 - 3s - loss: 0.0332
Epoch 80/80
 - 3s - loss: 0.0332
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 29022 samples, validate on 7256 samples
Epoch 1/80
 - 1s - loss: 4.4854 - val_loss: 1.3016
AUC: 0.8040

Epoch 2/80
 - 0s - loss: 2.7085 - val_loss: 1.2316
AUC: 0.8284

Epoch 3/80
 - 0s - loss: 1.7724 - val_loss: 0.7392
AUC: 0.8321

Epoch 4/80
 - 0s - loss: 1.3895 - val_loss: 0.7413
AUC: 0.8361

Epoch 5/80
 - 0s - loss: 1.2344 - val_loss: 0.7809
AUC: 0.8408

Epoch 6/80
 - 0s - loss: 1.1694 - val_loss: 0.7027
AUC: 0.8441

Epoch 7/80
 - 0s - loss: 1.1322 - val_loss: 0.6771
AUC: 0.8456

Epoch 8/80
 - 0s - loss: 1.1252 - val_loss: 0.6688
AUC: 0.8488

Epoch 9/80
 - 0s - loss: 1.1120 - val_loss: 0.6472
AUC: 0.8501

Epoch 10/80
 - 0s - loss: 1.0887 - val_loss: 0.6084
AUC: 0.8510

Epoch 11/80
 - 0s - loss: 1.0776 - val_loss: 0.6369
AUC: 0.8535

Epoch 12/80
 - 0s - loss: 1.0730 - val_loss: 0.6154
AUC: 0.8539

Epoch 13/80
 - 0s - loss: 1.0660 - val_loss: 0.6779
AUC: 0.8555

Epoch 14/80
 - 0s - loss: 1.0555 - val_loss: 0.7073
AUC: 0.8551

Epoch 15/80
 - 0s - loss: 1.0516 - val_loss: 0.5604
AUC: 0.8551

Epoch 16/80
 - 0s - loss: 1.0485 - val_loss: 0.6720
AUC: 0.8571

Epoch 17/80
 - 0s - loss: 1.0433 - val_loss: 0.6045
AUC: 0.8567

Epoch 18/80
 - 0s - loss: 1.0334 - val_loss: 0.5738
AUC: 0.8567

Epoch 19/80
 - 0s - loss: 1.0299 - val_loss: 0.6269
AUC: 0.8583

Epoch 20/80
 - 0s - loss: 1.0307 - val_loss: 0.6399
AUC: 0.8594

Epoch 21/80
 - 0s - loss: 1.0257 - val_loss: 0.6063
AUC: 0.8596

Epoch 22/80
 - 0s - loss: 1.0177 - val_loss: 0.6069
AUC: 0.8603

Epoch 23/80
 - 0s - loss: 1.0236 - val_loss: 0.7338
AUC: 0.8591

Epoch 24/80
 - 0s - loss: 1.0198 - val_loss: 0.6446
AUC: 0.8609

Epoch 25/80
 - 0s - loss: 1.0111 - val_loss: 0.5942
AUC: 0.8610

Epoch 26/80
 - 0s - loss: 1.0072 - val_loss: 0.6138
AUC: 0.8609

Epoch 27/80
 - 0s - loss: 1.0149 - val_loss: 0.6184
AUC: 0.8609

Epoch 28/80
 - 0s - loss: 1.0062 - val_loss: 0.6213
AUC: 0.8612

Epoch 29/80
 - 0s - loss: 1.0022 - val_loss: 0.6187
AUC: 0.8612

Epoch 30/80
 - 0s - loss: 1.0072 - val_loss: 0.6182
AUC: 0.8611

Epoch 31/80
 - 0s - loss: 1.0013 - val_loss: 0.6295
AUC: 0.8610

Epoch 32/80
 - 0s - loss: 1.0066 - val_loss: 0.6234
AUC: 0.8610

Epoch 33/80
 - 0s - loss: 0.9974 - val_loss: 0.6147
AUC: 0.8612

Epoch 34/80
 - 0s - loss: 0.9996 - val_loss: 0.6145
AUC: 0.8613

Epoch 35/80
 - 0s - loss: 1.0018 - val_loss: 0.6153
AUC: 0.8613

Epoch 36/80
 - 0s - loss: 1.0000 - val_loss: 0.6143
AUC: 0.8613

Epoch 37/80
 - 0s - loss: 0.9971 - val_loss: 0.6162
AUC: 0.8613

Epoch 38/80
 - 0s - loss: 0.9994 - val_loss: 0.6059
AUC: 0.8613

Epoch 39/80
 - 0s - loss: 0.9984 - val_loss: 0.6112
AUC: 0.8613

Epoch 40/80
 - 0s - loss: 1.0000 - val_loss: 0.6134
AUC: 0.8614

Epoch 41/80
 - 0s - loss: 1.0006 - val_loss: 0.6132
AUC: 0.8614

Epoch 42/80
 - 0s - loss: 1.0013 - val_loss: 0.6117
AUC: 0.8613

Epoch 43/80
 - 0s - loss: 0.9975 - val_loss: 0.6062
AUC: 0.8613

Epoch 44/80
 - 0s - loss: 0.9973 - val_loss: 0.6061
AUC: 0.8613

Epoch 45/80
 - 0s - loss: 0.9975 - val_loss: 0.6162
AUC: 0.8614

Train on 29022 samples, validate on 7256 samples
Epoch 1/30
 - 1s - loss: 0.9987 - val_loss: 0.6165
AUC: 0.8613

Epoch 2/30
 - 0s - loss: 0.9988 - val_loss: 0.6107
AUC: 0.8616

Epoch 3/30
 - 0s - loss: 0.9953 - val_loss: 0.6145
AUC: 0.8617

Epoch 4/30
 - 0s - loss: 0.9885 - val_loss: 0.6046
AUC: 0.8618

Epoch 5/30
 - 0s - loss: 0.9921 - val_loss: 0.6239
AUC: 0.8620

Epoch 6/30
 - 0s - loss: 0.9902 - val_loss: 0.6128
AUC: 0.8622

Epoch 7/30
 - 0s - loss: 0.9866 - val_loss: 0.6124
AUC: 0.8625

Epoch 8/30
 - 0s - loss: 0.9918 - val_loss: 0.5908
AUC: 0.8625

Epoch 9/30
 - 0s - loss: 0.9917 - val_loss: 0.6060
AUC: 0.8627

Epoch 10/30
 - 0s - loss: 0.9907 - val_loss: 0.6003
AUC: 0.8628

Epoch 11/30
 - 0s - loss: 0.9843 - val_loss: 0.6409
AUC: 0.8630

Epoch 12/30
 - 0s - loss: 0.9801 - val_loss: 0.5931
AUC: 0.8632

Epoch 13/30
 - 0s - loss: 0.9785 - val_loss: 0.5857
AUC: 0.8634

Epoch 14/30
 - 0s - loss: 0.9844 - val_loss: 0.5945
AUC: 0.8636

Epoch 15/30
 - 0s - loss: 0.9750 - val_loss: 0.5872
AUC: 0.8633

Epoch 16/30
 - 0s - loss: 0.9733 - val_loss: 0.6106
AUC: 0.8638

Epoch 17/30
 - 0s - loss: 0.9718 - val_loss: 0.6029
AUC: 0.8638

Epoch 18/30
 - 0s - loss: 0.9705 - val_loss: 0.6011
AUC: 0.8642

Epoch 19/30
 - 0s - loss: 0.9699 - val_loss: 0.5903
AUC: 0.8643

Epoch 20/30
 - 0s - loss: 0.9635 - val_loss: 0.5835
AUC: 0.8642

Epoch 21/30
 - 0s - loss: 0.9679 - val_loss: 0.5937
AUC: 0.8643

Epoch 22/30
 - 0s - loss: 0.9624 - val_loss: 0.6058
AUC: 0.8645

Epoch 23/30
 - 0s - loss: 0.9575 - val_loss: 0.5950
AUC: 0.8645

Epoch 24/30
 - 0s - loss: 0.9617 - val_loss: 0.6013
AUC: 0.8648

Epoch 25/30
 - 0s - loss: 0.9633 - val_loss: 0.6123
AUC: 0.8649

Epoch 26/30
 - 0s - loss: 0.9635 - val_loss: 0.5962
AUC: 0.8650

Epoch 27/30
 - 0s - loss: 0.9632 - val_loss: 0.5976
AUC: 0.8651

Epoch 28/30
 - 0s - loss: 0.9627 - val_loss: 0.5749
AUC: 0.8651

Epoch 29/30
 - 0s - loss: 0.9585 - val_loss: 0.5806
AUC: 0.8654

Epoch 30/30
 - 0s - loss: 0.9546 - val_loss: 0.5780
Using TensorFlow backend.
AUC: 0.8654

2019-03-08 13:06:06.008673: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:06:06.172628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:06:06.172672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:06:06.460519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:06:06.460572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:06:06.460580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:06:06.460834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36194 rows...
Finished. It takes 5.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.5529
Epoch 2/80
 - 3s - loss: 0.1235
Epoch 3/80
 - 3s - loss: 0.1095
Epoch 4/80
 - 3s - loss: 0.0975
Epoch 5/80
 - 3s - loss: 0.0883
Epoch 6/80
 - 3s - loss: 0.0808
Epoch 7/80
 - 3s - loss: 0.0744
Epoch 8/80
 - 3s - loss: 0.0690
Epoch 9/80
 - 3s - loss: 0.0645
Epoch 10/80
 - 3s - loss: 0.0606
Epoch 11/80
 - 3s - loss: 0.0572
Epoch 12/80
 - 3s - loss: 0.0542
Epoch 13/80
 - 3s - loss: 0.0517
Epoch 14/80
 - 3s - loss: 0.0496
Epoch 15/80
 - 3s - loss: 0.0478
Epoch 16/80
 - 3s - loss: 0.0465
Epoch 17/80
 - 3s - loss: 0.0453
Epoch 18/80
 - 3s - loss: 0.0444
Epoch 19/80
 - 3s - loss: 0.0437
Epoch 20/80
 - 3s - loss: 0.0430
Epoch 21/80
 - 3s - loss: 0.0425
Epoch 22/80
 - 3s - loss: 0.0421
Epoch 23/80
 - 3s - loss: 0.0417
Epoch 24/80
 - 3s - loss: 0.0413
Epoch 25/80
 - 3s - loss: 0.0410
Epoch 26/80
 - 3s - loss: 0.0408
Epoch 27/80
 - 3s - loss: 0.0406
Epoch 28/80
 - 3s - loss: 0.0404
Epoch 29/80
 - 3s - loss: 0.0402
Epoch 30/80
 - 3s - loss: 0.0400
Epoch 31/80
 - 3s - loss: 0.0399
Epoch 32/80
 - 3s - loss: 0.0398
Epoch 33/80
 - 3s - loss: 0.0397
Epoch 34/80
 - 3s - loss: 0.0396
Epoch 35/80
 - 3s - loss: 0.0395
Epoch 36/80
 - 3s - loss: 0.0394
Epoch 37/80
 - 3s - loss: 0.0393
Epoch 38/80
 - 3s - loss: 0.0392
Epoch 39/80
 - 3s - loss: 0.0392
Epoch 40/80
 - 3s - loss: 0.0391
Epoch 41/80
 - 3s - loss: 0.0391
Epoch 42/80
 - 3s - loss: 0.0390
Epoch 43/80
 - 3s - loss: 0.0390
Epoch 44/80
 - 3s - loss: 0.0389
Epoch 45/80
 - 3s - loss: 0.0389
Epoch 46/80
 - 3s - loss: 0.0389
Epoch 47/80
 - 3s - loss: 0.0388
Epoch 48/80
 - 3s - loss: 0.0388
Epoch 49/80
 - 3s - loss: 0.0388
Epoch 50/80
 - 3s - loss: 0.0387
Epoch 51/80
 - 3s - loss: 0.0387
Epoch 52/80
 - 3s - loss: 0.0387
Epoch 53/80
 - 3s - loss: 0.0375
Epoch 54/80
 - 3s - loss: 0.0374
Epoch 55/80
 - 3s - loss: 0.0374
Epoch 56/80
 - 3s - loss: 0.0374
Epoch 57/80
 - 3s - loss: 0.0373
Epoch 58/80
 - 3s - loss: 0.0370
Epoch 59/80
 - 3s - loss: 0.0370
Epoch 60/80
 - 3s - loss: 0.0370
Epoch 61/80
 - 3s - loss: 0.0370
Epoch 62/80
 - 3s - loss: 0.0370
Epoch 63/80
 - 3s - loss: 0.0370
Epoch 64/80
 - 3s - loss: 0.0370
Epoch 65/80
 - 3s - loss: 0.0370
Epoch 66/80
 - 3s - loss: 0.0370
Epoch 67/80
 - 3s - loss: 0.0370
Epoch 68/80
 - 3s - loss: 0.0370
Epoch 69/80
 - 3s - loss: 0.0370
Epoch 70/80
 - 3s - loss: 0.0370
Epoch 71/80
 - 3s - loss: 0.0370
Epoch 72/80
 - 3s - loss: 0.0370
Epoch 73/80
 - 3s - loss: 0.0370
Epoch 74/80
 - 3s - loss: 0.0370
Epoch 75/80
 - 3s - loss: 0.0370
Epoch 76/80
 - 3s - loss: 0.0370
Epoch 77/80
 - 3s - loss: 0.0370
Epoch 78/80
 - 3s - loss: 0.0370
Epoch 79/80
 - 3s - loss: 0.0370
Epoch 80/80
 - 3s - loss: 0.0370
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28955 samples, validate on 7239 samples
Epoch 1/80
 - 1s - loss: 3.8690 - val_loss: 1.5404
AUC: 0.7859

Epoch 2/80
 - 0s - loss: 2.5239 - val_loss: 1.0891
AUC: 0.8111

Epoch 3/80
 - 0s - loss: 1.6404 - val_loss: 0.7569
AUC: 0.8251

Epoch 4/80
 - 0s - loss: 1.3485 - val_loss: 0.8486
AUC: 0.8391

Epoch 5/80
 - 0s - loss: 1.2331 - val_loss: 0.7674
AUC: 0.8466

Epoch 6/80
 - 0s - loss: 1.1646 - val_loss: 0.6354
AUC: 0.8506

Epoch 7/80
 - 0s - loss: 1.1301 - val_loss: 0.7703
AUC: 0.8555

Epoch 8/80
 - 0s - loss: 1.1131 - val_loss: 0.6404
AUC: 0.8565

Epoch 9/80
 - 0s - loss: 1.1018 - val_loss: 0.6589
AUC: 0.8588

Epoch 10/80
 - 0s - loss: 1.0876 - val_loss: 0.6395
AUC: 0.8609

Epoch 11/80
 - 0s - loss: 1.0804 - val_loss: 0.6987
AUC: 0.8617

Epoch 12/80
 - 0s - loss: 1.0749 - val_loss: 0.6742
AUC: 0.8635

Epoch 13/80
 - 0s - loss: 1.0656 - val_loss: 0.6301
AUC: 0.8635

Epoch 14/80
 - 0s - loss: 1.0549 - val_loss: 0.6498
AUC: 0.8644

Epoch 15/80
 - 0s - loss: 1.0532 - val_loss: 0.6343
AUC: 0.8658

Epoch 16/80
 - 0s - loss: 1.0442 - val_loss: 0.5828
AUC: 0.8660

Epoch 17/80
 - 0s - loss: 1.0464 - val_loss: 0.6969
AUC: 0.8668

Epoch 18/80
 - 0s - loss: 1.0367 - val_loss: 0.6346
AUC: 0.8670

Epoch 19/80
 - 0s - loss: 1.0282 - val_loss: 0.6532
AUC: 0.8687

Epoch 20/80
 - 0s - loss: 1.0275 - val_loss: 0.6391
AUC: 0.8687

Epoch 21/80
 - 0s - loss: 1.0336 - val_loss: 0.6018
AUC: 0.8686

Epoch 22/80
 - 0s - loss: 1.0223 - val_loss: 0.7808
AUC: 0.8696

Epoch 23/80
 - 0s - loss: 1.0214 - val_loss: 0.6704
AUC: 0.8694

Epoch 24/80
 - 0s - loss: 1.0170 - val_loss: 0.5839
AUC: 0.8683

Epoch 25/80
 - 0s - loss: 1.0125 - val_loss: 0.5876
AUC: 0.8698

Epoch 26/80
 - 0s - loss: 1.0120 - val_loss: 0.6168
AUC: 0.8698

Epoch 27/80
 - 0s - loss: 1.0062 - val_loss: 0.6191
AUC: 0.8704

Epoch 28/80
 - 0s - loss: 0.9994 - val_loss: 0.6218
AUC: 0.8706

Epoch 29/80
 - 0s - loss: 0.9990 - val_loss: 0.6194
AUC: 0.8707

Epoch 30/80
 - 0s - loss: 0.9994 - val_loss: 0.6029
AUC: 0.8709

Epoch 31/80
 - 0s - loss: 1.0017 - val_loss: 0.5950
AUC: 0.8708

Epoch 32/80
 - 0s - loss: 0.9974 - val_loss: 0.6071
AUC: 0.8708

Epoch 33/80
 - 0s - loss: 0.9937 - val_loss: 0.6166
AUC: 0.8710

Epoch 34/80
 - 0s - loss: 0.9993 - val_loss: 0.6206
AUC: 0.8711

Epoch 35/80
 - 0s - loss: 0.9995 - val_loss: 0.6146
AUC: 0.8710

Epoch 36/80
 - 0s - loss: 0.9996 - val_loss: 0.6271
AUC: 0.8710

Epoch 37/80
 - 0s - loss: 0.9930 - val_loss: 0.6128
AUC: 0.8711

Epoch 38/80
 - 0s - loss: 0.9966 - val_loss: 0.6112
AUC: 0.8711

Epoch 39/80
 - 0s - loss: 0.9992 - val_loss: 0.6177
AUC: 0.8712

Epoch 40/80
 - 0s - loss: 0.9926 - val_loss: 0.6146
AUC: 0.8712

Epoch 41/80
 - 0s - loss: 0.9868 - val_loss: 0.6106
AUC: 0.8712

Epoch 42/80
 - 0s - loss: 0.9947 - val_loss: 0.6146
AUC: 0.8712

Epoch 43/80
 - 0s - loss: 0.9929 - val_loss: 0.6126
AUC: 0.8712

Epoch 44/80
 - 0s - loss: 0.9931 - val_loss: 0.6161
AUC: 0.8713

Epoch 45/80
 - 0s - loss: 0.9923 - val_loss: 0.6083
AUC: 0.8712

Epoch 46/80
 - 0s - loss: 0.9927 - val_loss: 0.6183
AUC: 0.8712

Train on 28955 samples, validate on 7239 samples
Epoch 1/30
 - 1s - loss: 0.9944 - val_loss: 0.6027
AUC: 0.8716

Epoch 2/30
 - 0s - loss: 0.9870 - val_loss: 0.6112
AUC: 0.8717

Epoch 3/30
 - 0s - loss: 0.9897 - val_loss: 0.6106
AUC: 0.8718

Epoch 4/30
 - 0s - loss: 0.9889 - val_loss: 0.5997
AUC: 0.8719

Epoch 5/30
 - 0s - loss: 0.9896 - val_loss: 0.6109
AUC: 0.8720

Epoch 6/30
 - 0s - loss: 0.9840 - val_loss: 0.6156
AUC: 0.8721

Epoch 7/30
 - 0s - loss: 0.9852 - val_loss: 0.6131
AUC: 0.8723

Epoch 8/30
 - 0s - loss: 0.9812 - val_loss: 0.6128
AUC: 0.8724

Epoch 9/30
 - 0s - loss: 0.9839 - val_loss: 0.6040
AUC: 0.8727

Epoch 10/30
 - 0s - loss: 0.9761 - val_loss: 0.5932
AUC: 0.8726

Epoch 11/30
 - 0s - loss: 0.9818 - val_loss: 0.5957
AUC: 0.8727

Epoch 12/30
 - 0s - loss: 0.9772 - val_loss: 0.6107
AUC: 0.8730

Epoch 13/30
 - 0s - loss: 0.9696 - val_loss: 0.6191
AUC: 0.8730

Epoch 14/30
 - 0s - loss: 0.9755 - val_loss: 0.5968
AUC: 0.8731

Epoch 15/30
 - 0s - loss: 0.9702 - val_loss: 0.6183
AUC: 0.8735

Epoch 16/30
 - 0s - loss: 0.9671 - val_loss: 0.6142
AUC: 0.8735

Epoch 17/30
 - 0s - loss: 0.9724 - val_loss: 0.5974
AUC: 0.8735

Epoch 18/30
 - 0s - loss: 0.9631 - val_loss: 0.5952
AUC: 0.8736

Epoch 19/30
 - 0s - loss: 0.9676 - val_loss: 0.6005
AUC: 0.8738

Epoch 20/30
 - 0s - loss: 0.9620 - val_loss: 0.6117
AUC: 0.8739

Epoch 21/30
 - 0s - loss: 0.9624 - val_loss: 0.5998
AUC: 0.8738

Epoch 22/30
 - 0s - loss: 0.9633 - val_loss: 0.5981
AUC: 0.8738

Epoch 23/30
 - 0s - loss: 0.9610 - val_loss: 0.5991
AUC: 0.8739

Epoch 24/30
 - 0s - loss: 0.9605 - val_loss: 0.5964
AUC: 0.8739

Epoch 25/30
 - 0s - loss: 0.9641 - val_loss: 0.5988
AUC: 0.8739

Epoch 26/30
 - 0s - loss: 0.9602 - val_loss: 0.5944
AUC: 0.8740

Epoch 27/30
 - 0s - loss: 0.9612 - val_loss: 0.5974
AUC: 0.8740

Epoch 28/30
 - 0s - loss: 0.9585 - val_loss: 0.5970
AUC: 0.8740

Epoch 29/30
 - 0s - loss: 0.9640 - val_loss: 0.5983
AUC: 0.8740

Epoch 30/30
 - 0s - loss: 0.9631 - val_loss: 0.5952
Using TensorFlow backend.
AUC: 0.8740

2019-03-08 13:10:53.443149: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:10:53.607334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:10:53.607378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:10:53.902492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:10:53.902543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:10:53.902553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:10:53.902807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35874 rows...
Finished. It takes 5.1 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9672
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:11:10.577718: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:11:10.739362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:11:10.739406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:11:11.043862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:11:11.043913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:11:11.043922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:11:11.044180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35230 rows...
Finished. It takes 4.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 2.3643
Epoch 2/80
 - 1s - loss: 0.6688
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:11:35.057584: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:11:35.224726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:11:35.224770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:11:35.514086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:11:35.514147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:11:35.514157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:11:35.514443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36244 rows...
Finished. It takes 5.3 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4887
Epoch 2/80
 - 3s - loss: 0.1146
Epoch 3/80
 - 3s - loss: 0.1058
Epoch 4/80
 - 3s - loss: 0.0999
Epoch 5/80
 - 3s - loss: 0.0930
Epoch 6/80
 - 3s - loss: 0.0842
Epoch 7/80
 - 3s - loss: 0.0748
Epoch 8/80
 - 3s - loss: 0.0670
Epoch 9/80
 - 3s - loss: 0.0610
Epoch 10/80
 - 3s - loss: 0.0562
Epoch 11/80
 - 3s - loss: 0.0525
Epoch 12/80
 - 3s - loss: 0.0496
Epoch 13/80
 - 3s - loss: 0.0473
Epoch 14/80
 - 3s - loss: 0.0455
Epoch 15/80
 - 3s - loss: 0.0440
Epoch 16/80
 - 3s - loss: 0.0428
Epoch 17/80
 - 3s - loss: 0.0419
Epoch 18/80
 - 3s - loss: 0.0411
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:12:52.138905: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:12:52.302634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:12:52.302678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:12:52.594874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:12:52.594927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:12:52.594936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:12:52.595209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35997 rows...
Finished. It takes 4.9 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.7848
Epoch 2/80
 - 2s - loss: 0.1616
Epoch 3/80
 - 2s - loss: 0.1447
Epoch 4/80
 - 2s - loss: 0.1387
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:13:17.862323: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:13:18.024452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:13:18.024494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:13:18.323039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:13:18.323091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:13:18.323099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:13:18.323366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35692 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.3199
Epoch 2/80
 - 1s - loss: 0.2549
Epoch 3/80
 - 1s - loss: 0.1833
Epoch 4/80
 - 1s - loss: 0.1707
Epoch 5/80
 - 1s - loss: 0.1600
Epoch 6/80
 - 1s - loss: 0.1495
Epoch 7/80
 - 1s - loss: 0.1396
Epoch 8/80
 - 1s - loss: 0.1308
Epoch 9/80
 - 1s - loss: 0.1234
Epoch 10/80
 - 1s - loss: 0.1167
Epoch 11/80
 - 1s - loss: 0.1105
Epoch 12/80
 - 1s - loss: 0.1046
Epoch 13/80
 - 1s - loss: 0.0989
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:14:03.962561: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:14:04.125435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:14:04.125491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:14:04.414038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:14:04.414089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:14:04.414098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:14:04.414409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36264 rows...
Finished. It takes 5.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4754
Epoch 2/80
 - 3s - loss: 0.1105
Epoch 3/80
 - 3s - loss: 0.0983
Epoch 4/80
 - 3s - loss: 0.0887
Epoch 5/80
 - 3s - loss: 0.0812
Epoch 6/80
 - 3s - loss: 0.0751
Epoch 7/80
 - 3s - loss: 0.0696
Epoch 8/80
 - 3s - loss: 0.0644
Epoch 9/80
 - 3s - loss: 0.0594
Epoch 10/80
 - 3s - loss: 0.0551
Epoch 11/80
 - 3s - loss: 0.0516
Epoch 12/80
 - 3s - loss: 0.0487
Epoch 13/80
 - 3s - loss: 0.0465
Epoch 14/80
 - 3s - loss: 0.0446
Epoch 15/80
 - 3s - loss: 0.0432
Epoch 16/80
 - 3s - loss: 0.0420
Epoch 17/80
 - 3s - loss: 0.0410
Epoch 18/80
 - 3s - loss: 0.0403
Epoch 19/80
 - 3s - loss: 0.0396
Epoch 20/80
 - 3s - loss: 0.0391
Epoch 21/80
 - 3s - loss: 0.0386
Epoch 22/80
 - 3s - loss: 0.0383
Epoch 23/80
 - 3s - loss: 0.0379
Epoch 24/80
 - 3s - loss: 0.0377
Epoch 25/80
 - 3s - loss: 0.0374
Epoch 26/80
 - 3s - loss: 0.0372
Epoch 27/80
 - 3s - loss: 0.0370
Epoch 28/80
 - 3s - loss: 0.0369
Epoch 29/80
 - 3s - loss: 0.0368
Epoch 30/80
 - 3s - loss: 0.0366
Epoch 31/80
 - 3s - loss: 0.0365
Epoch 32/80
 - 3s - loss: 0.0364
Epoch 33/80
 - 3s - loss: 0.0363
Epoch 34/80
 - 3s - loss: 0.0363
Epoch 35/80
 - 3s - loss: 0.0362
Epoch 36/80
 - 3s - loss: 0.0361
Epoch 37/80
 - 3s - loss: 0.0361
Epoch 38/80
 - 3s - loss: 0.0360
Epoch 39/80
 - 3s - loss: 0.0360
Epoch 40/80
 - 3s - loss: 0.0359
Epoch 41/80
 - 3s - loss: 0.0359
Epoch 42/80
 - 3s - loss: 0.0358
Epoch 43/80
 - 3s - loss: 0.0358
Epoch 44/80
 - 3s - loss: 0.0358
Epoch 45/80
 - 3s - loss: 0.0357
Epoch 46/80
 - 3s - loss: 0.0357
Epoch 47/80
 - 3s - loss: 0.0356
Epoch 48/80
 - 3s - loss: 0.0356
Epoch 49/80
 - 3s - loss: 0.0356
Epoch 50/80
 - 3s - loss: 0.0356
Epoch 51/80
 - 3s - loss: 0.0344
Epoch 52/80
 - 3s - loss: 0.0343
Epoch 53/80
 - 3s - loss: 0.0343
Epoch 54/80
 - 3s - loss: 0.0343
Epoch 55/80
 - 3s - loss: 0.0343
Epoch 56/80
 - 3s - loss: 0.0340
Epoch 57/80
 - 3s - loss: 0.0340
Epoch 58/80
 - 3s - loss: 0.0340
Epoch 59/80
 - 3s - loss: 0.0340
Epoch 60/80
 - 3s - loss: 0.0339
Epoch 61/80
 - 3s - loss: 0.0339
Epoch 62/80
 - 3s - loss: 0.0339
Epoch 63/80
 - 3s - loss: 0.0339
Epoch 64/80
 - 3s - loss: 0.0339
Epoch 65/80
 - 3s - loss: 0.0339
Epoch 66/80
 - 3s - loss: 0.0339
Epoch 67/80
 - 3s - loss: 0.0339
Epoch 68/80
 - 3s - loss: 0.0339
Epoch 69/80
 - 3s - loss: 0.0339
Epoch 70/80
 - 3s - loss: 0.0339
Epoch 71/80
 - 3s - loss: 0.0339
Epoch 72/80
 - 3s - loss: 0.0339
Epoch 73/80
 - 3s - loss: 0.0339
Epoch 74/80
 - 3s - loss: 0.0339
Epoch 75/80
 - 3s - loss: 0.0339
Epoch 76/80
 - 3s - loss: 0.0339
Epoch 77/80
 - 3s - loss: 0.0339
Epoch 78/80
 - 3s - loss: 0.0339
Epoch 79/80
 - 3s - loss: 0.0339
Epoch 80/80
 - 3s - loss: 0.0339
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 29011 samples, validate on 7253 samples
Epoch 1/80
 - 1s - loss: 5.3420 - val_loss: 1.8771
AUC: 0.7788

Epoch 2/80
 - 0s - loss: 3.5561 - val_loss: 1.2736
AUC: 0.8085

Epoch 3/80
 - 0s - loss: 2.4524 - val_loss: 1.0649
AUC: 0.8288

Epoch 4/80
 - 0s - loss: 1.7463 - val_loss: 0.7866
AUC: 0.8371

Epoch 5/80
 - 0s - loss: 1.4189 - val_loss: 0.7164
AUC: 0.8372

Epoch 6/80
 - 0s - loss: 1.2669 - val_loss: 0.6750
AUC: 0.8430

Epoch 7/80
 - 0s - loss: 1.1745 - val_loss: 0.7072
AUC: 0.8459

Epoch 8/80
 - 0s - loss: 1.1402 - val_loss: 0.7242
AUC: 0.8485

Epoch 9/80
 - 0s - loss: 1.1181 - val_loss: 0.6464
AUC: 0.8504

Epoch 10/80
 - 0s - loss: 1.0927 - val_loss: 0.6611
AUC: 0.8519

Epoch 11/80
 - 0s - loss: 1.0826 - val_loss: 0.6452
AUC: 0.8525

Epoch 12/80
 - 0s - loss: 1.0640 - val_loss: 0.7127
AUC: 0.8551

Epoch 13/80
 - 0s - loss: 1.0655 - val_loss: 0.6903
AUC: 0.8538

Epoch 14/80
 - 0s - loss: 1.0676 - val_loss: 0.6188
AUC: 0.8542

Epoch 15/80
 - 0s - loss: 1.0435 - val_loss: 0.6033
AUC: 0.8553

Epoch 16/80
 - 0s - loss: 1.0487 - val_loss: 0.7151
AUC: 0.8580

Epoch 17/80
 - 0s - loss: 1.0450 - val_loss: 0.6288
AUC: 0.8577

Epoch 18/80
 - 0s - loss: 1.0288 - val_loss: 0.6723
AUC: 0.8591

Epoch 19/80
 - 0s - loss: 1.0285 - val_loss: 0.6099
AUC: 0.8588

Epoch 20/80
 - 0s - loss: 1.0275 - val_loss: 0.6559
AUC: 0.8601

Epoch 21/80
 - 0s - loss: 1.0176 - val_loss: 0.6096
AUC: 0.8604

Epoch 22/80
 - 0s - loss: 1.0169 - val_loss: 0.5813
AUC: 0.8601

Epoch 23/80
 - 0s - loss: 1.0186 - val_loss: 0.6006
AUC: 0.8607

Epoch 24/80
 - 0s - loss: 1.0079 - val_loss: 0.6422
AUC: 0.8621

Epoch 25/80
 - 0s - loss: 1.0085 - val_loss: 0.6132
AUC: 0.8619

Epoch 26/80
 - 0s - loss: 1.0060 - val_loss: 0.5827
AUC: 0.8614

Epoch 27/80
 - 0s - loss: 1.0057 - val_loss: 0.6457
AUC: 0.8617

Epoch 28/80
 - 0s - loss: 1.0050 - val_loss: 0.5987
AUC: 0.8624

Epoch 29/80
 - 0s - loss: 0.9983 - val_loss: 0.6392
AUC: 0.8628

Epoch 30/80
 - 0s - loss: 1.0012 - val_loss: 0.6135
AUC: 0.8634

Epoch 31/80
 - 0s - loss: 0.9956 - val_loss: 0.6130
AUC: 0.8640

Epoch 32/80
 - 0s - loss: 0.9925 - val_loss: 0.6482
AUC: 0.8646

Epoch 33/80
 - 0s - loss: 0.9913 - val_loss: 0.5818
AUC: 0.8647

Epoch 34/80
 - 0s - loss: 0.9820 - val_loss: 0.6155
AUC: 0.8646

Epoch 35/80
 - 0s - loss: 0.9750 - val_loss: 0.6186
AUC: 0.8648

Epoch 36/80
 - 0s - loss: 0.9810 - val_loss: 0.6117
AUC: 0.8648

Epoch 37/80
 - 0s - loss: 0.9786 - val_loss: 0.6057
AUC: 0.8644

Epoch 38/80
 - 0s - loss: 0.9816 - val_loss: 0.6005
AUC: 0.8646

Epoch 39/80
 - 0s - loss: 0.9758 - val_loss: 0.6121
AUC: 0.8648

Epoch 40/80
 - 0s - loss: 0.9762 - val_loss: 0.6020
AUC: 0.8649

Epoch 41/80
 - 0s - loss: 0.9775 - val_loss: 0.6219
AUC: 0.8648

Epoch 42/80
 - 0s - loss: 0.9805 - val_loss: 0.6088
AUC: 0.8648

Epoch 43/80
 - 0s - loss: 0.9779 - val_loss: 0.6133
AUC: 0.8649

Epoch 44/80
 - 0s - loss: 0.9800 - val_loss: 0.6167
AUC: 0.8649

Epoch 45/80
 - 0s - loss: 0.9761 - val_loss: 0.6050
AUC: 0.8649

Epoch 46/80
 - 0s - loss: 0.9731 - val_loss: 0.6052
AUC: 0.8649

Epoch 47/80
 - 0s - loss: 0.9757 - val_loss: 0.6132
AUC: 0.8649

Epoch 48/80
 - 0s - loss: 0.9787 - val_loss: 0.6107
AUC: 0.8649

Epoch 49/80
 - 0s - loss: 0.9743 - val_loss: 0.6092
AUC: 0.8648

Epoch 50/80
 - 0s - loss: 0.9699 - val_loss: 0.6084
AUC: 0.8649

Epoch 51/80
 - 0s - loss: 0.9750 - val_loss: 0.6034
AUC: 0.8648

Epoch 52/80
 - 0s - loss: 0.9722 - val_loss: 0.6051
AUC: 0.8649

Train on 29011 samples, validate on 7253 samples
Epoch 1/30
 - 1s - loss: 0.9754 - val_loss: 0.5977
AUC: 0.8649

Epoch 2/30
 - 0s - loss: 0.9770 - val_loss: 0.6286
AUC: 0.8652

Epoch 3/30
 - 0s - loss: 0.9719 - val_loss: 0.6010
AUC: 0.8651

Epoch 4/30
 - 0s - loss: 0.9756 - val_loss: 0.6310
AUC: 0.8654

Epoch 5/30
 - 0s - loss: 0.9676 - val_loss: 0.6093
AUC: 0.8655

Epoch 6/30
 - 0s - loss: 0.9683 - val_loss: 0.5942
AUC: 0.8654

Epoch 7/30
 - 0s - loss: 0.9697 - val_loss: 0.6018
AUC: 0.8655

Epoch 8/30
 - 0s - loss: 0.9633 - val_loss: 0.5915
AUC: 0.8657

Epoch 9/30
 - 0s - loss: 0.9646 - val_loss: 0.6209
AUC: 0.8659

Epoch 10/30
 - 0s - loss: 0.9622 - val_loss: 0.6094
AUC: 0.8660

Epoch 11/30
 - 0s - loss: 0.9628 - val_loss: 0.6125
AUC: 0.8663

Epoch 12/30
 - 0s - loss: 0.9614 - val_loss: 0.5946
AUC: 0.8661

Epoch 13/30
 - 0s - loss: 0.9569 - val_loss: 0.6102
AUC: 0.8664

Epoch 14/30
 - 0s - loss: 0.9542 - val_loss: 0.5976
AUC: 0.8664

Epoch 15/30
 - 0s - loss: 0.9564 - val_loss: 0.6202
AUC: 0.8665

Epoch 16/30
 - 0s - loss: 0.9509 - val_loss: 0.6000
AUC: 0.8666

Epoch 17/30
 - 0s - loss: 0.9504 - val_loss: 0.5971
AUC: 0.8667

Epoch 18/30
 - 0s - loss: 0.9498 - val_loss: 0.5942
AUC: 0.8666

Epoch 19/30
 - 0s - loss: 0.9489 - val_loss: 0.5986
AUC: 0.8667

Epoch 20/30
 - 0s - loss: 0.9492 - val_loss: 0.5987
AUC: 0.8667

Epoch 21/30
 - 0s - loss: 0.9452 - val_loss: 0.5951
AUC: 0.8668

Epoch 22/30
 - 0s - loss: 0.9499 - val_loss: 0.5944
AUC: 0.8668

Epoch 23/30
 - 0s - loss: 0.9502 - val_loss: 0.5995
AUC: 0.8669

Epoch 24/30
 - 0s - loss: 0.9453 - val_loss: 0.5955
AUC: 0.8669

Epoch 25/30
 - 0s - loss: 0.9469 - val_loss: 0.5996
AUC: 0.8669

Epoch 26/30
 - 0s - loss: 0.9454 - val_loss: 0.5965
AUC: 0.8669

Epoch 27/30
 - 0s - loss: 0.9445 - val_loss: 0.5951
AUC: 0.8670

Epoch 28/30
 - 0s - loss: 0.9426 - val_loss: 0.5938
AUC: 0.8670

Epoch 29/30
 - 0s - loss: 0.9479 - val_loss: 0.5936
AUC: 0.8670

Epoch 30/30
 - 0s - loss: 0.9471 - val_loss: 0.5947
Using TensorFlow backend.
AUC: 0.8670

2019-03-08 13:19:24.389782: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:19:24.552127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:19:24.552194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:19:24.843410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:19:24.843489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:19:24.843498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:19:24.843774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36115 rows...
Finished. It takes 5.2 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.6465
Epoch 2/80
 - 2s - loss: 0.1388
Epoch 3/80
 - 2s - loss: 0.1264
Epoch 4/80
 - 3s - loss: 0.1204
Epoch 5/80
 - 2s - loss: 0.1124
Epoch 6/80
 - 2s - loss: 0.1015
Epoch 7/80
 - 2s - loss: 0.0907
Epoch 8/80
 - 2s - loss: 0.0819
Epoch 9/80
 - 2s - loss: 0.0748
Epoch 10/80
 - 2s - loss: 0.0690
Epoch 11/80
 - 2s - loss: 0.0644
Epoch 12/80
 - 2s - loss: 0.0606
Epoch 13/80
 - 2s - loss: 0.0573
Epoch 14/80
 - 2s - loss: 0.0547
Epoch 15/80
 - 2s - loss: 0.0526
Epoch 16/80
 - 2s - loss: 0.0509
Epoch 17/80
 - 2s - loss: 0.0495
Epoch 18/80
 - 2s - loss: 0.0483
Epoch 19/80
 - 2s - loss: 0.0474
Epoch 20/80
 - 2s - loss: 0.0466
Epoch 21/80
 - 2s - loss: 0.0459
Epoch 22/80
 - 2s - loss: 0.0453
Epoch 23/80
 - 2s - loss: 0.0449
Epoch 24/80
 - 2s - loss: 0.0445
Epoch 25/80
 - 2s - loss: 0.0441
Epoch 26/80
 - 2s - loss: 0.0438
Epoch 27/80
 - 2s - loss: 0.0435
Epoch 28/80
 - 2s - loss: 0.0433
Epoch 29/80
 - 2s - loss: 0.0431
Epoch 30/80
 - 2s - loss: 0.0429
Epoch 31/80
 - 2s - loss: 0.0428
Epoch 32/80
 - 2s - loss: 0.0426
Epoch 33/80
 - 2s - loss: 0.0425
Epoch 34/80
 - 2s - loss: 0.0424
Epoch 35/80
 - 2s - loss: 0.0423
Epoch 36/80
 - 2s - loss: 0.0422
Epoch 37/80
 - 2s - loss: 0.0421
Epoch 38/80
 - 2s - loss: 0.0420
Epoch 39/80
 - 2s - loss: 0.0419
Epoch 40/80
 - 2s - loss: 0.0419
Epoch 41/80
 - 2s - loss: 0.0418
Epoch 42/80
 - 2s - loss: 0.0417
Epoch 43/80
 - 2s - loss: 0.0417
Epoch 44/80
 - 2s - loss: 0.0416
Epoch 45/80
 - 2s - loss: 0.0416
Epoch 46/80
 - 2s - loss: 0.0415
Epoch 47/80
 - 2s - loss: 0.0415
Epoch 48/80
 - 2s - loss: 0.0415
Epoch 49/80
 - 2s - loss: 0.0414
Epoch 50/80
 - 2s - loss: 0.0414
Epoch 51/80
 - 2s - loss: 0.0414
Epoch 52/80
 - 2s - loss: 0.0414
Epoch 53/80
 - 2s - loss: 0.0413
Epoch 54/80
 - 2s - loss: 0.0402
Epoch 55/80
 - 2s - loss: 0.0400
Epoch 56/80
 - 2s - loss: 0.0400
Epoch 57/80
 - 2s - loss: 0.0400
Epoch 58/80
 - 2s - loss: 0.0400
Epoch 59/80
 - 2s - loss: 0.0397
Epoch 60/80
 - 2s - loss: 0.0397
Epoch 61/80
 - 2s - loss: 0.0397
Epoch 62/80
 - 2s - loss: 0.0397
Epoch 63/80
 - 2s - loss: 0.0396
Epoch 64/80
 - 2s - loss: 0.0396
Epoch 65/80
 - 2s - loss: 0.0396
Epoch 66/80
 - 2s - loss: 0.0396
Epoch 67/80
 - 2s - loss: 0.0396
Epoch 68/80
 - 2s - loss: 0.0396
Epoch 69/80
 - 2s - loss: 0.0396
Epoch 70/80
 - 2s - loss: 0.0396
Epoch 71/80
 - 2s - loss: 0.0396
Epoch 72/80
 - 2s - loss: 0.0396
Epoch 73/80
 - 2s - loss: 0.0396
Epoch 74/80
 - 2s - loss: 0.0396
Epoch 75/80
 - 2s - loss: 0.0396
Epoch 76/80
 - 2s - loss: 0.0396
Epoch 77/80
 - 2s - loss: 0.0396
Epoch 78/80
 - 2s - loss: 0.0396
Epoch 79/80
 - 3s - loss: 0.0396
Epoch 80/80
 - 2s - loss: 0.0396
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28892 samples, validate on 7223 samples
Epoch 1/80
 - 1s - loss: 5.6887 - val_loss: 2.3884
AUC: 0.8074

Epoch 2/80
 - 0s - loss: 3.9462 - val_loss: 1.3686
AUC: 0.8109

Epoch 3/80
 - 0s - loss: 2.8992 - val_loss: 1.1132
AUC: 0.8232

Epoch 4/80
 - 0s - loss: 2.0249 - val_loss: 0.8755
AUC: 0.8261

Epoch 5/80
 - 0s - loss: 1.4924 - val_loss: 0.8523
AUC: 0.8368

Epoch 6/80
 - 0s - loss: 1.2766 - val_loss: 0.6529
AUC: 0.8320

Epoch 7/80
 - 0s - loss: 1.2045 - val_loss: 0.7126
AUC: 0.8403

Epoch 8/80
 - 0s - loss: 1.1501 - val_loss: 0.6440
AUC: 0.8415

Epoch 9/80
 - 0s - loss: 1.1257 - val_loss: 0.7013
AUC: 0.8454

Epoch 10/80
 - 0s - loss: 1.1218 - val_loss: 0.6783
AUC: 0.8479

Epoch 11/80
 - 0s - loss: 1.0977 - val_loss: 0.7417
AUC: 0.8504

Epoch 12/80
 - 0s - loss: 1.0918 - val_loss: 0.6018
AUC: 0.8494

Epoch 13/80
 - 0s - loss: 1.0865 - val_loss: 0.7039
AUC: 0.8525

Epoch 14/80
 - 0s - loss: 1.0732 - val_loss: 0.6659
AUC: 0.8543

Epoch 15/80
 - 0s - loss: 1.0726 - val_loss: 0.6143
AUC: 0.8535

Epoch 16/80
 - 0s - loss: 1.0623 - val_loss: 0.6598
AUC: 0.8565

Epoch 17/80
 - 0s - loss: 1.0523 - val_loss: 0.5964
AUC: 0.8560

Epoch 18/80
 - 0s - loss: 1.0491 - val_loss: 0.5942
AUC: 0.8579

Epoch 19/80
 - 0s - loss: 1.0368 - val_loss: 0.6415
AUC: 0.8584

Epoch 20/80
 - 0s - loss: 1.0419 - val_loss: 0.6709
AUC: 0.8599

Epoch 21/80
 - 0s - loss: 1.0356 - val_loss: 0.6531
AUC: 0.8588

Epoch 22/80
 - 0s - loss: 1.0246 - val_loss: 0.6304
AUC: 0.8611

Epoch 23/80
 - 0s - loss: 1.0296 - val_loss: 0.6345
AUC: 0.8617

Epoch 24/80
 - 0s - loss: 1.0256 - val_loss: 0.6104
AUC: 0.8612

Epoch 25/80
 - 0s - loss: 1.0243 - val_loss: 0.5942
AUC: 0.8615

Epoch 26/80
 - 0s - loss: 1.0140 - val_loss: 0.6370
AUC: 0.8639

Epoch 27/80
 - 0s - loss: 1.0140 - val_loss: 0.5793
AUC: 0.8625

Epoch 28/80
 - 0s - loss: 1.0082 - val_loss: 0.6354
AUC: 0.8632

Epoch 29/80
 - 0s - loss: 1.0027 - val_loss: 0.5898
AUC: 0.8624

Epoch 30/80
 - 0s - loss: 1.0023 - val_loss: 0.6477
AUC: 0.8645

Epoch 31/80
 - 0s - loss: 1.0060 - val_loss: 0.6116
AUC: 0.8646

Epoch 32/80
 - 0s - loss: 1.0062 - val_loss: 0.6330
AUC: 0.8645

Epoch 33/80
 - 0s - loss: 0.9950 - val_loss: 0.5760
AUC: 0.8643

Epoch 34/80
 - 0s - loss: 0.9965 - val_loss: 0.6406
AUC: 0.8640

Epoch 35/80
 - 0s - loss: 0.9982 - val_loss: 0.5804
AUC: 0.8647

Epoch 36/80
 - 0s - loss: 0.9866 - val_loss: 0.5692
AUC: 0.8642

Epoch 37/80
 - 0s - loss: 0.9947 - val_loss: 0.6276
AUC: 0.8656

Epoch 38/80
 - 0s - loss: 0.9859 - val_loss: 0.6560
AUC: 0.8660

Epoch 39/80
 - 0s - loss: 0.9814 - val_loss: 0.5826
AUC: 0.8653

Epoch 40/80
 - 0s - loss: 0.9814 - val_loss: 0.6270
AUC: 0.8664

Epoch 41/80
 - 0s - loss: 0.9789 - val_loss: 0.6366
AUC: 0.8666

Epoch 42/80
 - 0s - loss: 0.9760 - val_loss: 0.5765
AUC: 0.8662

Epoch 43/80
 - 0s - loss: 0.9754 - val_loss: 0.5902
AUC: 0.8659

Epoch 44/80
 - 0s - loss: 0.9724 - val_loss: 0.5686
AUC: 0.8651

Epoch 45/80
 - 0s - loss: 0.9704 - val_loss: 0.6027
AUC: 0.8664

Epoch 46/80
 - 0s - loss: 0.9725 - val_loss: 0.6024
AUC: 0.8660

Epoch 47/80
 - 0s - loss: 0.9729 - val_loss: 0.5580
AUC: 0.8654

Epoch 48/80
 - 0s - loss: 0.9695 - val_loss: 0.5601
AUC: 0.8660

Epoch 49/80
 - 0s - loss: 0.9661 - val_loss: 0.5751
AUC: 0.8671

Epoch 50/80
 - 0s - loss: 0.9656 - val_loss: 0.6140
AUC: 0.8664

Epoch 51/80
 - 0s - loss: 0.9643 - val_loss: 0.5738
AUC: 0.8661

Epoch 52/80
 - 0s - loss: 0.9631 - val_loss: 0.5733
AUC: 0.8652

Epoch 53/80
 - 0s - loss: 0.9613 - val_loss: 0.5695
AUC: 0.8661

Epoch 54/80
 - 0s - loss: 0.9592 - val_loss: 0.6087
AUC: 0.8668

Epoch 55/80
 - 0s - loss: 0.9598 - val_loss: 0.5753
AUC: 0.8663

Epoch 56/80
 - 0s - loss: 0.9513 - val_loss: 0.6142
AUC: 0.8671

Epoch 57/80
 - 0s - loss: 0.9532 - val_loss: 0.6572
AUC: 0.8680

Epoch 58/80
 - 0s - loss: 0.9525 - val_loss: 0.5954
AUC: 0.8672

Epoch 59/80
 - 0s - loss: 0.9421 - val_loss: 0.6081
AUC: 0.8674

Epoch 60/80
 - 0s - loss: 0.9425 - val_loss: 0.5914
AUC: 0.8670

Epoch 61/80
 - 0s - loss: 0.9449 - val_loss: 0.5793
AUC: 0.8667

Epoch 62/80
 - 0s - loss: 0.9395 - val_loss: 0.5906
AUC: 0.8671

Epoch 63/80
 - 0s - loss: 0.9378 - val_loss: 0.5714
AUC: 0.8666

Epoch 64/80
 - 0s - loss: 0.9436 - val_loss: 0.5982
AUC: 0.8671

Epoch 65/80
 - 0s - loss: 0.9405 - val_loss: 0.5767
AUC: 0.8668

Epoch 66/80
 - 0s - loss: 0.9376 - val_loss: 0.5703
AUC: 0.8661

Epoch 67/80
 - 0s - loss: 0.9375 - val_loss: 0.5832
AUC: 0.8663

Epoch 68/80
 - 0s - loss: 0.9420 - val_loss: 0.5803
AUC: 0.8663

Epoch 69/80
 - 0s - loss: 0.9422 - val_loss: 0.5934
AUC: 0.8666

Epoch 70/80
 - 0s - loss: 0.9386 - val_loss: 0.5908
AUC: 0.8665

Epoch 71/80
 - 0s - loss: 0.9394 - val_loss: 0.5884
AUC: 0.8665

Epoch 72/80
 - 0s - loss: 0.9361 - val_loss: 0.5840
AUC: 0.8665

Epoch 73/80
 - 0s - loss: 0.9404 - val_loss: 0.5935
AUC: 0.8666

Epoch 74/80
 - 0s - loss: 0.9384 - val_loss: 0.5864
AUC: 0.8665

Epoch 75/80
 - 0s - loss: 0.9410 - val_loss: 0.5853
AUC: 0.8664

Epoch 76/80
 - 0s - loss: 0.9370 - val_loss: 0.5882
AUC: 0.8665

Epoch 77/80
 - 0s - loss: 0.9386 - val_loss: 0.5879
AUC: 0.8665

Train on 28892 samples, validate on 7223 samples
Epoch 1/30
 - 1s - loss: 0.9497 - val_loss: 0.5872
AUC: 0.8672

Epoch 2/30
 - 0s - loss: 0.9401 - val_loss: 0.5814
AUC: 0.8670

Epoch 3/30
 - 0s - loss: 0.9408 - val_loss: 0.5809
AUC: 0.8670

Epoch 4/30
 - 0s - loss: 0.9345 - val_loss: 0.5878
AUC: 0.8673

Epoch 5/30
 - 0s - loss: 0.9343 - val_loss: 0.5828
AUC: 0.8673

Epoch 6/30
 - 0s - loss: 0.9339 - val_loss: 0.5884
AUC: 0.8674

Epoch 7/30
 - 0s - loss: 0.9340 - val_loss: 0.5796
AUC: 0.8673

Epoch 8/30
 - 0s - loss: 0.9273 - val_loss: 0.5924
AUC: 0.8675

Epoch 9/30
 - 0s - loss: 0.9292 - val_loss: 0.6025
AUC: 0.8676

Epoch 10/30
 - 0s - loss: 0.9271 - val_loss: 0.5667
AUC: 0.8672

Epoch 11/30
 - 0s - loss: 0.9340 - val_loss: 0.5912
AUC: 0.8676

Epoch 12/30
 - 0s - loss: 0.9280 - val_loss: 0.5813
AUC: 0.8673

Epoch 13/30
 - 0s - loss: 0.9256 - val_loss: 0.5895
AUC: 0.8675

Epoch 14/30
 - 0s - loss: 0.9255 - val_loss: 0.5943
AUC: 0.8677

Epoch 15/30
 - 0s - loss: 0.9233 - val_loss: 0.5875
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.9222 - val_loss: 0.5870
AUC: 0.8677

Epoch 17/30
 - 0s - loss: 0.9212 - val_loss: 0.5886
AUC: 0.8677

Epoch 18/30
 - 0s - loss: 0.9220 - val_loss: 0.5710
AUC: 0.8674

Epoch 19/30
 - 0s - loss: 0.9210 - val_loss: 0.5741
AUC: 0.8673

Epoch 20/30
 - 0s - loss: 0.9169 - val_loss: 0.5742
AUC: 0.8674

Epoch 21/30
 - 0s - loss: 0.9124 - val_loss: 0.5793
AUC: 0.8675

Epoch 22/30
 - 0s - loss: 0.9124 - val_loss: 0.5779
AUC: 0.8675

Epoch 23/30
 - 0s - loss: 0.9152 - val_loss: 0.5779
AUC: 0.8675

Epoch 24/30
 - 0s - loss: 0.9155 - val_loss: 0.5771
AUC: 0.8675

Epoch 25/30
 - 0s - loss: 0.9140 - val_loss: 0.5778
AUC: 0.8675

Epoch 26/30
 - 0s - loss: 0.9121 - val_loss: 0.5760
AUC: 0.8675

Epoch 27/30
 - 0s - loss: 0.9136 - val_loss: 0.5798
AUC: 0.8676

Epoch 28/30
 - 0s - loss: 0.9111 - val_loss: 0.5767
AUC: 0.8675

Epoch 29/30
 - 0s - loss: 0.9107 - val_loss: 0.5774
AUC: 0.8675

Epoch 30/30
 - 0s - loss: 0.9089 - val_loss: 0.5786
Using TensorFlow backend.
AUC: 0.8676

2019-03-08 13:24:05.763726: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:24:05.929105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:24:05.929149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:24:06.226869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:24:06.226919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:24:06.226928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:24:06.227188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 5.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1629
Epoch 2/80
 - 2s - loss: 0.2193
Epoch 3/80
 - 2s - loss: 0.1692
Epoch 4/80
 - 2s - loss: 0.1558
Epoch 5/80
 - 1s - loss: 0.1431
Epoch 6/80
 - 2s - loss: 0.1317
Epoch 7/80
 - 1s - loss: 0.1224
Epoch 8/80
 - 1s - loss: 0.1152
Epoch 9/80
 - 1s - loss: 0.1094
Epoch 10/80
 - 1s - loss: 0.1042
Epoch 11/80
 - 2s - loss: 0.0990
Epoch 12/80
 - 1s - loss: 0.0935
Epoch 13/80
 - 2s - loss: 0.0879
Epoch 14/80
 - 2s - loss: 0.0826
Epoch 15/80
 - 2s - loss: 0.0780
Epoch 16/80
 - 2s - loss: 0.0742
Epoch 17/80
 - 2s - loss: 0.0709
Epoch 18/80
 - 2s - loss: 0.0681
Epoch 19/80
 - 2s - loss: 0.0656
Epoch 20/80
 - 2s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0617
Epoch 22/80
 - 2s - loss: 0.0602
Epoch 23/80
 - 2s - loss: 0.0589
Epoch 24/80
 - 2s - loss: 0.0577
Epoch 25/80
 - 2s - loss: 0.0568
Epoch 26/80
 - 2s - loss: 0.0559
Epoch 27/80
 - 2s - loss: 0.0552
Epoch 28/80
 - 1s - loss: 0.0546
Epoch 29/80
 - 1s - loss: 0.0541
Epoch 30/80
 - 1s - loss: 0.0536
Epoch 31/80
 - 1s - loss: 0.0532
Epoch 32/80
 - 1s - loss: 0.0529
Epoch 33/80
 - 1s - loss: 0.0526
Epoch 34/80
 - 1s - loss: 0.0523
Epoch 35/80
 - 2s - loss: 0.0521
Epoch 36/80
 - 1s - loss: 0.0519
Epoch 37/80
 - 1s - loss: 0.0517
Epoch 38/80
 - 1s - loss: 0.0515
Epoch 39/80
 - 2s - loss: 0.0514
Epoch 40/80
 - 1s - loss: 0.0512
Epoch 41/80
 - 1s - loss: 0.0511
Epoch 42/80
 - 1s - loss: 0.0510
Epoch 43/80
 - 1s - loss: 0.0509
Epoch 44/80
 - 1s - loss: 0.0508
Epoch 45/80
 - 2s - loss: 0.0507
Epoch 46/80
 - 1s - loss: 0.0507
Epoch 47/80
 - 1s - loss: 0.0506
Epoch 48/80
 - 1s - loss: 0.0505
Epoch 49/80
 - 1s - loss: 0.0505
Epoch 50/80
 - 1s - loss: 0.0504
Epoch 51/80
 - 1s - loss: 0.0504
Epoch 52/80
 - 2s - loss: 0.0503
Epoch 53/80
 - 1s - loss: 0.0503
Epoch 54/80
 - 1s - loss: 0.0502
Epoch 55/80
 - 2s - loss: 0.0502
Epoch 56/80
 - 1s - loss: 0.0501
Epoch 57/80
 - 2s - loss: 0.0501
Epoch 58/80
 - 2s - loss: 0.0501
Epoch 59/80
 - 2s - loss: 0.0500
Epoch 60/80
 - 2s - loss: 0.0500
Epoch 61/80
 - 1s - loss: 0.0500
Epoch 62/80
 - 1s - loss: 0.0499
Epoch 63/80
 - 1s - loss: 0.0489
Epoch 64/80
 - 2s - loss: 0.0487
Epoch 65/80
 - 1s - loss: 0.0487
Epoch 66/80
 - 1s - loss: 0.0487
Epoch 67/80
 - 1s - loss: 0.0487
Epoch 68/80
 - 1s - loss: 0.0484
Epoch 69/80
 - 1s - loss: 0.0484
Epoch 70/80
 - 2s - loss: 0.0484
Epoch 71/80
 - 1s - loss: 0.0484
Epoch 72/80
 - 2s - loss: 0.0483
Epoch 73/80
 - 2s - loss: 0.0483
Epoch 74/80
 - 2s - loss: 0.0483
Epoch 75/80
 - 1s - loss: 0.0483
Epoch 76/80
 - 2s - loss: 0.0483
Epoch 77/80
 - 2s - loss: 0.0483
Epoch 78/80
 - 2s - loss: 0.0483
Epoch 79/80
 - 2s - loss: 0.0483
Epoch 80/80
 - 2s - loss: 0.0483
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.3684 - val_loss: 1.9436
AUC: 0.8056

Epoch 2/80
 - 0s - loss: 3.3391 - val_loss: 1.1797
AUC: 0.8231

Epoch 3/80
 - 0s - loss: 2.4284 - val_loss: 1.0149
AUC: 0.8410

Epoch 4/80
 - 0s - loss: 1.7421 - val_loss: 0.7259
AUC: 0.8448

Epoch 5/80
 - 0s - loss: 1.3733 - val_loss: 0.6481
AUC: 0.8451

Epoch 6/80
 - 0s - loss: 1.2448 - val_loss: 0.6858
AUC: 0.8510

Epoch 7/80
 - 0s - loss: 1.1580 - val_loss: 0.6736
AUC: 0.8518

Epoch 8/80
 - 0s - loss: 1.1230 - val_loss: 0.6216
AUC: 0.8525

Epoch 9/80
 - 0s - loss: 1.1009 - val_loss: 0.6412
AUC: 0.8558

Epoch 10/80
 - 0s - loss: 1.0862 - val_loss: 0.6400
AUC: 0.8571

Epoch 11/80
 - 0s - loss: 1.0769 - val_loss: 0.6055
AUC: 0.8573

Epoch 12/80
 - 0s - loss: 1.0676 - val_loss: 0.6454
AUC: 0.8602

Epoch 13/80
 - 0s - loss: 1.0554 - val_loss: 0.6483
AUC: 0.8607

Epoch 14/80
 - 0s - loss: 1.0487 - val_loss: 0.6853
AUC: 0.8622

Epoch 15/80
 - 0s - loss: 1.0474 - val_loss: 0.6312
AUC: 0.8623

Epoch 16/80
 - 0s - loss: 1.0404 - val_loss: 0.6515
AUC: 0.8631

Epoch 17/80
 - 0s - loss: 1.0314 - val_loss: 0.6417
AUC: 0.8629

Epoch 18/80
 - 0s - loss: 1.0177 - val_loss: 0.6321
AUC: 0.8639

Epoch 19/80
 - 0s - loss: 1.0249 - val_loss: 0.5938
AUC: 0.8643

Epoch 20/80
 - 0s - loss: 1.0246 - val_loss: 0.6375
AUC: 0.8636

Epoch 21/80
 - 0s - loss: 1.0151 - val_loss: 0.6243
AUC: 0.8648

Epoch 22/80
 - 0s - loss: 1.0181 - val_loss: 0.6176
AUC: 0.8651

Epoch 23/80
 - 0s - loss: 1.0172 - val_loss: 0.6028
AUC: 0.8641

Epoch 24/80
 - 0s - loss: 1.0061 - val_loss: 0.6469
AUC: 0.8652

Epoch 25/80
 - 0s - loss: 1.0050 - val_loss: 0.6510
AUC: 0.8664

Epoch 26/80
 - 0s - loss: 1.0109 - val_loss: 0.6785
AUC: 0.8653

Epoch 27/80
 - 0s - loss: 1.0002 - val_loss: 0.6465
AUC: 0.8666

Epoch 28/80
 - 0s - loss: 1.0076 - val_loss: 0.6430
AUC: 0.8671

Epoch 29/80
 - 0s - loss: 0.9970 - val_loss: 0.5897
AUC: 0.8666

Epoch 30/80
 - 0s - loss: 0.9940 - val_loss: 0.6408
AUC: 0.8672

Epoch 31/80
 - 0s - loss: 0.9966 - val_loss: 0.6558
AUC: 0.8663

Epoch 32/80
 - 0s - loss: 0.9982 - val_loss: 0.6166
AUC: 0.8678

Epoch 33/80
 - 0s - loss: 0.9929 - val_loss: 0.6911
AUC: 0.8673

Epoch 34/80
 - 0s - loss: 0.9885 - val_loss: 0.5911
AUC: 0.8676

Epoch 35/80
 - 0s - loss: 0.9861 - val_loss: 0.6343
AUC: 0.8675

Epoch 36/80
 - 0s - loss: 0.9858 - val_loss: 0.6630
AUC: 0.8680

Epoch 37/80
 - 0s - loss: 0.9808 - val_loss: 0.5898
AUC: 0.8681

Epoch 38/80
 - 0s - loss: 0.9804 - val_loss: 0.6124
AUC: 0.8692

Epoch 39/80
 - 0s - loss: 0.9875 - val_loss: 0.5794
AUC: 0.8671

Epoch 40/80
 - 0s - loss: 0.9767 - val_loss: 0.5732
AUC: 0.8674

Epoch 41/80
 - 0s - loss: 0.9780 - val_loss: 0.6175
AUC: 0.8675

Epoch 42/80
 - 0s - loss: 0.9731 - val_loss: 0.5852
AUC: 0.8684

Epoch 43/80
 - 0s - loss: 0.9717 - val_loss: 0.5831
AUC: 0.8686

Epoch 44/80
 - 0s - loss: 0.9682 - val_loss: 0.5854
AUC: 0.8683

Epoch 45/80
 - 0s - loss: 0.9649 - val_loss: 0.6189
AUC: 0.8686

Epoch 46/80
 - 0s - loss: 0.9731 - val_loss: 0.6136
AUC: 0.8693

Epoch 47/80
 - 0s - loss: 0.9664 - val_loss: 0.6184
AUC: 0.8696

Epoch 48/80
 - 0s - loss: 0.9680 - val_loss: 0.5874
AUC: 0.8691

Epoch 49/80
 - 0s - loss: 0.9654 - val_loss: 0.6335
AUC: 0.8691

Epoch 50/80
 - 0s - loss: 0.9656 - val_loss: 0.5521
AUC: 0.8694

Epoch 51/80
 - 0s - loss: 0.9624 - val_loss: 0.5986
AUC: 0.8706

Epoch 52/80
 - 0s - loss: 0.9630 - val_loss: 0.6697
AUC: 0.8697

Epoch 53/80
 - 0s - loss: 0.9655 - val_loss: 0.5878
AUC: 0.8696

Epoch 54/80
 - 0s - loss: 0.9607 - val_loss: 0.6158
AUC: 0.8698

Epoch 55/80
 - 0s - loss: 0.9552 - val_loss: 0.5269
AUC: 0.8681

Epoch 56/80
 - 0s - loss: 0.9522 - val_loss: 0.5673
AUC: 0.8703

Epoch 57/80
 - 0s - loss: 0.9502 - val_loss: 0.5886
AUC: 0.8700

Epoch 58/80
 - 0s - loss: 0.9555 - val_loss: 0.5293
AUC: 0.8704

Epoch 59/80
 - 0s - loss: 0.9522 - val_loss: 0.5572
AUC: 0.8693

Epoch 60/80
 - 0s - loss: 0.9524 - val_loss: 0.6060
AUC: 0.8702

Epoch 61/80
 - 0s - loss: 0.9506 - val_loss: 0.5863
AUC: 0.8717

Epoch 62/80
 - 0s - loss: 0.9445 - val_loss: 0.6177
AUC: 0.8703

Epoch 63/80
 - 0s - loss: 0.9468 - val_loss: 0.6146
AUC: 0.8707

Epoch 64/80
 - 0s - loss: 0.9500 - val_loss: 0.5699
AUC: 0.8705

Epoch 65/80
 - 0s - loss: 0.9430 - val_loss: 0.5774
AUC: 0.8706

Epoch 66/80
 - 0s - loss: 0.9378 - val_loss: 0.5800
AUC: 0.8716

Epoch 67/80
 - 0s - loss: 0.9297 - val_loss: 0.5792
AUC: 0.8717

Epoch 68/80
 - 0s - loss: 0.9298 - val_loss: 0.5883
AUC: 0.8716

Epoch 69/80
 - 0s - loss: 0.9353 - val_loss: 0.5870
AUC: 0.8720

Epoch 70/80
 - 0s - loss: 0.9285 - val_loss: 0.5927
AUC: 0.8717

Epoch 71/80
 - 0s - loss: 0.9281 - val_loss: 0.5763
AUC: 0.8714

Epoch 72/80
 - 0s - loss: 0.9313 - val_loss: 0.5845
AUC: 0.8714

Epoch 73/80
 - 0s - loss: 0.9301 - val_loss: 0.5939
AUC: 0.8714

Epoch 74/80
 - 0s - loss: 0.9314 - val_loss: 0.5730
AUC: 0.8713

Epoch 75/80
 - 0s - loss: 0.9298 - val_loss: 0.5752
AUC: 0.8711

Epoch 76/80
 - 0s - loss: 0.9251 - val_loss: 0.5821
AUC: 0.8714

Epoch 77/80
 - 0s - loss: 0.9284 - val_loss: 0.5754
AUC: 0.8714

Epoch 78/80
 - 0s - loss: 0.9306 - val_loss: 0.5759
AUC: 0.8715

Epoch 79/80
 - 0s - loss: 0.9288 - val_loss: 0.5755
AUC: 0.8715

Epoch 80/80
 - 0s - loss: 0.9288 - val_loss: 0.5823
AUC: 0.8715

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9338 - val_loss: 0.5792
AUC: 0.8716

Epoch 2/30
 - 0s - loss: 0.9360 - val_loss: 0.5868
AUC: 0.8716

Epoch 3/30
 - 0s - loss: 0.9285 - val_loss: 0.5762
AUC: 0.8718

Epoch 4/30
 - 0s - loss: 0.9294 - val_loss: 0.5770
AUC: 0.8718

Epoch 5/30
 - 0s - loss: 0.9302 - val_loss: 0.5813
AUC: 0.8718

Epoch 6/30
 - 0s - loss: 0.9273 - val_loss: 0.5803
AUC: 0.8721

Epoch 7/30
 - 0s - loss: 0.9223 - val_loss: 0.5847
AUC: 0.8721

Epoch 8/30
 - 0s - loss: 0.9232 - val_loss: 0.5671
AUC: 0.8719

Epoch 9/30
 - 0s - loss: 0.9236 - val_loss: 0.5760
AUC: 0.8722

Epoch 10/30
 - 0s - loss: 0.9189 - val_loss: 0.5686
AUC: 0.8720

Epoch 11/30
 - 0s - loss: 0.9202 - val_loss: 0.5723
AUC: 0.8721

Epoch 12/30
 - 0s - loss: 0.9183 - val_loss: 0.5765
AUC: 0.8723

Epoch 13/30
 - 0s - loss: 0.9244 - val_loss: 0.5737
AUC: 0.8724

Epoch 14/30
 - 0s - loss: 0.9152 - val_loss: 0.5828
AUC: 0.8727

Epoch 15/30
 - 0s - loss: 0.9140 - val_loss: 0.5918
AUC: 0.8726

Epoch 16/30
 - 0s - loss: 0.9150 - val_loss: 0.5721
AUC: 0.8727

Epoch 17/30
 - 0s - loss: 0.9109 - val_loss: 0.5693
AUC: 0.8727

Epoch 18/30
 - 0s - loss: 0.9134 - val_loss: 0.5773
AUC: 0.8728

Epoch 19/30
 - 0s - loss: 0.9086 - val_loss: 0.5706
AUC: 0.8727

Epoch 20/30
 - 0s - loss: 0.9130 - val_loss: 0.5712
AUC: 0.8727

Epoch 21/30
 - 0s - loss: 0.9144 - val_loss: 0.5761
AUC: 0.8728

Epoch 22/30
 - 0s - loss: 0.9171 - val_loss: 0.5753
AUC: 0.8728

Epoch 23/30
 - 0s - loss: 0.9121 - val_loss: 0.5705
AUC: 0.8728

Epoch 24/30
 - 0s - loss: 0.9095 - val_loss: 0.5692
AUC: 0.8728

Epoch 25/30
 - 0s - loss: 0.9097 - val_loss: 0.5730
AUC: 0.8728

Epoch 26/30
 - 0s - loss: 0.9145 - val_loss: 0.5728
AUC: 0.8729

Epoch 27/30
 - 0s - loss: 0.9078 - val_loss: 0.5734
AUC: 0.8729

Epoch 28/30
 - 0s - loss: 0.9087 - val_loss: 0.5715
AUC: 0.8729

Epoch 29/30
 - 0s - loss: 0.9106 - val_loss: 0.5723
AUC: 0.8729

Epoch 30/30
 - 0s - loss: 0.9113 - val_loss: 0.5721
Using TensorFlow backend.
AUC: 0.8729

2019-03-08 13:27:41.771734: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:27:41.936005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:27:41.936049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:27:42.223930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:27:42.223981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:27:42.223991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:27:42.224294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36278 rows...
Finished. It takes 5.3 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 4s - loss: 0.4590
Epoch 2/80
 - 3s - loss: 0.1073
Epoch 3/80
 - 3s - loss: 0.0954
Epoch 4/80
 - 3s - loss: 0.0870
Epoch 5/80
 - 3s - loss: 0.0786
Epoch 6/80
 - 3s - loss: 0.0712
Epoch 7/80
 - 3s - loss: 0.0654
Epoch 8/80
 - 3s - loss: 0.0608
Epoch 9/80
 - 3s - loss: 0.0566
Epoch 10/80
 - 3s - loss: 0.0529
Epoch 11/80
 - 3s - loss: 0.0496
Epoch 12/80
 - 3s - loss: 0.0469
Epoch 13/80
 - 3s - loss: 0.0446
Epoch 14/80
 - 3s - loss: 0.0429
Epoch 15/80
 - 3s - loss: 0.0416
Epoch 16/80
 - 3s - loss: 0.0405
Epoch 17/80
 - 3s - loss: 0.0396
Epoch 18/80
 - 3s - loss: 0.0389
Epoch 19/80
 - 3s - loss: 0.0383
Epoch 20/80
 - 3s - loss: 0.0378
Epoch 21/80
 - 3s - loss: 0.0374
Epoch 22/80
 - 3s - loss: 0.0371
Epoch 23/80
 - 3s - loss: 0.0368
Epoch 24/80
 - 3s - loss: 0.0366
Epoch 25/80
 - 3s - loss: 0.0364
Epoch 26/80
 - 3s - loss: 0.0362
Epoch 27/80
 - 3s - loss: 0.0360
Epoch 28/80
 - 3s - loss: 0.0359
Epoch 29/80
 - 3s - loss: 0.0358
Epoch 30/80
 - 3s - loss: 0.0357
Epoch 31/80
 - 3s - loss: 0.0356
Epoch 32/80
 - 3s - loss: 0.0355
Epoch 33/80
 - 3s - loss: 0.0354
Epoch 34/80
 - 3s - loss: 0.0353
Epoch 35/80
 - 3s - loss: 0.0353
Epoch 36/80
 - 3s - loss: 0.0352
Epoch 37/80
 - 3s - loss: 0.0351
Epoch 38/80
 - 3s - loss: 0.0351
Epoch 39/80
 - 3s - loss: 0.0350
Epoch 40/80
 - 3s - loss: 0.0350
Epoch 41/80
 - 3s - loss: 0.0349
Epoch 42/80
 - 3s - loss: 0.0349
Epoch 43/80
 - 3s - loss: 0.0349
Epoch 44/80
 - 3s - loss: 0.0348
Epoch 45/80
 - 3s - loss: 0.0337
Epoch 46/80
 - 3s - loss: 0.0336
Epoch 47/80
 - 3s - loss: 0.0335
Epoch 48/80
 - 3s - loss: 0.0335
Epoch 49/80
 - 3s - loss: 0.0335
Epoch 50/80
 - 3s - loss: 0.0332
Epoch 51/80
 - 3s - loss: 0.0332
Epoch 52/80
 - 3s - loss: 0.0332
Epoch 53/80
 - 3s - loss: 0.0332
Epoch 54/80
 - 3s - loss: 0.0331
Epoch 55/80
 - 3s - loss: 0.0331
Epoch 56/80
 - 3s - loss: 0.0331
Epoch 57/80
 - 3s - loss: 0.0331
Epoch 58/80
 - 3s - loss: 0.0331
Epoch 59/80
 - 3s - loss: 0.0331
Epoch 60/80
 - 3s - loss: 0.0331
Epoch 61/80
 - 3s - loss: 0.0331
Epoch 62/80
 - 3s - loss: 0.0331
Epoch 63/80
 - 3s - loss: 0.0331
Epoch 64/80
 - 3s - loss: 0.0331
Epoch 65/80
 - 3s - loss: 0.0331
Epoch 66/80
 - 3s - loss: 0.0331
Epoch 67/80
 - 3s - loss: 0.0331
Epoch 68/80
 - 3s - loss: 0.0331
Epoch 69/80
 - 3s - loss: 0.0331
Epoch 70/80
 - 3s - loss: 0.0331
Epoch 71/80
 - 3s - loss: 0.0331
Epoch 72/80
 - 3s - loss: 0.0331
Epoch 73/80
 - 3s - loss: 0.0331
Epoch 74/80
 - 3s - loss: 0.0331
Epoch 75/80
 - 3s - loss: 0.0331
Epoch 76/80
 - 3s - loss: 0.0331
Epoch 77/80
 - 3s - loss: 0.0331
Epoch 78/80
 - 3s - loss: 0.0331
Epoch 79/80
 - 3s - loss: 0.0331
Epoch 80/80
 - 3s - loss: 0.0331
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 29022 samples, validate on 7256 samples
Epoch 1/80
 - 1s - loss: 3.6473 - val_loss: 1.4399
AUC: 0.8170

Epoch 2/80
 - 0s - loss: 2.3177 - val_loss: 0.9333
AUC: 0.8348

Epoch 3/80
 - 0s - loss: 1.5946 - val_loss: 0.8137
AUC: 0.8425

Epoch 4/80
 - 0s - loss: 1.3027 - val_loss: 0.7492
AUC: 0.8468

Epoch 5/80
 - 0s - loss: 1.1851 - val_loss: 0.6388
AUC: 0.8472

Epoch 6/80
 - 0s - loss: 1.1284 - val_loss: 0.6218
AUC: 0.8507

Epoch 7/80
 - 0s - loss: 1.1079 - val_loss: 0.6482
AUC: 0.8540

Epoch 8/80
 - 0s - loss: 1.0762 - val_loss: 0.6826
AUC: 0.8562

Epoch 9/80
 - 0s - loss: 1.0737 - val_loss: 0.6698
AUC: 0.8566

Epoch 10/80
 - 0s - loss: 1.0635 - val_loss: 0.6561
AUC: 0.8573

Epoch 11/80
 - 0s - loss: 1.0547 - val_loss: 0.6289
AUC: 0.8580

Epoch 12/80
 - 0s - loss: 1.0459 - val_loss: 0.6148
AUC: 0.8589

Epoch 13/80
 - 0s - loss: 1.0490 - val_loss: 0.6372
AUC: 0.8607

Epoch 14/80
 - 0s - loss: 1.0341 - val_loss: 0.6180
AUC: 0.8612

Epoch 15/80
 - 0s - loss: 1.0305 - val_loss: 0.6830
AUC: 0.8620

Epoch 16/80
 - 0s - loss: 1.0272 - val_loss: 0.6483
AUC: 0.8625

Epoch 17/80
 - 0s - loss: 1.0265 - val_loss: 0.6308
AUC: 0.8622

Epoch 18/80
 - 0s - loss: 1.0214 - val_loss: 0.5969
AUC: 0.8627

Epoch 19/80
 - 0s - loss: 1.0148 - val_loss: 0.6065
AUC: 0.8632

Epoch 20/80
 - 0s - loss: 1.0158 - val_loss: 0.6398
AUC: 0.8643

Epoch 21/80
 - 0s - loss: 1.0169 - val_loss: 0.6333
AUC: 0.8642

Epoch 22/80
 - 0s - loss: 1.0079 - val_loss: 0.5859
AUC: 0.8638

Epoch 23/80
 - 0s - loss: 1.0066 - val_loss: 0.6098
AUC: 0.8648

Epoch 24/80
 - 0s - loss: 0.9978 - val_loss: 0.6716
AUC: 0.8657

Epoch 25/80
 - 0s - loss: 0.9991 - val_loss: 0.6141
AUC: 0.8657

Epoch 26/80
 - 0s - loss: 0.9934 - val_loss: 0.6508
AUC: 0.8661

Epoch 27/80
 - 0s - loss: 0.9904 - val_loss: 0.5552
AUC: 0.8645

Epoch 28/80
 - 0s - loss: 0.9939 - val_loss: 0.5852
AUC: 0.8660

Epoch 29/80
 - 0s - loss: 0.9853 - val_loss: 0.6510
AUC: 0.8665

Epoch 30/80
 - 0s - loss: 0.9831 - val_loss: 0.6015
AUC: 0.8663

Epoch 31/80
 - 0s - loss: 0.9864 - val_loss: 0.6143
AUC: 0.8673

Epoch 32/80
 - 0s - loss: 0.9745 - val_loss: 0.6179
AUC: 0.8671

Epoch 33/80
 - 0s - loss: 0.9804 - val_loss: 0.5995
AUC: 0.8675

Epoch 34/80
 - 0s - loss: 0.9769 - val_loss: 0.6059
AUC: 0.8677

Epoch 35/80
 - 0s - loss: 0.9786 - val_loss: 0.5764
AUC: 0.8669

Epoch 36/80
 - 0s - loss: 0.9776 - val_loss: 0.6176
AUC: 0.8668

Epoch 37/80
 - 0s - loss: 0.9692 - val_loss: 0.6174
AUC: 0.8670

Epoch 38/80
 - 0s - loss: 0.9680 - val_loss: 0.5879
AUC: 0.8670

Epoch 39/80
 - 0s - loss: 0.9625 - val_loss: 0.6031
AUC: 0.8674

Epoch 40/80
 - 0s - loss: 0.9644 - val_loss: 0.5898
AUC: 0.8673

Epoch 41/80
 - 0s - loss: 0.9643 - val_loss: 0.6042
AUC: 0.8675

Epoch 42/80
 - 0s - loss: 0.9615 - val_loss: 0.5991
AUC: 0.8675

Epoch 43/80
 - 0s - loss: 0.9588 - val_loss: 0.5862
AUC: 0.8674

Epoch 44/80
 - 0s - loss: 0.9596 - val_loss: 0.6120
AUC: 0.8678

Epoch 45/80
 - 0s - loss: 0.9560 - val_loss: 0.5995
AUC: 0.8676

Epoch 46/80
 - 0s - loss: 0.9596 - val_loss: 0.6008
AUC: 0.8677

Epoch 47/80
 - 0s - loss: 0.9611 - val_loss: 0.5778
AUC: 0.8675

Epoch 48/80
 - 0s - loss: 0.9582 - val_loss: 0.5975
AUC: 0.8678

Epoch 49/80
 - 0s - loss: 0.9582 - val_loss: 0.5955
AUC: 0.8677

Epoch 50/80
 - 0s - loss: 0.9578 - val_loss: 0.5924
AUC: 0.8678

Epoch 51/80
 - 0s - loss: 0.9562 - val_loss: 0.5925
AUC: 0.8677

Epoch 52/80
 - 0s - loss: 0.9571 - val_loss: 0.5943
AUC: 0.8677

Epoch 53/80
 - 0s - loss: 0.9563 - val_loss: 0.5989
AUC: 0.8678

Epoch 54/80
 - 0s - loss: 0.9590 - val_loss: 0.5907
AUC: 0.8676

Epoch 55/80
 - 0s - loss: 0.9567 - val_loss: 0.5964
AUC: 0.8677

Epoch 56/80
 - 0s - loss: 0.9609 - val_loss: 0.5945
AUC: 0.8677

Epoch 57/80
 - 0s - loss: 0.9551 - val_loss: 0.5963
AUC: 0.8677

Train on 29022 samples, validate on 7256 samples
Epoch 1/30
 - 1s - loss: 0.9626 - val_loss: 0.6101
AUC: 0.8678

Epoch 2/30
 - 0s - loss: 0.9580 - val_loss: 0.5931
AUC: 0.8679

Epoch 3/30
 - 0s - loss: 0.9580 - val_loss: 0.5855
AUC: 0.8679

Epoch 4/30
 - 0s - loss: 0.9539 - val_loss: 0.5950
AUC: 0.8680

Epoch 5/30
 - 0s - loss: 0.9535 - val_loss: 0.6075
AUC: 0.8683

Epoch 6/30
 - 0s - loss: 0.9489 - val_loss: 0.5949
AUC: 0.8684

Epoch 7/30
 - 0s - loss: 0.9541 - val_loss: 0.5769
AUC: 0.8682

Epoch 8/30
 - 0s - loss: 0.9502 - val_loss: 0.5888
AUC: 0.8686

Epoch 9/30
 - 0s - loss: 0.9488 - val_loss: 0.5815
AUC: 0.8687

Epoch 10/30
 - 0s - loss: 0.9455 - val_loss: 0.5929
AUC: 0.8687

Epoch 11/30
 - 0s - loss: 0.9422 - val_loss: 0.5934
AUC: 0.8689

Epoch 12/30
 - 0s - loss: 0.9412 - val_loss: 0.5650
AUC: 0.8686

Epoch 13/30
 - 0s - loss: 0.9479 - val_loss: 0.5959
AUC: 0.8691

Epoch 14/30
 - 0s - loss: 0.9368 - val_loss: 0.5681
AUC: 0.8689

Epoch 15/30
 - 0s - loss: 0.9404 - val_loss: 0.5735
AUC: 0.8691

Epoch 16/30
 - 0s - loss: 0.9365 - val_loss: 0.5759
AUC: 0.8692

Epoch 17/30
 - 0s - loss: 0.9349 - val_loss: 0.5781
AUC: 0.8693

Epoch 18/30
 - 0s - loss: 0.9306 - val_loss: 0.5854
AUC: 0.8695

Epoch 19/30
 - 0s - loss: 0.9280 - val_loss: 0.5962
AUC: 0.8697

Epoch 20/30
 - 0s - loss: 0.9309 - val_loss: 0.5912
AUC: 0.8697

Epoch 21/30
 - 0s - loss: 0.9251 - val_loss: 0.5724
AUC: 0.8695

Epoch 22/30
 - 0s - loss: 0.9269 - val_loss: 0.5954
AUC: 0.8701

Epoch 23/30
 - 0s - loss: 0.9246 - val_loss: 0.5854
AUC: 0.8700

Epoch 24/30
 - 0s - loss: 0.9287 - val_loss: 0.5857
AUC: 0.8700

Epoch 25/30
 - 0s - loss: 0.9227 - val_loss: 0.5851
AUC: 0.8700

Epoch 26/30
 - 0s - loss: 0.9248 - val_loss: 0.5819
AUC: 0.8699

Epoch 27/30
 - 0s - loss: 0.9230 - val_loss: 0.5815
AUC: 0.8699

Epoch 28/30
 - 0s - loss: 0.9186 - val_loss: 0.5808
AUC: 0.8700

Epoch 29/30
 - 0s - loss: 0.9199 - val_loss: 0.5846
AUC: 0.8700

Epoch 30/30
 - 0s - loss: 0.9237 - val_loss: 0.5824
Using TensorFlow backend.
AUC: 0.8700

2019-03-08 13:33:14.982685: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:33:15.145349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:33:15.145395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:33:15.438392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:33:15.438444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:33:15.438453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:33:15.438709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 36194 rows...
Finished. It takes 5.3 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 3s - loss: 0.5474
Epoch 2/80
 - 3s - loss: 0.1244
Epoch 3/80
 - 3s - loss: 0.1120
Epoch 4/80
 - 3s - loss: 0.1036
Epoch 5/80
 - 3s - loss: 0.0937
Epoch 6/80
 - 3s - loss: 0.0838
Epoch 7/80
 - 3s - loss: 0.0758
Epoch 8/80
 - 3s - loss: 0.0695
Epoch 9/80
 - 3s - loss: 0.0642
Epoch 10/80
 - 3s - loss: 0.0599
Epoch 11/80
 - 3s - loss: 0.0565
Epoch 12/80
 - 3s - loss: 0.0536
Epoch 13/80
 - 3s - loss: 0.0513
Epoch 14/80
 - 3s - loss: 0.0493
Epoch 15/80
 - 3s - loss: 0.0477
Epoch 16/80
 - 3s - loss: 0.0463
Epoch 17/80
 - 3s - loss: 0.0452
Epoch 18/80
 - 3s - loss: 0.0443
Epoch 19/80
 - 3s - loss: 0.0435
Epoch 20/80
 - 3s - loss: 0.0429
Epoch 21/80
 - 3s - loss: 0.0423
Epoch 22/80
 - 3s - loss: 0.0419
Epoch 23/80
 - 3s - loss: 0.0415
Epoch 24/80
 - 3s - loss: 0.0412
Epoch 25/80
 - 3s - loss: 0.0409
Epoch 26/80
 - 3s - loss: 0.0406
Epoch 27/80
 - 3s - loss: 0.0404
Epoch 28/80
 - 3s - loss: 0.0402
Epoch 29/80
 - 3s - loss: 0.0401
Epoch 30/80
 - 3s - loss: 0.0399
Epoch 31/80
 - 3s - loss: 0.0398
Epoch 32/80
 - 3s - loss: 0.0397
Epoch 33/80
 - 3s - loss: 0.0396
Epoch 34/80
 - 3s - loss: 0.0395
Epoch 35/80
 - 3s - loss: 0.0394
Epoch 36/80
 - 3s - loss: 0.0393
Epoch 37/80
 - 3s - loss: 0.0392
Epoch 38/80
 - 3s - loss: 0.0392
Epoch 39/80
 - 3s - loss: 0.0391
Epoch 40/80
 - 3s - loss: 0.0390
Epoch 41/80
 - 3s - loss: 0.0390
Epoch 42/80
 - 3s - loss: 0.0390
Epoch 43/80
 - 3s - loss: 0.0389
Epoch 44/80
 - 3s - loss: 0.0389
Epoch 45/80
 - 3s - loss: 0.0388
Epoch 46/80
 - 3s - loss: 0.0388
Epoch 47/80
 - 3s - loss: 0.0387
Epoch 48/80
 - 3s - loss: 0.0387
Epoch 49/80
 - 3s - loss: 0.0387
Epoch 50/80
 - 3s - loss: 0.0375
Epoch 51/80
 - 3s - loss: 0.0374
Epoch 52/80
 - 3s - loss: 0.0374
Epoch 53/80
 - 3s - loss: 0.0374
Epoch 54/80
 - 3s - loss: 0.0374
Epoch 55/80
 - 3s - loss: 0.0371
Epoch 56/80
 - 3s - loss: 0.0371
Epoch 57/80
 - 3s - loss: 0.0371
Epoch 58/80
 - 3s - loss: 0.0370
Epoch 59/80
 - 3s - loss: 0.0370
Epoch 60/80
 - 3s - loss: 0.0370
Epoch 61/80
 - 3s - loss: 0.0370
Epoch 62/80
 - 3s - loss: 0.0370
Epoch 63/80
 - 3s - loss: 0.0370
Epoch 64/80
 - 3s - loss: 0.0370
Epoch 65/80
 - 3s - loss: 0.0370
Epoch 66/80
 - 3s - loss: 0.0370
Epoch 67/80
 - 3s - loss: 0.0370
Epoch 68/80
 - 3s - loss: 0.0370
Epoch 69/80
 - 3s - loss: 0.0370
Epoch 70/80
 - 3s - loss: 0.0370
Epoch 71/80
 - 3s - loss: 0.0370
Epoch 72/80
 - 3s - loss: 0.0370
Epoch 73/80
 - 3s - loss: 0.0370
Epoch 74/80
 - 3s - loss: 0.0370
Epoch 75/80
 - 3s - loss: 0.0370
Epoch 76/80
 - 3s - loss: 0.0370
Epoch 77/80
 - 3s - loss: 0.0370
Epoch 78/80
 - 3s - loss: 0.0370
Epoch 79/80
 - 3s - loss: 0.0370
Epoch 80/80
 - 3s - loss: 0.0370
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28955 samples, validate on 7239 samples
Epoch 1/80
 - 1s - loss: 4.7382 - val_loss: 1.8045
AUC: 0.7775

Epoch 2/80
 - 0s - loss: 3.0249 - val_loss: 0.9928
AUC: 0.7936

Epoch 3/80
 - 0s - loss: 1.9910 - val_loss: 0.8272
AUC: 0.8161

Epoch 4/80
 - 0s - loss: 1.4983 - val_loss: 0.7805
AUC: 0.8271

Epoch 5/80
 - 0s - loss: 1.2790 - val_loss: 0.7059
AUC: 0.8332

Epoch 6/80
 - 0s - loss: 1.2078 - val_loss: 0.7540
AUC: 0.8367

Epoch 7/80
 - 0s - loss: 1.1594 - val_loss: 0.7189
AUC: 0.8412

Epoch 8/80
 - 0s - loss: 1.1301 - val_loss: 0.5516
AUC: 0.8423

Epoch 9/80
 - 0s - loss: 1.1121 - val_loss: 0.6537
AUC: 0.8472

Epoch 10/80
 - 0s - loss: 1.0936 - val_loss: 0.6442
AUC: 0.8483

Epoch 11/80
 - 0s - loss: 1.0801 - val_loss: 0.6246
AUC: 0.8478

Epoch 12/80
 - 0s - loss: 1.0699 - val_loss: 0.6917
AUC: 0.8519

Epoch 13/80
 - 0s - loss: 1.0658 - val_loss: 0.6729
AUC: 0.8522

Epoch 14/80
 - 0s - loss: 1.0561 - val_loss: 0.6662
AUC: 0.8526

Epoch 15/80
 - 0s - loss: 1.0564 - val_loss: 0.6094
AUC: 0.8533

Epoch 16/80
 - 0s - loss: 1.0491 - val_loss: 0.7056
AUC: 0.8543

Epoch 17/80
 - 0s - loss: 1.0446 - val_loss: 0.6224
AUC: 0.8551

Epoch 18/80
 - 0s - loss: 1.0387 - val_loss: 0.6060
AUC: 0.8559

Epoch 19/80
 - 0s - loss: 1.0302 - val_loss: 0.6349
AUC: 0.8564

Epoch 20/80
 - 0s - loss: 1.0327 - val_loss: 0.6452
AUC: 0.8571

Epoch 21/80
 - 0s - loss: 1.0242 - val_loss: 0.6509
AUC: 0.8569

Epoch 22/80
 - 0s - loss: 1.0247 - val_loss: 0.6449
AUC: 0.8574

Epoch 23/80
 - 0s - loss: 1.0204 - val_loss: 0.6382
AUC: 0.8574

Epoch 24/80
 - 0s - loss: 1.0219 - val_loss: 0.6546
AUC: 0.8578

Epoch 25/80
 - 0s - loss: 1.0235 - val_loss: 0.6458
AUC: 0.8577

Epoch 26/80
 - 0s - loss: 1.0208 - val_loss: 0.6272
AUC: 0.8574

Epoch 27/80
 - 0s - loss: 1.0227 - val_loss: 0.6377
AUC: 0.8578

Epoch 28/80
 - 0s - loss: 1.0186 - val_loss: 0.6291
AUC: 0.8577

Epoch 29/80
 - 0s - loss: 1.0139 - val_loss: 0.6351
AUC: 0.8580

Epoch 30/80
 - 0s - loss: 1.0191 - val_loss: 0.6361
AUC: 0.8580

Epoch 31/80
 - 0s - loss: 1.0158 - val_loss: 0.6380
AUC: 0.8580

Epoch 32/80
 - 0s - loss: 1.0140 - val_loss: 0.6369
AUC: 0.8580

Epoch 33/80
 - 0s - loss: 1.0155 - val_loss: 0.6338
AUC: 0.8579

Epoch 34/80
 - 0s - loss: 1.0202 - val_loss: 0.6420
AUC: 0.8581

Epoch 35/80
 - 0s - loss: 1.0139 - val_loss: 0.6416
AUC: 0.8581

Epoch 36/80
 - 0s - loss: 1.0179 - val_loss: 0.6387
AUC: 0.8582

Epoch 37/80
 - 0s - loss: 1.0150 - val_loss: 0.6387
AUC: 0.8582

Epoch 38/80
 - 0s - loss: 1.0115 - val_loss: 0.6370
AUC: 0.8582

Train on 28955 samples, validate on 7239 samples
Epoch 1/30
 - 1s - loss: 1.0160 - val_loss: 0.6350
AUC: 0.8581

Epoch 2/30
 - 0s - loss: 1.0150 - val_loss: 0.6381
AUC: 0.8585

Epoch 3/30
 - 0s - loss: 1.0164 - val_loss: 0.6485
AUC: 0.8592

Epoch 4/30
 - 0s - loss: 1.0075 - val_loss: 0.6252
AUC: 0.8589

Epoch 5/30
 - 0s - loss: 1.0075 - val_loss: 0.6484
AUC: 0.8590

Epoch 6/30
 - 0s - loss: 1.0088 - val_loss: 0.6444
AUC: 0.8594

Epoch 7/30
 - 0s - loss: 1.0068 - val_loss: 0.6255
AUC: 0.8593

Epoch 8/30
 - 0s - loss: 1.0014 - val_loss: 0.6358
AUC: 0.8595

Epoch 9/30
 - 0s - loss: 1.0001 - val_loss: 0.6311
AUC: 0.8595

Epoch 10/30
 - 0s - loss: 1.0064 - val_loss: 0.6217
AUC: 0.8598

Epoch 11/30
 - 0s - loss: 0.9892 - val_loss: 0.6249
AUC: 0.8599

Epoch 12/30
 - 0s - loss: 0.9934 - val_loss: 0.6439
AUC: 0.8606

Epoch 13/30
 - 0s - loss: 0.9953 - val_loss: 0.6457
AUC: 0.8606

Epoch 14/30
 - 0s - loss: 0.9939 - val_loss: 0.6384
AUC: 0.8607

Epoch 15/30
 - 0s - loss: 0.9914 - val_loss: 0.6154
AUC: 0.8606

Epoch 16/30
 - 0s - loss: 0.9836 - val_loss: 0.6150
AUC: 0.8607

Epoch 17/30
 - 0s - loss: 0.9875 - val_loss: 0.6484
AUC: 0.8613

Epoch 18/30
 - 0s - loss: 0.9807 - val_loss: 0.6272
AUC: 0.8611

Epoch 19/30
 - 0s - loss: 0.9884 - val_loss: 0.6288
AUC: 0.8614

Epoch 20/30
 - 0s - loss: 0.9820 - val_loss: 0.6279
AUC: 0.8613

Epoch 21/30
 - 0s - loss: 0.9824 - val_loss: 0.6196
AUC: 0.8610

Epoch 22/30
 - 0s - loss: 0.9837 - val_loss: 0.6224
AUC: 0.8614

Epoch 23/30
 - 0s - loss: 0.9714 - val_loss: 0.6069
AUC: 0.8612

Epoch 24/30
 - 0s - loss: 0.9780 - val_loss: 0.6234
AUC: 0.8618

Epoch 25/30
 - 0s - loss: 0.9735 - val_loss: 0.6002
AUC: 0.8614

Epoch 26/30
 - 0s - loss: 0.9775 - val_loss: 0.6316
AUC: 0.8621

Epoch 27/30
 - 0s - loss: 0.9719 - val_loss: 0.6289
AUC: 0.8621

Epoch 28/30
 - 0s - loss: 0.9692 - val_loss: 0.6206
AUC: 0.8619

Epoch 29/30
 - 0s - loss: 0.9673 - val_loss: 0.6156
AUC: 0.8620

Epoch 30/30
 - 0s - loss: 0.9666 - val_loss: 0.6261
Using TensorFlow backend.
AUC: 0.8624

2019-03-08 13:38:00.787254: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:38:00.951244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:38:00.951288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:38:01.248803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:38:01.248855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:38:01.248874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:38:01.249127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35874 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 0.9705
Epoch 2/80
 - 2s - loss: 0.1862
Epoch 3/80
 - 2s - loss: 0.1558
Epoch 4/80
 - 2s - loss: 0.1434
Epoch 5/80
 - 2s - loss: 0.1329
Epoch 6/80
 - 2s - loss: 0.1246
Epoch 7/80
 - 2s - loss: 0.1169
Epoch 8/80
 - 2s - loss: 0.1091
Epoch 9/80
 - 2s - loss: 0.1013
Epoch 10/80
 - 2s - loss: 0.0938
Epoch 11/80
 - 2s - loss: 0.0871
Epoch 12/80
 - 2s - loss: 0.0814
Epoch 13/80
 - 2s - loss: 0.0766
Epoch 14/80
 - 2s - loss: 0.0726
Epoch 15/80
 - 2s - loss: 0.0690
Epoch 16/80
 - 2s - loss: 0.0659
Epoch 17/80
 - 2s - loss: 0.0632
Epoch 18/80
 - 2s - loss: 0.0610
Epoch 19/80
 - 2s - loss: 0.0592
Epoch 20/80
 - 2s - loss: 0.0577
Epoch 21/80
 - 2s - loss: 0.0564
Epoch 22/80
 - 2s - loss: 0.0554
Epoch 23/80
 - 2s - loss: 0.0545
Epoch 24/80
 - 2s - loss: 0.0537
Epoch 25/80
 - 2s - loss: 0.0531
Epoch 26/80
 - 2s - loss: 0.0525
Epoch 27/80
 - 2s - loss: 0.0520
Epoch 28/80
 - 2s - loss: 0.0516
Epoch 29/80
 - 2s - loss: 0.0512
Epoch 30/80
 - 2s - loss: 0.0509
Epoch 31/80
 - 2s - loss: 0.0506
Epoch 32/80
 - 2s - loss: 0.0504
Epoch 33/80
 - 2s - loss: 0.0502
Epoch 34/80
 - 2s - loss: 0.0500
Epoch 35/80
 - 2s - loss: 0.0498
Epoch 36/80
 - 2s - loss: 0.0496
Epoch 37/80
 - 2s - loss: 0.0495
Epoch 38/80
 - 2s - loss: 0.0494
Epoch 39/80
 - 2s - loss: 0.0493
Epoch 40/80
 - 2s - loss: 0.0492
Epoch 41/80
 - 2s - loss: 0.0491
Epoch 42/80
 - 2s - loss: 0.0490
Epoch 43/80
 - 2s - loss: 0.0489
Epoch 44/80
 - 2s - loss: 0.0488
Epoch 45/80
 - 2s - loss: 0.0488
Epoch 46/80
 - 2s - loss: 0.0487
Epoch 47/80
 - 2s - loss: 0.0486
Epoch 48/80
 - 2s - loss: 0.0486
Epoch 49/80
 - 2s - loss: 0.0485
Epoch 50/80
 - 2s - loss: 0.0485
Epoch 51/80
 - 2s - loss: 0.0484
Epoch 52/80
 - 2s - loss: 0.0484
Epoch 53/80
 - 2s - loss: 0.0484
Epoch 54/80
 - 2s - loss: 0.0483
Epoch 55/80
 - 2s - loss: 0.0483
Epoch 56/80
 - 2s - loss: 0.0483
Epoch 57/80
 - 2s - loss: 0.0482
Epoch 58/80
 - 2s - loss: 0.0482
Epoch 59/80
 - 2s - loss: 0.0471
Epoch 60/80
 - 2s - loss: 0.0470
Epoch 61/80
 - 2s - loss: 0.0469
Epoch 62/80
 - 2s - loss: 0.0469
Epoch 63/80
 - 2s - loss: 0.0469
Epoch 64/80
 - 2s - loss: 0.0466
Epoch 65/80
 - 2s - loss: 0.0466
Epoch 66/80
 - 2s - loss: 0.0466
Epoch 67/80
 - 2s - loss: 0.0466
Epoch 68/80
 - 2s - loss: 0.0466
Epoch 69/80
 - 2s - loss: 0.0466
Epoch 70/80
 - 2s - loss: 0.0466
Epoch 71/80
 - 2s - loss: 0.0465
Epoch 72/80
 - 2s - loss: 0.0465
Epoch 73/80
 - 2s - loss: 0.0465
Epoch 74/80
 - 2s - loss: 0.0465
Epoch 75/80
 - 2s - loss: 0.0465
Epoch 76/80
 - 2s - loss: 0.0465
Epoch 77/80
 - 2s - loss: 0.0465
Epoch 78/80
 - 2s - loss: 0.0465
Epoch 79/80
 - 2s - loss: 0.0465
Epoch 80/80
 - 2s - loss: 0.0465
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28699 samples, validate on 7175 samples
Epoch 1/80
 - 1s - loss: 4.6781 - val_loss: 1.9773
AUC: 0.7993

Epoch 2/80
 - 0s - loss: 3.2027 - val_loss: 1.1828
AUC: 0.8180

Epoch 3/80
 - 0s - loss: 2.2954 - val_loss: 0.8522
AUC: 0.8284

Epoch 4/80
 - 0s - loss: 1.6776 - val_loss: 0.6830
AUC: 0.8334

Epoch 5/80
 - 0s - loss: 1.3979 - val_loss: 0.7167
AUC: 0.8349

Epoch 6/80
 - 0s - loss: 1.2648 - val_loss: 0.7654
AUC: 0.8407

Epoch 7/80
 - 0s - loss: 1.1821 - val_loss: 0.5575
AUC: 0.8396

Epoch 8/80
 - 0s - loss: 1.1522 - val_loss: 0.6946
AUC: 0.8455

Epoch 9/80
 - 0s - loss: 1.1249 - val_loss: 0.7273
AUC: 0.8474

Epoch 10/80
 - 0s - loss: 1.1044 - val_loss: 0.7515
AUC: 0.8514

Epoch 11/80
 - 0s - loss: 1.0945 - val_loss: 0.6090
AUC: 0.8508

Epoch 12/80
 - 0s - loss: 1.0778 - val_loss: 0.6263
AUC: 0.8532

Epoch 13/80
 - 0s - loss: 1.0747 - val_loss: 0.6482
AUC: 0.8531

Epoch 14/80
 - 0s - loss: 1.0686 - val_loss: 0.6570
AUC: 0.8557

Epoch 15/80
 - 0s - loss: 1.0643 - val_loss: 0.6343
AUC: 0.8565

Epoch 16/80
 - 0s - loss: 1.0438 - val_loss: 0.6222
AUC: 0.8554

Epoch 17/80
 - 0s - loss: 1.0467 - val_loss: 0.6252
AUC: 0.8573

Epoch 18/80
 - 0s - loss: 1.0352 - val_loss: 0.6600
AUC: 0.8581

Epoch 19/80
 - 0s - loss: 1.0370 - val_loss: 0.6156
AUC: 0.8576

Epoch 20/80
 - 0s - loss: 1.0333 - val_loss: 0.6194
AUC: 0.8578

Epoch 21/80
 - 0s - loss: 1.0409 - val_loss: 0.6340
AUC: 0.8584

Epoch 22/80
 - 0s - loss: 1.0300 - val_loss: 0.6261
AUC: 0.8583

Epoch 23/80
 - 0s - loss: 1.0301 - val_loss: 0.6506
AUC: 0.8592

Epoch 24/80
 - 0s - loss: 1.0270 - val_loss: 0.6267
AUC: 0.8592

Epoch 25/80
 - 0s - loss: 1.0222 - val_loss: 0.6119
AUC: 0.8589

Epoch 26/80
 - 0s - loss: 1.0197 - val_loss: 0.6193
AUC: 0.8590

Epoch 27/80
 - 0s - loss: 1.0177 - val_loss: 0.6116
AUC: 0.8589

Epoch 28/80
 - 0s - loss: 1.0260 - val_loss: 0.6273
AUC: 0.8590

Epoch 29/80
 - 0s - loss: 1.0198 - val_loss: 0.6348
AUC: 0.8594

Epoch 30/80
 - 0s - loss: 1.0261 - val_loss: 0.6253
AUC: 0.8594

Epoch 31/80
 - 0s - loss: 1.0262 - val_loss: 0.6335
AUC: 0.8595

Epoch 32/80
 - 0s - loss: 1.0199 - val_loss: 0.6363
AUC: 0.8597

Epoch 33/80
 - 0s - loss: 1.0241 - val_loss: 0.6320
AUC: 0.8596

Epoch 34/80
 - 0s - loss: 1.0183 - val_loss: 0.6300
AUC: 0.8596

Epoch 35/80
 - 0s - loss: 1.0261 - val_loss: 0.6315
AUC: 0.8597

Epoch 36/80
 - 0s - loss: 1.0144 - val_loss: 0.6293
AUC: 0.8596

Epoch 37/80
 - 0s - loss: 1.0262 - val_loss: 0.6268
AUC: 0.8595

Train on 28699 samples, validate on 7175 samples
Epoch 1/30
 - 1s - loss: 1.0255 - val_loss: 0.6404
AUC: 0.8599

Epoch 2/30
 - 0s - loss: 1.0145 - val_loss: 0.6263
AUC: 0.8599

Epoch 3/30
 - 0s - loss: 1.0173 - val_loss: 0.6331
AUC: 0.8599

Epoch 4/30
 - 0s - loss: 1.0152 - val_loss: 0.6248
AUC: 0.8604

Epoch 5/30
 - 0s - loss: 1.0157 - val_loss: 0.6390
AUC: 0.8608

Epoch 6/30
 - 0s - loss: 1.0075 - val_loss: 0.6389
AUC: 0.8609

Epoch 7/30
 - 0s - loss: 1.0115 - val_loss: 0.6052
AUC: 0.8606

Epoch 8/30
 - 0s - loss: 1.0084 - val_loss: 0.6375
AUC: 0.8612

Epoch 9/30
 - 0s - loss: 1.0102 - val_loss: 0.6231
AUC: 0.8610

Epoch 10/30
 - 0s - loss: 1.0044 - val_loss: 0.6277
AUC: 0.8613

Epoch 11/30
 - 0s - loss: 1.0017 - val_loss: 0.6269
AUC: 0.8615

Epoch 12/30
 - 0s - loss: 0.9970 - val_loss: 0.6290
AUC: 0.8618

Epoch 13/30
 - 0s - loss: 1.0084 - val_loss: 0.6027
AUC: 0.8615

Epoch 14/30
 - 0s - loss: 0.9977 - val_loss: 0.6181
AUC: 0.8621

Epoch 15/30
 - 0s - loss: 0.9971 - val_loss: 0.6111
AUC: 0.8621

Epoch 16/30
 - 0s - loss: 0.9957 - val_loss: 0.6263
AUC: 0.8623

Epoch 17/30
 - 0s - loss: 0.9952 - val_loss: 0.6246
AUC: 0.8624

Epoch 18/30
 - 0s - loss: 0.9908 - val_loss: 0.6171
AUC: 0.8624

Epoch 19/30
 - 0s - loss: 0.9852 - val_loss: 0.6202
AUC: 0.8626

Epoch 20/30
 - 0s - loss: 0.9857 - val_loss: 0.6299
AUC: 0.8629

Epoch 21/30
 - 0s - loss: 0.9919 - val_loss: 0.6129
AUC: 0.8626

Epoch 22/30
 - 0s - loss: 0.9836 - val_loss: 0.6329
AUC: 0.8632

Epoch 23/30
 - 0s - loss: 0.9888 - val_loss: 0.6292
AUC: 0.8634

Epoch 24/30
 - 0s - loss: 0.9824 - val_loss: 0.6212
AUC: 0.8634

Epoch 25/30
 - 0s - loss: 0.9814 - val_loss: 0.6163
AUC: 0.8634

Epoch 26/30
 - 0s - loss: 0.9830 - val_loss: 0.6173
AUC: 0.8634

Epoch 27/30
 - 0s - loss: 0.9809 - val_loss: 0.6105
AUC: 0.8633

Epoch 28/30
 - 0s - loss: 0.9814 - val_loss: 0.6100
AUC: 0.8633

Epoch 29/30
 - 0s - loss: 0.9842 - val_loss: 0.6138
AUC: 0.8634

Epoch 30/30
 - 0s - loss: 0.9831 - val_loss: 0.6122
Using TensorFlow backend.
AUC: 0.8633

2019-03-08 13:41:24.861837: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:41:25.025604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:41:25.025655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:41:25.321999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:41:25.322051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:41:25.322059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:41:25.322319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35230 rows...
Finished. It takes 4.0 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 2.3694
Epoch 2/80
 - 1s - loss: 0.7105
Epoch 3/80
 - 1s - loss: 0.2717
Epoch 4/80
 - 1s - loss: 0.2309
Epoch 5/80
 - 1s - loss: 0.2165
Epoch 6/80
 - 1s - loss: 0.2051
Epoch 7/80
 - 1s - loss: 0.1957
Epoch 8/80
 - 1s - loss: 0.1883
Epoch 9/80
 - 1s - loss: 0.1820
Epoch 10/80
 - 1s - loss: 0.1759
Epoch 11/80
 - 1s - loss: 0.1696
Epoch 12/80
 - 1s - loss: 0.1630
Epoch 13/80
 - 1s - loss: 0.1560
Epoch 14/80
 - 1s - loss: 0.1491
Epoch 15/80
 - 1s - loss: 0.1423
Epoch 16/80
 - 1s - loss: 0.1357
Epoch 17/80
 - 1s - loss: 0.1291
Epoch 18/80
 - 1s - loss: 0.1227
Epoch 19/80
 - 1s - loss: 0.1166
Epoch 20/80
 - 1s - loss: 0.1108
Epoch 21/80
 - 1s - loss: 0.1056
Epoch 22/80
 - 1s - loss: 0.1009
Epoch 23/80
 - 1s - loss: 0.0967
Epoch 24/80
 - 1s - loss: 0.0929
Epoch 25/80
 - 1s - loss: 0.0895
Epoch 26/80
 - 1s - loss: 0.0865
Epoch 27/80
 - 1s - loss: 0.0838
Epoch 28/80
 - 1s - loss: 0.0813
Epoch 29/80
 - 1s - loss: 0.0791
Epoch 30/80
 - 1s - loss: 0.0770
Epoch 31/80
 - 1s - loss: 0.0752
Epoch 32/80
 - 1s - loss: 0.0736
Epoch 33/80
 - 1s - loss: 0.0721
Epoch 34/80
 - 1s - loss: 0.0708
Epoch 35/80
 - 1s - loss: 0.0695
Epoch 36/80
 - 1s - loss: 0.0684
Epoch 37/80
 - 1s - loss: 0.0674
Epoch 38/80
 - 1s - loss: 0.0665
Epoch 39/80
 - 1s - loss: 0.0657
Epoch 40/80
 - 1s - loss: 0.0650
Epoch 41/80
 - 1s - loss: 0.0643
Epoch 42/80
 - 1s - loss: 0.0637
Epoch 43/80
 - 1s - loss: 0.0632
Epoch 44/80
 - 1s - loss: 0.0627
Epoch 45/80
 - 1s - loss: 0.0623
Epoch 46/80
 - 1s - loss: 0.0619
Epoch 47/80
 - 1s - loss: 0.0616
Epoch 48/80
 - 1s - loss: 0.0613
Epoch 49/80
 - 1s - loss: 0.0610
Epoch 50/80
 - 1s - loss: 0.0607
Epoch 51/80
 - 1s - loss: 0.0605
Epoch 52/80
 - 1s - loss: 0.0603
Epoch 53/80
 - 1s - loss: 0.0601
Epoch 54/80
 - 1s - loss: 0.0599
Epoch 55/80
 - 1s - loss: 0.0598
Epoch 56/80
 - 1s - loss: 0.0596
Epoch 57/80
 - 1s - loss: 0.0595
Epoch 58/80
 - 1s - loss: 0.0594
Epoch 59/80
 - 1s - loss: 0.0593
Epoch 60/80
 - 1s - loss: 0.0592
Epoch 61/80
 - 1s - loss: 0.0591
Epoch 62/80
 - 1s - loss: 0.0590
Epoch 63/80
 - 1s - loss: 0.0589
Epoch 64/80
 - 1s - loss: 0.0588
Epoch 65/80
 - 1s - loss: 0.0588
Epoch 66/80
 - 1s - loss: 0.0587
Epoch 67/80
 - 1s - loss: 0.0586
Epoch 68/80
 - 1s - loss: 0.0586
Epoch 69/80
 - 1s - loss: 0.0585
Epoch 70/80
 - 1s - loss: 0.0585
Epoch 71/80
 - 1s - loss: 0.0584
Epoch 72/80
 - 1s - loss: 0.0584
Epoch 73/80
 - 1s - loss: 0.0583
Epoch 74/80
 - 1s - loss: 0.0583
Epoch 75/80
 - 1s - loss: 0.0582
Epoch 76/80
 - 1s - loss: 0.0582
Epoch 77/80
 - 1s - loss: 0.0582
Epoch 78/80
 - 1s - loss: 0.0581
Epoch 79/80
 - 1s - loss: 0.0581
Epoch 80/80
 - 1s - loss: 0.0581
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28184 samples, validate on 7046 samples
Epoch 1/80
 - 1s - loss: 4.7197 - val_loss: 1.7224
AUC: 0.7988

Epoch 2/80
 - 0s - loss: 2.7726 - val_loss: 1.1045
AUC: 0.8194

Epoch 3/80
 - 0s - loss: 1.7717 - val_loss: 0.7966
AUC: 0.8267

Epoch 4/80
 - 0s - loss: 1.3986 - val_loss: 0.8190
AUC: 0.8312

Epoch 5/80
 - 0s - loss: 1.2383 - val_loss: 0.6845
AUC: 0.8344

Epoch 6/80
 - 0s - loss: 1.1791 - val_loss: 0.7429
AUC: 0.8396

Epoch 7/80
 - 0s - loss: 1.1385 - val_loss: 0.7236
AUC: 0.8437

Epoch 8/80
 - 0s - loss: 1.1191 - val_loss: 0.6374
AUC: 0.8446

Epoch 9/80
 - 0s - loss: 1.0965 - val_loss: 0.6957
AUC: 0.8483

Epoch 10/80
 - 0s - loss: 1.0982 - val_loss: 0.6882
AUC: 0.8488

Epoch 11/80
 - 0s - loss: 1.0867 - val_loss: 0.6710
AUC: 0.8518

Epoch 12/80
 - 0s - loss: 1.0756 - val_loss: 0.6322
AUC: 0.8522

Epoch 13/80
 - 0s - loss: 1.0641 - val_loss: 0.6465
AUC: 0.8530

Epoch 14/80
 - 0s - loss: 1.0537 - val_loss: 0.6423
AUC: 0.8545

Epoch 15/80
 - 0s - loss: 1.0510 - val_loss: 0.6478
AUC: 0.8558

Epoch 16/80
 - 0s - loss: 1.0446 - val_loss: 0.6597
AUC: 0.8576

Epoch 17/80
 - 0s - loss: 1.0430 - val_loss: 0.6503
AUC: 0.8574

Epoch 18/80
 - 0s - loss: 1.0342 - val_loss: 0.6512
AUC: 0.8580

Epoch 19/80
 - 0s - loss: 1.0329 - val_loss: 0.6153
AUC: 0.8568

Epoch 20/80
 - 0s - loss: 1.0297 - val_loss: 0.6509
AUC: 0.8577

Epoch 21/80
 - 0s - loss: 1.0200 - val_loss: 0.6184
AUC: 0.8583

Epoch 22/80
 - 0s - loss: 1.0213 - val_loss: 0.6865
AUC: 0.8602

Epoch 23/80
 - 0s - loss: 1.0194 - val_loss: 0.5720
AUC: 0.8576

Epoch 24/80
 - 0s - loss: 1.0187 - val_loss: 0.5768
AUC: 0.8592

Epoch 25/80
 - 0s - loss: 1.0222 - val_loss: 0.6737
AUC: 0.8610

Epoch 26/80
 - 0s - loss: 1.0145 - val_loss: 0.6180
AUC: 0.8603

Epoch 27/80
 - 0s - loss: 1.0064 - val_loss: 0.6783
AUC: 0.8611

Epoch 28/80
 - 0s - loss: 1.0087 - val_loss: 0.5726
AUC: 0.8611

Epoch 29/80
 - 0s - loss: 1.0058 - val_loss: 0.6662
AUC: 0.8616

Epoch 30/80
 - 0s - loss: 1.0021 - val_loss: 0.6137
AUC: 0.8621

Epoch 31/80
 - 0s - loss: 1.0034 - val_loss: 0.6249
AUC: 0.8620

Epoch 32/80
 - 0s - loss: 0.9979 - val_loss: 0.6217
AUC: 0.8608

Epoch 33/80
 - 0s - loss: 0.9968 - val_loss: 0.5952
AUC: 0.8628

Epoch 34/80
 - 0s - loss: 0.9944 - val_loss: 0.5890
AUC: 0.8628

Epoch 35/80
 - 0s - loss: 0.9922 - val_loss: 0.5977
AUC: 0.8627

Epoch 36/80
 - 0s - loss: 0.9867 - val_loss: 0.5857
AUC: 0.8628

Epoch 37/80
 - 0s - loss: 0.9844 - val_loss: 0.5953
AUC: 0.8629

Epoch 38/80
 - 0s - loss: 0.9864 - val_loss: 0.6175
AUC: 0.8631

Epoch 39/80
 - 0s - loss: 0.9871 - val_loss: 0.6024
AUC: 0.8634

Epoch 40/80
 - 0s - loss: 0.9890 - val_loss: 0.6198
AUC: 0.8634

Epoch 41/80
 - 0s - loss: 0.9857 - val_loss: 0.6137
AUC: 0.8634

Epoch 42/80
 - 0s - loss: 0.9888 - val_loss: 0.6055
AUC: 0.8634

Epoch 43/80
 - 0s - loss: 0.9850 - val_loss: 0.6377
AUC: 0.8635

Epoch 44/80
 - 0s - loss: 0.9851 - val_loss: 0.6146
AUC: 0.8635

Epoch 45/80
 - 0s - loss: 0.9853 - val_loss: 0.6124
AUC: 0.8634

Epoch 46/80
 - 0s - loss: 0.9863 - val_loss: 0.6159
AUC: 0.8635

Epoch 47/80
 - 0s - loss: 0.9814 - val_loss: 0.6137
AUC: 0.8635

Epoch 48/80
 - 0s - loss: 0.9805 - val_loss: 0.6084
AUC: 0.8634

Epoch 49/80
 - 0s - loss: 0.9874 - val_loss: 0.6115
AUC: 0.8635

Epoch 50/80
 - 0s - loss: 0.9814 - val_loss: 0.6162
AUC: 0.8635

Epoch 51/80
 - 0s - loss: 0.9843 - val_loss: 0.6145
AUC: 0.8634

Epoch 52/80
 - 0s - loss: 0.9874 - val_loss: 0.6145
AUC: 0.8634

Epoch 53/80
 - 0s - loss: 0.9870 - val_loss: 0.6140
AUC: 0.8634

Train on 28184 samples, validate on 7046 samples
Epoch 1/30
 - 1s - loss: 0.9865 - val_loss: 0.6108
AUC: 0.8636

Epoch 2/30
 - 0s - loss: 0.9856 - val_loss: 0.6018
AUC: 0.8635

Epoch 3/30
 - 0s - loss: 0.9848 - val_loss: 0.6197
AUC: 0.8640

Epoch 4/30
 - 0s - loss: 0.9849 - val_loss: 0.6110
AUC: 0.8641

Epoch 5/30
 - 0s - loss: 0.9859 - val_loss: 0.6280
AUC: 0.8642

Epoch 6/30
 - 0s - loss: 0.9756 - val_loss: 0.6078
AUC: 0.8642

Epoch 7/30
 - 0s - loss: 0.9800 - val_loss: 0.6105
AUC: 0.8642

Epoch 8/30
 - 0s - loss: 0.9763 - val_loss: 0.6139
AUC: 0.8641

Epoch 9/30
 - 0s - loss: 0.9782 - val_loss: 0.5980
AUC: 0.8641

Epoch 10/30
 - 0s - loss: 0.9754 - val_loss: 0.5978
AUC: 0.8644

Epoch 11/30
 - 0s - loss: 0.9725 - val_loss: 0.6091
AUC: 0.8644

Epoch 12/30
 - 0s - loss: 0.9770 - val_loss: 0.6051
AUC: 0.8649

Epoch 13/30
 - 0s - loss: 0.9741 - val_loss: 0.6043
AUC: 0.8648

Epoch 14/30
 - 0s - loss: 0.9724 - val_loss: 0.5944
AUC: 0.8647

Epoch 15/30
 - 0s - loss: 0.9772 - val_loss: 0.5994
AUC: 0.8650

Epoch 16/30
 - 0s - loss: 0.9695 - val_loss: 0.6085
AUC: 0.8652

Epoch 17/30
 - 0s - loss: 0.9678 - val_loss: 0.6000
AUC: 0.8650

Epoch 18/30
 - 0s - loss: 0.9645 - val_loss: 0.5923
AUC: 0.8651

Epoch 19/30
 - 0s - loss: 0.9724 - val_loss: 0.6131
AUC: 0.8654

Epoch 20/30
 - 0s - loss: 0.9706 - val_loss: 0.5998
AUC: 0.8654

Epoch 21/30
 - 0s - loss: 0.9625 - val_loss: 0.5988
AUC: 0.8655

Epoch 22/30
 - 0s - loss: 0.9661 - val_loss: 0.5898
AUC: 0.8654

Epoch 23/30
 - 0s - loss: 0.9653 - val_loss: 0.6122
AUC: 0.8657

Epoch 24/30
 - 0s - loss: 0.9666 - val_loss: 0.6049
AUC: 0.8658

Epoch 25/30
 - 0s - loss: 0.9638 - val_loss: 0.6091
AUC: 0.8658

Epoch 26/30
 - 0s - loss: 0.9656 - val_loss: 0.6008
AUC: 0.8659

Epoch 27/30
 - 0s - loss: 0.9623 - val_loss: 0.6072
AUC: 0.8660

Epoch 28/30
 - 0s - loss: 0.9648 - val_loss: 0.6050
AUC: 0.8662

Epoch 29/30
 - 0s - loss: 0.9603 - val_loss: 0.5984
AUC: 0.8661

Epoch 30/30
 - 0s - loss: 0.9569 - val_loss: 0.5956
Using TensorFlow backend.
AUC: 0.8661

2019-03-08 13:43:45.068383: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:43:45.233473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:43:45.233518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:43:45.523170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:43:45.523221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:43:45.523230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:43:45.523482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1204
Epoch 2/80
 - 1s - loss: 0.2130
Epoch 3/80
 - 1s - loss: 0.1738
Epoch 4/80
 - 1s - loss: 0.1680
Epoch 5/80
 - 1s - loss: 0.1637
Epoch 6/80
 - 1s - loss: 0.1578
Epoch 7/80
 - 1s - loss: 0.1488
Epoch 8/80
 - 1s - loss: 0.1372
Epoch 9/80
 - 1s - loss: 0.1254
Epoch 10/80
 - 1s - loss: 0.1148
Epoch 11/80
 - 1s - loss: 0.1054
Epoch 12/80
 - 1s - loss: 0.0971
Epoch 13/80
 - 1s - loss: 0.0899
Epoch 14/80
 - 1s - loss: 0.0842
Epoch 15/80
 - 1s - loss: 0.0795
Epoch 16/80
 - 1s - loss: 0.0756
Epoch 17/80
 - 1s - loss: 0.0722
Epoch 18/80
 - 1s - loss: 0.0691
Epoch 19/80
 - 2s - loss: 0.0665
Epoch 20/80
 - 1s - loss: 0.0642
Epoch 21/80
 - 1s - loss: 0.0622
Epoch 22/80
 - 1s - loss: 0.0606
Epoch 23/80
 - 1s - loss: 0.0592
Epoch 24/80
 - 1s - loss: 0.0581
Epoch 25/80
 - 2s - loss: 0.0571
Epoch 26/80
 - 1s - loss: 0.0563
Epoch 27/80
 - 1s - loss: 0.0556
Epoch 28/80
 - 1s - loss: 0.0549
Epoch 29/80
 - 1s - loss: 0.0544
Epoch 30/80
 - 1s - loss: 0.0539
Epoch 31/80
 - 1s - loss: 0.0535
Epoch 32/80
 - 1s - loss: 0.0532
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 1s - loss: 0.0525
Epoch 35/80
 - 1s - loss: 0.0523
Epoch 36/80
 - 1s - loss: 0.0521
Epoch 37/80
 - 1s - loss: 0.0519
Epoch 38/80
 - 1s - loss: 0.0517
Epoch 39/80
 - 1s - loss: 0.0515
Epoch 40/80
 - 1s - loss: 0.0514
Epoch 41/80
 - 1s - loss: 0.0512
Epoch 42/80
 - 1s - loss: 0.0511
Epoch 43/80
 - 1s - loss: 0.0510
Epoch 44/80
 - 1s - loss: 0.0509
Epoch 45/80
 - 1s - loss: 0.0508
Epoch 46/80
 - 1s - loss: 0.0507
Epoch 47/80
 - 1s - loss: 0.0507
Epoch 48/80
 - 1s - loss: 0.0506
Epoch 49/80
 - 1s - loss: 0.0505
Epoch 50/80
 - 1s - loss: 0.0505
Epoch 51/80
 - 1s - loss: 0.0504
Epoch 52/80
 - 1s - loss: 0.0504
Epoch 53/80
 - 2s - loss: 0.0503
Epoch 54/80
 - 1s - loss: 0.0502
Epoch 55/80
 - 1s - loss: 0.0502
Epoch 56/80
 - 1s - loss: 0.0502
Epoch 57/80
 - 1s - loss: 0.0501
Epoch 58/80
 - 1s - loss: 0.0501
Epoch 59/80
 - 1s - loss: 0.0501
Epoch 60/80
 - 1s - loss: 0.0500
Epoch 61/80
 - 1s - loss: 0.0500
Epoch 62/80
 - 1s - loss: 0.0500
Epoch 63/80
 - 1s - loss: 0.0499
Epoch 64/80
 - 1s - loss: 0.0489
Epoch 65/80
 - 1s - loss: 0.0487
Epoch 66/80
 - 1s - loss: 0.0487
Epoch 67/80
 - 1s - loss: 0.0487
Epoch 68/80
 - 1s - loss: 0.0487
Epoch 69/80
 - 1s - loss: 0.0484
Epoch 70/80
 - 1s - loss: 0.0484
Epoch 71/80
 - 1s - loss: 0.0484
Epoch 72/80
 - 1s - loss: 0.0484
Epoch 73/80
 - 1s - loss: 0.0483
Epoch 74/80
 - 1s - loss: 0.0483
Epoch 75/80
 - 1s - loss: 0.0483
Epoch 76/80
 - 1s - loss: 0.0483
Epoch 77/80
 - 1s - loss: 0.0483
Epoch 78/80
 - 1s - loss: 0.0483
Epoch 79/80
 - 1s - loss: 0.0483
Epoch 80/80
 - 1s - loss: 0.0483
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 1.3828 - val_loss: 0.5699
AUC: 0.6574

Epoch 2/80
 - 0s - loss: 0.8510 - val_loss: 0.4239
AUC: 0.7526

Epoch 3/80
 - 0s - loss: 0.5636 - val_loss: 0.3631
AUC: 0.7885

Epoch 4/80
 - 0s - loss: 0.4320 - val_loss: 0.3414
AUC: 0.8075

Epoch 5/80
 - 0s - loss: 0.3878 - val_loss: 0.3355
AUC: 0.8190

Epoch 6/80
 - 0s - loss: 0.3649 - val_loss: 0.3320
AUC: 0.8287

Epoch 7/80
 - 0s - loss: 0.3568 - val_loss: 0.3272
AUC: 0.8315

Epoch 8/80
 - 0s - loss: 0.3492 - val_loss: 0.3255
AUC: 0.8345

Epoch 9/80
 - 0s - loss: 0.3400 - val_loss: 0.3218
AUC: 0.8398

Epoch 10/80
 - 0s - loss: 0.3382 - val_loss: 0.3229
AUC: 0.8385

Epoch 11/80
 - 0s - loss: 0.3362 - val_loss: 0.3190
AUC: 0.8437

Epoch 12/80
 - 0s - loss: 0.3311 - val_loss: 0.3188
AUC: 0.8464

Epoch 13/80
 - 0s - loss: 0.3288 - val_loss: 0.3162
AUC: 0.8497

Epoch 14/80
 - 0s - loss: 0.3265 - val_loss: 0.3157
AUC: 0.8506

Epoch 15/80
 - 0s - loss: 0.3270 - val_loss: 0.3149
AUC: 0.8493

Epoch 16/80
 - 0s - loss: 0.3243 - val_loss: 0.3135
AUC: 0.8509

Epoch 17/80
 - 0s - loss: 0.3223 - val_loss: 0.3114
AUC: 0.8537

Epoch 18/80
 - 0s - loss: 0.3227 - val_loss: 0.3124
AUC: 0.8554

Epoch 19/80
 - 0s - loss: 0.3190 - val_loss: 0.3100
AUC: 0.8568

Epoch 20/80
 - 0s - loss: 0.3188 - val_loss: 0.3092
AUC: 0.8555

Epoch 21/80
 - 0s - loss: 0.3182 - val_loss: 0.3085
AUC: 0.8559

Epoch 22/80
 - 0s - loss: 0.3168 - val_loss: 0.3070
AUC: 0.8583

Epoch 23/80
 - 0s - loss: 0.3155 - val_loss: 0.3070
AUC: 0.8594

Epoch 24/80
 - 0s - loss: 0.3130 - val_loss: 0.3059
AUC: 0.8592

Epoch 25/80
 - 0s - loss: 0.3132 - val_loss: 0.3052
AUC: 0.8617

Epoch 26/80
 - 0s - loss: 0.3135 - val_loss: 0.3039
AUC: 0.8616

Epoch 27/80
 - 0s - loss: 0.3121 - val_loss: 0.3044
AUC: 0.8623

Epoch 28/80
 - 0s - loss: 0.3117 - val_loss: 0.3039
AUC: 0.8615

Epoch 29/80
 - 0s - loss: 0.3108 - val_loss: 0.3035
AUC: 0.8622

Epoch 30/80
 - 0s - loss: 0.3108 - val_loss: 0.3026
AUC: 0.8628

Epoch 31/80
 - 0s - loss: 0.3100 - val_loss: 0.3025
AUC: 0.8625

Epoch 32/80
 - 0s - loss: 0.3088 - val_loss: 0.3015
AUC: 0.8646

Epoch 33/80
 - 0s - loss: 0.3079 - val_loss: 0.3007
AUC: 0.8648

Epoch 34/80
 - 0s - loss: 0.3071 - val_loss: 0.3022
AUC: 0.8632

Epoch 35/80
 - 0s - loss: 0.3065 - val_loss: 0.3005
AUC: 0.8672

Epoch 36/80
 - 0s - loss: 0.3069 - val_loss: 0.3012
AUC: 0.8642

Epoch 37/80
 - 0s - loss: 0.3052 - val_loss: 0.2998
AUC: 0.8660

Epoch 38/80
 - 0s - loss: 0.3054 - val_loss: 0.2991
AUC: 0.8671

Epoch 39/80
 - 0s - loss: 0.3038 - val_loss: 0.2998
AUC: 0.8660

Epoch 40/80
 - 0s - loss: 0.3022 - val_loss: 0.2982
AUC: 0.8676

Epoch 41/80
 - 0s - loss: 0.3033 - val_loss: 0.2981
AUC: 0.8678

Epoch 42/80
 - 0s - loss: 0.3012 - val_loss: 0.3001
AUC: 0.8678

Epoch 43/80
 - 0s - loss: 0.3030 - val_loss: 0.2975
AUC: 0.8688

Epoch 44/80
 - 0s - loss: 0.3005 - val_loss: 0.2983
AUC: 0.8675

Epoch 45/80
 - 0s - loss: 0.3013 - val_loss: 0.2981
AUC: 0.8698

Epoch 46/80
 - 0s - loss: 0.3009 - val_loss: 0.2979
AUC: 0.8690

Epoch 47/80
 - 0s - loss: 0.3008 - val_loss: 0.2971
AUC: 0.8702

Epoch 48/80
 - 0s - loss: 0.3012 - val_loss: 0.2953
AUC: 0.8710

Epoch 49/80
 - 0s - loss: 0.2990 - val_loss: 0.2964
AUC: 0.8705

Epoch 50/80
 - 0s - loss: 0.2982 - val_loss: 0.2968
AUC: 0.8702

Epoch 51/80
 - 0s - loss: 0.2978 - val_loss: 0.2964
AUC: 0.8717

Epoch 52/80
 - 0s - loss: 0.3000 - val_loss: 0.2951
AUC: 0.8718

Epoch 53/80
 - 0s - loss: 0.2968 - val_loss: 0.2960
AUC: 0.8702

Epoch 54/80
 - 0s - loss: 0.2965 - val_loss: 0.2958
AUC: 0.8718

Epoch 55/80
 - 0s - loss: 0.2971 - val_loss: 0.2956
AUC: 0.8703

Epoch 56/80
 - 0s - loss: 0.2950 - val_loss: 0.2942
AUC: 0.8725

Epoch 57/80
 - 0s - loss: 0.2949 - val_loss: 0.2948
AUC: 0.8714

Epoch 58/80
 - 0s - loss: 0.2967 - val_loss: 0.2957
AUC: 0.8709

Epoch 59/80
 - 0s - loss: 0.2959 - val_loss: 0.2943
AUC: 0.8720

Epoch 60/80
 - 0s - loss: 0.2948 - val_loss: 0.2954
AUC: 0.8710

Epoch 61/80
 - 0s - loss: 0.2958 - val_loss: 0.2946
AUC: 0.8721

Epoch 62/80
 - 0s - loss: 0.2947 - val_loss: 0.2959
AUC: 0.8710

Epoch 63/80
 - 0s - loss: 0.2936 - val_loss: 0.2929
AUC: 0.8738

Epoch 64/80
 - 0s - loss: 0.2943 - val_loss: 0.2949
AUC: 0.8720

Epoch 65/80
 - 0s - loss: 0.2931 - val_loss: 0.2945
AUC: 0.8718

Epoch 66/80
 - 0s - loss: 0.2933 - val_loss: 0.2940
AUC: 0.8724

Epoch 67/80
 - 0s - loss: 0.2930 - val_loss: 0.2938
AUC: 0.8729

Epoch 68/80
 - 0s - loss: 0.2933 - val_loss: 0.2944
AUC: 0.8726

Epoch 69/80
 - 0s - loss: 0.2916 - val_loss: 0.2928
AUC: 0.8742

Epoch 70/80
 - 0s - loss: 0.2895 - val_loss: 0.2946
AUC: 0.8721

Epoch 71/80
 - 0s - loss: 0.2908 - val_loss: 0.2948
AUC: 0.8715

Epoch 72/80
 - 0s - loss: 0.2916 - val_loss: 0.2943
AUC: 0.8720

Epoch 73/80
 - 0s - loss: 0.2915 - val_loss: 0.2946
AUC: 0.8727

Epoch 74/80
 - 0s - loss: 0.2899 - val_loss: 0.2924
AUC: 0.8744

Epoch 75/80
 - 0s - loss: 0.2897 - val_loss: 0.2950
AUC: 0.8718

Epoch 76/80
 - 0s - loss: 0.2901 - val_loss: 0.2947
AUC: 0.8717

Epoch 77/80
 - 0s - loss: 0.2899 - val_loss: 0.2927
AUC: 0.8743

Epoch 78/80
 - 0s - loss: 0.2898 - val_loss: 0.2943
AUC: 0.8730

Epoch 79/80
 - 0s - loss: 0.2895 - val_loss: 0.2986
AUC: 0.8737

Epoch 80/80
 - 0s - loss: 0.2885 - val_loss: 0.2941
AUC: 0.8732

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.2885 - val_loss: 0.2924
AUC: 0.8741

Epoch 2/30
 - 0s - loss: 0.2877 - val_loss: 0.2926
AUC: 0.8740

Epoch 3/30
 - 0s - loss: 0.2875 - val_loss: 0.2927
AUC: 0.8738

Epoch 4/30
 - 0s - loss: 0.2858 - val_loss: 0.2928
AUC: 0.8739

Epoch 5/30
 - 0s - loss: 0.2865 - val_loss: 0.2930
AUC: 0.8736

Epoch 6/30
 - 0s - loss: 0.2865 - val_loss: 0.2928
AUC: 0.8738

Epoch 7/30
 - 0s - loss: 0.2862 - val_loss: 0.2925
AUC: 0.8741

Epoch 8/30
 - 0s - loss: 0.2853 - val_loss: 0.2928
AUC: 0.8739

Epoch 9/30
 - 0s - loss: 0.2851 - val_loss: 0.2925
AUC: 0.8742

Epoch 10/30
 - 0s - loss: 0.2849 - val_loss: 0.2928
AUC: 0.8740

Epoch 11/30
 - 0s - loss: 0.2840 - val_loss: 0.2928
AUC: 0.8741

Epoch 12/30
 - 0s - loss: 0.2837 - val_loss: 0.2926
AUC: 0.8742

Epoch 13/30
 - 0s - loss: 0.2819 - val_loss: 0.2925
AUC: 0.8742

Epoch 14/30
 - 0s - loss: 0.2821 - val_loss: 0.2925
AUC: 0.8743

Epoch 15/30
 - 0s - loss: 0.2834 - val_loss: 0.2925
AUC: 0.8743

Epoch 16/30
 - 0s - loss: 0.2835 - val_loss: 0.2925
AUC: 0.8743

Epoch 17/30
 - 0s - loss: 0.2828 - val_loss: 0.2924
AUC: 0.8743

Epoch 18/30
 - 0s - loss: 0.2836 - val_loss: 0.2924
AUC: 0.8743

Epoch 19/30
 - 0s - loss: 0.2834 - val_loss: 0.2924
AUC: 0.8744

Epoch 20/30
 - 0s - loss: 0.2829 - val_loss: 0.2924
AUC: 0.8744

Epoch 21/30
 - 0s - loss: 0.2833 - val_loss: 0.2924
AUC: 0.8743

Epoch 22/30
 - 0s - loss: 0.2836 - val_loss: 0.2924
AUC: 0.8743

Epoch 23/30
 - 0s - loss: 0.2840 - val_loss: 0.2924
AUC: 0.8744

Epoch 24/30
 - 0s - loss: 0.2831 - val_loss: 0.2924
AUC: 0.8744

Epoch 25/30
 - 0s - loss: 0.2828 - val_loss: 0.2924
AUC: 0.8744

Epoch 26/30
 - 0s - loss: 0.2831 - val_loss: 0.2924
AUC: 0.8744

Epoch 27/30
 - 0s - loss: 0.2840 - val_loss: 0.2924
AUC: 0.8744

Epoch 28/30
 - 0s - loss: 0.2840 - val_loss: 0.2924
AUC: 0.8744

Epoch 29/30
 - 0s - loss: 0.2838 - val_loss: 0.2924
AUC: 0.8744

Epoch 30/30
 - 0s - loss: 0.2835 - val_loss: 0.2924
Using TensorFlow backend.
AUC: 0.8744

2019-03-08 13:47:16.399179: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:47:16.564210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:47:16.564252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:47:16.856249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:47:16.856300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:47:16.856309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:47:16.856566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1401
Epoch 2/80
 - 1s - loss: 0.2154
Epoch 3/80
 - 1s - loss: 0.1732
Epoch 4/80
 - 1s - loss: 0.1662
Epoch 5/80
 - 1s - loss: 0.1601
Epoch 6/80
 - 1s - loss: 0.1516
Epoch 7/80
 - 1s - loss: 0.1402
Epoch 8/80
 - 1s - loss: 0.1279
Epoch 9/80
 - 1s - loss: 0.1170
Epoch 10/80
 - 1s - loss: 0.1078
Epoch 11/80
 - 1s - loss: 0.1001
Epoch 12/80
 - 2s - loss: 0.0935
Epoch 13/80
 - 2s - loss: 0.0881
Epoch 14/80
 - 1s - loss: 0.0833
Epoch 15/80
 - 1s - loss: 0.0791
Epoch 16/80
 - 1s - loss: 0.0752
Epoch 17/80
 - 1s - loss: 0.0717
Epoch 18/80
 - 1s - loss: 0.0687
Epoch 19/80
 - 1s - loss: 0.0661
Epoch 20/80
 - 1s - loss: 0.0639
Epoch 21/80
 - 1s - loss: 0.0620
Epoch 22/80
 - 1s - loss: 0.0604
Epoch 23/80
 - 1s - loss: 0.0591
Epoch 24/80
 - 1s - loss: 0.0579
Epoch 25/80
 - 1s - loss: 0.0569
Epoch 26/80
 - 1s - loss: 0.0560
Epoch 27/80
 - 1s - loss: 0.0553
Epoch 28/80
 - 1s - loss: 0.0546
Epoch 29/80
 - 1s - loss: 0.0541
Epoch 30/80
 - 1s - loss: 0.0536
Epoch 31/80
 - 1s - loss: 0.0532
Epoch 32/80
 - 2s - loss: 0.0529
Epoch 33/80
 - 1s - loss: 0.0526
Epoch 34/80
 - 1s - loss: 0.0523
Epoch 35/80
 - 1s - loss: 0.0521
Epoch 36/80
 - 1s - loss: 0.0519
Epoch 37/80
 - 1s - loss: 0.0517
Epoch 38/80
 - 1s - loss: 0.0515
Epoch 39/80
 - 1s - loss: 0.0514
Epoch 40/80
 - 1s - loss: 0.0512
Epoch 41/80
 - 1s - loss: 0.0511
Epoch 42/80
 - 1s - loss: 0.0510
Epoch 43/80
 - 1s - loss: 0.0509
Epoch 44/80
 - 1s - loss: 0.0508
Epoch 45/80
 - 1s - loss: 0.0507
Epoch 46/80
 - 1s - loss: 0.0506
Epoch 47/80
 - 1s - loss: 0.0505
Epoch 48/80
 - 1s - loss: 0.0505
Epoch 49/80
 - 1s - loss: 0.0504
Epoch 50/80
 - 1s - loss: 0.0504
Epoch 51/80
 - 1s - loss: 0.0503
Epoch 52/80
 - 2s - loss: 0.0503
Epoch 53/80
 - 1s - loss: 0.0502
Epoch 54/80
 - 1s - loss: 0.0501
Epoch 55/80
 - 1s - loss: 0.0501
Epoch 56/80
 - 1s - loss: 0.0501
Epoch 57/80
 - 1s - loss: 0.0500
Epoch 58/80
 - 1s - loss: 0.0500
Epoch 59/80
 - 1s - loss: 0.0500
Epoch 60/80
 - 1s - loss: 0.0489
Epoch 61/80
 - 1s - loss: 0.0487
Epoch 62/80
 - 1s - loss: 0.0487
Epoch 63/80
 - 1s - loss: 0.0487
Epoch 64/80
 - 1s - loss: 0.0487
Epoch 65/80
 - 1s - loss: 0.0484
Epoch 66/80
 - 1s - loss: 0.0484
Epoch 67/80
 - 1s - loss: 0.0484
Epoch 68/80
 - 1s - loss: 0.0484
Epoch 69/80
 - 2s - loss: 0.0483
Epoch 70/80
 - 1s - loss: 0.0483
Epoch 71/80
 - 2s - loss: 0.0483
Epoch 72/80
 - 2s - loss: 0.0483
Epoch 73/80
 - 2s - loss: 0.0483
Epoch 74/80
 - 2s - loss: 0.0483
Epoch 75/80
 - 1s - loss: 0.0483
Epoch 76/80
 - 1s - loss: 0.0483
Epoch 77/80
 - 2s - loss: 0.0483
Epoch 78/80
 - 1s - loss: 0.0483
Epoch 79/80
 - 1s - loss: 0.0483
Epoch 80/80
 - 1s - loss: 0.0483
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.4675 - val_loss: 1.3348
AUC: 0.7984

Epoch 2/80
 - 0s - loss: 2.1045 - val_loss: 1.1404
AUC: 0.8195

Epoch 3/80
 - 0s - loss: 1.6131 - val_loss: 0.9919
AUC: 0.8328

Epoch 4/80
 - 0s - loss: 1.4465 - val_loss: 0.9596
AUC: 0.8405

Epoch 5/80
 - 0s - loss: 1.3910 - val_loss: 0.8176
AUC: 0.8458

Epoch 6/80
 - 0s - loss: 1.3472 - val_loss: 0.7955
AUC: 0.8507

Epoch 7/80
 - 0s - loss: 1.3294 - val_loss: 0.8031
AUC: 0.8537

Epoch 8/80
 - 0s - loss: 1.3084 - val_loss: 0.7899
AUC: 0.8566

Epoch 9/80
 - 0s - loss: 1.2854 - val_loss: 0.8079
AUC: 0.8588

Epoch 10/80
 - 0s - loss: 1.2812 - val_loss: 0.7528
AUC: 0.8601

Epoch 11/80
 - 0s - loss: 1.2710 - val_loss: 0.8235
AUC: 0.8616

Epoch 12/80
 - 0s - loss: 1.2553 - val_loss: 0.7813
AUC: 0.8621

Epoch 13/80
 - 0s - loss: 1.2552 - val_loss: 0.8317
AUC: 0.8642

Epoch 14/80
 - 0s - loss: 1.2518 - val_loss: 0.7471
AUC: 0.8626

Epoch 15/80
 - 0s - loss: 1.2383 - val_loss: 0.8116
AUC: 0.8644

Epoch 16/80
 - 0s - loss: 1.2288 - val_loss: 0.7431
AUC: 0.8649

Epoch 17/80
 - 0s - loss: 1.2235 - val_loss: 0.7385
AUC: 0.8653

Epoch 18/80
 - 0s - loss: 1.2240 - val_loss: 0.7475
AUC: 0.8664

Epoch 19/80
 - 0s - loss: 1.2220 - val_loss: 0.7593
AUC: 0.8656

Epoch 20/80
 - 0s - loss: 1.2155 - val_loss: 0.7771
AUC: 0.8660

Epoch 21/80
 - 0s - loss: 1.2113 - val_loss: 0.7326
AUC: 0.8659

Epoch 22/80
 - 0s - loss: 1.2126 - val_loss: 0.7633
AUC: 0.8669

Epoch 23/80
 - 0s - loss: 1.2033 - val_loss: 0.8247
AUC: 0.8679

Epoch 24/80
 - 0s - loss: 1.2057 - val_loss: 0.7695
AUC: 0.8687

Epoch 25/80
 - 0s - loss: 1.2081 - val_loss: 0.8136
AUC: 0.8687

Epoch 26/80
 - 0s - loss: 1.2045 - val_loss: 0.7754
AUC: 0.8690

Epoch 27/80
 - 0s - loss: 1.2046 - val_loss: 0.8061
AUC: 0.8695

Epoch 28/80
 - 0s - loss: 1.2035 - val_loss: 0.7143
AUC: 0.8691

Epoch 29/80
 - 0s - loss: 1.1909 - val_loss: 0.6988
AUC: 0.8682

Epoch 30/80
 - 0s - loss: 1.1974 - val_loss: 0.8021
AUC: 0.8696

Epoch 31/80
 - 0s - loss: 1.1860 - val_loss: 0.6993
AUC: 0.8683

Epoch 32/80
 - 0s - loss: 1.1854 - val_loss: 0.7460
AUC: 0.8691

Epoch 33/80
 - 0s - loss: 1.1827 - val_loss: 0.7377
AUC: 0.8691

Epoch 34/80
 - 0s - loss: 1.1838 - val_loss: 0.7618
AUC: 0.8694

Epoch 35/80
 - 0s - loss: 1.1727 - val_loss: 0.7292
AUC: 0.8696

Epoch 36/80
 - 0s - loss: 1.1828 - val_loss: 0.7547
AUC: 0.8689

Epoch 37/80
 - 0s - loss: 1.1738 - val_loss: 0.7037
AUC: 0.8695

Epoch 38/80
 - 0s - loss: 1.1762 - val_loss: 0.6795
AUC: 0.8703

Epoch 39/80
 - 0s - loss: 1.1722 - val_loss: 0.7639
AUC: 0.8706

Epoch 40/80
 - 0s - loss: 1.1698 - val_loss: 0.7600
AUC: 0.8708

Epoch 41/80
 - 0s - loss: 1.1690 - val_loss: 0.7604
AUC: 0.8694

Epoch 42/80
 - 0s - loss: 1.1678 - val_loss: 0.7907
AUC: 0.8709

Epoch 43/80
 - 0s - loss: 1.1597 - val_loss: 0.7386
AUC: 0.8711

Epoch 44/80
 - 0s - loss: 1.1585 - val_loss: 0.7449
AUC: 0.8700

Epoch 45/80
 - 0s - loss: 1.1618 - val_loss: 0.7390
AUC: 0.8707

Epoch 46/80
 - 0s - loss: 1.1628 - val_loss: 0.7852
AUC: 0.8707

Epoch 47/80
 - 0s - loss: 1.1520 - val_loss: 0.8100
AUC: 0.8716

Epoch 48/80
 - 0s - loss: 1.1586 - val_loss: 0.7517
AUC: 0.8710

Epoch 49/80
 - 0s - loss: 1.1510 - val_loss: 0.7261
AUC: 0.8713

Epoch 50/80
 - 0s - loss: 1.1417 - val_loss: 0.7344
AUC: 0.8714

Epoch 51/80
 - 0s - loss: 1.1459 - val_loss: 0.7418
AUC: 0.8715

Epoch 52/80
 - 0s - loss: 1.1401 - val_loss: 0.7252
AUC: 0.8712

Epoch 53/80
 - 0s - loss: 1.1459 - val_loss: 0.7164
AUC: 0.8714

Epoch 54/80
 - 0s - loss: 1.1431 - val_loss: 0.7258
AUC: 0.8715

Epoch 55/80
 - 0s - loss: 1.1416 - val_loss: 0.7348
AUC: 0.8717

Epoch 56/80
 - 0s - loss: 1.1436 - val_loss: 0.7321
AUC: 0.8717

Epoch 57/80
 - 0s - loss: 1.1443 - val_loss: 0.7393
AUC: 0.8717

Epoch 58/80
 - 0s - loss: 1.1431 - val_loss: 0.7189
AUC: 0.8716

Epoch 59/80
 - 0s - loss: 1.1421 - val_loss: 0.7323
AUC: 0.8717

Epoch 60/80
 - 0s - loss: 1.1416 - val_loss: 0.7314
AUC: 0.8716

Epoch 61/80
 - 0s - loss: 1.1338 - val_loss: 0.7223
AUC: 0.8715

Epoch 62/80
 - 0s - loss: 1.1401 - val_loss: 0.7219
AUC: 0.8716

Epoch 63/80
 - 0s - loss: 1.1345 - val_loss: 0.7199
AUC: 0.8715

Epoch 64/80
 - 0s - loss: 1.1401 - val_loss: 0.7292
AUC: 0.8716

Epoch 65/80
 - 0s - loss: 1.1369 - val_loss: 0.7219
AUC: 0.8716

Epoch 66/80
 - 0s - loss: 1.1398 - val_loss: 0.7264
AUC: 0.8716

Epoch 67/80
 - 0s - loss: 1.1350 - val_loss: 0.7236
AUC: 0.8715

Epoch 68/80
 - 0s - loss: 1.1395 - val_loss: 0.7144
AUC: 0.8714

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.1416 - val_loss: 0.7197
AUC: 0.8714

Epoch 2/30
 - 0s - loss: 1.1357 - val_loss: 0.7292
AUC: 0.8715

Epoch 3/30
 - 0s - loss: 1.1367 - val_loss: 0.7262
AUC: 0.8716

Epoch 4/30
 - 0s - loss: 1.1410 - val_loss: 0.7396
AUC: 0.8717

Epoch 5/30
 - 0s - loss: 1.1389 - val_loss: 0.7335
AUC: 0.8717

Epoch 6/30
 - 0s - loss: 1.1288 - val_loss: 0.7088
AUC: 0.8717

Epoch 7/30
 - 0s - loss: 1.1331 - val_loss: 0.7318
AUC: 0.8720

Epoch 8/30
 - 0s - loss: 1.1293 - val_loss: 0.7248
AUC: 0.8720

Epoch 9/30
 - 0s - loss: 1.1310 - val_loss: 0.7309
AUC: 0.8721

Epoch 10/30
 - 0s - loss: 1.1270 - val_loss: 0.7248
AUC: 0.8720

Epoch 11/30
 - 0s - loss: 1.1243 - val_loss: 0.7148
AUC: 0.8722

Epoch 12/30
 - 0s - loss: 1.1266 - val_loss: 0.7185
AUC: 0.8722

Epoch 13/30
 - 0s - loss: 1.1259 - val_loss: 0.7100
AUC: 0.8724

Epoch 14/30
 - 0s - loss: 1.1169 - val_loss: 0.7114
AUC: 0.8723

Epoch 15/30
 - 0s - loss: 1.1271 - val_loss: 0.7184
AUC: 0.8724

Epoch 16/30
 - 0s - loss: 1.1236 - val_loss: 0.7209
AUC: 0.8725

Epoch 17/30
 - 0s - loss: 1.1208 - val_loss: 0.7156
AUC: 0.8724

Epoch 18/30
 - 0s - loss: 1.1195 - val_loss: 0.7148
AUC: 0.8724

Epoch 19/30
 - 0s - loss: 1.1201 - val_loss: 0.7138
AUC: 0.8724

Epoch 20/30
 - 0s - loss: 1.1194 - val_loss: 0.7160
AUC: 0.8724

Epoch 21/30
 - 0s - loss: 1.1210 - val_loss: 0.7127
AUC: 0.8724

Epoch 22/30
 - 0s - loss: 1.1236 - val_loss: 0.7142
AUC: 0.8725

Epoch 23/30
 - 0s - loss: 1.1236 - val_loss: 0.7150
AUC: 0.8725

Epoch 24/30
 - 0s - loss: 1.1199 - val_loss: 0.7166
AUC: 0.8725

Epoch 25/30
 - 0s - loss: 1.1185 - val_loss: 0.7156
AUC: 0.8726

Epoch 26/30
 - 0s - loss: 1.1209 - val_loss: 0.7175
AUC: 0.8726

Epoch 27/30
 - 0s - loss: 1.1171 - val_loss: 0.7152
AUC: 0.8726

Epoch 28/30
 - 0s - loss: 1.1183 - val_loss: 0.7164
AUC: 0.8726

Epoch 29/30
 - 0s - loss: 1.1178 - val_loss: 0.7152
AUC: 0.8726

Epoch 30/30
 - 0s - loss: 1.1173 - val_loss: 0.7145
Using TensorFlow backend.
AUC: 0.8726

2019-03-08 13:50:42.066294: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:50:42.229072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:50:42.229116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:50:42.518534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:50:42.518585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:50:42.518595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:50:42.518848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1743
Epoch 2/80
 - 1s - loss: 0.2156
Epoch 3/80
 - 1s - loss: 0.1712
Epoch 4/80
 - 1s - loss: 0.1626
Epoch 5/80
 - 1s - loss: 0.1539
Epoch 6/80
 - 1s - loss: 0.1443
Epoch 7/80
 - 1s - loss: 0.1352
Epoch 8/80
 - 1s - loss: 0.1268
Epoch 9/80
 - 2s - loss: 0.1185
Epoch 10/80
 - 1s - loss: 0.1101
Epoch 11/80
 - 2s - loss: 0.1020
Epoch 12/80
 - 1s - loss: 0.0949
Epoch 13/80
 - 1s - loss: 0.0885
Epoch 14/80
 - 1s - loss: 0.0829
Epoch 15/80
 - 2s - loss: 0.0781
Epoch 16/80
 - 1s - loss: 0.0740
Epoch 17/80
 - 1s - loss: 0.0706
Epoch 18/80
 - 1s - loss: 0.0678
Epoch 19/80
 - 1s - loss: 0.0654
Epoch 20/80
 - 1s - loss: 0.0633
Epoch 21/80
 - 1s - loss: 0.0616
Epoch 22/80
 - 1s - loss: 0.0601
Epoch 23/80
 - 1s - loss: 0.0589
Epoch 24/80
 - 1s - loss: 0.0578
Epoch 25/80
 - 1s - loss: 0.0568
Epoch 26/80
 - 1s - loss: 0.0560
Epoch 27/80
 - 1s - loss: 0.0553
Epoch 28/80
 - 1s - loss: 0.0547
Epoch 29/80
 - 1s - loss: 0.0542
Epoch 30/80
 - 1s - loss: 0.0537
Epoch 31/80
 - 1s - loss: 0.0533
Epoch 32/80
 - 1s - loss: 0.0529
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:51:56.363786: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:51:56.526294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:51:56.526337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:51:56.815832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:51:56.815886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:51:56.815895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:51:56.816147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1576
Epoch 2/80
 - 1s - loss: 0.2152
Epoch 3/80
 - 2s - loss: 0.1733
Epoch 4/80
 - 1s - loss: 0.1666
Epoch 5/80
 - 2s - loss: 0.1606
Epoch 6/80
 - 2s - loss: 0.1535
Epoch 7/80
 - 2s - loss: 0.1453
Epoch 8/80
 - 2s - loss: 0.1358
Epoch 9/80
 - 1s - loss: 0.1244
Epoch 10/80
 - 1s - loss: 0.1125
Epoch 11/80
 - 1s - loss: 0.1021
Epoch 12/80
 - 2s - loss: 0.0940
Epoch 13/80
 - 1s - loss: 0.0876
Epoch 14/80
 - 1s - loss: 0.0823
Epoch 15/80
 - 1s - loss: 0.0779
Epoch 16/80
 - 1s - loss: 0.0741
Epoch 17/80
 - 1s - loss: 0.0708
Epoch 18/80
 - 1s - loss: 0.0680
Epoch 19/80
 - 1s - loss: 0.0656
Epoch 20/80
 - 1s - loss: 0.0636
Epoch 21/80
 - 1s - loss: 0.0619
Epoch 22/80
 - 1s - loss: 0.0604
Epoch 23/80
 - 1s - loss: 0.0591
Epoch 24/80
 - 1s - loss: 0.0580
Epoch 25/80
 - 1s - loss: 0.0571
Epoch 26/80
 - 1s - loss: 0.0562
Epoch 27/80
 - 1s - loss: 0.0555
Epoch 28/80
 - 1s - loss: 0.0549
Epoch 29/80
 - 1s - loss: 0.0544
Epoch 30/80
 - 1s - loss: 0.0540
Epoch 31/80
 - 1s - loss: 0.0536
Epoch 32/80
 - 1s - loss: 0.0532
Epoch 33/80
 - 1s - loss: 0.0529
Epoch 34/80
 - 1s - loss: 0.0527
Epoch 35/80
 - 1s - loss: 0.0525
Epoch 36/80
 - 1s - loss: 0.0522
Epoch 37/80
 - 1s - loss: 0.0520
Epoch 38/80
 - 1s - loss: 0.0519
Epoch 39/80
 - 1s - loss: 0.0517
Epoch 40/80
 - 1s - loss: 0.0516
Epoch 41/80
 - 1s - loss: 0.0515
Epoch 42/80
 - 1s - loss: 0.0513
Epoch 43/80
 - 1s - loss: 0.0512
Epoch 44/80
 - 1s - loss: 0.0511
Epoch 45/80
 - 1s - loss: 0.0510
Epoch 46/80
 - 1s - loss: 0.0510
Epoch 47/80
 - 1s - loss: 0.0509
Epoch 48/80
 - 1s - loss: 0.0508
Epoch 49/80
 - 1s - loss: 0.0507
Epoch 50/80
 - 1s - loss: 0.0507
Epoch 51/80
 - 1s - loss: 0.0506
Epoch 52/80
 - 1s - loss: 0.0506
Epoch 53/80
 - 1s - loss: 0.0505
Epoch 54/80
 - 1s - loss: 0.0505
Epoch 55/80
 - 1s - loss: 0.0504
Epoch 56/80
 - 1s - loss: 0.0504
Epoch 57/80
 - 1s - loss: 0.0503
Epoch 58/80
 - 1s - loss: 0.0503
Epoch 59/80
 - 1s - loss: 0.0503
Epoch 60/80
 - 1s - loss: 0.0502
Epoch 61/80
 - 1s - loss: 0.0502
Epoch 62/80
 - 1s - loss: 0.0502
Epoch 63/80
 - 1s - loss: 0.0501
Epoch 64/80
 - 1s - loss: 0.0501
Epoch 65/80
 - 1s - loss: 0.0501
Epoch 66/80
 - 1s - loss: 0.0490
Epoch 67/80
 - 1s - loss: 0.0489
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:54:03.770943: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:54:03.933635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:54:03.933678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:54:04.220767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:54:04.220820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:54:04.220829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:54:04.221116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1445
Epoch 2/80
 - 2s - loss: 0.2157
Epoch 3/80
 - 1s - loss: 0.1724
Epoch 4/80
 - 2s - loss: 0.1639
Epoch 5/80
 - 2s - loss: 0.1559
Epoch 6/80
 - 2s - loss: 0.1472
Epoch 7/80
 - 2s - loss: 0.1383
Epoch 8/80
 - 2s - loss: 0.1291
Epoch 9/80
 - 2s - loss: 0.1200
Epoch 10/80
 - 1s - loss: 0.1115
Epoch 11/80
 - 2s - loss: 0.1040
Epoch 12/80
 - 2s - loss: 0.0971
Epoch 13/80
 - 1s - loss: 0.0908
Epoch 14/80
 - 2s - loss: 0.0852
Epoch 15/80
 - 1s - loss: 0.0803
Epoch 16/80
 - 1s - loss: 0.0763
Epoch 17/80
 - 2s - loss: 0.0728
Epoch 18/80
 - 1s - loss: 0.0698
Epoch 19/80
 - 1s - loss: 0.0671
Epoch 20/80
 - 1s - loss: 0.0648
Epoch 21/80
 - 1s - loss: 0.0629
Epoch 22/80
 - 1s - loss: 0.0612
Epoch 23/80
 - 1s - loss: 0.0597
Epoch 24/80
 - 1s - loss: 0.0585
Epoch 25/80
 - 1s - loss: 0.0574
Epoch 26/80
 - 1s - loss: 0.0565
Epoch 27/80
 - 1s - loss: 0.0558
Epoch 28/80
 - 1s - loss: 0.0552
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 13:55:12.268326: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:55:12.429454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:55:12.429512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:55:12.720958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:55:12.721004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:55:12.721013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:55:12.721274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1434
Epoch 2/80
 - 1s - loss: 0.2172
Epoch 3/80
 - 1s - loss: 0.1728
Epoch 4/80
 - 1s - loss: 0.1642
Epoch 5/80
 - 1s - loss: 0.1566
Epoch 6/80
 - 1s - loss: 0.1480
Epoch 7/80
 - 1s - loss: 0.1387
Epoch 8/80
 - 1s - loss: 0.1295
Epoch 9/80
 - 1s - loss: 0.1203
Epoch 10/80
 - 1s - loss: 0.1111
Epoch 11/80
 - 1s - loss: 0.1025
Epoch 12/80
 - 1s - loss: 0.0949
Epoch 13/80
 - 1s - loss: 0.0882
Epoch 14/80
 - 1s - loss: 0.0826
Epoch 15/80
 - 1s - loss: 0.0779
Epoch 16/80
 - 1s - loss: 0.0740
Epoch 17/80
 - 1s - loss: 0.0707
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1116, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/saving.py", line 446, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/group.py", line 60, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5g.pyx", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
2019-03-08 13:55:57.507765: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:55:57.670470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:55:57.670521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:55:57.957962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:55:57.958012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:55:57.958022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:55:57.958280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1549
Epoch 2/80
 - 1s - loss: 0.2184
Epoch 3/80
 - 1s - loss: 0.1745
Epoch 4/80
 - 1s - loss: 0.1673
Epoch 5/80
 - 1s - loss: 0.1622
Epoch 6/80
 - 1s - loss: 0.1557
Epoch 7/80
 - 1s - loss: 0.1470
Epoch 8/80
 - 1s - loss: 0.1358
Epoch 9/80
 - 1s - loss: 0.1240
Epoch 10/80
 - 1s - loss: 0.1134
Epoch 11/80
 - 1s - loss: 0.1042
Epoch 12/80
 - 1s - loss: 0.0964
Epoch 13/80
 - 1s - loss: 0.0897
Epoch 14/80
 - 1s - loss: 0.0838
Epoch 15/80
 - 1s - loss: 0.0789
Epoch 16/80
 - 1s - loss: 0.0747
Epoch 17/80
 - 1s - loss: 0.0713
Epoch 18/80
 - 1s - loss: 0.0683
Epoch 19/80
 - 1s - loss: 0.0660
Epoch 20/80
 - 1s - loss: 0.0639
Epoch 21/80
 - 1s - loss: 0.0623
Epoch 22/80
 - 1s - loss: 0.0608
Epoch 23/80
 - 1s - loss: 0.0596
Epoch 24/80
 - 1s - loss: 0.0585
Epoch 25/80
 - 2s - loss: 0.0575
Epoch 26/80
 - 1s - loss: 0.0567
Epoch 27/80
 - 1s - loss: 0.0560
Epoch 28/80
 - 1s - loss: 0.0553
Epoch 29/80
 - 1s - loss: 0.0548
Epoch 30/80
 - 1s - loss: 0.0543
Epoch 31/80
 - 1s - loss: 0.0539
Epoch 32/80
 - 1s - loss: 0.0535
Epoch 33/80
 - 1s - loss: 0.0532
Epoch 34/80
 - 1s - loss: 0.0529
Epoch 35/80
 - 1s - loss: 0.0526
Epoch 36/80
 - 1s - loss: 0.0524
Epoch 37/80
 - 1s - loss: 0.0522
Epoch 38/80
 - 1s - loss: 0.0520
Epoch 39/80
 - 1s - loss: 0.0518
Epoch 40/80
 - 1s - loss: 0.0517
Epoch 41/80
 - 1s - loss: 0.0515
Epoch 42/80
 - 1s - loss: 0.0514
Epoch 43/80
 - 1s - loss: 0.0513
Epoch 44/80
 - 1s - loss: 0.0512
Epoch 45/80
 - 1s - loss: 0.0511
Epoch 46/80
 - 1s - loss: 0.0510
Epoch 47/80
 - 1s - loss: 0.0509
Epoch 48/80
 - 1s - loss: 0.0509
Epoch 49/80
 - 1s - loss: 0.0508
Epoch 50/80
 - 1s - loss: 0.0507
Epoch 51/80
 - 1s - loss: 0.0506
Epoch 52/80
 - 1s - loss: 0.0506
Epoch 53/80
 - 1s - loss: 0.0505
Epoch 54/80
 - 1s - loss: 0.0505
Epoch 55/80
 - 1s - loss: 0.0504
Epoch 56/80
 - 1s - loss: 0.0504
Epoch 57/80
 - 1s - loss: 0.0503
Epoch 58/80
 - 1s - loss: 0.0503
Epoch 59/80
 - 1s - loss: 0.0503
Epoch 60/80
 - 1s - loss: 0.0502
Epoch 61/80
 - 1s - loss: 0.0502
Epoch 62/80
 - 1s - loss: 0.0502
Epoch 63/80
 - 1s - loss: 0.0501
Epoch 64/80
 - 1s - loss: 0.0501
Epoch 65/80
 - 1s - loss: 0.0490
Epoch 66/80
 - 1s - loss: 0.0489
Epoch 67/80
 - 1s - loss: 0.0489
Epoch 68/80
 - 1s - loss: 0.0488
Epoch 69/80
 - 1s - loss: 0.0488
Epoch 70/80
 - 1s - loss: 0.0486
Epoch 71/80
 - 1s - loss: 0.0486
Epoch 72/80
 - 1s - loss: 0.0485
Epoch 73/80
 - 1s - loss: 0.0485
Epoch 74/80
 - 1s - loss: 0.0485
Epoch 75/80
 - 1s - loss: 0.0485
Epoch 76/80
 - 1s - loss: 0.0485
Epoch 77/80
 - 1s - loss: 0.0485
Epoch 78/80
 - 1s - loss: 0.0485
Epoch 79/80
 - 1s - loss: 0.0485
Epoch 80/80
 - 1s - loss: 0.0485
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.0161 - val_loss: 1.6294
AUC: 0.7989

Epoch 2/80
 - 0s - loss: 3.2168 - val_loss: 1.0912
AUC: 0.8219

Epoch 3/80
 - 0s - loss: 2.1144 - val_loss: 0.7511
AUC: 0.8300

Epoch 4/80
 - 0s - loss: 1.6229 - val_loss: 0.8003
AUC: 0.8377

Epoch 5/80
 - 0s - loss: 1.3395 - val_loss: 0.6888
AUC: 0.8396

Epoch 6/80
 - 0s - loss: 1.2348 - val_loss: 0.6718
AUC: 0.8440

Epoch 7/80
 - 0s - loss: 1.1699 - val_loss: 0.6574
AUC: 0.8471

Epoch 8/80
 - 0s - loss: 1.1425 - val_loss: 0.6878
AUC: 0.8503

Epoch 9/80
 - 0s - loss: 1.1231 - val_loss: 0.6707
AUC: 0.8510

Epoch 10/80
 - 0s - loss: 1.1126 - val_loss: 0.6902
AUC: 0.8537

Epoch 11/80
 - 0s - loss: 1.1028 - val_loss: 0.6930
AUC: 0.8552

Epoch 12/80
 - 0s - loss: 1.0837 - val_loss: 0.6474
AUC: 0.8566

Epoch 13/80
 - 0s - loss: 1.0695 - val_loss: 0.6481
AUC: 0.8580

Epoch 14/80
 - 0s - loss: 1.0681 - val_loss: 0.6599
AUC: 0.8568

Epoch 15/80
 - 0s - loss: 1.0620 - val_loss: 0.7019
AUC: 0.8590

Epoch 16/80
 - 0s - loss: 1.0565 - val_loss: 0.6297
AUC: 0.8592

Epoch 17/80
 - 0s - loss: 1.0528 - val_loss: 0.6458
AUC: 0.8591

Epoch 18/80
 - 0s - loss: 1.0538 - val_loss: 0.6004
AUC: 0.8597

Epoch 19/80
 - 0s - loss: 1.0336 - val_loss: 0.6782
AUC: 0.8603

Epoch 20/80
 - 0s - loss: 1.0384 - val_loss: 0.5965
AUC: 0.8600

Epoch 21/80
 - 0s - loss: 1.0396 - val_loss: 0.5826
AUC: 0.8605

Epoch 22/80
 - 0s - loss: 1.0308 - val_loss: 0.6029
AUC: 0.8612

Epoch 23/80
 - 0s - loss: 1.0267 - val_loss: 0.6406
AUC: 0.8616

Epoch 24/80
 - 0s - loss: 1.0231 - val_loss: 0.6333
AUC: 0.8614

Epoch 25/80
 - 0s - loss: 1.0250 - val_loss: 0.5754
AUC: 0.8613

Epoch 26/80
 - 0s - loss: 1.0260 - val_loss: 0.6599
AUC: 0.8620

Epoch 27/80
 - 0s - loss: 1.0271 - val_loss: 0.6310
AUC: 0.8630

Epoch 28/80
 - 0s - loss: 1.0207 - val_loss: 0.6534
AUC: 0.8624

Epoch 29/80
 - 0s - loss: 1.0112 - val_loss: 0.6139
AUC: 0.8626

Epoch 30/80
 - 0s - loss: 1.0168 - val_loss: 0.6502
AUC: 0.8630

Epoch 31/80
 - 0s - loss: 1.0141 - val_loss: 0.6613
AUC: 0.8631

Epoch 32/80
 - 0s - loss: 1.0122 - val_loss: 0.5843
AUC: 0.8636

Epoch 33/80
 - 0s - loss: 1.0054 - val_loss: 0.6175
AUC: 0.8638

Epoch 34/80
 - 0s - loss: 1.0031 - val_loss: 0.6531
AUC: 0.8639

Epoch 35/80
 - 0s - loss: 1.0028 - val_loss: 0.6419
AUC: 0.8634

Epoch 36/80
 - 0s - loss: 0.9955 - val_loss: 0.5998
AUC: 0.8636

Epoch 37/80
 - 0s - loss: 0.9950 - val_loss: 0.6116
AUC: 0.8635

Epoch 38/80
 - 0s - loss: 0.9936 - val_loss: 0.5938
AUC: 0.8634

Epoch 39/80
 - 0s - loss: 0.9893 - val_loss: 0.6233
AUC: 0.8638

Epoch 40/80
 - 0s - loss: 0.9937 - val_loss: 0.6184
AUC: 0.8638

Epoch 41/80
 - 0s - loss: 0.9919 - val_loss: 0.6073
AUC: 0.8637

Epoch 42/80
 - 0s - loss: 0.9920 - val_loss: 0.6156
AUC: 0.8638

Epoch 43/80
 - 0s - loss: 0.9933 - val_loss: 0.6046
AUC: 0.8638

Epoch 44/80
 - 0s - loss: 0.9878 - val_loss: 0.6362
AUC: 0.8640

Epoch 45/80
 - 0s - loss: 0.9928 - val_loss: 0.6169
AUC: 0.8640

Epoch 46/80
 - 0s - loss: 0.9872 - val_loss: 0.6088
AUC: 0.8640

Epoch 47/80
 - 0s - loss: 0.9919 - val_loss: 0.6215
AUC: 0.8641

Epoch 48/80
 - 0s - loss: 0.9892 - val_loss: 0.6121
AUC: 0.8641

Epoch 49/80
 - 0s - loss: 0.9841 - val_loss: 0.6097
AUC: 0.8641

Epoch 50/80
 - 0s - loss: 0.9810 - val_loss: 0.6122
AUC: 0.8642

Epoch 51/80
 - 0s - loss: 0.9857 - val_loss: 0.6164
AUC: 0.8642

Epoch 52/80
 - 0s - loss: 0.9869 - val_loss: 0.6122
AUC: 0.8642

Epoch 53/80
 - 0s - loss: 0.9850 - val_loss: 0.6117
AUC: 0.8641

Epoch 54/80
 - 0s - loss: 0.9839 - val_loss: 0.6107
AUC: 0.8641

Epoch 55/80
 - 0s - loss: 0.9869 - val_loss: 0.6094
AUC: 0.8642

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9900 - val_loss: 0.6146
AUC: 0.8642

Epoch 2/30
 - 0s - loss: 0.9838 - val_loss: 0.5944
AUC: 0.8642

Epoch 3/30
 - 0s - loss: 0.9882 - val_loss: 0.6089
AUC: 0.8644

Epoch 4/30
 - 0s - loss: 0.9825 - val_loss: 0.6067
AUC: 0.8646

Epoch 5/30
 - 0s - loss: 0.9883 - val_loss: 0.6113
AUC: 0.8646

Epoch 6/30
 - 0s - loss: 0.9851 - val_loss: 0.6281
AUC: 0.8650

Epoch 7/30
 - 0s - loss: 0.9789 - val_loss: 0.6115
AUC: 0.8651

Epoch 8/30
 - 0s - loss: 0.9751 - val_loss: 0.6153
AUC: 0.8651

Epoch 9/30
 - 0s - loss: 0.9831 - val_loss: 0.6156
AUC: 0.8652

Epoch 10/30
 - 0s - loss: 0.9756 - val_loss: 0.6065
AUC: 0.8652

Epoch 11/30
 - 0s - loss: 0.9729 - val_loss: 0.5992
AUC: 0.8652

Epoch 12/30
 - 0s - loss: 0.9742 - val_loss: 0.6081
AUC: 0.8655

Epoch 13/30
 - 0s - loss: 0.9695 - val_loss: 0.6073
AUC: 0.8655

Epoch 14/30
 - 0s - loss: 0.9758 - val_loss: 0.6131
AUC: 0.8656

Epoch 15/30
 - 0s - loss: 0.9743 - val_loss: 0.6083
AUC: 0.8655

Epoch 16/30
 - 0s - loss: 0.9687 - val_loss: 0.6086
AUC: 0.8655

Epoch 17/30
 - 0s - loss: 0.9701 - val_loss: 0.6054
AUC: 0.8656

Epoch 18/30
 - 0s - loss: 0.9705 - val_loss: 0.6044
AUC: 0.8656

Epoch 19/30
 - 0s - loss: 0.9734 - val_loss: 0.6123
AUC: 0.8657

Epoch 20/30
 - 0s - loss: 0.9712 - val_loss: 0.6043
AUC: 0.8656

Epoch 21/30
 - 0s - loss: 0.9702 - val_loss: 0.6045
AUC: 0.8657

Epoch 22/30
 - 0s - loss: 0.9724 - val_loss: 0.6084
AUC: 0.8657

Epoch 23/30
 - 0s - loss: 0.9708 - val_loss: 0.6073
AUC: 0.8657

Epoch 24/30
 - 0s - loss: 0.9691 - val_loss: 0.6080
AUC: 0.8657

Epoch 25/30
 - 0s - loss: 0.9736 - val_loss: 0.6067
AUC: 0.8657

Epoch 26/30
 - 0s - loss: 0.9731 - val_loss: 0.6070
AUC: 0.8657

Epoch 27/30
 - 0s - loss: 0.9710 - val_loss: 0.6052
AUC: 0.8657

Epoch 28/30
 - 0s - loss: 0.9730 - val_loss: 0.6063
AUC: 0.8657

Epoch 29/30
 - 0s - loss: 0.9680 - val_loss: 0.6052
AUC: 0.8657

Epoch 30/30
 - 0s - loss: 0.9696 - val_loss: 0.6065
Using TensorFlow backend.
AUC: 0.8657

2019-03-08 13:59:15.111918: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 13:59:15.277350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 13:59:15.277395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 13:59:15.567526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 13:59:15.567578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 13:59:15.567587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 13:59:15.567839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1786
Epoch 2/80
 - 1s - loss: 0.2221
Epoch 3/80
 - 2s - loss: 0.1742
Epoch 4/80
 - 2s - loss: 0.1646
Epoch 5/80
 - 1s - loss: 0.1573
Epoch 6/80
 - 1s - loss: 0.1488
Epoch 7/80
 - 2s - loss: 0.1390
Epoch 8/80
 - 1s - loss: 0.1295
Epoch 9/80
 - 2s - loss: 0.1207
Epoch 10/80
 - 1s - loss: 0.1123
Epoch 11/80
 - 1s - loss: 0.1040
Epoch 12/80
 - 1s - loss: 0.0963
Epoch 13/80
 - 2s - loss: 0.0896
Epoch 14/80
 - 1s - loss: 0.0838
Epoch 15/80
 - 1s - loss: 0.0788
Epoch 16/80
 - 1s - loss: 0.0747
Epoch 17/80
 - 1s - loss: 0.0712
Epoch 18/80
 - 1s - loss: 0.0684
Epoch 19/80
 - 1s - loss: 0.0660
Epoch 20/80
 - 1s - loss: 0.0640
Epoch 21/80
 - 1s - loss: 0.0622
Epoch 22/80
 - 1s - loss: 0.0608
Epoch 23/80
 - 1s - loss: 0.0595
Epoch 24/80
 - 1s - loss: 0.0584
Epoch 25/80
 - 1s - loss: 0.0575
Epoch 26/80
 - 1s - loss: 0.0566
Epoch 27/80
 - 2s - loss: 0.0560
Epoch 28/80
 - 1s - loss: 0.0553
Epoch 29/80
 - 2s - loss: 0.0548
Epoch 30/80
 - 1s - loss: 0.0543
Epoch 31/80
 - 2s - loss: 0.0539
Epoch 32/80
 - 1s - loss: 0.0535
Epoch 33/80
 - 2s - loss: 0.0532
Epoch 34/80
 - 1s - loss: 0.0530
Epoch 35/80
 - 1s - loss: 0.0527
Epoch 36/80
 - 1s - loss: 0.0525
Epoch 37/80
 - 2s - loss: 0.0523
Epoch 38/80
 - 1s - loss: 0.0521
Using TensorFlow backend.
Traceback (most recent call last):
  File "train_template_sub0228.py", line 136, in <module>
    verbose=2)
  File "/home/wsliu/Codes/DLproj/NRD/glove.py", line 105, in train_glove
    sample_weight=weights, callbacks=[checkpoint, reduce_lr, earlystop], verbose=verbose)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py", line 1037, in fit
    validation_steps=validation_steps)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training_arrays.py", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 77, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/callbacks.py", line 442, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/network.py", line 1115, in save_weights
    with h5py.File(filepath, 'w') as f:
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/h5py/_hl/files.py", line 148, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 98, in h5py.h5f.create
OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
2019-03-08 14:00:38.556092: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 14:00:38.736703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 14:00:38.736747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 14:00:39.026349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 14:00:39.026401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 14:00:39.026409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 14:00:39.026671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1709
Epoch 2/80
 - 2s - loss: 0.2191
Epoch 3/80
 - 2s - loss: 0.1738
Epoch 4/80
 - 2s - loss: 0.1663
Epoch 5/80
 - 2s - loss: 0.1591
Epoch 6/80
 - 2s - loss: 0.1497
Epoch 7/80
 - 2s - loss: 0.1386
Epoch 8/80
 - 2s - loss: 0.1272
Epoch 9/80
 - 2s - loss: 0.1169
Epoch 10/80
 - 2s - loss: 0.1080
Epoch 11/80
 - 2s - loss: 0.1002
Epoch 12/80
 - 2s - loss: 0.0932
Epoch 13/80
 - 2s - loss: 0.0872
Epoch 14/80
 - 2s - loss: 0.0821
Epoch 15/80
 - 2s - loss: 0.0778
Epoch 16/80
 - 2s - loss: 0.0741
Epoch 17/80
 - 2s - loss: 0.0708
Epoch 18/80
 - 2s - loss: 0.0680
Epoch 19/80
 - 2s - loss: 0.0656
Epoch 20/80
 - 2s - loss: 0.0636
Epoch 21/80
 - 2s - loss: 0.0618
Epoch 22/80
 - 2s - loss: 0.0603
Epoch 23/80
 - 2s - loss: 0.0590
Epoch 24/80
 - 2s - loss: 0.0579
Epoch 25/80
 - 2s - loss: 0.0570
Epoch 26/80
 - 2s - loss: 0.0562
Epoch 27/80
 - 2s - loss: 0.0555
Epoch 28/80
 - 2s - loss: 0.0549
Epoch 29/80
 - 2s - loss: 0.0544
Epoch 30/80
 - 2s - loss: 0.0540
Epoch 31/80
 - 2s - loss: 0.0536
Epoch 32/80
 - 2s - loss: 0.0533
Epoch 33/80
 - 2s - loss: 0.0530
Epoch 34/80
 - 2s - loss: 0.0527
Epoch 35/80
 - 2s - loss: 0.0525
Epoch 36/80
 - 2s - loss: 0.0523
Epoch 37/80
 - 2s - loss: 0.0521
Epoch 38/80
 - 2s - loss: 0.0519
Epoch 39/80
 - 2s - loss: 0.0517
Epoch 40/80
 - 2s - loss: 0.0516
Epoch 41/80
 - 2s - loss: 0.0515
Epoch 42/80
 - 2s - loss: 0.0514
Epoch 43/80
 - 2s - loss: 0.0512
Epoch 44/80
 - 2s - loss: 0.0512
Epoch 45/80
 - 2s - loss: 0.0511
Epoch 46/80
 - 2s - loss: 0.0510
Epoch 47/80
 - 2s - loss: 0.0509
Epoch 48/80
 - 2s - loss: 0.0508
Epoch 49/80
 - 2s - loss: 0.0507
Epoch 50/80
 - 2s - loss: 0.0507
Epoch 51/80
 - 2s - loss: 0.0506
Epoch 52/80
 - 2s - loss: 0.0506
Epoch 53/80
 - 2s - loss: 0.0505
Epoch 54/80
 - 2s - loss: 0.0504
Epoch 55/80
 - 2s - loss: 0.0504
Epoch 56/80
 - 2s - loss: 0.0504
Epoch 57/80
 - 2s - loss: 0.0503
Epoch 58/80
 - 2s - loss: 0.0503
Epoch 59/80
 - 2s - loss: 0.0503
Epoch 60/80
 - 2s - loss: 0.0491
Epoch 61/80
 - 2s - loss: 0.0490
Epoch 62/80
 - 2s - loss: 0.0490
Epoch 63/80
 - 2s - loss: 0.0490
Epoch 64/80
 - 2s - loss: 0.0490
Epoch 65/80
 - 2s - loss: 0.0487
Epoch 66/80
 - 2s - loss: 0.0487
Epoch 67/80
 - 2s - loss: 0.0487
Epoch 68/80
 - 2s - loss: 0.0487
Epoch 69/80
 - 2s - loss: 0.0486
Epoch 70/80
 - 2s - loss: 0.0486
Epoch 71/80
 - 2s - loss: 0.0486
Epoch 72/80
 - 2s - loss: 0.0486
Epoch 73/80
 - 2s - loss: 0.0486
Epoch 74/80
 - 2s - loss: 0.0486
Epoch 75/80
 - 2s - loss: 0.0486
Epoch 76/80
 - 2s - loss: 0.0486
Epoch 77/80
 - 2s - loss: 0.0486
Epoch 78/80
 - 2s - loss: 0.0486
Epoch 79/80
 - 2s - loss: 0.0486
Epoch 80/80
 - 2s - loss: 0.0486
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 1.3177 - val_loss: 0.6112
AUC: 0.6048

Epoch 2/80
 - 0s - loss: 0.7872 - val_loss: 0.4271
AUC: 0.7215

Epoch 3/80
 - 0s - loss: 0.5116 - val_loss: 0.3711
AUC: 0.7567

Epoch 4/80
 - 0s - loss: 0.4129 - val_loss: 0.3571
AUC: 0.7793

Epoch 5/80
 - 0s - loss: 0.3846 - val_loss: 0.3496
AUC: 0.7991

Epoch 6/80
 - 0s - loss: 0.3709 - val_loss: 0.3450
AUC: 0.8002

Epoch 7/80
 - 0s - loss: 0.3608 - val_loss: 0.3403
AUC: 0.8088

Epoch 8/80
 - 0s - loss: 0.3562 - val_loss: 0.3418
AUC: 0.8240

Epoch 9/80
 - 0s - loss: 0.3490 - val_loss: 0.3319
AUC: 0.8243

Epoch 10/80
 - 0s - loss: 0.3436 - val_loss: 0.3288
AUC: 0.8279

Epoch 11/80
 - 0s - loss: 0.3391 - val_loss: 0.3291
AUC: 0.8289

Epoch 12/80
 - 0s - loss: 0.3354 - val_loss: 0.3258
AUC: 0.8325

Epoch 13/80
 - 0s - loss: 0.3341 - val_loss: 0.3235
AUC: 0.8355

Epoch 14/80
 - 0s - loss: 0.3298 - val_loss: 0.3222
AUC: 0.8373

Epoch 15/80
 - 0s - loss: 0.3283 - val_loss: 0.3198
AUC: 0.8413

Epoch 16/80
 - 0s - loss: 0.3265 - val_loss: 0.3196
AUC: 0.8414

Epoch 17/80
 - 0s - loss: 0.3259 - val_loss: 0.3183
AUC: 0.8442

Epoch 18/80
 - 0s - loss: 0.3223 - val_loss: 0.3177
AUC: 0.8465

Epoch 19/80
 - 0s - loss: 0.3214 - val_loss: 0.3160
AUC: 0.8465

Epoch 20/80
 - 0s - loss: 0.3209 - val_loss: 0.3149
AUC: 0.8488

Epoch 21/80
 - 0s - loss: 0.3184 - val_loss: 0.3140
AUC: 0.8493

Epoch 22/80
 - 0s - loss: 0.3165 - val_loss: 0.3145
AUC: 0.8514

Epoch 23/80
 - 0s - loss: 0.3159 - val_loss: 0.3135
AUC: 0.8500

Epoch 24/80
 - 0s - loss: 0.3141 - val_loss: 0.3126
AUC: 0.8510

Epoch 25/80
 - 0s - loss: 0.3135 - val_loss: 0.3133
AUC: 0.8516

Epoch 26/80
 - 0s - loss: 0.3135 - val_loss: 0.3116
AUC: 0.8527

Epoch 27/80
 - 0s - loss: 0.3116 - val_loss: 0.3105
AUC: 0.8550

Epoch 28/80
 - 0s - loss: 0.3112 - val_loss: 0.3100
AUC: 0.8553

Epoch 29/80
 - 0s - loss: 0.3087 - val_loss: 0.3124
AUC: 0.8532

Epoch 30/80
 - 0s - loss: 0.3074 - val_loss: 0.3098
AUC: 0.8548

Epoch 31/80
 - 0s - loss: 0.3084 - val_loss: 0.3108
AUC: 0.8547

Epoch 32/80
 - 0s - loss: 0.3068 - val_loss: 0.3088
AUC: 0.8560

Epoch 33/80
 - 0s - loss: 0.3089 - val_loss: 0.3082
AUC: 0.8577

Epoch 34/80
 - 0s - loss: 0.3056 - val_loss: 0.3074
AUC: 0.8576

Epoch 35/80
 - 0s - loss: 0.3058 - val_loss: 0.3076
AUC: 0.8577

Epoch 36/80
 - 0s - loss: 0.3061 - val_loss: 0.3092
AUC: 0.8586

Epoch 37/80
 - 0s - loss: 0.3051 - val_loss: 0.3083
AUC: 0.8579

Epoch 38/80
 - 0s - loss: 0.3044 - val_loss: 0.3074
AUC: 0.8580

Epoch 39/80
 - 0s - loss: 0.3034 - val_loss: 0.3073
AUC: 0.8584

Epoch 40/80
 - 0s - loss: 0.3038 - val_loss: 0.3061
AUC: 0.8594

Epoch 41/80
 - 0s - loss: 0.3029 - val_loss: 0.3063
AUC: 0.8588

Epoch 42/80
 - 0s - loss: 0.3010 - val_loss: 0.3065
AUC: 0.8605

Epoch 43/80
 - 0s - loss: 0.3009 - val_loss: 0.3051
AUC: 0.8609

Epoch 44/80
 - 0s - loss: 0.3008 - val_loss: 0.3089
AUC: 0.8595

Epoch 45/80
 - 0s - loss: 0.2993 - val_loss: 0.3050
AUC: 0.8616

Epoch 46/80
 - 0s - loss: 0.3010 - val_loss: 0.3077
AUC: 0.8597

Epoch 47/80
 - 0s - loss: 0.3002 - val_loss: 0.3046
AUC: 0.8617

Epoch 48/80
 - 0s - loss: 0.2985 - val_loss: 0.3066
AUC: 0.8606

Epoch 49/80
 - 0s - loss: 0.2990 - val_loss: 0.3054
AUC: 0.8615

Epoch 50/80
 - 0s - loss: 0.2989 - val_loss: 0.3063
AUC: 0.8611

Epoch 51/80
 - 0s - loss: 0.2983 - val_loss: 0.3039
AUC: 0.8621

Epoch 52/80
 - 0s - loss: 0.2976 - val_loss: 0.3073
AUC: 0.8611

Epoch 53/80
 - 0s - loss: 0.2971 - val_loss: 0.3035
AUC: 0.8622

Epoch 54/80
 - 0s - loss: 0.2963 - val_loss: 0.3039
AUC: 0.8629

Epoch 55/80
 - 0s - loss: 0.2964 - val_loss: 0.3066
AUC: 0.8617

Epoch 56/80
 - 0s - loss: 0.2965 - val_loss: 0.3066
AUC: 0.8633

Epoch 57/80
 - 0s - loss: 0.2959 - val_loss: 0.3030
AUC: 0.8634

Epoch 58/80
 - 0s - loss: 0.2957 - val_loss: 0.3059
AUC: 0.8629

Epoch 59/80
 - 0s - loss: 0.2954 - val_loss: 0.3025
AUC: 0.8637

Epoch 60/80
 - 0s - loss: 0.2941 - val_loss: 0.3049
AUC: 0.8634

Epoch 61/80
 - 0s - loss: 0.2950 - val_loss: 0.3031
AUC: 0.8651

Epoch 62/80
 - 0s - loss: 0.2933 - val_loss: 0.3022
AUC: 0.8642

Epoch 63/80
 - 0s - loss: 0.2926 - val_loss: 0.3029
AUC: 0.8637

Epoch 64/80
 - 0s - loss: 0.2950 - val_loss: 0.3070
AUC: 0.8633

Epoch 65/80
 - 0s - loss: 0.2943 - val_loss: 0.3032
AUC: 0.8636

Epoch 66/80
 - 0s - loss: 0.2938 - val_loss: 0.3055
AUC: 0.8639

Epoch 67/80
 - 0s - loss: 0.2927 - val_loss: 0.3014
AUC: 0.8648

Epoch 68/80
 - 0s - loss: 0.2912 - val_loss: 0.3019
AUC: 0.8654

Epoch 69/80
 - 0s - loss: 0.2928 - val_loss: 0.3033
AUC: 0.8646

Epoch 70/80
 - 0s - loss: 0.2915 - val_loss: 0.3015
AUC: 0.8658

Epoch 71/80
 - 0s - loss: 0.2906 - val_loss: 0.3047
AUC: 0.8651

Epoch 72/80
 - 0s - loss: 0.2901 - val_loss: 0.3024
AUC: 0.8650

Epoch 73/80
 - 0s - loss: 0.2904 - val_loss: 0.3012
AUC: 0.8665

Epoch 74/80
 - 0s - loss: 0.2897 - val_loss: 0.3033
AUC: 0.8657

Epoch 75/80
 - 0s - loss: 0.2904 - val_loss: 0.3012
AUC: 0.8657

Epoch 76/80
 - 0s - loss: 0.2898 - val_loss: 0.3030
AUC: 0.8651

Epoch 77/80
 - 0s - loss: 0.2897 - val_loss: 0.3017
AUC: 0.8654

Epoch 78/80
 - 0s - loss: 0.2900 - val_loss: 0.3033
AUC: 0.8645

Epoch 79/80
 - 0s - loss: 0.2894 - val_loss: 0.3039
AUC: 0.8663

Epoch 80/80
 - 0s - loss: 0.2894 - val_loss: 0.3005
AUC: 0.8664

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.2880 - val_loss: 0.3010
AUC: 0.8663

Epoch 2/30
 - 0s - loss: 0.2871 - val_loss: 0.3013
AUC: 0.8662

Epoch 3/30
 - 0s - loss: 0.2871 - val_loss: 0.3008
AUC: 0.8665

Epoch 4/30
 - 0s - loss: 0.2866 - val_loss: 0.3007
AUC: 0.8666

Epoch 5/30
 - 0s - loss: 0.2862 - val_loss: 0.3009
AUC: 0.8665

Epoch 6/30
 - 0s - loss: 0.2851 - val_loss: 0.3011
AUC: 0.8667

Epoch 7/30
 - 0s - loss: 0.2856 - val_loss: 0.3004
AUC: 0.8670

Epoch 8/30
 - 0s - loss: 0.2853 - val_loss: 0.3005
AUC: 0.8672

Epoch 9/30
 - 0s - loss: 0.2859 - val_loss: 0.3002
AUC: 0.8672

Epoch 10/30
 - 0s - loss: 0.2844 - val_loss: 0.3001
AUC: 0.8672

Epoch 11/30
 - 0s - loss: 0.2842 - val_loss: 0.3005
AUC: 0.8672

Epoch 12/30
 - 0s - loss: 0.2843 - val_loss: 0.3000
AUC: 0.8675

Epoch 13/30
 - 0s - loss: 0.2844 - val_loss: 0.2999
AUC: 0.8677

Epoch 14/30
 - 0s - loss: 0.2835 - val_loss: 0.3000
AUC: 0.8675

Epoch 15/30
 - 0s - loss: 0.2832 - val_loss: 0.2998
AUC: 0.8677

Epoch 16/30
 - 0s - loss: 0.2828 - val_loss: 0.3001
AUC: 0.8676

Epoch 17/30
 - 0s - loss: 0.2824 - val_loss: 0.2996
AUC: 0.8680

Epoch 18/30
 - 0s - loss: 0.2823 - val_loss: 0.2998
AUC: 0.8679

Epoch 19/30
 - 0s - loss: 0.2819 - val_loss: 0.2996
AUC: 0.8682

Epoch 20/30
 - 0s - loss: 0.2830 - val_loss: 0.2996
AUC: 0.8681

Epoch 21/30
 - 0s - loss: 0.2822 - val_loss: 0.2997
AUC: 0.8680

Epoch 22/30
 - 0s - loss: 0.2811 - val_loss: 0.2999
AUC: 0.8682

Epoch 23/30
 - 0s - loss: 0.2817 - val_loss: 0.2999
AUC: 0.8681

Epoch 24/30
 - 0s - loss: 0.2810 - val_loss: 0.2994
AUC: 0.8683

Epoch 25/30
 - 0s - loss: 0.2810 - val_loss: 0.2997
AUC: 0.8683

Epoch 26/30
 - 0s - loss: 0.2804 - val_loss: 0.2992
AUC: 0.8687

Epoch 27/30
 - 0s - loss: 0.2801 - val_loss: 0.2992
AUC: 0.8688

Epoch 28/30
 - 0s - loss: 0.2806 - val_loss: 0.2992
AUC: 0.8686

Epoch 29/30
 - 0s - loss: 0.2797 - val_loss: 0.2992
AUC: 0.8688

Epoch 30/30
 - 0s - loss: 0.2806 - val_loss: 0.2992
Using TensorFlow backend.
AUC: 0.8689

2019-03-08 14:04:13.174250: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 14:04:13.341567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 14:04:13.341610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 14:04:13.632825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 14:04:13.632877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 14:04:13.632885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 14:04:13.633139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.8 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.2085
Epoch 2/80
 - 1s - loss: 0.2261
Epoch 3/80
 - 1s - loss: 0.1733
Epoch 4/80
 - 1s - loss: 0.1650
Epoch 5/80
 - 1s - loss: 0.1556
Epoch 6/80
 - 1s - loss: 0.1425
Epoch 7/80
 - 1s - loss: 0.1288
Epoch 8/80
 - 1s - loss: 0.1174
Epoch 9/80
 - 1s - loss: 0.1084
Epoch 10/80
 - 1s - loss: 0.1010
Epoch 11/80
 - 1s - loss: 0.0948
Epoch 12/80
 - 1s - loss: 0.0896
Epoch 13/80
 - 1s - loss: 0.0851
Epoch 14/80
 - 1s - loss: 0.0810
Epoch 15/80
 - 1s - loss: 0.0774
Epoch 16/80
 - 1s - loss: 0.0741
Epoch 17/80
 - 1s - loss: 0.0712
Epoch 18/80
 - 1s - loss: 0.0687
Epoch 19/80
 - 1s - loss: 0.0665
Epoch 20/80
 - 1s - loss: 0.0645
Epoch 21/80
 - 1s - loss: 0.0628
Epoch 22/80
 - 1s - loss: 0.0613
Epoch 23/80
 - 1s - loss: 0.0600
Epoch 24/80
 - 1s - loss: 0.0589
Epoch 25/80
 - 1s - loss: 0.0579
Epoch 26/80
 - 1s - loss: 0.0570
Epoch 27/80
 - 1s - loss: 0.0562
Epoch 28/80
 - 1s - loss: 0.0555
Epoch 29/80
 - 1s - loss: 0.0550
Epoch 30/80
 - 1s - loss: 0.0544
Epoch 31/80
 - 1s - loss: 0.0540
Epoch 32/80
 - 2s - loss: 0.0536
Epoch 33/80
 - 1s - loss: 0.0533
Epoch 34/80
 - 2s - loss: 0.0530
Epoch 35/80
 - 1s - loss: 0.0527
Epoch 36/80
 - 1s - loss: 0.0525
Epoch 37/80
 - 1s - loss: 0.0522
Epoch 38/80
 - 1s - loss: 0.0520
Epoch 39/80
 - 1s - loss: 0.0519
Epoch 40/80
 - 1s - loss: 0.0517
Epoch 41/80
 - 1s - loss: 0.0516
Epoch 42/80
 - 1s - loss: 0.0514
Epoch 43/80
 - 1s - loss: 0.0513
Epoch 44/80
 - 1s - loss: 0.0512
Epoch 45/80
 - 1s - loss: 0.0511
Epoch 46/80
 - 1s - loss: 0.0510
Epoch 47/80
 - 1s - loss: 0.0510
Epoch 48/80
 - 1s - loss: 0.0509
Epoch 49/80
 - 1s - loss: 0.0508
Epoch 50/80
 - 1s - loss: 0.0507
Epoch 51/80
 - 1s - loss: 0.0507
Epoch 52/80
 - 1s - loss: 0.0506
Epoch 53/80
 - 1s - loss: 0.0505
Epoch 54/80
 - 2s - loss: 0.0505
Epoch 55/80
 - 1s - loss: 0.0505
Epoch 56/80
 - 1s - loss: 0.0504
Epoch 57/80
 - 1s - loss: 0.0504
Epoch 58/80
 - 1s - loss: 0.0504
Epoch 59/80
 - 1s - loss: 0.0503
Epoch 60/80
 - 1s - loss: 0.0503
Epoch 61/80
 - 1s - loss: 0.0502
Epoch 62/80
 - 1s - loss: 0.0502
Epoch 63/80
 - 1s - loss: 0.0502
Epoch 64/80
 - 1s - loss: 0.0501
Epoch 65/80
 - 1s - loss: 0.0501
Epoch 66/80
 - 1s - loss: 0.0501
Epoch 67/80
 - 1s - loss: 0.0490
Epoch 68/80
 - 1s - loss: 0.0489
Epoch 69/80
 - 1s - loss: 0.0489
Epoch 70/80
 - 1s - loss: 0.0488
Epoch 71/80
 - 1s - loss: 0.0488
Epoch 72/80
 - 1s - loss: 0.0486
Epoch 73/80
 - 1s - loss: 0.0486
Epoch 74/80
 - 2s - loss: 0.0485
Epoch 75/80
 - 1s - loss: 0.0485
Epoch 76/80
 - 1s - loss: 0.0485
Epoch 77/80
 - 1s - loss: 0.0485
Epoch 78/80
 - 1s - loss: 0.0485
Epoch 79/80
 - 1s - loss: 0.0485
Epoch 80/80
 - 1s - loss: 0.0485
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 5.1079 - val_loss: 2.1497
AUC: 0.8027

Epoch 2/80
 - 0s - loss: 3.1150 - val_loss: 1.2937
AUC: 0.8183

Epoch 3/80
 - 0s - loss: 2.0490 - val_loss: 1.1682
AUC: 0.8294

Epoch 4/80
 - 0s - loss: 1.6171 - val_loss: 0.7987
AUC: 0.8391

Epoch 5/80
 - 0s - loss: 1.4401 - val_loss: 0.8846
AUC: 0.8467

Epoch 6/80
 - 0s - loss: 1.3775 - val_loss: 0.9353
AUC: 0.8518

Epoch 7/80
 - 0s - loss: 1.3459 - val_loss: 0.8746
AUC: 0.8532

Epoch 8/80
 - 0s - loss: 1.3275 - val_loss: 0.8284
AUC: 0.8539

Epoch 9/80
 - 0s - loss: 1.3079 - val_loss: 0.8539
AUC: 0.8562

Epoch 10/80
 - 0s - loss: 1.2923 - val_loss: 0.8229
AUC: 0.8556

Epoch 11/80
 - 0s - loss: 1.2772 - val_loss: 0.7241
AUC: 0.8555

Epoch 12/80
 - 0s - loss: 1.2605 - val_loss: 0.7316
AUC: 0.8568

Epoch 13/80
 - 0s - loss: 1.2542 - val_loss: 0.6904
AUC: 0.8565

Epoch 14/80
 - 0s - loss: 1.2445 - val_loss: 0.6852
AUC: 0.8557

Epoch 15/80
 - 0s - loss: 1.2410 - val_loss: 0.8020
AUC: 0.8584

Epoch 16/80
 - 0s - loss: 1.2399 - val_loss: 0.7867
AUC: 0.8594

Epoch 17/80
 - 0s - loss: 1.2290 - val_loss: 0.7961
AUC: 0.8586

Epoch 18/80
 - 0s - loss: 1.2266 - val_loss: 0.7327
AUC: 0.8590

Epoch 19/80
 - 0s - loss: 1.2238 - val_loss: 0.8025
AUC: 0.8604

Epoch 20/80
 - 0s - loss: 1.2170 - val_loss: 0.6815
AUC: 0.8594

Epoch 21/80
 - 0s - loss: 1.2204 - val_loss: 0.8010
AUC: 0.8594

Epoch 22/80
 - 0s - loss: 1.2075 - val_loss: 0.6714
AUC: 0.8589

Epoch 23/80
 - 0s - loss: 1.2051 - val_loss: 0.7996
AUC: 0.8608

Epoch 24/80
 - 0s - loss: 1.2021 - val_loss: 0.7820
AUC: 0.8610

Epoch 25/80
 - 0s - loss: 1.2000 - val_loss: 0.7763
AUC: 0.8615

Epoch 26/80
 - 0s - loss: 1.2067 - val_loss: 0.6829
AUC: 0.8602

Epoch 27/80
 - 0s - loss: 1.1939 - val_loss: 0.7909
AUC: 0.8617

Epoch 28/80
 - 0s - loss: 1.1880 - val_loss: 0.7582
AUC: 0.8622

Epoch 29/80
 - 0s - loss: 1.1931 - val_loss: 0.8375
AUC: 0.8630

Epoch 30/80
 - 0s - loss: 1.1829 - val_loss: 0.7561
AUC: 0.8619

Epoch 31/80
 - 0s - loss: 1.1837 - val_loss: 0.7351
AUC: 0.8625

Epoch 32/80
 - 0s - loss: 1.1820 - val_loss: 0.7688
AUC: 0.8627

Epoch 33/80
 - 0s - loss: 1.1682 - val_loss: 0.7135
AUC: 0.8624

Epoch 34/80
 - 0s - loss: 1.1715 - val_loss: 0.7331
AUC: 0.8630

Epoch 35/80
 - 0s - loss: 1.1645 - val_loss: 0.7215
AUC: 0.8627

Epoch 36/80
 - 0s - loss: 1.1720 - val_loss: 0.7554
AUC: 0.8632

Epoch 37/80
 - 0s - loss: 1.1640 - val_loss: 0.7169
AUC: 0.8626

Epoch 38/80
 - 0s - loss: 1.1653 - val_loss: 0.7397
AUC: 0.8630

Epoch 39/80
 - 0s - loss: 1.1670 - val_loss: 0.7645
AUC: 0.8633

Epoch 40/80
 - 0s - loss: 1.1609 - val_loss: 0.7282
AUC: 0.8630

Epoch 41/80
 - 0s - loss: 1.1696 - val_loss: 0.7389
AUC: 0.8630

Epoch 42/80
 - 0s - loss: 1.1608 - val_loss: 0.7792
AUC: 0.8634

Epoch 43/80
 - 0s - loss: 1.1625 - val_loss: 0.7389
AUC: 0.8631

Epoch 44/80
 - 0s - loss: 1.1617 - val_loss: 0.7277
AUC: 0.8630

Epoch 45/80
 - 0s - loss: 1.1657 - val_loss: 0.7349
AUC: 0.8630

Epoch 46/80
 - 0s - loss: 1.1622 - val_loss: 0.7392
AUC: 0.8631

Epoch 47/80
 - 0s - loss: 1.1611 - val_loss: 0.7319
AUC: 0.8631

Epoch 48/80
 - 0s - loss: 1.1634 - val_loss: 0.7285
AUC: 0.8631

Epoch 49/80
 - 0s - loss: 1.1560 - val_loss: 0.7335
AUC: 0.8631

Epoch 50/80
 - 0s - loss: 1.1638 - val_loss: 0.7356
AUC: 0.8631

Epoch 51/80
 - 0s - loss: 1.1612 - val_loss: 0.7337
AUC: 0.8631

Epoch 52/80
 - 0s - loss: 1.1688 - val_loss: 0.7444
AUC: 0.8632

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.1613 - val_loss: 0.7250
AUC: 0.8633

Epoch 2/30
 - 0s - loss: 1.1633 - val_loss: 0.7226
AUC: 0.8634

Epoch 3/30
 - 0s - loss: 1.1581 - val_loss: 0.7233
AUC: 0.8635

Epoch 4/30
 - 0s - loss: 1.1651 - val_loss: 0.7525
AUC: 0.8639

Epoch 5/30
 - 0s - loss: 1.1565 - val_loss: 0.7108
AUC: 0.8636

Epoch 6/30
 - 0s - loss: 1.1541 - val_loss: 0.7390
AUC: 0.8638

Epoch 7/30
 - 0s - loss: 1.1541 - val_loss: 0.7128
AUC: 0.8638

Epoch 8/30
 - 0s - loss: 1.1533 - val_loss: 0.7318
AUC: 0.8642

Epoch 9/30
 - 0s - loss: 1.1462 - val_loss: 0.7176
AUC: 0.8642

Epoch 10/30
 - 0s - loss: 1.1483 - val_loss: 0.7045
AUC: 0.8644

Epoch 11/30
 - 0s - loss: 1.1486 - val_loss: 0.7304
AUC: 0.8647

Epoch 12/30
 - 0s - loss: 1.1457 - val_loss: 0.7335
AUC: 0.8649

Epoch 13/30
 - 0s - loss: 1.1383 - val_loss: 0.7183
AUC: 0.8649

Epoch 14/30
 - 0s - loss: 1.1407 - val_loss: 0.7303
AUC: 0.8651

Epoch 15/30
 - 0s - loss: 1.1385 - val_loss: 0.7170
AUC: 0.8651

Epoch 16/30
 - 0s - loss: 1.1434 - val_loss: 0.7391
AUC: 0.8653

Epoch 17/30
 - 0s - loss: 1.1371 - val_loss: 0.7206
AUC: 0.8652

Epoch 18/30
 - 0s - loss: 1.1458 - val_loss: 0.7102
AUC: 0.8652

Epoch 19/30
 - 0s - loss: 1.1329 - val_loss: 0.7308
AUC: 0.8655

Epoch 20/30
 - 0s - loss: 1.1367 - val_loss: 0.7262
AUC: 0.8656

Epoch 21/30
 - 0s - loss: 1.1334 - val_loss: 0.7256
AUC: 0.8656

Epoch 22/30
 - 0s - loss: 1.1357 - val_loss: 0.7221
AUC: 0.8656

Epoch 23/30
 - 0s - loss: 1.1343 - val_loss: 0.7226
AUC: 0.8656

Epoch 24/30
 - 0s - loss: 1.1326 - val_loss: 0.7204
AUC: 0.8656

Epoch 25/30
 - 0s - loss: 1.1379 - val_loss: 0.7251
AUC: 0.8657

Epoch 26/30
 - 0s - loss: 1.1262 - val_loss: 0.7189
AUC: 0.8656

Epoch 27/30
 - 0s - loss: 1.1351 - val_loss: 0.7248
AUC: 0.8657

Epoch 28/30
 - 0s - loss: 1.1328 - val_loss: 0.7246
AUC: 0.8657

Epoch 29/30
 - 0s - loss: 1.1295 - val_loss: 0.7211
AUC: 0.8657

Epoch 30/30
 - 0s - loss: 1.1341 - val_loss: 0.7186
Using TensorFlow backend.
AUC: 0.8658

2019-03-08 14:07:29.100012: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 14:07:29.267076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 14:07:29.267109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 14:07:29.562907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 14:07:29.562958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 14:07:29.562968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 14:07:29.563229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1329
Epoch 2/80
 - 2s - loss: 0.2130
Epoch 3/80
 - 2s - loss: 0.1740
Epoch 4/80
 - 2s - loss: 0.1682
Epoch 5/80
 - 2s - loss: 0.1635
Epoch 6/80
 - 2s - loss: 0.1572
Epoch 7/80
 - 2s - loss: 0.1484
Epoch 8/80
 - 2s - loss: 0.1371
Epoch 9/80
 - 2s - loss: 0.1250
Epoch 10/80
 - 2s - loss: 0.1141
Epoch 11/80
 - 2s - loss: 0.1046
Epoch 12/80
 - 1s - loss: 0.0963
Epoch 13/80
 - 1s - loss: 0.0891
Epoch 14/80
 - 2s - loss: 0.0831
Epoch 15/80
 - 1s - loss: 0.0782
Epoch 16/80
 - 2s - loss: 0.0741
Epoch 17/80
 - 2s - loss: 0.0707
Epoch 18/80
 - 2s - loss: 0.0679
Epoch 19/80
 - 1s - loss: 0.0655
Epoch 20/80
 - 2s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0618
Epoch 22/80
 - 2s - loss: 0.0604
Epoch 23/80
 - 2s - loss: 0.0592
Epoch 24/80
 - 2s - loss: 0.0582
Epoch 25/80
 - 1s - loss: 0.0573
Epoch 26/80
 - 2s - loss: 0.0565
Epoch 27/80
 - 2s - loss: 0.0558
Epoch 28/80
 - 2s - loss: 0.0552
Epoch 29/80
 - 2s - loss: 0.0547
Epoch 30/80
 - 2s - loss: 0.0542
Epoch 31/80
 - 2s - loss: 0.0538
Epoch 32/80
 - 2s - loss: 0.0535
Epoch 33/80
 - 2s - loss: 0.0532
Epoch 34/80
 - 2s - loss: 0.0529
Epoch 35/80
 - 2s - loss: 0.0526
Epoch 36/80
 - 1s - loss: 0.0524
Epoch 37/80
 - 2s - loss: 0.0522
Epoch 38/80
 - 2s - loss: 0.0520
Epoch 39/80
 - 2s - loss: 0.0518
Epoch 40/80
 - 2s - loss: 0.0517
Epoch 41/80
 - 1s - loss: 0.0516
Epoch 42/80
 - 2s - loss: 0.0514
Epoch 43/80
 - 2s - loss: 0.0513
Epoch 44/80
 - 2s - loss: 0.0512
Epoch 45/80
 - 2s - loss: 0.0512
Epoch 46/80
 - 2s - loss: 0.0511
Epoch 47/80
 - 2s - loss: 0.0510
Epoch 48/80
 - 2s - loss: 0.0509
Epoch 49/80
 - 2s - loss: 0.0508
Epoch 50/80
 - 2s - loss: 0.0508
Epoch 51/80
 - 1s - loss: 0.0507
Epoch 52/80
 - 1s - loss: 0.0507
Epoch 53/80
 - 1s - loss: 0.0506
Epoch 54/80
 - 2s - loss: 0.0506
Epoch 55/80
 - 2s - loss: 0.0505
Epoch 56/80
 - 2s - loss: 0.0505
Epoch 57/80
 - 1s - loss: 0.0505
Epoch 58/80
 - 2s - loss: 0.0504
Epoch 59/80
 - 2s - loss: 0.0504
Epoch 60/80
 - 2s - loss: 0.0504
Epoch 61/80
 - 2s - loss: 0.0493
Epoch 62/80
 - 2s - loss: 0.0491
Epoch 63/80
 - 2s - loss: 0.0491
Epoch 64/80
 - 2s - loss: 0.0491
Epoch 65/80
 - 2s - loss: 0.0491
Epoch 66/80
 - 2s - loss: 0.0488
Epoch 67/80
 - 2s - loss: 0.0488
Epoch 68/80
 - 2s - loss: 0.0488
Epoch 69/80
 - 2s - loss: 0.0488
Epoch 70/80
 - 2s - loss: 0.0487
Epoch 71/80
 - 2s - loss: 0.0487
Epoch 72/80
 - 2s - loss: 0.0487
Epoch 73/80
 - 2s - loss: 0.0487
Epoch 74/80
 - 2s - loss: 0.0487
Epoch 75/80
 - 1s - loss: 0.0487
Epoch 76/80
 - 1s - loss: 0.0487
Epoch 77/80
 - 2s - loss: 0.0487
Epoch 78/80
 - 2s - loss: 0.0487
Epoch 79/80
 - 2s - loss: 0.0487
Epoch 80/80
 - 2s - loss: 0.0487
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 4.5105 - val_loss: 1.3481
AUC: 0.7901

Epoch 2/80
 - 0s - loss: 2.6110 - val_loss: 1.2970
AUC: 0.8143

Epoch 3/80
 - 0s - loss: 1.7249 - val_loss: 0.7613
AUC: 0.8266

Epoch 4/80
 - 0s - loss: 1.3898 - val_loss: 0.7208
AUC: 0.8342

Epoch 5/80
 - 0s - loss: 1.2421 - val_loss: 0.7129
AUC: 0.8401

Epoch 6/80
 - 0s - loss: 1.1857 - val_loss: 0.6587
AUC: 0.8428

Epoch 7/80
 - 0s - loss: 1.1616 - val_loss: 0.7144
AUC: 0.8485

Epoch 8/80
 - 0s - loss: 1.1294 - val_loss: 0.7379
AUC: 0.8499

Epoch 9/80
 - 0s - loss: 1.1219 - val_loss: 0.6360
AUC: 0.8528

Epoch 10/80
 - 0s - loss: 1.0952 - val_loss: 0.6402
AUC: 0.8531

Epoch 11/80
 - 0s - loss: 1.0896 - val_loss: 0.6537
AUC: 0.8557

Epoch 12/80
 - 0s - loss: 1.0816 - val_loss: 0.6107
AUC: 0.8541

Epoch 13/80
 - 0s - loss: 1.0622 - val_loss: 0.6282
AUC: 0.8554

Epoch 14/80
 - 0s - loss: 1.0636 - val_loss: 0.6671
AUC: 0.8581

Epoch 15/80
 - 0s - loss: 1.0586 - val_loss: 0.6706
AUC: 0.8585

Epoch 16/80
 - 0s - loss: 1.0570 - val_loss: 0.6140
AUC: 0.8565

Epoch 17/80
 - 0s - loss: 1.0486 - val_loss: 0.6071
AUC: 0.8574

Epoch 18/80
 - 0s - loss: 1.0402 - val_loss: 0.6691
AUC: 0.8586

Epoch 19/80
 - 0s - loss: 1.0390 - val_loss: 0.6402
AUC: 0.8589

Epoch 20/80
 - 0s - loss: 1.0271 - val_loss: 0.6952
AUC: 0.8601

Epoch 21/80
 - 0s - loss: 1.0306 - val_loss: 0.6979
AUC: 0.8596

Epoch 22/80
 - 0s - loss: 1.0296 - val_loss: 0.6563
AUC: 0.8618

Epoch 23/80
 - 0s - loss: 1.0204 - val_loss: 0.6714
AUC: 0.8608

Epoch 24/80
 - 0s - loss: 1.0167 - val_loss: 0.6615
AUC: 0.8619

Epoch 25/80
 - 0s - loss: 1.0145 - val_loss: 0.5927
AUC: 0.8614

Epoch 26/80
 - 0s - loss: 1.0117 - val_loss: 0.6155
AUC: 0.8621

Epoch 27/80
 - 0s - loss: 1.0098 - val_loss: 0.6783
AUC: 0.8629

Epoch 28/80
 - 0s - loss: 1.0123 - val_loss: 0.5900
AUC: 0.8609

Epoch 29/80
 - 0s - loss: 1.0100 - val_loss: 0.6252
AUC: 0.8620

Epoch 30/80
 - 0s - loss: 1.0075 - val_loss: 0.6301
AUC: 0.8640

Epoch 31/80
 - 0s - loss: 1.0078 - val_loss: 0.6108
AUC: 0.8633

Epoch 32/80
 - 0s - loss: 1.0003 - val_loss: 0.5904
AUC: 0.8629

Epoch 33/80
 - 0s - loss: 0.9994 - val_loss: 0.6015
AUC: 0.8618

Epoch 34/80
 - 0s - loss: 1.0003 - val_loss: 0.5684
AUC: 0.8624

Epoch 35/80
 - 0s - loss: 0.9938 - val_loss: 0.6422
AUC: 0.8637

Epoch 36/80
 - 0s - loss: 0.9938 - val_loss: 0.6330
AUC: 0.8640

Epoch 37/80
 - 0s - loss: 0.9895 - val_loss: 0.6133
AUC: 0.8631

Epoch 38/80
 - 0s - loss: 0.9840 - val_loss: 0.6083
AUC: 0.8647

Epoch 39/80
 - 0s - loss: 0.9887 - val_loss: 0.6375
AUC: 0.8642

Epoch 40/80
 - 0s - loss: 0.9868 - val_loss: 0.6280
AUC: 0.8639

Epoch 41/80
 - 0s - loss: 0.9849 - val_loss: 0.6194
AUC: 0.8647

Epoch 42/80
 - 0s - loss: 0.9812 - val_loss: 0.6293
AUC: 0.8647

Epoch 43/80
 - 0s - loss: 0.9770 - val_loss: 0.6360
AUC: 0.8639

Epoch 44/80
 - 0s - loss: 0.9813 - val_loss: 0.6024
AUC: 0.8657

Epoch 45/80
 - 0s - loss: 0.9742 - val_loss: 0.6205
AUC: 0.8656

Epoch 46/80
 - 0s - loss: 0.9704 - val_loss: 0.6390
AUC: 0.8653

Epoch 47/80
 - 0s - loss: 0.9692 - val_loss: 0.5956
AUC: 0.8646

Epoch 48/80
 - 0s - loss: 0.9669 - val_loss: 0.5911
AUC: 0.8650

Epoch 49/80
 - 0s - loss: 0.9674 - val_loss: 0.6057
AUC: 0.8651

Epoch 50/80
 - 0s - loss: 0.9680 - val_loss: 0.6110
AUC: 0.8652

Epoch 51/80
 - 0s - loss: 0.9656 - val_loss: 0.5995
AUC: 0.8652

Epoch 52/80
 - 0s - loss: 0.9657 - val_loss: 0.5947
AUC: 0.8650

Epoch 53/80
 - 0s - loss: 0.9624 - val_loss: 0.6083
AUC: 0.8647

Epoch 54/80
 - 0s - loss: 0.9608 - val_loss: 0.5988
AUC: 0.8651

Epoch 55/80
 - 0s - loss: 0.9623 - val_loss: 0.6040
AUC: 0.8652

Epoch 56/80
 - 0s - loss: 0.9637 - val_loss: 0.6065
AUC: 0.8652

Epoch 57/80
 - 0s - loss: 0.9614 - val_loss: 0.6013
AUC: 0.8652

Epoch 58/80
 - 0s - loss: 0.9635 - val_loss: 0.6056
AUC: 0.8651

Epoch 59/80
 - 0s - loss: 0.9668 - val_loss: 0.5998
AUC: 0.8651

Epoch 60/80
 - 0s - loss: 0.9659 - val_loss: 0.6027
AUC: 0.8651

Epoch 61/80
 - 0s - loss: 0.9596 - val_loss: 0.6070
AUC: 0.8652

Epoch 62/80
 - 0s - loss: 0.9631 - val_loss: 0.6070
AUC: 0.8653

Epoch 63/80
 - 0s - loss: 0.9601 - val_loss: 0.5980
AUC: 0.8651

Epoch 64/80
 - 0s - loss: 0.9609 - val_loss: 0.5970
AUC: 0.8651

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.9754 - val_loss: 0.6133
AUC: 0.8656

Epoch 2/30
 - 0s - loss: 0.9673 - val_loss: 0.6089
AUC: 0.8654

Epoch 3/30
 - 0s - loss: 0.9651 - val_loss: 0.6051
AUC: 0.8654

Epoch 4/30
 - 0s - loss: 0.9663 - val_loss: 0.5987
AUC: 0.8654

Epoch 5/30
 - 0s - loss: 0.9609 - val_loss: 0.5921
AUC: 0.8652

Epoch 6/30
 - 0s - loss: 0.9634 - val_loss: 0.6037
AUC: 0.8657

Epoch 7/30
 - 0s - loss: 0.9588 - val_loss: 0.6043
AUC: 0.8656

Epoch 8/30
 - 0s - loss: 0.9579 - val_loss: 0.6011
AUC: 0.8656

Epoch 9/30
 - 0s - loss: 0.9624 - val_loss: 0.6241
AUC: 0.8659

Epoch 10/30
 - 0s - loss: 0.9558 - val_loss: 0.6139
AUC: 0.8661

Epoch 11/30
 - 0s - loss: 0.9525 - val_loss: 0.5951
AUC: 0.8659

Epoch 12/30
 - 0s - loss: 0.9574 - val_loss: 0.6189
AUC: 0.8662

Epoch 13/30
 - 0s - loss: 0.9530 - val_loss: 0.6006
AUC: 0.8663

Epoch 14/30
 - 0s - loss: 0.9578 - val_loss: 0.6072
AUC: 0.8662

Epoch 15/30
 - 0s - loss: 0.9511 - val_loss: 0.6045
AUC: 0.8664

Epoch 16/30
 - 0s - loss: 0.9534 - val_loss: 0.5970
AUC: 0.8664

Epoch 17/30
 - 0s - loss: 0.9523 - val_loss: 0.5982
AUC: 0.8665

Epoch 18/30
 - 0s - loss: 0.9497 - val_loss: 0.5967
AUC: 0.8665

Epoch 19/30
 - 0s - loss: 0.9531 - val_loss: 0.5961
AUC: 0.8665

Epoch 20/30
 - 0s - loss: 0.9501 - val_loss: 0.5971
AUC: 0.8665

Epoch 21/30
 - 0s - loss: 0.9453 - val_loss: 0.5960
AUC: 0.8665

Epoch 22/30
 - 0s - loss: 0.9494 - val_loss: 0.5976
AUC: 0.8665

Epoch 23/30
 - 0s - loss: 0.9523 - val_loss: 0.5965
AUC: 0.8665

Epoch 24/30
 - 0s - loss: 0.9518 - val_loss: 0.5993
AUC: 0.8665

Epoch 25/30
 - 0s - loss: 0.9464 - val_loss: 0.5961
AUC: 0.8665

Epoch 26/30
 - 0s - loss: 0.9462 - val_loss: 0.5960
AUC: 0.8665

Epoch 27/30
 - 0s - loss: 0.9486 - val_loss: 0.5970
AUC: 0.8665

Epoch 28/30
 - 0s - loss: 0.9453 - val_loss: 0.5957
AUC: 0.8665

Epoch 29/30
 - 0s - loss: 0.9469 - val_loss: 0.5964
AUC: 0.8665

Epoch 30/30
 - 0s - loss: 0.9485 - val_loss: 0.5962
Using TensorFlow backend.
AUC: 0.8665

2019-03-08 14:10:53.785005: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 14:10:53.946795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 14:10:53.946837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 14:10:54.234018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 14:10:54.234068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 14:10:54.234076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 14:10:54.234335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1255
Epoch 2/80
 - 2s - loss: 0.2139
Epoch 3/80
 - 2s - loss: 0.1730
Epoch 4/80
 - 2s - loss: 0.1652
Epoch 5/80
 - 2s - loss: 0.1585
Epoch 6/80
 - 2s - loss: 0.1510
Epoch 7/80
 - 2s - loss: 0.1430
Epoch 8/80
 - 2s - loss: 0.1340
Epoch 9/80
 - 2s - loss: 0.1233
Epoch 10/80
 - 2s - loss: 0.1124
Epoch 11/80
 - 2s - loss: 0.1030
Epoch 12/80
 - 1s - loss: 0.0953
Epoch 13/80
 - 2s - loss: 0.0887
Epoch 14/80
 - 2s - loss: 0.0830
Epoch 15/80
 - 1s - loss: 0.0782
Epoch 16/80
 - 1s - loss: 0.0741
Epoch 17/80
 - 2s - loss: 0.0707
Epoch 18/80
 - 2s - loss: 0.0679
Epoch 19/80
 - 1s - loss: 0.0655
Epoch 20/80
 - 1s - loss: 0.0635
Epoch 21/80
 - 2s - loss: 0.0617
Epoch 22/80
 - 1s - loss: 0.0603
Epoch 23/80
 - 2s - loss: 0.0590
Epoch 24/80
 - 2s - loss: 0.0580
Epoch 25/80
 - 1s - loss: 0.0570
Epoch 26/80
 - 1s - loss: 0.0562
Epoch 27/80
 - 2s - loss: 0.0555
Epoch 28/80
 - 2s - loss: 0.0549
Epoch 29/80
 - 1s - loss: 0.0543
Epoch 30/80
 - 1s - loss: 0.0539
Epoch 31/80
 - 2s - loss: 0.0535
Epoch 32/80
 - 1s - loss: 0.0531
Epoch 33/80
 - 2s - loss: 0.0528
Epoch 34/80
 - 2s - loss: 0.0526
Epoch 35/80
 - 1s - loss: 0.0523
Epoch 36/80
 - 1s - loss: 0.0521
Epoch 37/80
 - 2s - loss: 0.0519
Epoch 38/80
 - 2s - loss: 0.0518
Epoch 39/80
 - 1s - loss: 0.0516
Epoch 40/80
 - 2s - loss: 0.0515
Epoch 41/80
 - 2s - loss: 0.0513
Epoch 42/80
 - 1s - loss: 0.0512
Epoch 43/80
 - 2s - loss: 0.0511
Epoch 44/80
 - 2s - loss: 0.0510
Epoch 45/80
 - 2s - loss: 0.0509
Epoch 46/80
 - 2s - loss: 0.0509
Epoch 47/80
 - 2s - loss: 0.0508
Epoch 48/80
 - 2s - loss: 0.0507
Epoch 49/80
 - 2s - loss: 0.0506
Epoch 50/80
 - 2s - loss: 0.0506
Epoch 51/80
 - 2s - loss: 0.0505
Epoch 52/80
 - 2s - loss: 0.0505
Epoch 53/80
 - 2s - loss: 0.0504
Epoch 54/80
 - 2s - loss: 0.0504
Epoch 55/80
 - 2s - loss: 0.0503
Epoch 56/80
 - 2s - loss: 0.0503
Epoch 57/80
 - 2s - loss: 0.0502
Epoch 58/80
 - 2s - loss: 0.0502
Epoch 59/80
 - 2s - loss: 0.0502
Epoch 60/80
 - 2s - loss: 0.0501
Epoch 61/80
 - 2s - loss: 0.0501
Epoch 62/80
 - 2s - loss: 0.0501
Epoch 63/80
 - 2s - loss: 0.0500
Epoch 64/80
 - 2s - loss: 0.0500
Epoch 65/80
 - 2s - loss: 0.0500
Epoch 66/80
 - 2s - loss: 0.0489
Epoch 67/80
 - 2s - loss: 0.0488
Epoch 68/80
 - 2s - loss: 0.0488
Epoch 69/80
 - 2s - loss: 0.0487
Epoch 70/80
 - 1s - loss: 0.0487
Epoch 71/80
 - 2s - loss: 0.0485
Epoch 72/80
 - 2s - loss: 0.0485
Epoch 73/80
 - 2s - loss: 0.0485
Epoch 74/80
 - 2s - loss: 0.0484
Epoch 75/80
 - 2s - loss: 0.0484
Epoch 76/80
 - 1s - loss: 0.0484
Epoch 77/80
 - 1s - loss: 0.0484
Epoch 78/80
 - 1s - loss: 0.0484
Epoch 79/80
 - 2s - loss: 0.0484
Epoch 80/80
 - 2s - loss: 0.0484
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 3.5851 - val_loss: 0.7543
AUC: 0.7787

Epoch 2/80
 - 0s - loss: 2.3145 - val_loss: 0.5775
AUC: 0.8090

Epoch 3/80
 - 0s - loss: 1.6591 - val_loss: 0.4899
AUC: 0.8260

Epoch 4/80
 - 0s - loss: 1.2437 - val_loss: 0.5581
AUC: 0.8400

Epoch 5/80
 - 0s - loss: 1.0103 - val_loss: 0.5117
AUC: 0.8451

Epoch 6/80
 - 0s - loss: 0.9079 - val_loss: 0.5276
AUC: 0.8485

Epoch 7/80
 - 0s - loss: 0.8528 - val_loss: 0.4630
AUC: 0.8480

Epoch 8/80
 - 0s - loss: 0.8336 - val_loss: 0.4853
AUC: 0.8530

Epoch 9/80
 - 0s - loss: 0.8175 - val_loss: 0.4837
AUC: 0.8575

Epoch 10/80
 - 0s - loss: 0.8035 - val_loss: 0.5166
AUC: 0.8603

Epoch 11/80
 - 0s - loss: 0.7892 - val_loss: 0.4599
AUC: 0.8590

Epoch 12/80
 - 0s - loss: 0.7848 - val_loss: 0.4660
AUC: 0.8605

Epoch 13/80
 - 0s - loss: 0.7796 - val_loss: 0.4538
AUC: 0.8602

Epoch 14/80
 - 0s - loss: 0.7709 - val_loss: 0.4797
AUC: 0.8660

Epoch 15/80
 - 0s - loss: 0.7666 - val_loss: 0.4785
AUC: 0.8663

Epoch 16/80
 - 0s - loss: 0.7586 - val_loss: 0.4466
AUC: 0.8674

Epoch 17/80
 - 0s - loss: 0.7556 - val_loss: 0.4531
AUC: 0.8671

Epoch 18/80
 - 0s - loss: 0.7492 - val_loss: 0.4964
AUC: 0.8690

Epoch 19/80
 - 0s - loss: 0.7496 - val_loss: 0.4191
AUC: 0.8682

Epoch 20/80
 - 0s - loss: 0.7442 - val_loss: 0.4927
AUC: 0.8707

Epoch 21/80
 - 0s - loss: 0.7449 - val_loss: 0.4536
AUC: 0.8690

Epoch 22/80
 - 0s - loss: 0.7441 - val_loss: 0.4638
AUC: 0.8708

Epoch 23/80
 - 0s - loss: 0.7377 - val_loss: 0.4254
AUC: 0.8707

Epoch 24/80
 - 0s - loss: 0.7282 - val_loss: 0.4044
AUC: 0.8708

Epoch 25/80
 - 0s - loss: 0.7300 - val_loss: 0.4228
AUC: 0.8718

Epoch 26/80
 - 0s - loss: 0.7331 - val_loss: 0.5019
AUC: 0.8728

Epoch 27/80
 - 0s - loss: 0.7300 - val_loss: 0.4205
AUC: 0.8707

Epoch 28/80
 - 0s - loss: 0.7275 - val_loss: 0.4329
AUC: 0.8727

Epoch 29/80
 - 0s - loss: 0.7272 - val_loss: 0.4680
AUC: 0.8736

Epoch 30/80
 - 0s - loss: 0.7244 - val_loss: 0.3971
AUC: 0.8727

Epoch 31/80
 - 0s - loss: 0.7221 - val_loss: 0.4439
AUC: 0.8742

Epoch 32/80
 - 0s - loss: 0.7228 - val_loss: 0.3949
AUC: 0.8729

Epoch 33/80
 - 0s - loss: 0.7212 - val_loss: 0.4541
AUC: 0.8741

Epoch 34/80
 - 0s - loss: 0.7181 - val_loss: 0.4170
AUC: 0.8736

Epoch 35/80
 - 0s - loss: 0.7199 - val_loss: 0.4236
AUC: 0.8747

Epoch 36/80
 - 0s - loss: 0.7136 - val_loss: 0.4606
AUC: 0.8753

Epoch 37/80
 - 0s - loss: 0.7155 - val_loss: 0.4350
AUC: 0.8731

Epoch 38/80
 - 0s - loss: 0.7099 - val_loss: 0.4291
AUC: 0.8747

Epoch 39/80
 - 0s - loss: 0.7119 - val_loss: 0.4319
AUC: 0.8748

Epoch 40/80
 - 0s - loss: 0.7087 - val_loss: 0.4111
AUC: 0.8741

Epoch 41/80
 - 0s - loss: 0.7050 - val_loss: 0.4346
AUC: 0.8752

Epoch 42/80
 - 0s - loss: 0.7050 - val_loss: 0.4800
AUC: 0.8756

Epoch 43/80
 - 0s - loss: 0.7016 - val_loss: 0.4207
AUC: 0.8758

Epoch 44/80
 - 0s - loss: 0.6967 - val_loss: 0.4281
AUC: 0.8757

Epoch 45/80
 - 0s - loss: 0.6986 - val_loss: 0.4386
AUC: 0.8759

Epoch 46/80
 - 0s - loss: 0.6977 - val_loss: 0.4401
AUC: 0.8760

Epoch 47/80
 - 0s - loss: 0.7006 - val_loss: 0.4398
AUC: 0.8760

Epoch 48/80
 - 0s - loss: 0.6986 - val_loss: 0.4392
AUC: 0.8758

Epoch 49/80
 - 0s - loss: 0.6961 - val_loss: 0.4258
AUC: 0.8760

Epoch 50/80
 - 0s - loss: 0.6966 - val_loss: 0.4319
AUC: 0.8759

Epoch 51/80
 - 0s - loss: 0.6928 - val_loss: 0.4197
AUC: 0.8760

Epoch 52/80
 - 0s - loss: 0.6997 - val_loss: 0.4342
AUC: 0.8762

Epoch 53/80
 - 0s - loss: 0.6948 - val_loss: 0.4291
AUC: 0.8761

Epoch 54/80
 - 0s - loss: 0.6946 - val_loss: 0.4299
AUC: 0.8761

Epoch 55/80
 - 0s - loss: 0.6943 - val_loss: 0.4258
AUC: 0.8760

Epoch 56/80
 - 0s - loss: 0.6958 - val_loss: 0.4318
AUC: 0.8761

Epoch 57/80
 - 0s - loss: 0.6952 - val_loss: 0.4360
AUC: 0.8761

Epoch 58/80
 - 0s - loss: 0.6927 - val_loss: 0.4323
AUC: 0.8761

Epoch 59/80
 - 0s - loss: 0.6888 - val_loss: 0.4301
AUC: 0.8761

Epoch 60/80
 - 0s - loss: 0.6928 - val_loss: 0.4311
AUC: 0.8761

Epoch 61/80
 - 0s - loss: 0.6941 - val_loss: 0.4303
AUC: 0.8761

Epoch 62/80
 - 0s - loss: 0.6924 - val_loss: 0.4294
AUC: 0.8761

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.6940 - val_loss: 0.4319
AUC: 0.8762

Epoch 2/30
 - 0s - loss: 0.6972 - val_loss: 0.4260
AUC: 0.8762

Epoch 3/30
 - 0s - loss: 0.6933 - val_loss: 0.4232
AUC: 0.8762

Epoch 4/30
 - 0s - loss: 0.6901 - val_loss: 0.4304
AUC: 0.8763

Epoch 5/30
 - 0s - loss: 0.6912 - val_loss: 0.4279
AUC: 0.8764

Epoch 6/30
 - 0s - loss: 0.6903 - val_loss: 0.4218
AUC: 0.8763

Epoch 7/30
 - 0s - loss: 0.6871 - val_loss: 0.4275
AUC: 0.8764

Epoch 8/30
 - 0s - loss: 0.6895 - val_loss: 0.4213
AUC: 0.8765

Epoch 9/30
 - 0s - loss: 0.6880 - val_loss: 0.4313
AUC: 0.8767

Epoch 10/30
 - 0s - loss: 0.6899 - val_loss: 0.4179
AUC: 0.8766

Epoch 11/30
 - 0s - loss: 0.6884 - val_loss: 0.4316
AUC: 0.8768

Epoch 12/30
 - 0s - loss: 0.6847 - val_loss: 0.4333
AUC: 0.8769

Epoch 13/30
 - 0s - loss: 0.6876 - val_loss: 0.4307
AUC: 0.8769

Epoch 14/30
 - 0s - loss: 0.6804 - val_loss: 0.4345
AUC: 0.8770

Epoch 15/30
 - 0s - loss: 0.6835 - val_loss: 0.4234
AUC: 0.8771

Epoch 16/30
 - 0s - loss: 0.6827 - val_loss: 0.4266
AUC: 0.8772

Epoch 17/30
 - 0s - loss: 0.6825 - val_loss: 0.4313
AUC: 0.8773

Epoch 18/30
 - 0s - loss: 0.6804 - val_loss: 0.4153
AUC: 0.8773

Epoch 19/30
 - 0s - loss: 0.6814 - val_loss: 0.4278
AUC: 0.8773

Epoch 20/30
 - 0s - loss: 0.6798 - val_loss: 0.4177
AUC: 0.8773

Epoch 21/30
 - 0s - loss: 0.6752 - val_loss: 0.4335
AUC: 0.8776

Epoch 22/30
 - 0s - loss: 0.6801 - val_loss: 0.4262
AUC: 0.8776

Epoch 23/30
 - 0s - loss: 0.6753 - val_loss: 0.4334
AUC: 0.8777

Epoch 24/30
 - 0s - loss: 0.6763 - val_loss: 0.4157
AUC: 0.8775

Epoch 25/30
 - 0s - loss: 0.6749 - val_loss: 0.4196
AUC: 0.8777

Epoch 26/30
 - 0s - loss: 0.6730 - val_loss: 0.4127
AUC: 0.8776

Epoch 27/30
 - 0s - loss: 0.6751 - val_loss: 0.4179
AUC: 0.8777

Epoch 28/30
 - 0s - loss: 0.6747 - val_loss: 0.4325
AUC: 0.8779

Epoch 29/30
 - 0s - loss: 0.6769 - val_loss: 0.4206
AUC: 0.8778

Epoch 30/30
 - 0s - loss: 0.6778 - val_loss: 0.4240
Using TensorFlow backend.
AUC: 0.8780

2019-03-08 14:14:17.824787: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 14:14:17.987823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 14:14:17.987865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 14:14:18.276011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 14:14:18.276062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 14:14:18.276071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 14:14:18.276330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.5 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1617
Epoch 2/80
 - 1s - loss: 0.2161
Epoch 3/80
 - 1s - loss: 0.1632
Epoch 4/80
 - 1s - loss: 0.1473
Epoch 5/80
 - 1s - loss: 0.1365
Epoch 6/80
 - 1s - loss: 0.1282
Epoch 7/80
 - 1s - loss: 0.1213
Epoch 8/80
 - 1s - loss: 0.1155
Epoch 9/80
 - 1s - loss: 0.1104
Epoch 10/80
 - 1s - loss: 0.1053
Epoch 11/80
 - 2s - loss: 0.1000
Epoch 12/80
 - 1s - loss: 0.0943
Epoch 13/80
 - 1s - loss: 0.0885
Epoch 14/80
 - 1s - loss: 0.0830
Epoch 15/80
 - 1s - loss: 0.0782
Epoch 16/80
 - 1s - loss: 0.0742
Epoch 17/80
 - 1s - loss: 0.0707
Epoch 18/80
 - 1s - loss: 0.0677
Epoch 19/80
 - 1s - loss: 0.0652
Epoch 20/80
 - 1s - loss: 0.0631
Epoch 21/80
 - 1s - loss: 0.0613
Epoch 22/80
 - 1s - loss: 0.0598
Epoch 23/80
 - 1s - loss: 0.0585
Epoch 24/80
 - 1s - loss: 0.0575
Epoch 25/80
 - 1s - loss: 0.0566
Epoch 26/80
 - 1s - loss: 0.0559
Epoch 27/80
 - 1s - loss: 0.0552
Epoch 28/80
 - 1s - loss: 0.0547
Epoch 29/80
 - 1s - loss: 0.0542
Epoch 30/80
 - 1s - loss: 0.0538
Epoch 31/80
 - 1s - loss: 0.0534
Epoch 32/80
 - 1s - loss: 0.0531
Epoch 33/80
 - 1s - loss: 0.0528
Epoch 34/80
 - 1s - loss: 0.0526
Epoch 35/80
 - 1s - loss: 0.0524
Epoch 36/80
 - 1s - loss: 0.0521
Epoch 37/80
 - 1s - loss: 0.0520
Epoch 38/80
 - 1s - loss: 0.0518
Epoch 39/80
 - 1s - loss: 0.0517
Epoch 40/80
 - 1s - loss: 0.0516
Epoch 41/80
 - 1s - loss: 0.0514
Epoch 42/80
 - 1s - loss: 0.0513
Epoch 43/80
 - 1s - loss: 0.0512
Epoch 44/80
 - 1s - loss: 0.0512
Epoch 45/80
 - 2s - loss: 0.0511
Epoch 46/80
 - 2s - loss: 0.0510
Epoch 47/80
 - 2s - loss: 0.0509
Epoch 48/80
 - 1s - loss: 0.0509
Epoch 49/80
 - 1s - loss: 0.0508
Epoch 50/80
 - 1s - loss: 0.0507
Epoch 51/80
 - 1s - loss: 0.0507
Epoch 52/80
 - 1s - loss: 0.0506
Epoch 53/80
 - 1s - loss: 0.0506
Epoch 54/80
 - 1s - loss: 0.0505
Epoch 55/80
 - 1s - loss: 0.0505
Epoch 56/80
 - 1s - loss: 0.0505
Epoch 57/80
 - 1s - loss: 0.0504
Epoch 58/80
 - 1s - loss: 0.0504
Epoch 59/80
 - 1s - loss: 0.0504
Epoch 60/80
 - 1s - loss: 0.0503
Epoch 61/80
 - 1s - loss: 0.0503
Epoch 62/80
 - 1s - loss: 0.0503
Epoch 63/80
 - 1s - loss: 0.0503
Epoch 64/80
 - 1s - loss: 0.0492
Epoch 65/80
 - 1s - loss: 0.0490
Epoch 66/80
 - 1s - loss: 0.0490
Epoch 67/80
 - 1s - loss: 0.0490
Epoch 68/80
 - 1s - loss: 0.0490
Epoch 69/80
 - 1s - loss: 0.0487
Epoch 70/80
 - 1s - loss: 0.0487
Epoch 71/80
 - 1s - loss: 0.0487
Epoch 72/80
 - 1s - loss: 0.0487
Epoch 73/80
 - 1s - loss: 0.0486
Epoch 74/80
 - 1s - loss: 0.0486
Epoch 75/80
 - 1s - loss: 0.0486
Epoch 76/80
 - 1s - loss: 0.0486
Epoch 77/80
 - 1s - loss: 0.0486
Epoch 78/80
 - 1s - loss: 0.0486
Epoch 79/80
 - 1s - loss: 0.0486
Epoch 80/80
 - 1s - loss: 0.0486
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 1.6179 - val_loss: 1.0036
AUC: 0.4867

Epoch 2/80
 - 0s - loss: 1.2220 - val_loss: 0.7835
AUC: 0.6394

Epoch 3/80
 - 0s - loss: 0.9550 - val_loss: 0.5113
AUC: 0.7380

Epoch 4/80
 - 0s - loss: 0.7055 - val_loss: 0.4212
AUC: 0.7742

Epoch 5/80
 - 0s - loss: 0.5126 - val_loss: 0.3639
AUC: 0.7967

Epoch 6/80
 - 0s - loss: 0.4129 - val_loss: 0.3562
AUC: 0.8046

Epoch 7/80
 - 0s - loss: 0.3798 - val_loss: 0.3515
AUC: 0.8101

Epoch 8/80
 - 0s - loss: 0.3667 - val_loss: 0.3489
AUC: 0.8153

Epoch 9/80
 - 0s - loss: 0.3572 - val_loss: 0.3470
AUC: 0.8175

Epoch 10/80
 - 0s - loss: 0.3506 - val_loss: 0.3404
AUC: 0.8285

Epoch 11/80
 - 0s - loss: 0.3469 - val_loss: 0.3399
AUC: 0.8279

Epoch 12/80
 - 0s - loss: 0.3435 - val_loss: 0.3382
AUC: 0.8317

Epoch 13/80
 - 0s - loss: 0.3379 - val_loss: 0.3357
AUC: 0.8340

Epoch 14/80
 - 0s - loss: 0.3362 - val_loss: 0.3336
AUC: 0.8372

Epoch 15/80
 - 0s - loss: 0.3353 - val_loss: 0.3331
AUC: 0.8377

Epoch 16/80
 - 0s - loss: 0.3334 - val_loss: 0.3316
AUC: 0.8392

Epoch 17/80
 - 0s - loss: 0.3273 - val_loss: 0.3348
AUC: 0.8373

Epoch 18/80
 - 0s - loss: 0.3286 - val_loss: 0.3319
AUC: 0.8423

Epoch 19/80
 - 0s - loss: 0.3273 - val_loss: 0.3293
AUC: 0.8431

Epoch 20/80
 - 0s - loss: 0.3256 - val_loss: 0.3279
AUC: 0.8454

Epoch 21/80
 - 0s - loss: 0.3224 - val_loss: 0.3266
AUC: 0.8462

Epoch 22/80
 - 0s - loss: 0.3250 - val_loss: 0.3283
AUC: 0.8445

Epoch 23/80
 - 0s - loss: 0.3222 - val_loss: 0.3248
AUC: 0.8484

Epoch 24/80
 - 0s - loss: 0.3193 - val_loss: 0.3238
AUC: 0.8504

Epoch 25/80
 - 0s - loss: 0.3203 - val_loss: 0.3276
AUC: 0.8502

Epoch 26/80
 - 0s - loss: 0.3185 - val_loss: 0.3241
AUC: 0.8503

Epoch 27/80
 - 0s - loss: 0.3164 - val_loss: 0.3216
AUC: 0.8526

Epoch 28/80
 - 0s - loss: 0.3170 - val_loss: 0.3219
AUC: 0.8523

Epoch 29/80
 - 0s - loss: 0.3163 - val_loss: 0.3228
AUC: 0.8524

Epoch 30/80
 - 0s - loss: 0.3154 - val_loss: 0.3217
AUC: 0.8524

Epoch 31/80
 - 0s - loss: 0.3140 - val_loss: 0.3197
AUC: 0.8545

Epoch 32/80
 - 0s - loss: 0.3125 - val_loss: 0.3194
AUC: 0.8546

Epoch 33/80
 - 0s - loss: 0.3117 - val_loss: 0.3191
AUC: 0.8549

Epoch 34/80
 - 0s - loss: 0.3103 - val_loss: 0.3209
AUC: 0.8545

Epoch 35/80
 - 0s - loss: 0.3102 - val_loss: 0.3183
AUC: 0.8558

Epoch 36/80
 - 0s - loss: 0.3111 - val_loss: 0.3182
AUC: 0.8558

Epoch 37/80
 - 0s - loss: 0.3074 - val_loss: 0.3165
AUC: 0.8584

Epoch 38/80
 - 0s - loss: 0.3071 - val_loss: 0.3177
AUC: 0.8580

Epoch 39/80
 - 0s - loss: 0.3070 - val_loss: 0.3164
AUC: 0.8585

Epoch 40/80
 - 0s - loss: 0.3071 - val_loss: 0.3169
AUC: 0.8581

Epoch 41/80
 - 0s - loss: 0.3067 - val_loss: 0.3147
AUC: 0.8597

Epoch 42/80
 - 0s - loss: 0.3050 - val_loss: 0.3168
AUC: 0.8580

Epoch 43/80
 - 0s - loss: 0.3050 - val_loss: 0.3143
AUC: 0.8604

Epoch 44/80
 - 0s - loss: 0.3042 - val_loss: 0.3158
AUC: 0.8594

Epoch 45/80
 - 0s - loss: 0.3048 - val_loss: 0.3143
AUC: 0.8604

Epoch 46/80
 - 0s - loss: 0.3024 - val_loss: 0.3128
AUC: 0.8624

Epoch 47/80
 - 0s - loss: 0.3045 - val_loss: 0.3152
AUC: 0.8608

Epoch 48/80
 - 0s - loss: 0.3023 - val_loss: 0.3131
AUC: 0.8617

Epoch 49/80
 - 0s - loss: 0.3013 - val_loss: 0.3123
AUC: 0.8621

Epoch 50/80
 - 0s - loss: 0.3014 - val_loss: 0.3140
AUC: 0.8613

Epoch 51/80
 - 0s - loss: 0.3023 - val_loss: 0.3130
AUC: 0.8617

Epoch 52/80
 - 0s - loss: 0.3000 - val_loss: 0.3124
AUC: 0.8623

Epoch 53/80
 - 0s - loss: 0.3009 - val_loss: 0.3116
AUC: 0.8633

Epoch 54/80
 - 0s - loss: 0.2993 - val_loss: 0.3121
AUC: 0.8621

Epoch 55/80
 - 0s - loss: 0.2989 - val_loss: 0.3102
AUC: 0.8643

Epoch 56/80
 - 0s - loss: 0.2997 - val_loss: 0.3119
AUC: 0.8634

Epoch 57/80
 - 0s - loss: 0.2981 - val_loss: 0.3116
AUC: 0.8635

Epoch 58/80
 - 0s - loss: 0.2973 - val_loss: 0.3113
AUC: 0.8641

Epoch 59/80
 - 0s - loss: 0.2969 - val_loss: 0.3128
AUC: 0.8634

Epoch 60/80
 - 0s - loss: 0.2980 - val_loss: 0.3106
AUC: 0.8649

Epoch 61/80
 - 0s - loss: 0.2959 - val_loss: 0.3116
AUC: 0.8636

Epoch 62/80
 - 0s - loss: 0.2963 - val_loss: 0.3095
AUC: 0.8657

Epoch 63/80
 - 0s - loss: 0.2963 - val_loss: 0.3119
AUC: 0.8639

Epoch 64/80
 - 0s - loss: 0.2957 - val_loss: 0.3102
AUC: 0.8651

Epoch 65/80
 - 0s - loss: 0.2961 - val_loss: 0.3103
AUC: 0.8651

Epoch 66/80
 - 0s - loss: 0.2961 - val_loss: 0.3128
AUC: 0.8647

Epoch 67/80
 - 0s - loss: 0.2949 - val_loss: 0.3094
AUC: 0.8661

Epoch 68/80
 - 0s - loss: 0.2952 - val_loss: 0.3079
AUC: 0.8668

Epoch 69/80
 - 0s - loss: 0.2942 - val_loss: 0.3146
AUC: 0.8632

Epoch 70/80
 - 0s - loss: 0.2924 - val_loss: 0.3128
AUC: 0.8656

Epoch 71/80
 - 0s - loss: 0.2940 - val_loss: 0.3089
AUC: 0.8664

Epoch 72/80
 - 0s - loss: 0.2936 - val_loss: 0.3083
AUC: 0.8664

Epoch 73/80
 - 0s - loss: 0.2935 - val_loss: 0.3101
AUC: 0.8660

Epoch 74/80
 - 0s - loss: 0.2919 - val_loss: 0.3104
AUC: 0.8666

Epoch 75/80
 - 0s - loss: 0.2918 - val_loss: 0.3089
AUC: 0.8662

Epoch 76/80
 - 0s - loss: 0.2922 - val_loss: 0.3079
AUC: 0.8674

Epoch 77/80
 - 0s - loss: 0.2921 - val_loss: 0.3087
AUC: 0.8668

Epoch 78/80
 - 0s - loss: 0.2916 - val_loss: 0.3089
AUC: 0.8663

Epoch 79/80
 - 0s - loss: 0.2889 - val_loss: 0.3080
AUC: 0.8671

Epoch 80/80
 - 0s - loss: 0.2884 - val_loss: 0.3079
AUC: 0.8675

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 0.2878 - val_loss: 0.3074
AUC: 0.8678

Epoch 2/30
 - 0s - loss: 0.2882 - val_loss: 0.3077
AUC: 0.8678

Epoch 3/30
 - 0s - loss: 0.2875 - val_loss: 0.3074
AUC: 0.8679

Epoch 4/30
 - 0s - loss: 0.2868 - val_loss: 0.3070
AUC: 0.8682

Epoch 5/30
 - 0s - loss: 0.2876 - val_loss: 0.3072
AUC: 0.8680

Epoch 6/30
 - 0s - loss: 0.2854 - val_loss: 0.3072
AUC: 0.8682

Epoch 7/30
 - 0s - loss: 0.2857 - val_loss: 0.3072
AUC: 0.8682

Epoch 8/30
 - 0s - loss: 0.2864 - val_loss: 0.3077
AUC: 0.8684

Epoch 9/30
 - 0s - loss: 0.2848 - val_loss: 0.3069
AUC: 0.8686

Epoch 10/30
 - 0s - loss: 0.2846 - val_loss: 0.3071
AUC: 0.8685

Epoch 11/30
 - 0s - loss: 0.2845 - val_loss: 0.3070
AUC: 0.8686

Epoch 12/30
 - 0s - loss: 0.2838 - val_loss: 0.3078
AUC: 0.8686

Epoch 13/30
 - 0s - loss: 0.2834 - val_loss: 0.3077
AUC: 0.8684

Epoch 14/30
 - 0s - loss: 0.2833 - val_loss: 0.3068
AUC: 0.8688

Epoch 15/30
 - 0s - loss: 0.2843 - val_loss: 0.3069
AUC: 0.8687

Epoch 16/30
 - 0s - loss: 0.2826 - val_loss: 0.3070
AUC: 0.8688

Epoch 17/30
 - 0s - loss: 0.2831 - val_loss: 0.3071
AUC: 0.8689

Epoch 18/30
 - 0s - loss: 0.2831 - val_loss: 0.3064
AUC: 0.8691

Epoch 19/30
 - 0s - loss: 0.2836 - val_loss: 0.3064
AUC: 0.8692

Epoch 20/30
 - 0s - loss: 0.2823 - val_loss: 0.3064
AUC: 0.8692

Epoch 21/30
 - 0s - loss: 0.2811 - val_loss: 0.3066
AUC: 0.8692

Epoch 22/30
 - 0s - loss: 0.2810 - val_loss: 0.3061
AUC: 0.8696

Epoch 23/30
 - 0s - loss: 0.2823 - val_loss: 0.3066
AUC: 0.8695

Epoch 24/30
 - 0s - loss: 0.2819 - val_loss: 0.3080
AUC: 0.8693

Epoch 25/30
 - 0s - loss: 0.2801 - val_loss: 0.3063
AUC: 0.8696

Epoch 26/30
 - 0s - loss: 0.2819 - val_loss: 0.3068
AUC: 0.8696

Epoch 27/30
 - 0s - loss: 0.2812 - val_loss: 0.3064
AUC: 0.8698

Epoch 28/30
 - 0s - loss: 0.2790 - val_loss: 0.3062
AUC: 0.8699

Epoch 29/30
 - 0s - loss: 0.2802 - val_loss: 0.3061
AUC: 0.8698

Epoch 30/30
 - 0s - loss: 0.2801 - val_loss: 0.3062
Using TensorFlow backend.
AUC: 0.8699

2019-03-08 14:17:48.852685: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-08 14:17:49.012440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K40m major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-08 14:17:49.012483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-08 14:17:49.302457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-08 14:17:49.302507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-08 14:17:49.302516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-08 14:17:49.302770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0, compute capability: 3.5)
Updating co-occurrence matrix from a Dataframe with 35770 rows...
Finished. It takes 4.6 seconds to update the cooccurrences.
Preparing data...
Defining the GloVe model...
Training the GloVe model...
Epoch 1/80
 - 2s - loss: 1.1556
Epoch 2/80
 - 1s - loss: 0.2164
Epoch 3/80
 - 1s - loss: 0.1735
Epoch 4/80
 - 1s - loss: 0.1664
Epoch 5/80
 - 1s - loss: 0.1591
Epoch 6/80
 - 1s - loss: 0.1488
Epoch 7/80
 - 1s - loss: 0.1365
Epoch 8/80
 - 1s - loss: 0.1249
Epoch 9/80
 - 1s - loss: 0.1152
Epoch 10/80
 - 1s - loss: 0.1073
Epoch 11/80
 - 1s - loss: 0.1005
Epoch 12/80
 - 2s - loss: 0.0943
Epoch 13/80
 - 1s - loss: 0.0887
Epoch 14/80
 - 1s - loss: 0.0836
Epoch 15/80
 - 1s - loss: 0.0791
Epoch 16/80
 - 1s - loss: 0.0752
Epoch 17/80
 - 1s - loss: 0.0718
Epoch 18/80
 - 1s - loss: 0.0689
Epoch 19/80
 - 1s - loss: 0.0664
Epoch 20/80
 - 1s - loss: 0.0642
Epoch 21/80
 - 1s - loss: 0.0623
Epoch 22/80
 - 1s - loss: 0.0608
Epoch 23/80
 - 1s - loss: 0.0595
Epoch 24/80
 - 1s - loss: 0.0583
Epoch 25/80
 - 1s - loss: 0.0574
Epoch 26/80
 - 2s - loss: 0.0565
Epoch 27/80
 - 2s - loss: 0.0558
Epoch 28/80
 - 1s - loss: 0.0552
Epoch 29/80
 - 1s - loss: 0.0547
Epoch 30/80
 - 1s - loss: 0.0542
Epoch 31/80
 - 1s - loss: 0.0539
Epoch 32/80
 - 1s - loss: 0.0535
Epoch 33/80
 - 1s - loss: 0.0532
Epoch 34/80
 - 1s - loss: 0.0529
Epoch 35/80
 - 1s - loss: 0.0527
Epoch 36/80
 - 1s - loss: 0.0524
Epoch 37/80
 - 1s - loss: 0.0522
Epoch 38/80
 - 1s - loss: 0.0521
Epoch 39/80
 - 1s - loss: 0.0519
Epoch 40/80
 - 1s - loss: 0.0517
Epoch 41/80
 - 1s - loss: 0.0516
Epoch 42/80
 - 1s - loss: 0.0515
Epoch 43/80
 - 1s - loss: 0.0514
Epoch 44/80
 - 1s - loss: 0.0513
Epoch 45/80
 - 1s - loss: 0.0512
Epoch 46/80
 - 1s - loss: 0.0511
Epoch 47/80
 - 1s - loss: 0.0510
Epoch 48/80
 - 1s - loss: 0.0509
Epoch 49/80
 - 1s - loss: 0.0509
Epoch 50/80
 - 1s - loss: 0.0508
Epoch 51/80
 - 1s - loss: 0.0507
Epoch 52/80
 - 1s - loss: 0.0507
Epoch 53/80
 - 1s - loss: 0.0506
Epoch 54/80
 - 1s - loss: 0.0506
Epoch 55/80
 - 1s - loss: 0.0505
Epoch 56/80
 - 1s - loss: 0.0505
Epoch 57/80
 - 1s - loss: 0.0504
Epoch 58/80
 - 1s - loss: 0.0504
Epoch 59/80
 - 1s - loss: 0.0504
Epoch 60/80
 - 1s - loss: 0.0503
Epoch 61/80
 - 1s - loss: 0.0503
Epoch 62/80
 - 1s - loss: 0.0502
Epoch 63/80
 - 1s - loss: 0.0502
Epoch 64/80
 - 1s - loss: 0.0502
Epoch 65/80
 - 1s - loss: 0.0491
Epoch 66/80
 - 1s - loss: 0.0490
Epoch 67/80
 - 1s - loss: 0.0489
Epoch 68/80
 - 1s - loss: 0.0489
Epoch 69/80
 - 1s - loss: 0.0489
Epoch 70/80
 - 1s - loss: 0.0486
Epoch 71/80
 - 1s - loss: 0.0486
Epoch 72/80
 - 1s - loss: 0.0486
Epoch 73/80
 - 1s - loss: 0.0486
Epoch 74/80
 - 1s - loss: 0.0486
Epoch 75/80
 - 1s - loss: 0.0486
Epoch 76/80
 - 1s - loss: 0.0486
Epoch 77/80
 - 1s - loss: 0.0486
Epoch 78/80
 - 1s - loss: 0.0486
Epoch 79/80
 - 1s - loss: 0.0486
Epoch 80/80
 - 1s - loss: 0.0486
Finished. The pretrained embedding matrix can be retrieved by .get_embed_mat().
Train on 28616 samples, validate on 7154 samples
Epoch 1/80
 - 1s - loss: 6.4504 - val_loss: 2.8677
AUC: 0.7882

Epoch 2/80
 - 0s - loss: 4.4028 - val_loss: 1.8356
AUC: 0.8162

Epoch 3/80
 - 0s - loss: 2.9750 - val_loss: 1.2947
AUC: 0.8293

Epoch 4/80
 - 0s - loss: 1.9927 - val_loss: 0.8605
AUC: 0.8285

Epoch 5/80
 - 0s - loss: 1.5930 - val_loss: 0.8637
AUC: 0.8325

Epoch 6/80
 - 0s - loss: 1.4480 - val_loss: 0.8940
AUC: 0.8360

Epoch 7/80
 - 0s - loss: 1.3987 - val_loss: 0.8601
AUC: 0.8408

Epoch 8/80
 - 0s - loss: 1.3476 - val_loss: 0.8501
AUC: 0.8428

Epoch 9/80
 - 0s - loss: 1.3271 - val_loss: 0.8693
AUC: 0.8461

Epoch 10/80
 - 0s - loss: 1.3288 - val_loss: 0.8054
AUC: 0.8466

Epoch 11/80
 - 0s - loss: 1.2959 - val_loss: 0.7497
AUC: 0.8459

Epoch 12/80
 - 0s - loss: 1.2898 - val_loss: 0.7849
AUC: 0.8507

Epoch 13/80
 - 0s - loss: 1.2756 - val_loss: 0.8627
AUC: 0.8513

Epoch 14/80
 - 0s - loss: 1.2759 - val_loss: 0.7653
AUC: 0.8531

Epoch 15/80
 - 0s - loss: 1.2651 - val_loss: 0.7965
AUC: 0.8528

Epoch 16/80
 - 0s - loss: 1.2530 - val_loss: 0.8201
AUC: 0.8531

Epoch 17/80
 - 0s - loss: 1.2561 - val_loss: 0.8346
AUC: 0.8547

Epoch 18/80
 - 0s - loss: 1.2435 - val_loss: 0.8125
AUC: 0.8542

Epoch 19/80
 - 0s - loss: 1.2371 - val_loss: 0.8254
AUC: 0.8548

Epoch 20/80
 - 0s - loss: 1.2360 - val_loss: 0.7826
AUC: 0.8556

Epoch 21/80
 - 0s - loss: 1.2317 - val_loss: 0.7924
AUC: 0.8540

Epoch 22/80
 - 0s - loss: 1.2231 - val_loss: 0.7524
AUC: 0.8563

Epoch 23/80
 - 0s - loss: 1.2175 - val_loss: 0.7620
AUC: 0.8559

Epoch 24/80
 - 0s - loss: 1.2196 - val_loss: 0.7839
AUC: 0.8568

Epoch 25/80
 - 0s - loss: 1.2100 - val_loss: 0.7293
AUC: 0.8560

Epoch 26/80
 - 0s - loss: 1.2162 - val_loss: 0.7952
AUC: 0.8573

Epoch 27/80
 - 0s - loss: 1.2221 - val_loss: 0.8101
AUC: 0.8574

Epoch 28/80
 - 0s - loss: 1.2161 - val_loss: 0.7957
AUC: 0.8574

Epoch 29/80
 - 0s - loss: 1.2172 - val_loss: 0.7584
AUC: 0.8571

Epoch 30/80
 - 0s - loss: 1.2141 - val_loss: 0.7483
AUC: 0.8574

Epoch 31/80
 - 0s - loss: 1.2083 - val_loss: 0.7561
AUC: 0.8573

Epoch 32/80
 - 0s - loss: 1.2162 - val_loss: 0.7646
AUC: 0.8577

Epoch 33/80
 - 0s - loss: 1.2125 - val_loss: 0.7957
AUC: 0.8582

Epoch 34/80
 - 0s - loss: 1.2109 - val_loss: 0.7703
AUC: 0.8575

Epoch 35/80
 - 0s - loss: 1.2018 - val_loss: 0.7760
AUC: 0.8578

Epoch 36/80
 - 0s - loss: 1.2026 - val_loss: 0.7661
AUC: 0.8578

Epoch 37/80
 - 0s - loss: 1.2009 - val_loss: 0.7675
AUC: 0.8579

Epoch 38/80
 - 0s - loss: 1.2037 - val_loss: 0.7669
AUC: 0.8579

Epoch 39/80
 - 0s - loss: 1.1998 - val_loss: 0.7672
AUC: 0.8578

Epoch 40/80
 - 0s - loss: 1.2034 - val_loss: 0.7698
AUC: 0.8581

Epoch 41/80
 - 0s - loss: 1.2076 - val_loss: 0.7642
AUC: 0.8579

Epoch 42/80
 - 0s - loss: 1.2094 - val_loss: 0.7669
AUC: 0.8581

Epoch 43/80
 - 0s - loss: 1.2039 - val_loss: 0.7676
AUC: 0.8581

Epoch 44/80
 - 0s - loss: 1.2036 - val_loss: 0.7664
AUC: 0.8581

Epoch 45/80
 - 0s - loss: 1.2050 - val_loss: 0.7740
AUC: 0.8581

Epoch 46/80
 - 0s - loss: 1.2065 - val_loss: 0.7712
AUC: 0.8581

Epoch 47/80
 - 0s - loss: 1.2022 - val_loss: 0.7665
AUC: 0.8581

Epoch 48/80
 - 0s - loss: 1.2037 - val_loss: 0.7671
AUC: 0.8581

Epoch 49/80
 - 0s - loss: 1.2031 - val_loss: 0.7673
AUC: 0.8581

Epoch 50/80
 - 0s - loss: 1.2096 - val_loss: 0.7678
AUC: 0.8581

Epoch 51/80
 - 0s - loss: 1.2113 - val_loss: 0.7678
AUC: 0.8581

Epoch 52/80
 - 0s - loss: 1.2072 - val_loss: 0.7678
AUC: 0.8581

Epoch 53/80
 - 0s - loss: 1.2039 - val_loss: 0.7673
AUC: 0.8581

Epoch 54/80
 - 0s - loss: 1.2049 - val_loss: 0.7678
AUC: 0.8581

Epoch 55/80
 - 0s - loss: 1.2074 - val_loss: 0.7675
AUC: 0.8581

Train on 28616 samples, validate on 7154 samples
Epoch 1/30
 - 1s - loss: 1.2067 - val_loss: 0.7536
AUC: 0.8579

Epoch 2/30
 - 0s - loss: 1.2050 - val_loss: 0.7537
AUC: 0.8579

Epoch 3/30
 - 0s - loss: 1.1959 - val_loss: 0.7816
AUC: 0.8586

Epoch 4/30
 - 0s - loss: 1.2078 - val_loss: 0.7960
AUC: 0.8591

Epoch 5/30
 - 0s - loss: 1.1985 - val_loss: 0.7494
AUC: 0.8589

Epoch 6/30
 - 0s - loss: 1.1977 - val_loss: 0.7571
AUC: 0.8590

Epoch 7/30
 - 0s - loss: 1.2015 - val_loss: 0.7598
AUC: 0.8596

Epoch 8/30
 - 0s - loss: 1.1967 - val_loss: 0.7782
AUC: 0.8597

Epoch 9/30
 - 0s - loss: 1.1954 - val_loss: 0.7268
AUC: 0.8598

Epoch 10/30
 - 0s - loss: 1.1925 - val_loss: 0.7351
AUC: 0.8594

Epoch 11/30
 - 0s - loss: 1.1913 - val_loss: 0.7343
AUC: 0.8600

Epoch 12/30
 - 0s - loss: 1.1894 - val_loss: 0.7582
AUC: 0.8603

Epoch 13/30
 - 0s - loss: 1.1903 - val_loss: 0.7669
AUC: 0.8606

Epoch 14/30
 - 0s - loss: 1.1898 - val_loss: 0.7714
AUC: 0.8611

Epoch 15/30
 - 0s - loss: 1.1827 - val_loss: 0.7495
AUC: 0.8607

Epoch 16/30
 - 0s - loss: 1.1783 - val_loss: 0.7630
AUC: 0.8613

Epoch 17/30
 - 0s - loss: 1.1795 - val_loss: 0.7670
AUC: 0.8614

Epoch 18/30
 - 0s - loss: 1.1745 - val_loss: 0.7446
AUC: 0.8614

Epoch 19/30
 - 0s - loss: 1.1761 - val_loss: 0.7290
AUC: 0.8615

Epoch 20/30
 - 0s - loss: 1.1732 - val_loss: 0.7474
AUC: 0.8618

Epoch 21/30
 - 0s - loss: 1.1727 - val_loss: 0.7503
AUC: 0.8619

Epoch 22/30
 - 0s - loss: 1.1675 - val_loss: 0.7513
AUC: 0.8619

Epoch 23/30
 - 0s - loss: 1.1758 - val_loss: 0.7504
AUC: 0.8619

Epoch 24/30
 - 0s - loss: 1.1726 - val_loss: 0.7452
AUC: 0.8618

Epoch 25/30
 - 0s - loss: 1.1703 - val_loss: 0.7426
AUC: 0.8618

Epoch 26/30
 - 0s - loss: 1.1759 - val_loss: 0.7496
AUC: 0.8620

Epoch 27/30
 - 0s - loss: 1.1749 - val_loss: 0.7467
AUC: 0.8619

Epoch 28/30
 - 0s - loss: 1.1759 - val_loss: 0.7516
AUC: 0.8621

Epoch 29/30
 - 0s - loss: 1.1723 - val_loss: 0.7454
AUC: 0.8621

Epoch 30/30
 - 0s - loss: 1.1746 - val_loss: 0.7474
Using TensorFlow backend.
AUC: 0.8621

