{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "1730edf3-124d-4ee1-8cba-c6b768fcda02"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "b0dc1204-4fa1-4193-85b2-a7f98320cd85"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "829f67c2-c684-4b5e-ba7e-a7b3cfd9e61d"
    }
   },
   "outputs": [],
   "source": [
    "path = '/nfs/turbo/umms-awaljee/wsliu/Data/NRD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "d864e090-8ee0-4676-b1fa-740190e7a86c"
    }
   },
   "outputs": [],
   "source": [
    "module_path = '/home/wsliu/Codes/DLproj'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if module_path+'/NRD' not in sys.path:\n",
    "    sys.path.append(module_path+'/NRD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "79f706dc-412b-45b6-ad4e-8f00a384a1e5"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ccs_tools import core_dtypes_pd\n",
    "from utils import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bb532a32-9675-44f2-be9e-8b88677409d9"
    }
   },
   "source": [
    "## Prepare hyper-parameters and generate the .sh files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1a73999b-151b-4b79-a21f-e3dc20bd31f4"
    }
   },
   "source": [
    "For embedding+NN with a subset of codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "0c9d10e1-2f33-4208-9748-e8c7b7fc66a9"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm hypertune*.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "3fd6daa3-60ef-4da6-9d4a-d02782df6009"
    }
   },
   "outputs": [],
   "source": [
    "model_names = ['setsum_nn']\n",
    "code_embed_dims = [200]\n",
    "fc_widths = [512]\n",
    "md_widths = [128]\n",
    "lr1s = [2e-4]\n",
    "#lr2s = [2e-5]\n",
    "dropouts = [0.3]\n",
    "batchsizes = [128, 256, 512]\n",
    "embed_mats = ['random']\n",
    "#penalties = [0, 0.5, 1.]\n",
    "#penalty_metrics = ['cosine']\n",
    "#count_caps = [0, 5, 20]\n",
    "tst_seeds = [0]\n",
    "cohorts = ['ami']\n",
    "#DX_rarecutpoints = [20]\n",
    "#PR_rarecutpoints = [drp/2 for drp in DX_rarecutpoints]\n",
    "val_seeds = range(5)\n",
    "lambs = [15., 25.]\n",
    "n_sampless = [250, 350, 400]\n",
    "result_files = ['output/ht_result1212_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "764b3b19-fb4d-43ea-821a-2b3ddfd8cc88"
    }
   },
   "outputs": [],
   "source": [
    "para_itr = itertools.product(model_names, code_embed_dims, fc_widths, md_widths, lr1s, dropouts, batchsizes, embed_mats, \n",
    "                            tst_seeds, cohorts, val_seeds, lambs, n_sampless, result_files)\n",
    "para_lst = [(mn, ced, fc, md, l1, do, bs, em, ts, ch, vs, la, ns, rf) \n",
    "            for mn, ced, fc, md, l1, do, bs, em, ts, ch, vs, la, ns, rf in para_itr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "2f7c1f69-6229-41c7-958c-1481424acbe6"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "542d0a3e-3f5d-4d35-8401-7c157805ff32"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = 7\n",
    "for para, job_ind in zip(para_lst, itertools.cycle(range(n_jobs))):\n",
    "    with open('hypertune'+str(job_ind)+'.sh', 'a') as f:\n",
    "        f.write('python template_skipgram1209.py --model_name {} --code_embed_dim {} --fc_width {} --md_width {} --lr1 {} --dropout {} --batchsize {} --embed_file {} --tst_seed {} --cohort {} --val_seed {} --lamb {} --n_samples {} --result_file {} --job_index {}\\n'.format(*para, job_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "5eb07071-3e95-40af-b3e1-3029b4e13786"
    }
   },
   "outputs": [],
   "source": [
    "job_index = 10\n",
    "for para in para_lst[:1]:\n",
    "    with open('hypertune'+str(job_index)+'.sh', 'a') as f:\n",
    "        f.write('python template_skipgram1209.py --model_name {} --code_embed_dim {} --fc_width {} --md_width {} --lr1 {} --dropout {} --batchsize {} --embed_file {} --tst_seed {} --cohort {} --val_seed {} --lamb {} --n_samples {} --result_file {} --job_index {}\\n'.format(*para, job_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "47fa3e6c-b03c-4971-90f0-3d46a2f661f9"
    }
   },
   "source": [
    "Random search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "5c0ba0c8-2e08-4d8b-9c25-9b608d0a3daf"
    }
   },
   "outputs": [],
   "source": [
    "n_sample = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "8ff84363-66eb-47be-aec3-b381ada67025"
    }
   },
   "outputs": [],
   "source": [
    "model_names = np.random.choice(['setsum_nn'], n_sample)\n",
    "code_embed_dims = np.random.choice([200, 300], n_sample)\n",
    "fc_widths = np.random.choice([512, 1024], n_sample)\n",
    "md_widths = np.random.choice([128, 256], n_sample)\n",
    "lr1s = np.random.choice([2e-4], n_sample)\n",
    "lr2s = np.random.choice([2e-5], n_sample)\n",
    "dropouts = np.random.choice([0.3], n_sample)\n",
    "batchsizes = np.random.choice([256, 512], n_sample)\n",
    "embed_mats = np.random.choice(['pretrain'], n_sample)\n",
    "penalties = np.random.choice([0, 0.5, 1.], n_sample)\n",
    "penalty_metrics = np.random.choice(['cosine'], n_sample)\n",
    "count_caps = np.random.choice([0, 5, 20], n_sample)\n",
    "cohorts = np.random.choice(['ami'], n_sample)\n",
    "DX_rarecutpoints = np.random.choice([20], n_sample)\n",
    "PR_rarecutpoints = [int(drp/2) for drp in DX_rarecutpoints]\n",
    "val_folds = np.random.choice([5], n_sample)\n",
    "result_files = ['output/ht_result1001_{}.csv']*n_sample\n",
    "\n",
    "zips = zip(model_names, code_embed_dims, fc_widths, md_widths, lr1s, lr2s, dropouts, batchsizes, embed_mats, \n",
    "                             penalties, penalty_metrics, count_caps, cohorts, DX_rarecutpoints, PR_rarecutpoints,\n",
    "                             val_folds, result_files)\n",
    "tst_seeds = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "adc5db58-bd8c-4fcc-95f6-94028103a117"
    }
   },
   "outputs": [],
   "source": [
    "para_itr = itertools.product(zips, tst_seeds)\n",
    "\n",
    "para_lst = [(*z, t) for z, t in para_itr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "7bbdde24-710d-4a30-9536-e25f6fb42574"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "82beda51-3287-4318-8d8d-d771e2d1fdd0"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = 4\n",
    "for para, job_ind in zip(para_lst, itertools.cycle(range(n_jobs))):\n",
    "    with open('hypertune'+str(job_ind)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_sub0922.py --model_name {0} --code_embed_dim {1} --fc_width {2} --md_width {3} --lr1 {4} --lr2 {5} --dropout {6} --batchsize {7} --embed_file {8} --penalty {9} --penalty_metric {10} --count_cap {11} --cohort {12} --dx_rarecutpoint {13} --pr_rarecutpoint {14} --val_fold {15} --result_file {16} --tst_seed {17} --job_index {18}\\n'.format(*para, job_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ce09c5e0-d56f-412c-9b2d-4ded9659036b"
    }
   },
   "source": [
    "For OHE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "faf5c473-5ddd-4307-9ea5-40c8898b6415"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm hypertune*.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f33391f1-40be-4d91-a45a-4bf869fbc8a5"
    }
   },
   "outputs": [],
   "source": [
    "fc_width1s = [1024]\n",
    "fc_width2s = [256]\n",
    "lrs = [1e-4]\n",
    "dropouts = [0.3]\n",
    "batchsizes = [512]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami', 'chf', 'pna']\n",
    "val_folds = [5]\n",
    "dx_rarecutpoints = [10]\n",
    "pr_rarecutpoints = [10]\n",
    "result_files = ['output/ht_result0925_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "2a13a665-c5b2-4203-ad1e-fa8cae629590"
    }
   },
   "outputs": [],
   "source": [
    "para_itr = itertools.product(fc_width1s, fc_width2s, lrs, dropouts, batchsizes, tst_seeds, cohorts, val_folds, \n",
    "                             dx_rarecutpoints, pr_rarecutpoints, result_files)\n",
    "\n",
    "para_lst = list(para_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "ca11da94-e028-4ec8-9140-0b43a10e3863"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "7054c303-c50b-4db8-b6f5-b184ac7a2e81"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "for para, job_ind in zip(para_lst, itertools.cycle(range(n_jobs))):\n",
    "    with open('hypertune'+str(job_ind)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_ohe0925.py --fc_width1 {} --fc_width2 {} --lr {} --dropout {} --batchsize {} --tst_seed {} --cohort {} --val_fold {} --dx_rarecutpoint {} --pr_rarecutpoint {} --result_file {} --job_index {}\\n'.format(*para, job_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "nbpresent": {
     "id": "fc12af30-b824-4f41-87f6-30ce34e93f55"
    }
   },
   "outputs": [],
   "source": [
    "job_index = 5\n",
    "for para in para_lst:\n",
    "    with open('hypertune'+str(job_index)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_all0827.py --model_name {0} --code_embed_dim {1} --fc_width {2} --md_width {3} --lr1 {4} --lr2 {5} --dropout {6} --batchsize {7} --embed_file {8} --tst_seed {9} --cohort {10} --sep_dx1 {11} --val_fold {12} --result_file {13} --job_index {14}\\n'.format(*para, job_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fbf216da-ad10-433f-89f4-aced0366589e"
    }
   },
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1efdd259-994a-47b6-abdc-9e208ea12f30"
    }
   },
   "source": [
    "### Embedding + NN with all codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "a37028a6-72f9-4dbf-a1f2-cf76d21fa9f8"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "72416bfe-ad5e-40e6-88e1-61aeefd7abc7"
    }
   },
   "outputs": [],
   "source": [
    "for job_ind in range(8):\n",
    "    df = pd.read_csv('output/ht_result1212_'+str(job_ind)+'.csv', \n",
    "                     names=['model_name', 'code_embed_dim', 'hosp_embed_dim', 'fc_width', 'md_width', 'lr1', 'dropout',\n",
    "                            'batchsize', 'embed_file', 'cohort', 'tst_seed', 'val_seed', 'lamb', 'n_sample', 'auc', 'y_pred_file'], index_col=None)\n",
    "    res = pd.concat([res, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "88ca5907-9e79-44a0-8730-68372f180dc5"
    }
   },
   "outputs": [],
   "source": [
    "res = res.assign(cohort_seed=res.cohort+res.tst_seed.apply(lambda x:str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "82e12be0-cda6-410b-b937-4582a09de86c"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>hosp_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>lr1</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>embed_file</th>\n",
       "      <th>cohort</th>\n",
       "      <th>tst_seed</th>\n",
       "      <th>val_seed</th>\n",
       "      <th>lamb</th>\n",
       "      <th>n_sample</th>\n",
       "      <th>auc</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70881</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71091</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71304</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71155</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71072</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71304</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70965</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71133</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70999</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71033</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71283</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70933</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71226</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70962</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71005</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71324</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70775</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70953</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71085</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71105</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71255</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70793</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71045</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71094</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71138</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71298</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70767</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70945</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70962</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71331</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70788</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70986</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71002</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71076</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70942</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71219</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70967</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71230</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70975</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71302</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70985</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71210</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71306</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71186</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71245</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70913</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71033</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71097</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70896</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1024</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.70933</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>random</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.71141</td>\n",
       "      <td>/nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  code_embed_dim  hosp_embed_dim  fc_width  md_width     lr1  \\\n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0002   \n",
       "3  setsum_nn             200               1       512       128  0.0002   \n",
       "4  setsum_nn             200               1       512       128  0.0005   \n",
       "5  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0002   \n",
       "3  setsum_nn             200               1       512       128  0.0002   \n",
       "4  setsum_nn             200               1       512       128  0.0005   \n",
       "5  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0002   \n",
       "3  setsum_nn             200               1       512       128  0.0002   \n",
       "4  setsum_nn             200               1       512       128  0.0005   \n",
       "5  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0002   \n",
       "3  setsum_nn             200               1       512       128  0.0002   \n",
       "4  setsum_nn             200               1       512       128  0.0005   \n",
       "5  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0002   \n",
       "3  setsum_nn             200               1       512       128  0.0002   \n",
       "4  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0002   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0002   \n",
       "2  setsum_nn             200               1       512       128  0.0005   \n",
       "3  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0001   \n",
       "3  setsum_nn             200               1       512       128  0.0001   \n",
       "4  setsum_nn             200               1       512       128  0.0002   \n",
       "5  setsum_nn             200               1       512       128  0.0005   \n",
       "6  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0001   \n",
       "2  setsum_nn             200               1       512       128  0.0002   \n",
       "3  setsum_nn             200               1       512       128  0.0002   \n",
       "4  setsum_nn             200               1       512       128  0.0005   \n",
       "5  setsum_nn             200               1       512       128  0.0005   \n",
       "0  setsum_nn             200               1       512       128  0.0001   \n",
       "1  setsum_nn             200               1       512       128  0.0002   \n",
       "\n",
       "   dropout  batchsize embed_file cohort  tst_seed  val_seed  lamb  n_sample  \\\n",
       "0      0.3        512     random    ami         0         0   0.2       100   \n",
       "1      0.3       1024     random    ami         0         0   1.0       100   \n",
       "2      0.3        512     random    ami         0         0  10.0       100   \n",
       "3      0.3       1024     random    ami         0         1   0.2       100   \n",
       "4      0.3        512     random    ami         0         1   1.0       100   \n",
       "5      0.3       1024     random    ami         0         1  10.0       100   \n",
       "0      0.3        512     random    ami         0         0   1.0       100   \n",
       "1      0.3       1024     random    ami         0         0  10.0       100   \n",
       "2      0.3        512     random    ami         0         1   0.2       100   \n",
       "3      0.3       1024     random    ami         0         1   1.0       100   \n",
       "4      0.3        512     random    ami         0         1  10.0       100   \n",
       "5      0.3       1024     random    ami         0         2   0.2       100   \n",
       "0      0.3        512     random    ami         0         0  10.0       100   \n",
       "1      0.3       1024     random    ami         0         1   0.2       100   \n",
       "2      0.3        512     random    ami         0         1   1.0       100   \n",
       "3      0.3       1024     random    ami         0         1  10.0       100   \n",
       "4      0.3        512     random    ami         0         2   0.2       100   \n",
       "5      0.3       1024     random    ami         0         2   1.0       100   \n",
       "0      0.3        512     random    ami         0         1   0.2       100   \n",
       "1      0.3       1024     random    ami         0         1   1.0       100   \n",
       "2      0.3        512     random    ami         0         1  10.0       100   \n",
       "3      0.3       1024     random    ami         0         2   0.2       100   \n",
       "4      0.3        512     random    ami         0         2   1.0       100   \n",
       "5      0.3       1024     random    ami         0         2  10.0       100   \n",
       "0      0.3        512     random    ami         0         1   1.0       100   \n",
       "1      0.3       1024     random    ami         0         1  10.0       100   \n",
       "2      0.3        512     random    ami         0         2   0.2       100   \n",
       "3      0.3       1024     random    ami         0         2   1.0       100   \n",
       "4      0.3        512     random    ami         0         2  10.0       100   \n",
       "0      0.3        512     random    ami         0         1  10.0       100   \n",
       "1      0.3       1024     random    ami         0         2   0.2       100   \n",
       "2      0.3        512     random    ami         0         2   1.0       100   \n",
       "0      0.3       1024     random    ami         0         2   1.0       100   \n",
       "1      0.3        512     random    ami         0         2  10.0       100   \n",
       "2      0.3        512     random    ami         0         0   0.2       100   \n",
       "3      0.3       1024     random    ami         0         0   1.0       100   \n",
       "0      0.3        512     random    ami         0         2   1.0       100   \n",
       "1      0.3       1024     random    ami         0         2  10.0       100   \n",
       "2      0.3        512     random    ami         0         2   1.0       100   \n",
       "3      0.3       1024     random    ami         0         2  10.0       100   \n",
       "4      0.3       1024     random    ami         0         0   0.2       100   \n",
       "5      0.3        512     random    ami         0         0   1.0       100   \n",
       "6      0.3       1024     random    ami         0         0  10.0       100   \n",
       "0      0.3        512     random    ami         0         2  10.0       100   \n",
       "1      0.3        512     random    ami         0         2  10.0       100   \n",
       "2      0.3        512     random    ami         0         0   0.2       100   \n",
       "3      0.3       1024     random    ami         0         0   1.0       100   \n",
       "4      0.3        512     random    ami         0         0  10.0       100   \n",
       "5      0.3       1024     random    ami         0         1   0.2       100   \n",
       "0      0.3       1024     random    ami         0         0   0.2       100   \n",
       "1      0.3        512     random    ami         0         0   1.0       100   \n",
       "\n",
       "       auc                                        y_pred_file  \n",
       "0  0.70881  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71091  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.71304  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.71155  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "4  0.71072  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "5  0.71304  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.70965  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71133  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.70999  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.71033  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "4  0.71283  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "5  0.70933  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.71226  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.70962  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.71005  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.71324  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "4  0.70775  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "5  0.70953  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.71085  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71105  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.71255  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.70793  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "4  0.71045  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "5  0.71094  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.71138  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71298  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.70767  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.70945  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "4  0.70962  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.71331  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.70788  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.70986  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.71002  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71076  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.70942  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.71219  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.70967  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71230  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.70975  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.71302  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "4  0.70985  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "5  0.71210  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "6  0.71306  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.71186  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71245  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "2  0.70913  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "3  0.71033  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "4  0.71097  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "5  0.70896  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "0  0.70933  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  \n",
       "1  0.71141  /nfs/turbo/umms-awaljee/wsliu/Data/NRD/preproc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "05efd8ab-48df-47c9-a2d4-9c5fb5c584a3"
    }
   },
   "outputs": [],
   "source": [
    "res_grouped = res.groupby(['n_sample', 'lamb', 'batchsize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2de5ff07-d84f-4969-ba32-acdd456f8503"
    }
   },
   "source": [
    "The two-step training with GloVe can get auc_freeze 0.7158, and auc_finetune 0.7167, auc_avg 0.7196 on tst_seed 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "b32c59fc-84c5-4cf0-b0f7-80a637ffa5b9"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show = res_grouped['auc'].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sample</th>\n",
       "      <th>lamb</th>\n",
       "      <th>batchsize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <th>25.0</th>\n",
       "      <th>256</th>\n",
       "      <td>0.713110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">300</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">20.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.712996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.713332</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">50.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.711488</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.711418</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">350</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">15.0</th>\n",
       "      <th>128</th>\n",
       "      <td>0.712740</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.712578</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">25.0</th>\n",
       "      <th>128</th>\n",
       "      <td>0.712913</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.712590</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.711700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">400</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">15.0</th>\n",
       "      <th>128</th>\n",
       "      <td>0.712320</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.712157</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">25.0</th>\n",
       "      <th>128</th>\n",
       "      <td>0.712430</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.712103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">500</th>\n",
       "      <th>5.0</th>\n",
       "      <th>512</th>\n",
       "      <td>0.711788</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>512</th>\n",
       "      <td>0.712476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <th>512</th>\n",
       "      <td>0.712376</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">800</th>\n",
       "      <th>20.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.712190</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.711565</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean  count\n",
       "n_sample lamb batchsize                 \n",
       "250      25.0 256        0.713110      4\n",
       "300      20.0 16         0.712996      5\n",
       "              512        0.713332      5\n",
       "         50.0 16         0.711488      5\n",
       "              512        0.711418      5\n",
       "350      15.0 128        0.712740      5\n",
       "              256        0.712578      4\n",
       "         25.0 128        0.712913      6\n",
       "              256        0.712590      4\n",
       "              512        0.711700      1\n",
       "400      15.0 128        0.712320      6\n",
       "              256        0.712157      4\n",
       "         25.0 128        0.712430      6\n",
       "              256        0.712103      3\n",
       "500      5.0  512        0.711788      5\n",
       "         10.0 512        0.712476      5\n",
       "         30.0 512        0.712376      5\n",
       "800      20.0 16         0.712190      5\n",
       "         50.0 16         0.711565      4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show.iloc[19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbpresent": {
     "id": "e27530a0-ecec-4cdf-914d-b0bf8bd6b259"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv('output/ht_result1210.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "2a458225-d28f-422f-a7b4-be93238d15fb"
    }
   },
   "outputs": [],
   "source": [
    "for _, g in res_grouped:\n",
    "    if g.auc_avg.mean() == res_grouped.auc_avg.mean().max():\n",
    "        best = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "3e7206d9-4573-41c8-ac6d-d36250376f54"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami freeze: 0.7193 (0.0017) mean: 0.7202 (0.0017) avg: 0.7222 (0.0017)\n",
      "chf freeze: 0.6298 (0.0015) mean: 0.6309 (0.0015) avg: 0.6337 (0.0015)\n",
      "pna freeze: 0.6748 (0.0011) mean: 0.6758 (0.0011) avg: 0.6782 (0.0011)\n"
     ]
    }
   ],
   "source": [
    "for n, g in res_grouped:\n",
    "    print(n, 'freeze: {0:.4f} ({1:.4f})'.format(g.auc_freeze.mean(), g.auc_freeze.std()/np.sqrt(len(g))), \n",
    "         'mean: {0:.4f} ({1:.4f})'.format(g.auc_mean.mean(), g.auc_mean.std()/np.sqrt(len(g))), \n",
    "         'avg: {0:.4f} ({1:.4f})'.format(g.auc_avg.mean(), g.auc_avg.std()/np.sqrt(len(g))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "c7cafea2-c86b-4bc9-b689-607f9ffd49ff"
    }
   },
   "outputs": [],
   "source": [
    "res2 = pd.read_csv('output/ht_result0928embed_nn_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "001585b4-d21e-414a-adcd-c60a95028452"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>hosp_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>embed_file</th>\n",
       "      <th>...</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>penalty</th>\n",
       "      <th>penalty_metric</th>\n",
       "      <th>count_cap</th>\n",
       "      <th>DX_rarecutpoint</th>\n",
       "      <th>PR_rarecutpoint</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_avg</th>\n",
       "      <th>auc_freeze</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.71652</td>\n",
       "      <td>0.71957</td>\n",
       "      <td>0.71607</td>\n",
       "      <td>output/y_pred_mat18_09_29_07_12_53.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  code_embed_dim  hosp_embed_dim  fc_width  md_width     lr1  \\\n",
       "60     setsum             100               1       512       128  0.0002   \n",
       "\n",
       "        lr2  dropout  batchsize embed_file  \\\n",
       "60  0.00002      0.3        256   pretrain   \n",
       "\n",
       "                     ...                   n_fold  penalty  penalty_metric  \\\n",
       "60                   ...                        3      0.0          cosine   \n",
       "\n",
       "    count_cap DX_rarecutpoint  PR_rarecutpoint  auc_mean  auc_avg  auc_freeze  \\\n",
       "60          5              10                5   0.71652  0.71957     0.71607   \n",
       "\n",
       "                               y_pred_file  \n",
       "60  output/y_pred_mat18_09_29_07_12_53.npy  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.loc[(res2.tst_seed==0) & (res2.DX_rarecutpoint==10)&(res2.PR_rarecutpoint==5)&(res2.count_cap==5)&(res2.penalty==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "00191c48-faea-45da-9bd1-bebe5d0e4a8c"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_freeze</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DX_rarecutpoint</th>\n",
       "      <th>PR_rarecutpoint</th>\n",
       "      <th>penalty</th>\n",
       "      <th>count_cap</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th>5</th>\n",
       "      <td>0.715840</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716669</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719623</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716013</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716834</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719555</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.716204</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717220</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719924</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716347</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717014</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719814</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716614</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717380</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.715653</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719622</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716738</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717823</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720226</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.715693</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717198</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.713752</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716295</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718870</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716178</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716827</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719707</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719845</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.716341</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719983</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716484</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720182</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716781</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717785</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720346</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.715583</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719747</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>5</th>\n",
       "      <td>0.717004</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717891</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720442</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.715679</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717447</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.713264</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716171</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718844</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">20</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th>5</th>\n",
       "      <td>0.715458</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716425</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719319</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716405</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717102</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719945</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.715954</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716995</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719687</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716243</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717028</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719784</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716810</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717486</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720101</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.715678</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719783</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>5</th>\n",
       "      <td>0.717149</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717726</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720274</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.715645</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716895</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719519</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.713778</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716195</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718950</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">50</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">25</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th>5</th>\n",
       "      <td>0.715594</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716224</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719140</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716259</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716838</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719612</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.715740</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716887</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719505</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716586</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717316</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720106</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.716924</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717645</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.716282</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717310</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719817</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716803</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717615</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720216</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.715631</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717093</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.713750</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716029</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718732</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  auc_freeze        auc_mean  \\\n",
       "                                                        mean count      mean   \n",
       "DX_rarecutpoint PR_rarecutpoint penalty count_cap                              \n",
       "0               0               0.0     5           0.715840    10  0.716669   \n",
       "                                        100         0.716013    10  0.716834   \n",
       "                                        500         0.716204    10  0.717220   \n",
       "                                0.1     5           0.716347    10  0.717014   \n",
       "                                        100         0.716614    10  0.717380   \n",
       "                                        500         0.715653    10  0.717059   \n",
       "                                0.5     5           0.716738    10  0.717823   \n",
       "                                        100         0.715693    10  0.717198   \n",
       "                                        500         0.713752    10  0.716295   \n",
       "10              5               0.0     5           0.716178    10  0.716827   \n",
       "                                        100         0.716100    10  0.717042   \n",
       "                                        500         0.716341    10  0.717224   \n",
       "                                0.1     5           0.716484    10  0.717391   \n",
       "                                        100         0.716781    10  0.717785   \n",
       "                                        500         0.715583    10  0.717200   \n",
       "                                0.5     5           0.717004    10  0.717891   \n",
       "                                        100         0.715679    10  0.717447   \n",
       "                                        500         0.713264    10  0.716171   \n",
       "20              10              0.0     5           0.715458    10  0.716425   \n",
       "                                        100         0.716405    10  0.717102   \n",
       "                                        500         0.715954    10  0.716995   \n",
       "                                0.1     5           0.716243    10  0.717028   \n",
       "                                        100         0.716810    10  0.717486   \n",
       "                                        500         0.715678    10  0.717134   \n",
       "                                0.5     5           0.717149    10  0.717726   \n",
       "                                        100         0.715645    10  0.716895   \n",
       "                                        500         0.713778    10  0.716195   \n",
       "50              25              0.0     5           0.715594    10  0.716224   \n",
       "                                        100         0.716259    10  0.716838   \n",
       "                                        500         0.715740    10  0.716887   \n",
       "                                0.1     5           0.716586    10  0.717316   \n",
       "                                        100         0.716924    10  0.717645   \n",
       "                                        500         0.716282    10  0.717310   \n",
       "                                0.5     5           0.716803    10  0.717615   \n",
       "                                        100         0.715631    10  0.717093   \n",
       "                                        500         0.713750    10  0.716029   \n",
       "\n",
       "                                                          auc_avg        \n",
       "                                                  count      mean count  \n",
       "DX_rarecutpoint PR_rarecutpoint penalty count_cap                        \n",
       "0               0               0.0     5            10  0.719623    10  \n",
       "                                        100          10  0.719555    10  \n",
       "                                        500          10  0.719924    10  \n",
       "                                0.1     5            10  0.719814    10  \n",
       "                                        100          10  0.719987    10  \n",
       "                                        500          10  0.719622    10  \n",
       "                                0.5     5            10  0.720226    10  \n",
       "                                        100          10  0.719665    10  \n",
       "                                        500          10  0.718870    10  \n",
       "10              5               0.0     5            10  0.719707    10  \n",
       "                                        100          10  0.719845    10  \n",
       "                                        500          10  0.719983    10  \n",
       "                                0.1     5            10  0.720182    10  \n",
       "                                        100          10  0.720346    10  \n",
       "                                        500          10  0.719747    10  \n",
       "                                0.5     5            10  0.720442    10  \n",
       "                                        100          10  0.719940    10  \n",
       "                                        500          10  0.718844    10  \n",
       "20              10              0.0     5            10  0.719319    10  \n",
       "                                        100          10  0.719945    10  \n",
       "                                        500          10  0.719687    10  \n",
       "                                0.1     5            10  0.719784    10  \n",
       "                                        100          10  0.720101    10  \n",
       "                                        500          10  0.719783    10  \n",
       "                                0.5     5            10  0.720274    10  \n",
       "                                        100          10  0.719519    10  \n",
       "                                        500          10  0.718950    10  \n",
       "50              25              0.0     5            10  0.719140    10  \n",
       "                                        100          10  0.719612    10  \n",
       "                                        500          10  0.719505    10  \n",
       "                                0.1     5            10  0.720106    10  \n",
       "                                        100          10  0.720215    10  \n",
       "                                        500          10  0.719817    10  \n",
       "                                0.5     5            10  0.720216    10  \n",
       "                                        100          10  0.719527    10  \n",
       "                                        500          10  0.718732    10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.groupby(['DX_rarecutpoint', 'PR_rarecutpoint', 'penalty', 'count_cap'])[['auc_freeze', 'auc_mean', 'auc_avg']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "90e28005-8fd0-462a-840e-952635f7d1b3"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv('output/ht_result1009penalty0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "1c8c9527-69b3-476d-bb84-843b716b8edf"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.concat([res, res2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "nbpresent": {
     "id": "28d27d2b-72be-4569-81f9-8025eed4beda"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b822428b978>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.plot.scatter('penalty', 'auc_avg', xlim=(0, 1), ylim=(0.725, 0.733))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nbpresent": {
     "id": "2cc85f9d-34ff-4106-b57f-bb22be701651"
    }
   },
   "outputs": [],
   "source": [
    "res = res.loc[res.md_width>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "6aa00d90-08d9-4347-960f-e3a7bc3bd79b"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ab55625ef28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.plot.scatter('fc_width', 'auc_mean', ylim=(0.71, 0.735))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbpresent": {
     "id": "a33f0fa4-4b4c-40b8-be09-d6d5bcd57434"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b5a2a76bf28>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.plot.scatter('batchsize', 'auc_mean', ylim=(0.72, 0.73))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbpresent": {
     "id": "5e0d5922-0b71-448d-8b30-6ede7b81658b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_file</th>\n",
       "      <th>y_pred_file</th>\n",
       "      <th>auc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all/embed_mat_pen6e-7.npy</td>\n",
       "      <td>output/y_pred_mat18_08_30_01_34_24.npy</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all/embed_mat_pen9e-7.npy</td>\n",
       "      <td>output/y_pred_mat18_08_30_03_43_48.npy</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  embed_file                             y_pred_file  auc_mean\n",
       "5  all/embed_mat_pen6e-7.npy  output/y_pred_mat18_08_30_01_34_24.npy    0.7282\n",
       "8  all/embed_mat_pen9e-7.npy  output/y_pred_mat18_08_30_03_43_48.npy    0.7282"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res.auc_mean==res.auc_mean.max(), ['embed_file', 'y_pred_file', 'auc_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "nbpresent": {
     "id": "f0741411-58a2-438c-81b8-0436fe447884"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>hosp_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>embed_file</th>\n",
       "      <th>data_file</th>\n",
       "      <th>sep_dx1</th>\n",
       "      <th>tst_seed</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_cil</th>\n",
       "      <th>auc_cih</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7275</td>\n",
       "      <td>0.7298)</td>\n",
       "      <td>output/y_pred_mat18_08_30_11_48_48.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7278</td>\n",
       "      <td>0.7295)</td>\n",
       "      <td>output/y_pred_mat18_08_30_06_42_42.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>(0.7275</td>\n",
       "      <td>0.7300)</td>\n",
       "      <td>output/y_pred_mat18_08_30_11_59_33.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7271</td>\n",
       "      <td>0.7301)</td>\n",
       "      <td>output/y_pred_mat18_08_30_08_38_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7278</td>\n",
       "      <td>0.7294)</td>\n",
       "      <td>output/y_pred_mat18_08_30_12_04_01.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  code_embed_dim  hosp_embed_dim  fc_width  md_width     lr1  \\\n",
       "26     setsum             100               1       128       128  0.0002   \n",
       "35     setsum             100               1       128       256  0.0002   \n",
       "24     setsum             100               1       128       128  0.0002   \n",
       "34     setsum             100               1       128       256  0.0002   \n",
       "27     setsum             100               1       128       128  0.0002   \n",
       "\n",
       "        lr2  dropout  batchsize                    embed_file  \\\n",
       "26  0.00002      0.1        128  all/embed_mat_pen_2_1e-6.npy   \n",
       "35  0.00005      0.3        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "24  0.00001      0.1        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "34  0.00005      0.1        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "27  0.00002      0.5        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "\n",
       "                   data_file  sep_dx1  tst_seed  n_fold  auc_mean  auc_cil  \\\n",
       "26  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7275   \n",
       "35  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7278   \n",
       "24  cohorts/ami/ami_pred.csv        0         0       7    0.7287  (0.7275   \n",
       "34  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7271   \n",
       "27  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7278   \n",
       "\n",
       "     auc_cih                             y_pred_file  \n",
       "26   0.7298)  output/y_pred_mat18_08_30_11_48_48.npy  \n",
       "35   0.7295)  output/y_pred_mat18_08_30_06_42_42.npy  \n",
       "24   0.7300)  output/y_pred_mat18_08_30_11_59_33.npy  \n",
       "34   0.7301)  output/y_pred_mat18_08_30_08_38_31.npy  \n",
       "27   0.7294)  output/y_pred_mat18_08_30_12_04_01.npy  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res.auc_mean>0.7285, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "94a5b35f-d21d-4be0-bde0-70d0e6c88f76"
    }
   },
   "source": [
    "### Embedding + NN  with subset of codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "f2692662-e808-499a-8a94-7a0508bfbefe"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "75618457-5989-405f-a376-f5e0cadabdbb"
    }
   },
   "outputs": [],
   "source": [
    "for job_ind in range(4):\n",
    "    df = pd.read_csv('output/ht_result1001_'+str(job_ind)+'.csv', \n",
    "                     names=['model_name', 'code_embed_dim', 'hosp_embed_dim', 'fc_width', 'md_width', 'lr1', 'lr2', 'dropout',\n",
    "                            'batchsize', 'embed_file', 'cohort', 'tst_seed', 'n_fold', 'penalty', 'penalty_metric', 'count_cap', \n",
    "                            'DX_rarecutpoint', 'PR_rarecutpoint', 'auc_mean', 'auc_avg', 'auc_freeze', 'y_pred_file'], index_col=None)\n",
    "    res = pd.concat([res, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "063a15f2-5d08-4d75-a858-6d4fa67ac199"
    }
   },
   "outputs": [],
   "source": [
    "res = res.loc[res.model_name=='embed_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "af5f557c-975e-4a1f-86e6-d709d896372e"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>hosp_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>embed_file</th>\n",
       "      <th>...</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>penalty</th>\n",
       "      <th>penalty_metric</th>\n",
       "      <th>count_cap</th>\n",
       "      <th>DX_rarecutpoint</th>\n",
       "      <th>PR_rarecutpoint</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_avg</th>\n",
       "      <th>auc_freeze</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71854</td>\n",
       "      <td>0.72020</td>\n",
       "      <td>0.71711</td>\n",
       "      <td>output/y_pred_mat18_10_03_04_03_11.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71977</td>\n",
       "      <td>0.72173</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>output/y_pred_mat18_10_03_04_32_18.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72522</td>\n",
       "      <td>0.72696</td>\n",
       "      <td>0.72325</td>\n",
       "      <td>output/y_pred_mat18_10_03_05_02_18.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71286</td>\n",
       "      <td>0.71549</td>\n",
       "      <td>0.71256</td>\n",
       "      <td>output/y_pred_mat18_10_03_05_34_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70873</td>\n",
       "      <td>0.71141</td>\n",
       "      <td>0.70968</td>\n",
       "      <td>output/y_pred_mat18_10_03_06_07_20.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71711</td>\n",
       "      <td>0.71959</td>\n",
       "      <td>0.71640</td>\n",
       "      <td>output/y_pred_mat18_10_03_06_30_57.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71793</td>\n",
       "      <td>0.72071</td>\n",
       "      <td>0.71688</td>\n",
       "      <td>output/y_pred_mat18_10_03_06_56_58.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72293</td>\n",
       "      <td>0.72548</td>\n",
       "      <td>0.72196</td>\n",
       "      <td>output/y_pred_mat18_10_03_07_22_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71236</td>\n",
       "      <td>0.71453</td>\n",
       "      <td>0.71221</td>\n",
       "      <td>output/y_pred_mat18_10_03_07_46_51.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70821</td>\n",
       "      <td>0.71076</td>\n",
       "      <td>0.70844</td>\n",
       "      <td>output/y_pred_mat18_10_03_08_11_43.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71723</td>\n",
       "      <td>0.72062</td>\n",
       "      <td>0.71692</td>\n",
       "      <td>output/y_pred_mat18_10_03_08_35_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71853</td>\n",
       "      <td>0.72099</td>\n",
       "      <td>0.71741</td>\n",
       "      <td>output/y_pred_mat18_10_03_09_00_59.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72344</td>\n",
       "      <td>0.72629</td>\n",
       "      <td>0.72262</td>\n",
       "      <td>output/y_pred_mat18_10_03_09_23_57.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71379</td>\n",
       "      <td>0.71601</td>\n",
       "      <td>0.71339</td>\n",
       "      <td>output/y_pred_mat18_10_03_09_56_12.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71009</td>\n",
       "      <td>0.71229</td>\n",
       "      <td>0.70927</td>\n",
       "      <td>output/y_pred_mat18_10_03_10_29_24.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71819</td>\n",
       "      <td>0.71988</td>\n",
       "      <td>0.71718</td>\n",
       "      <td>output/y_pred_mat18_10_03_11_00_11.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72016</td>\n",
       "      <td>0.72193</td>\n",
       "      <td>0.71890</td>\n",
       "      <td>output/y_pred_mat18_10_03_11_30_07.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72496</td>\n",
       "      <td>0.72680</td>\n",
       "      <td>0.72423</td>\n",
       "      <td>output/y_pred_mat18_10_03_11_59_46.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71500</td>\n",
       "      <td>0.71696</td>\n",
       "      <td>0.71463</td>\n",
       "      <td>output/y_pred_mat18_10_04_12_23_00.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71217</td>\n",
       "      <td>0.71411</td>\n",
       "      <td>0.71183</td>\n",
       "      <td>output/y_pred_mat18_10_04_12_45_58.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71751</td>\n",
       "      <td>0.71936</td>\n",
       "      <td>0.71660</td>\n",
       "      <td>output/y_pred_mat18_10_04_01_14_27.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71969</td>\n",
       "      <td>0.72185</td>\n",
       "      <td>0.71861</td>\n",
       "      <td>output/y_pred_mat18_10_04_01_44_52.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72424</td>\n",
       "      <td>0.72625</td>\n",
       "      <td>0.72315</td>\n",
       "      <td>output/y_pred_mat18_10_04_02_14_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71420</td>\n",
       "      <td>0.71593</td>\n",
       "      <td>0.71327</td>\n",
       "      <td>output/y_pred_mat18_10_04_02_45_39.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71199</td>\n",
       "      <td>0.71367</td>\n",
       "      <td>0.71137</td>\n",
       "      <td>output/y_pred_mat18_10_04_03_18_59.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71698</td>\n",
       "      <td>0.71959</td>\n",
       "      <td>0.71534</td>\n",
       "      <td>output/y_pred_mat18_10_04_03_49_57.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71927</td>\n",
       "      <td>0.72210</td>\n",
       "      <td>0.71814</td>\n",
       "      <td>output/y_pred_mat18_10_04_04_23_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72331</td>\n",
       "      <td>0.72622</td>\n",
       "      <td>0.72231</td>\n",
       "      <td>output/y_pred_mat18_10_04_04_53_22.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71461</td>\n",
       "      <td>0.71644</td>\n",
       "      <td>0.71409</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_16_38.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71123</td>\n",
       "      <td>0.71338</td>\n",
       "      <td>0.71102</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_41_02.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72314</td>\n",
       "      <td>0.72572</td>\n",
       "      <td>0.72237</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_08_46.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71225</td>\n",
       "      <td>0.71484</td>\n",
       "      <td>0.71148</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_41_13.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72401</td>\n",
       "      <td>0.72693</td>\n",
       "      <td>0.72306</td>\n",
       "      <td>output/y_pred_mat18_10_04_06_11_25.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71677</td>\n",
       "      <td>0.71873</td>\n",
       "      <td>0.71533</td>\n",
       "      <td>output/y_pred_mat18_10_04_06_40_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71557</td>\n",
       "      <td>0.71755</td>\n",
       "      <td>0.71351</td>\n",
       "      <td>output/y_pred_mat18_10_04_07_10_32.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72539</td>\n",
       "      <td>0.72684</td>\n",
       "      <td>0.72447</td>\n",
       "      <td>output/y_pred_mat18_10_04_07_35_02.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71467</td>\n",
       "      <td>0.71645</td>\n",
       "      <td>0.71426</td>\n",
       "      <td>output/y_pred_mat18_10_04_07_59_16.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72565</td>\n",
       "      <td>0.72755</td>\n",
       "      <td>0.72517</td>\n",
       "      <td>output/y_pred_mat18_10_04_08_22_34.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71522</td>\n",
       "      <td>0.71784</td>\n",
       "      <td>0.71458</td>\n",
       "      <td>output/y_pred_mat18_10_04_08_55_09.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71384</td>\n",
       "      <td>0.71651</td>\n",
       "      <td>0.71312</td>\n",
       "      <td>output/y_pred_mat18_10_04_09_25_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72579</td>\n",
       "      <td>0.72774</td>\n",
       "      <td>0.72474</td>\n",
       "      <td>output/y_pred_mat18_10_04_09_55_17.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71455</td>\n",
       "      <td>0.71633</td>\n",
       "      <td>0.71415</td>\n",
       "      <td>output/y_pred_mat18_10_04_10_27_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72636</td>\n",
       "      <td>0.72838</td>\n",
       "      <td>0.72565</td>\n",
       "      <td>output/y_pred_mat18_10_04_11_00_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71626</td>\n",
       "      <td>0.71819</td>\n",
       "      <td>0.71575</td>\n",
       "      <td>output/y_pred_mat18_10_04_11_30_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71488</td>\n",
       "      <td>0.71726</td>\n",
       "      <td>0.71456</td>\n",
       "      <td>output/y_pred_mat18_10_05_12_04_34.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72396</td>\n",
       "      <td>0.72630</td>\n",
       "      <td>0.72379</td>\n",
       "      <td>output/y_pred_mat18_10_05_12_28_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71332</td>\n",
       "      <td>0.71520</td>\n",
       "      <td>0.71174</td>\n",
       "      <td>output/y_pred_mat18_10_05_12_53_17.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72563</td>\n",
       "      <td>0.72804</td>\n",
       "      <td>0.72553</td>\n",
       "      <td>output/y_pred_mat18_10_05_01_17_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71562</td>\n",
       "      <td>0.71742</td>\n",
       "      <td>0.71492</td>\n",
       "      <td>output/y_pred_mat18_10_05_01_41_18.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71433</td>\n",
       "      <td>0.71656</td>\n",
       "      <td>0.71357</td>\n",
       "      <td>output/y_pred_mat18_10_05_02_07_30.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72298</td>\n",
       "      <td>0.72598</td>\n",
       "      <td>0.72267</td>\n",
       "      <td>output/y_pred_mat18_10_05_02_29_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71134</td>\n",
       "      <td>0.71424</td>\n",
       "      <td>0.71027</td>\n",
       "      <td>output/y_pred_mat18_10_05_02_52_45.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72385</td>\n",
       "      <td>0.72683</td>\n",
       "      <td>0.72324</td>\n",
       "      <td>output/y_pred_mat18_10_05_03_17_09.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71721</td>\n",
       "      <td>0.71913</td>\n",
       "      <td>0.71654</td>\n",
       "      <td>output/y_pred_mat18_10_05_03_41_06.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71574</td>\n",
       "      <td>0.71779</td>\n",
       "      <td>0.71498</td>\n",
       "      <td>output/y_pred_mat18_10_05_04_03_51.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72365</td>\n",
       "      <td>0.72589</td>\n",
       "      <td>0.72420</td>\n",
       "      <td>output/y_pred_mat18_10_05_04_25_55.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71374</td>\n",
       "      <td>0.71567</td>\n",
       "      <td>0.71349</td>\n",
       "      <td>output/y_pred_mat18_10_05_04_50_06.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72543</td>\n",
       "      <td>0.72766</td>\n",
       "      <td>0.72451</td>\n",
       "      <td>output/y_pred_mat18_10_05_05_13_41.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71746</td>\n",
       "      <td>0.71926</td>\n",
       "      <td>0.71700</td>\n",
       "      <td>output/y_pred_mat18_10_05_05_38_41.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71563</td>\n",
       "      <td>0.71758</td>\n",
       "      <td>0.71543</td>\n",
       "      <td>output/y_pred_mat18_10_05_06_02_06.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  code_embed_dim  hosp_embed_dim  fc_width  md_width     lr1  \\\n",
       "0    setsum_nn             200               1      1024       256  0.0002   \n",
       "1    setsum_nn             200               1      1024       256  0.0002   \n",
       "2    setsum_nn             200               1      1024       256  0.0002   \n",
       "3    setsum_nn             200               1       512       256  0.0002   \n",
       "4    setsum_nn             200               1       512       256  0.0002   \n",
       "5    setsum_nn             300               1      1024       256  0.0002   \n",
       "6    setsum_nn             300               1      1024       256  0.0002   \n",
       "7    setsum_nn             300               1      1024       256  0.0002   \n",
       "8    setsum_nn             300               1      1024       256  0.0002   \n",
       "9    setsum_nn             300               1      1024       256  0.0002   \n",
       "10   setsum_nn             200               1      1024       128  0.0002   \n",
       "11   setsum_nn             200               1      1024       128  0.0002   \n",
       "12   setsum_nn             200               1      1024       128  0.0002   \n",
       "13   setsum_nn             200               1      1024       256  0.0002   \n",
       "14   setsum_nn             200               1      1024       256  0.0002   \n",
       "15   setsum_nn             200               1       512       256  0.0002   \n",
       "16   setsum_nn             200               1       512       256  0.0002   \n",
       "17   setsum_nn             200               1       512       256  0.0002   \n",
       "18   setsum_nn             300               1       512       128  0.0002   \n",
       "19   setsum_nn             300               1       512       128  0.0002   \n",
       "20   setsum_nn             200               1      1024       256  0.0002   \n",
       "21   setsum_nn             200               1      1024       256  0.0002   \n",
       "22   setsum_nn             200               1      1024       256  0.0002   \n",
       "23   setsum_nn             300               1      1024       256  0.0002   \n",
       "24   setsum_nn             300               1      1024       256  0.0002   \n",
       "25   setsum_nn             200               1       512       128  0.0002   \n",
       "26   setsum_nn             200               1       512       128  0.0002   \n",
       "27   setsum_nn             200               1       512       128  0.0002   \n",
       "28   setsum_nn             300               1       512       128  0.0002   \n",
       "29   setsum_nn             300               1       512       128  0.0002   \n",
       "..         ...             ...             ...       ...       ...     ...   \n",
       "300  setsum_nn             200               1       512       128  0.0002   \n",
       "301  setsum_nn             200               1       512       128  0.0002   \n",
       "302  setsum_nn             200               1       512       128  0.0002   \n",
       "303  setsum_nn             200               1       512       128  0.0002   \n",
       "304  setsum_nn             200               1       512       128  0.0002   \n",
       "305  setsum_nn             300               1      1024       128  0.0002   \n",
       "306  setsum_nn             300               1      1024       128  0.0002   \n",
       "307  setsum_nn             300               1      1024       128  0.0002   \n",
       "308  setsum_nn             200               1      1024       128  0.0002   \n",
       "309  setsum_nn             200               1      1024       128  0.0002   \n",
       "310  setsum_nn             200               1       512       128  0.0002   \n",
       "311  setsum_nn             200               1       512       128  0.0002   \n",
       "312  setsum_nn             200               1       512       128  0.0002   \n",
       "313  setsum_nn             300               1       512       128  0.0002   \n",
       "314  setsum_nn             300               1       512       128  0.0002   \n",
       "315  setsum_nn             200               1      1024       256  0.0002   \n",
       "316  setsum_nn             200               1      1024       256  0.0002   \n",
       "317  setsum_nn             200               1      1024       256  0.0002   \n",
       "318  setsum_nn             300               1      1024       256  0.0002   \n",
       "319  setsum_nn             300               1      1024       256  0.0002   \n",
       "320  setsum_nn             200               1       512       128  0.0002   \n",
       "321  setsum_nn             200               1       512       128  0.0002   \n",
       "322  setsum_nn             200               1       512       128  0.0002   \n",
       "323  setsum_nn             300               1      1024       128  0.0002   \n",
       "324  setsum_nn             300               1      1024       128  0.0002   \n",
       "325  setsum_nn             200               1       512       256  0.0002   \n",
       "326  setsum_nn             200               1       512       256  0.0002   \n",
       "327  setsum_nn             200               1       512       256  0.0002   \n",
       "328  setsum_nn             300               1      1024       128  0.0002   \n",
       "329  setsum_nn             300               1      1024       128  0.0002   \n",
       "\n",
       "         lr2  dropout  batchsize embed_file  \\\n",
       "0    0.00002      0.3        256   pretrain   \n",
       "1    0.00002      0.3        256   pretrain   \n",
       "2    0.00002      0.3        256   pretrain   \n",
       "3    0.00002      0.3        256   pretrain   \n",
       "4    0.00002      0.3        256   pretrain   \n",
       "5    0.00002      0.3        512   pretrain   \n",
       "6    0.00002      0.3        512   pretrain   \n",
       "7    0.00002      0.3        512   pretrain   \n",
       "8    0.00002      0.3        512   pretrain   \n",
       "9    0.00002      0.3        512   pretrain   \n",
       "10   0.00002      0.3        512   pretrain   \n",
       "11   0.00002      0.3        512   pretrain   \n",
       "12   0.00002      0.3        512   pretrain   \n",
       "13   0.00002      0.3        256   pretrain   \n",
       "14   0.00002      0.3        256   pretrain   \n",
       "15   0.00002      0.3        256   pretrain   \n",
       "16   0.00002      0.3        256   pretrain   \n",
       "17   0.00002      0.3        256   pretrain   \n",
       "18   0.00002      0.3        512   pretrain   \n",
       "19   0.00002      0.3        512   pretrain   \n",
       "20   0.00002      0.3        256   pretrain   \n",
       "21   0.00002      0.3        256   pretrain   \n",
       "22   0.00002      0.3        256   pretrain   \n",
       "23   0.00002      0.3        256   pretrain   \n",
       "24   0.00002      0.3        256   pretrain   \n",
       "25   0.00002      0.3        256   pretrain   \n",
       "26   0.00002      0.3        256   pretrain   \n",
       "27   0.00002      0.3        256   pretrain   \n",
       "28   0.00002      0.3        512   pretrain   \n",
       "29   0.00002      0.3        512   pretrain   \n",
       "..       ...      ...        ...        ...   \n",
       "300  0.00002      0.3        256   pretrain   \n",
       "301  0.00002      0.3        256   pretrain   \n",
       "302  0.00002      0.3        256   pretrain   \n",
       "303  0.00002      0.3        256   pretrain   \n",
       "304  0.00002      0.3        256   pretrain   \n",
       "305  0.00002      0.3        512   pretrain   \n",
       "306  0.00002      0.3        512   pretrain   \n",
       "307  0.00002      0.3        512   pretrain   \n",
       "308  0.00002      0.3        256   pretrain   \n",
       "309  0.00002      0.3        256   pretrain   \n",
       "310  0.00002      0.3        256   pretrain   \n",
       "311  0.00002      0.3        256   pretrain   \n",
       "312  0.00002      0.3        256   pretrain   \n",
       "313  0.00002      0.3        256   pretrain   \n",
       "314  0.00002      0.3        256   pretrain   \n",
       "315  0.00002      0.3        512   pretrain   \n",
       "316  0.00002      0.3        512   pretrain   \n",
       "317  0.00002      0.3        512   pretrain   \n",
       "318  0.00002      0.3        512   pretrain   \n",
       "319  0.00002      0.3        512   pretrain   \n",
       "320  0.00002      0.3        512   pretrain   \n",
       "321  0.00002      0.3        512   pretrain   \n",
       "322  0.00002      0.3        512   pretrain   \n",
       "323  0.00002      0.3        512   pretrain   \n",
       "324  0.00002      0.3        512   pretrain   \n",
       "325  0.00002      0.3        512   pretrain   \n",
       "326  0.00002      0.3        512   pretrain   \n",
       "327  0.00002      0.3        512   pretrain   \n",
       "328  0.00002      0.3        512   pretrain   \n",
       "329  0.00002      0.3        512   pretrain   \n",
       "\n",
       "                      ...                   n_fold  penalty  penalty_metric  \\\n",
       "0                     ...                        5      1.0          cosine   \n",
       "1                     ...                        5      1.0          cosine   \n",
       "2                     ...                        5      1.0          cosine   \n",
       "3                     ...                        5      0.0          cosine   \n",
       "4                     ...                        5      0.0          cosine   \n",
       "5                     ...                        5      0.0          cosine   \n",
       "6                     ...                        5      0.0          cosine   \n",
       "7                     ...                        5      0.0          cosine   \n",
       "8                     ...                        5      0.0          cosine   \n",
       "9                     ...                        5      0.0          cosine   \n",
       "10                    ...                        5      0.0          cosine   \n",
       "11                    ...                        5      0.0          cosine   \n",
       "12                    ...                        5      0.0          cosine   \n",
       "13                    ...                        5      0.5          cosine   \n",
       "14                    ...                        5      0.5          cosine   \n",
       "15                    ...                        5      0.5          cosine   \n",
       "16                    ...                        5      0.5          cosine   \n",
       "17                    ...                        5      0.5          cosine   \n",
       "18                    ...                        5      1.0          cosine   \n",
       "19                    ...                        5      1.0          cosine   \n",
       "20                    ...                        5      0.5          cosine   \n",
       "21                    ...                        5      0.5          cosine   \n",
       "22                    ...                        5      0.5          cosine   \n",
       "23                    ...                        5      1.0          cosine   \n",
       "24                    ...                        5      1.0          cosine   \n",
       "25                    ...                        5      0.0          cosine   \n",
       "26                    ...                        5      0.0          cosine   \n",
       "27                    ...                        5      0.0          cosine   \n",
       "28                    ...                        5      0.5          cosine   \n",
       "29                    ...                        5      0.5          cosine   \n",
       "..                    ...                      ...      ...             ...   \n",
       "300                   ...                        5      0.0          cosine   \n",
       "301                   ...                        5      0.0          cosine   \n",
       "302                   ...                        5      0.0          cosine   \n",
       "303                   ...                        5      1.0          cosine   \n",
       "304                   ...                        5      1.0          cosine   \n",
       "305                   ...                        5      0.5          cosine   \n",
       "306                   ...                        5      0.5          cosine   \n",
       "307                   ...                        5      0.5          cosine   \n",
       "308                   ...                        5      0.0          cosine   \n",
       "309                   ...                        5      0.0          cosine   \n",
       "310                   ...                        5      1.0          cosine   \n",
       "311                   ...                        5      1.0          cosine   \n",
       "312                   ...                        5      1.0          cosine   \n",
       "313                   ...                        5      0.5          cosine   \n",
       "314                   ...                        5      0.5          cosine   \n",
       "315                   ...                        5      0.5          cosine   \n",
       "316                   ...                        5      0.5          cosine   \n",
       "317                   ...                        5      0.5          cosine   \n",
       "318                   ...                        5      0.5          cosine   \n",
       "319                   ...                        5      0.5          cosine   \n",
       "320                   ...                        5      0.0          cosine   \n",
       "321                   ...                        5      0.0          cosine   \n",
       "322                   ...                        5      0.0          cosine   \n",
       "323                   ...                        5      1.0          cosine   \n",
       "324                   ...                        5      1.0          cosine   \n",
       "325                   ...                        5      1.0          cosine   \n",
       "326                   ...                        5      1.0          cosine   \n",
       "327                   ...                        5      1.0          cosine   \n",
       "328                   ...                        5      0.5          cosine   \n",
       "329                   ...                        5      0.5          cosine   \n",
       "\n",
       "     count_cap DX_rarecutpoint  PR_rarecutpoint  auc_mean  auc_avg  \\\n",
       "0            5              20               10   0.71854  0.72020   \n",
       "1            5              20               10   0.71977  0.72173   \n",
       "2            5              20               10   0.72522  0.72696   \n",
       "3            5              20               10   0.71286  0.71549   \n",
       "4            5              20               10   0.70873  0.71141   \n",
       "5            0              20               10   0.71711  0.71959   \n",
       "6            0              20               10   0.71793  0.72071   \n",
       "7            0              20               10   0.72293  0.72548   \n",
       "8            0              20               10   0.71236  0.71453   \n",
       "9            0              20               10   0.70821  0.71076   \n",
       "10           5              20               10   0.71723  0.72062   \n",
       "11           5              20               10   0.71853  0.72099   \n",
       "12           5              20               10   0.72344  0.72629   \n",
       "13           0              20               10   0.71379  0.71601   \n",
       "14           0              20               10   0.71009  0.71229   \n",
       "15          20              20               10   0.71819  0.71988   \n",
       "16          20              20               10   0.72016  0.72193   \n",
       "17          20              20               10   0.72496  0.72680   \n",
       "18           5              20               10   0.71500  0.71696   \n",
       "19           5              20               10   0.71217  0.71411   \n",
       "20           5              20               10   0.71751  0.71936   \n",
       "21           5              20               10   0.71969  0.72185   \n",
       "22           5              20               10   0.72424  0.72625   \n",
       "23           5              20               10   0.71420  0.71593   \n",
       "24           5              20               10   0.71199  0.71367   \n",
       "25          20              20               10   0.71698  0.71959   \n",
       "26          20              20               10   0.71927  0.72210   \n",
       "27          20              20               10   0.72331  0.72622   \n",
       "28          20              20               10   0.71461  0.71644   \n",
       "29          20              20               10   0.71123  0.71338   \n",
       "..         ...             ...              ...       ...      ...   \n",
       "300         20              20               10   0.72314  0.72572   \n",
       "301         20              20               10   0.71225  0.71484   \n",
       "302         20              20               10   0.72401  0.72693   \n",
       "303         20              20               10   0.71677  0.71873   \n",
       "304         20              20               10   0.71557  0.71755   \n",
       "305         20              20               10   0.72539  0.72684   \n",
       "306         20              20               10   0.71467  0.71645   \n",
       "307         20              20               10   0.72565  0.72755   \n",
       "308          5              20               10   0.71522  0.71784   \n",
       "309          5              20               10   0.71384  0.71651   \n",
       "310          5              20               10   0.72579  0.72774   \n",
       "311          5              20               10   0.71455  0.71633   \n",
       "312          5              20               10   0.72636  0.72838   \n",
       "313          5              20               10   0.71626  0.71819   \n",
       "314          5              20               10   0.71488  0.71726   \n",
       "315          0              20               10   0.72396  0.72630   \n",
       "316          0              20               10   0.71332  0.71520   \n",
       "317          0              20               10   0.72563  0.72804   \n",
       "318          5              20               10   0.71562  0.71742   \n",
       "319          5              20               10   0.71433  0.71656   \n",
       "320          0              20               10   0.72298  0.72598   \n",
       "321          0              20               10   0.71134  0.71424   \n",
       "322          0              20               10   0.72385  0.72683   \n",
       "323         20              20               10   0.71721  0.71913   \n",
       "324         20              20               10   0.71574  0.71779   \n",
       "325          0              20               10   0.72365  0.72589   \n",
       "326          0              20               10   0.71374  0.71567   \n",
       "327          0              20               10   0.72543  0.72766   \n",
       "328         20              20               10   0.71746  0.71926   \n",
       "329         20              20               10   0.71563  0.71758   \n",
       "\n",
       "     auc_freeze                             y_pred_file  \n",
       "0       0.71711  output/y_pred_mat18_10_03_04_03_11.npy  \n",
       "1       0.71875  output/y_pred_mat18_10_03_04_32_18.npy  \n",
       "2       0.72325  output/y_pred_mat18_10_03_05_02_18.npy  \n",
       "3       0.71256  output/y_pred_mat18_10_03_05_34_03.npy  \n",
       "4       0.70968  output/y_pred_mat18_10_03_06_07_20.npy  \n",
       "5       0.71640  output/y_pred_mat18_10_03_06_30_57.npy  \n",
       "6       0.71688  output/y_pred_mat18_10_03_06_56_58.npy  \n",
       "7       0.72196  output/y_pred_mat18_10_03_07_22_56.npy  \n",
       "8       0.71221  output/y_pred_mat18_10_03_07_46_51.npy  \n",
       "9       0.70844  output/y_pred_mat18_10_03_08_11_43.npy  \n",
       "10      0.71692  output/y_pred_mat18_10_03_08_35_03.npy  \n",
       "11      0.71741  output/y_pred_mat18_10_03_09_00_59.npy  \n",
       "12      0.72262  output/y_pred_mat18_10_03_09_23_57.npy  \n",
       "13      0.71339  output/y_pred_mat18_10_03_09_56_12.npy  \n",
       "14      0.70927  output/y_pred_mat18_10_03_10_29_24.npy  \n",
       "15      0.71718  output/y_pred_mat18_10_03_11_00_11.npy  \n",
       "16      0.71890  output/y_pred_mat18_10_03_11_30_07.npy  \n",
       "17      0.72423  output/y_pred_mat18_10_03_11_59_46.npy  \n",
       "18      0.71463  output/y_pred_mat18_10_04_12_23_00.npy  \n",
       "19      0.71183  output/y_pred_mat18_10_04_12_45_58.npy  \n",
       "20      0.71660  output/y_pred_mat18_10_04_01_14_27.npy  \n",
       "21      0.71861  output/y_pred_mat18_10_04_01_44_52.npy  \n",
       "22      0.72315  output/y_pred_mat18_10_04_02_14_31.npy  \n",
       "23      0.71327  output/y_pred_mat18_10_04_02_45_39.npy  \n",
       "24      0.71137  output/y_pred_mat18_10_04_03_18_59.npy  \n",
       "25      0.71534  output/y_pred_mat18_10_04_03_49_57.npy  \n",
       "26      0.71814  output/y_pred_mat18_10_04_04_23_49.npy  \n",
       "27      0.72231  output/y_pred_mat18_10_04_04_53_22.npy  \n",
       "28      0.71409  output/y_pred_mat18_10_04_05_16_38.npy  \n",
       "29      0.71102  output/y_pred_mat18_10_04_05_41_02.npy  \n",
       "..          ...                                     ...  \n",
       "300     0.72237  output/y_pred_mat18_10_04_05_08_46.npy  \n",
       "301     0.71148  output/y_pred_mat18_10_04_05_41_13.npy  \n",
       "302     0.72306  output/y_pred_mat18_10_04_06_11_25.npy  \n",
       "303     0.71533  output/y_pred_mat18_10_04_06_40_56.npy  \n",
       "304     0.71351  output/y_pred_mat18_10_04_07_10_32.npy  \n",
       "305     0.72447  output/y_pred_mat18_10_04_07_35_02.npy  \n",
       "306     0.71426  output/y_pred_mat18_10_04_07_59_16.npy  \n",
       "307     0.72517  output/y_pred_mat18_10_04_08_22_34.npy  \n",
       "308     0.71458  output/y_pred_mat18_10_04_08_55_09.npy  \n",
       "309     0.71312  output/y_pred_mat18_10_04_09_25_49.npy  \n",
       "310     0.72474  output/y_pred_mat18_10_04_09_55_17.npy  \n",
       "311     0.71415  output/y_pred_mat18_10_04_10_27_56.npy  \n",
       "312     0.72565  output/y_pred_mat18_10_04_11_00_15.npy  \n",
       "313     0.71575  output/y_pred_mat18_10_04_11_30_56.npy  \n",
       "314     0.71456  output/y_pred_mat18_10_05_12_04_34.npy  \n",
       "315     0.72379  output/y_pred_mat18_10_05_12_28_15.npy  \n",
       "316     0.71174  output/y_pred_mat18_10_05_12_53_17.npy  \n",
       "317     0.72553  output/y_pred_mat18_10_05_01_17_47.npy  \n",
       "318     0.71492  output/y_pred_mat18_10_05_01_41_18.npy  \n",
       "319     0.71357  output/y_pred_mat18_10_05_02_07_30.npy  \n",
       "320     0.72267  output/y_pred_mat18_10_05_02_29_47.npy  \n",
       "321     0.71027  output/y_pred_mat18_10_05_02_52_45.npy  \n",
       "322     0.72324  output/y_pred_mat18_10_05_03_17_09.npy  \n",
       "323     0.71654  output/y_pred_mat18_10_05_03_41_06.npy  \n",
       "324     0.71498  output/y_pred_mat18_10_05_04_03_51.npy  \n",
       "325     0.72420  output/y_pred_mat18_10_05_04_25_55.npy  \n",
       "326     0.71349  output/y_pred_mat18_10_05_04_50_06.npy  \n",
       "327     0.72451  output/y_pred_mat18_10_05_05_13_41.npy  \n",
       "328     0.71700  output/y_pred_mat18_10_05_05_38_41.npy  \n",
       "329     0.71543  output/y_pred_mat18_10_05_06_02_06.npy  \n",
       "\n",
       "[330 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "7f3ce5a4-228e-41d8-a865-c4cb964336b0"
    }
   },
   "outputs": [],
   "source": [
    "res_grouped = res.groupby(['code_embed_dim', 'fc_width', 'md_width', 'penalty', 'batchsize', 'count_cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "27ed11fc-2de4-411f-93c9-203f271914db"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_freeze</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>penalty</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>count_cap</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">200</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">512</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">128</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>256</th>\n",
       "      <th>20</th>\n",
       "      <td>0.716274</td>\n",
       "      <td>20</td>\n",
       "      <td>0.717040</td>\n",
       "      <td>20</td>\n",
       "      <td>0.719784</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <th>0</th>\n",
       "      <td>0.716043</td>\n",
       "      <td>20</td>\n",
       "      <td>0.716647</td>\n",
       "      <td>20</td>\n",
       "      <td>0.719599</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <th>0.0</th>\n",
       "      <th>256</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716623</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717226</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719562</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1024</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">128</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">256</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716075</td>\n",
       "      <td>20</td>\n",
       "      <td>0.716861</td>\n",
       "      <td>20</td>\n",
       "      <td>0.719762</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.716289</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717320</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719926</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716510</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717119</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720019</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <th>1024</th>\n",
       "      <th>256</th>\n",
       "      <th>0.0</th>\n",
       "      <th>512</th>\n",
       "      <th>0</th>\n",
       "      <td>0.715975</td>\n",
       "      <td>20</td>\n",
       "      <td>0.716324</td>\n",
       "      <td>20</td>\n",
       "      <td>0.718935</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             auc_freeze        \\\n",
       "                                                                   mean count   \n",
       "code_embed_dim fc_width md_width penalty batchsize count_cap                    \n",
       "200            512      128      0.0     256       20          0.716274    20   \n",
       "                                         512       0           0.716043    20   \n",
       "                        256      0.0     256       5           0.716623    10   \n",
       "               1024     128      0.0     256       5           0.716075    20   \n",
       "                                                   20          0.716289    10   \n",
       "                                         512       5           0.716510    10   \n",
       "300            1024     256      0.0     512       0           0.715975    20   \n",
       "\n",
       "                                                              auc_mean        \\\n",
       "                                                                  mean count   \n",
       "code_embed_dim fc_width md_width penalty batchsize count_cap                   \n",
       "200            512      128      0.0     256       20         0.717040    20   \n",
       "                                         512       0          0.716647    20   \n",
       "                        256      0.0     256       5          0.717226    10   \n",
       "               1024     128      0.0     256       5          0.716861    20   \n",
       "                                                   20         0.717320    10   \n",
       "                                         512       5          0.717119    10   \n",
       "300            1024     256      0.0     512       0          0.716324    20   \n",
       "\n",
       "                                                               auc_avg        \n",
       "                                                                  mean count  \n",
       "code_embed_dim fc_width md_width penalty batchsize count_cap                  \n",
       "200            512      128      0.0     256       20         0.719784    20  \n",
       "                                         512       0          0.719599    20  \n",
       "                        256      0.0     256       5          0.719562    10  \n",
       "               1024     128      0.0     256       5          0.719762    20  \n",
       "                                                   20         0.719926    10  \n",
       "                                         512       5          0.720019    10  \n",
       "300            1024     256      0.0     512       0          0.718935    20  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_grouped[['auc_freeze', 'auc_mean', 'auc_avg']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "b08bd040-db92-4229-bd5a-a1a28285b094"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv('output/ht_result1003embed_nn_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "b51b0f14-8e83-4420-bfc3-6b13f953ab81"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv('output/ht_result1003embed_nn_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "7397fa11-948b-4ca6-b6f6-8f73c300e378"
    }
   },
   "outputs": [],
   "source": [
    "res = res.loc[res.penalty==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "be0d5cb0-d251-4963-b423-dbeb003521ad"
    }
   },
   "source": [
    "### OHE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nbpresent": {
     "id": "95c6c85b-6ffd-4797-a4e0-b57139d947ca"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbpresent": {
     "id": "b816b5fb-2afc-4b05-981f-af0ac84613ad"
    }
   },
   "outputs": [],
   "source": [
    "for job_ind in range(1):\n",
    "    df = pd.read_csv('output/ht_result0925_'+str(job_ind)+'.csv', \n",
    "                     names=['fc_width1', 'fc_width2', 'lr', 'dropout', 'batchsize', 'cohort', 'tst_seed', 'n_fold', \n",
    "                            'DX_rarecutpoint', 'PR_rarecutpoint', 'auc_mean', 'auc_avg', 'y_pred_file'], index_col=None)\n",
    "    res = pd.concat([res, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "858f4bb9-ecb1-4727-8660-180cdab2f822"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fc_width1</th>\n",
       "      <th>fc_width2</th>\n",
       "      <th>lr</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>cohort</th>\n",
       "      <th>tst_seed</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>DX_rarecutpoint</th>\n",
       "      <th>PR_rarecutpoint</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_avg</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71339</td>\n",
       "      <td>0.71610</td>\n",
       "      <td>output/y_pred_mat18_09_26_12_37_55.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.61783</td>\n",
       "      <td>0.62129</td>\n",
       "      <td>output/y_pred_mat18_09_26_12_50_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66755</td>\n",
       "      <td>0.67043</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_14_10.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71938</td>\n",
       "      <td>0.72227</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_20_51.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62258</td>\n",
       "      <td>0.62686</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_34_06.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67248</td>\n",
       "      <td>0.67472</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_56_41.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70725</td>\n",
       "      <td>0.71013</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_03_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62727</td>\n",
       "      <td>0.63157</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_16_32.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66761</td>\n",
       "      <td>0.67088</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_39_27.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71382</td>\n",
       "      <td>0.71638</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_46_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62566</td>\n",
       "      <td>0.62988</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_59_21.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67220</td>\n",
       "      <td>0.67531</td>\n",
       "      <td>output/y_pred_mat18_09_26_03_22_40.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71510</td>\n",
       "      <td>0.71780</td>\n",
       "      <td>output/y_pred_mat18_09_26_03_28_53.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.62996</td>\n",
       "      <td>output/y_pred_mat18_09_26_03_42_05.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66816</td>\n",
       "      <td>0.67011</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_06_08.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70978</td>\n",
       "      <td>0.71214</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_12_34.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62471</td>\n",
       "      <td>0.62859</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_25_45.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65954</td>\n",
       "      <td>0.66240</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_49_25.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70653</td>\n",
       "      <td>0.70901</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_55_33.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62151</td>\n",
       "      <td>0.62525</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_08_13.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66753</td>\n",
       "      <td>0.66960</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_32_26.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71184</td>\n",
       "      <td>0.71453</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_38_54.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63224</td>\n",
       "      <td>0.63636</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_52_02.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66699</td>\n",
       "      <td>0.66899</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_14_59.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72035</td>\n",
       "      <td>0.72306</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_21_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62885</td>\n",
       "      <td>0.63326</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_34_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66799</td>\n",
       "      <td>0.67020</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_56_48.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72035</td>\n",
       "      <td>0.72289</td>\n",
       "      <td>output/y_pred_mat18_09_26_07_03_12.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62468</td>\n",
       "      <td>0.62774</td>\n",
       "      <td>output/y_pred_mat18_09_26_07_15_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66460</td>\n",
       "      <td>0.66769</td>\n",
       "      <td>output/y_pred_mat18_09_26_07_38_37.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fc_width1  fc_width2      lr  dropout  batchsize cohort  tst_seed  n_fold  \\\n",
       "0        1024        256  0.0001      0.3        512    ami         0       5   \n",
       "1        1024        256  0.0001      0.3        512    chf         0       5   \n",
       "2        1024        256  0.0001      0.3        512    pna         0       5   \n",
       "3        1024        256  0.0001      0.3        512    ami         1       5   \n",
       "4        1024        256  0.0001      0.3        512    chf         1       5   \n",
       "5        1024        256  0.0001      0.3        512    pna         1       5   \n",
       "6        1024        256  0.0001      0.3        512    ami         2       5   \n",
       "7        1024        256  0.0001      0.3        512    chf         2       5   \n",
       "8        1024        256  0.0001      0.3        512    pna         2       5   \n",
       "9        1024        256  0.0001      0.3        512    ami         3       5   \n",
       "10       1024        256  0.0001      0.3        512    chf         3       5   \n",
       "11       1024        256  0.0001      0.3        512    pna         3       5   \n",
       "12       1024        256  0.0001      0.3        512    ami         4       5   \n",
       "13       1024        256  0.0001      0.3        512    chf         4       5   \n",
       "14       1024        256  0.0001      0.3        512    pna         4       5   \n",
       "15       1024        256  0.0001      0.3        512    ami         5       5   \n",
       "16       1024        256  0.0001      0.3        512    chf         5       5   \n",
       "17       1024        256  0.0001      0.3        512    pna         5       5   \n",
       "18       1024        256  0.0001      0.3        512    ami         6       5   \n",
       "19       1024        256  0.0001      0.3        512    chf         6       5   \n",
       "20       1024        256  0.0001      0.3        512    pna         6       5   \n",
       "21       1024        256  0.0001      0.3        512    ami         7       5   \n",
       "22       1024        256  0.0001      0.3        512    chf         7       5   \n",
       "23       1024        256  0.0001      0.3        512    pna         7       5   \n",
       "24       1024        256  0.0001      0.3        512    ami         8       5   \n",
       "25       1024        256  0.0001      0.3        512    chf         8       5   \n",
       "26       1024        256  0.0001      0.3        512    pna         8       5   \n",
       "27       1024        256  0.0001      0.3        512    ami         9       5   \n",
       "28       1024        256  0.0001      0.3        512    chf         9       5   \n",
       "29       1024        256  0.0001      0.3        512    pna         9       5   \n",
       "\n",
       "    DX_rarecutpoint  PR_rarecutpoint  auc_mean  auc_avg  \\\n",
       "0                10               10   0.71339  0.71610   \n",
       "1                10               10   0.61783  0.62129   \n",
       "2                10               10   0.66755  0.67043   \n",
       "3                10               10   0.71938  0.72227   \n",
       "4                10               10   0.62258  0.62686   \n",
       "5                10               10   0.67248  0.67472   \n",
       "6                10               10   0.70725  0.71013   \n",
       "7                10               10   0.62727  0.63157   \n",
       "8                10               10   0.66761  0.67088   \n",
       "9                10               10   0.71382  0.71638   \n",
       "10               10               10   0.62566  0.62988   \n",
       "11               10               10   0.67220  0.67531   \n",
       "12               10               10   0.71510  0.71780   \n",
       "13               10               10   0.62636  0.62996   \n",
       "14               10               10   0.66816  0.67011   \n",
       "15               10               10   0.70978  0.71214   \n",
       "16               10               10   0.62471  0.62859   \n",
       "17               10               10   0.65954  0.66240   \n",
       "18               10               10   0.70653  0.70901   \n",
       "19               10               10   0.62151  0.62525   \n",
       "20               10               10   0.66753  0.66960   \n",
       "21               10               10   0.71184  0.71453   \n",
       "22               10               10   0.63224  0.63636   \n",
       "23               10               10   0.66699  0.66899   \n",
       "24               10               10   0.72035  0.72306   \n",
       "25               10               10   0.62885  0.63326   \n",
       "26               10               10   0.66799  0.67020   \n",
       "27               10               10   0.72035  0.72289   \n",
       "28               10               10   0.62468  0.62774   \n",
       "29               10               10   0.66460  0.66769   \n",
       "\n",
       "                               y_pred_file  \n",
       "0   output/y_pred_mat18_09_26_12_37_55.npy  \n",
       "1   output/y_pred_mat18_09_26_12_50_49.npy  \n",
       "2   output/y_pred_mat18_09_26_01_14_10.npy  \n",
       "3   output/y_pred_mat18_09_26_01_20_51.npy  \n",
       "4   output/y_pred_mat18_09_26_01_34_06.npy  \n",
       "5   output/y_pred_mat18_09_26_01_56_41.npy  \n",
       "6   output/y_pred_mat18_09_26_02_03_15.npy  \n",
       "7   output/y_pred_mat18_09_26_02_16_32.npy  \n",
       "8   output/y_pred_mat18_09_26_02_39_27.npy  \n",
       "9   output/y_pred_mat18_09_26_02_46_03.npy  \n",
       "10  output/y_pred_mat18_09_26_02_59_21.npy  \n",
       "11  output/y_pred_mat18_09_26_03_22_40.npy  \n",
       "12  output/y_pred_mat18_09_26_03_28_53.npy  \n",
       "13  output/y_pred_mat18_09_26_03_42_05.npy  \n",
       "14  output/y_pred_mat18_09_26_04_06_08.npy  \n",
       "15  output/y_pred_mat18_09_26_04_12_34.npy  \n",
       "16  output/y_pred_mat18_09_26_04_25_45.npy  \n",
       "17  output/y_pred_mat18_09_26_04_49_25.npy  \n",
       "18  output/y_pred_mat18_09_26_04_55_33.npy  \n",
       "19  output/y_pred_mat18_09_26_05_08_13.npy  \n",
       "20  output/y_pred_mat18_09_26_05_32_26.npy  \n",
       "21  output/y_pred_mat18_09_26_05_38_54.npy  \n",
       "22  output/y_pred_mat18_09_26_05_52_02.npy  \n",
       "23  output/y_pred_mat18_09_26_06_14_59.npy  \n",
       "24  output/y_pred_mat18_09_26_06_21_31.npy  \n",
       "25  output/y_pred_mat18_09_26_06_34_15.npy  \n",
       "26  output/y_pred_mat18_09_26_06_56_48.npy  \n",
       "27  output/y_pred_mat18_09_26_07_03_12.npy  \n",
       "28  output/y_pred_mat18_09_26_07_15_49.npy  \n",
       "29  output/y_pred_mat18_09_26_07_38_37.npy  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbpresent": {
     "id": "435a1a04-1b96-46ba-a0cb-753f04c93203"
    }
   },
   "outputs": [],
   "source": [
    "res_grouped = res.groupby(['cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbpresent": {
     "id": "a883ba8e-5109-4a73-a943-84f84c4cc62b"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ami</th>\n",
       "      <td>0.713779</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716431</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chf</th>\n",
       "      <td>0.625169</td>\n",
       "      <td>10</td>\n",
       "      <td>0.629076</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pna</th>\n",
       "      <td>0.667465</td>\n",
       "      <td>10</td>\n",
       "      <td>0.670033</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        auc_mean         auc_avg      \n",
       "            mean count      mean count\n",
       "cohort                                \n",
       "ami     0.713779    10  0.716431    10\n",
       "chf     0.625169    10  0.629076    10\n",
       "pna     0.667465    10  0.670033    10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_grouped[['auc_mean', 'auc_avg']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbpresent": {
     "id": "6d18bd53-c4fe-4d21-ac4b-b31994a61b70"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami mean: 0.7138 (0.0016) avg: 0.7164 (0.0016)\n",
      "chf mean: 0.6252 (0.0013) avg: 0.6291 (0.0013)\n",
      "pna mean: 0.6675 (0.0012) avg: 0.6700 (0.0011)\n"
     ]
    }
   ],
   "source": [
    "for n, g in res_grouped:\n",
    "    print(n, 'mean: {0:.4f} ({1:.4f})'.format(g.auc_mean.mean(), g.auc_mean.std()/np.sqrt(len(g))), \n",
    "         'avg: {0:.4f} ({1:.4f})'.format(g.auc_avg.mean(), g.auc_avg.std()/np.sqrt(len(g))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1c3716b8-56e1-4797-89c3-35a7ebbd39a0"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
